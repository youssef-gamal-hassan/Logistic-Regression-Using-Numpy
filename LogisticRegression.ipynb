{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Logistic Regression - Youssef Hassan<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_circles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Exploration and Preparation<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_circles(n_samples=20000, noise=0.1, factor=0.4, random_state=42)\n",
    "y = y.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the bias column\n",
    "\n",
    "X= np.hstack((np.ones((X.shape[0], 1)), X))\n",
    "\n",
    "# Squaring x1 and x2 \n",
    "x1_squared = (X[:, 1] ** 2).reshape(-1, 1)\n",
    "x2_squared = (X[:, 2] ** 2).reshape(-1, 1)\n",
    "\n",
    "# making their interaction column\n",
    "x1_times_x2 = (X[:, 1] * X[:, 2]).reshape(-1, 1)\n",
    "\n",
    "# adding the columns in the order x1_squared, x1_times_x2, x2_squared\n",
    "X = np.hstack((X, x1_squared))\n",
    "X = np.hstack((X, x1_times_x2))\n",
    "X = np.hstack((X, x2_squared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X: (20000, 6)\n",
      "Shape of y: (20000,)\n",
      "First 5 examples of X:\n",
      " [[ 1.          0.34963522  0.04731161  0.12224479  0.0165418   0.00223839]\n",
      " [ 1.          0.24359506  0.94263203  0.05933856  0.22962051  0.88855514]\n",
      " [ 1.          0.53789301 -0.63389047  0.28932889 -0.34096526  0.40181713]\n",
      " [ 1.          0.82178506  0.5393179   0.67533068  0.44320339  0.2908638 ]\n",
      " [ 1.         -0.486447    0.32636728  0.23663068 -0.15876038  0.1065156 ]]\n",
      "First 5 labels:\n",
      " [1 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X:\", X.shape)\n",
    "print(\"Shape of y:\", y.shape)\n",
    "\n",
    "print(\"First 5 examples of X:\\n\", X[:5])\n",
    "print(\"First 5 labels:\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Implementation<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_sigmoid_func(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_loss_function(y, y_pred):\n",
    "    return np.mean(-(y*np.log(y_pred)) - ((1-y)*np.log(1 - y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_gradient_descent_with_early_stopping(X_train, y_train, X_val, y_val, theta, learning_rate, epochs, patience):\n",
    "    '''\n",
    "\n",
    "    For the gradient descent function, I chose to make it with an early stopping function. Based on my previous experience with Machine Learning,\n",
    "    early stopping usually speeds up processing time and results in an acceptable theta without wasting processing time.\n",
    "    '''\n",
    "    \n",
    "    m = X_train.shape[0]\n",
    "\n",
    "    # Variables used for early_stopping\n",
    "    best_theta = theta\n",
    "    best_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    loss_history = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        Y_pred = my_sigmoid_func(np.dot(X_train, np.transpose(theta)))\n",
    "        \n",
    "        train_loss = my_loss_function(y_train, Y_pred)\n",
    "\n",
    "        theta = theta - learning_rate * np.dot(np.transpose(X_train), (Y_pred - y_train)) / m \n",
    "\n",
    "\n",
    "        #validation loss is calculated to check if the gradient descent should stop here\n",
    "        val_predictions = my_sigmoid_func(np.dot(X_val, theta))\n",
    "        \n",
    "        val_loss = my_loss_function(y_val, val_predictions)\n",
    "        \n",
    "        loss_history.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} - Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "\n",
    "        #I check if the val_loss is better than our best loss, if not the patience_counter is increased\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            best_theta = theta.copy()\n",
    "            patience_counter = 0  \n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "\n",
    "        #if we reach the specified patience, gradient descent is stopped\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n",
    "    \n",
    "    return best_theta, best_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_val_test_split(X, y, train_size = 0.6, val_size = 0.2, test_size= 0.2, seed = None):\n",
    "    \n",
    "    # check if ratios don't add up\n",
    "    if(train_size + val_size + test_size != 1):\n",
    "        raise ValueError\n",
    "    \n",
    "    # to randomize\n",
    "    if(seed != None):\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    shuffled_indices = np.random.permutation(X.shape[0])\n",
    "\n",
    "    # determining how many data points per train/val/test subset\n",
    "\n",
    "    end_of_train = int(train_size * X.shape[0])\n",
    "    end_of_val = end_of_train + int(val_size * X.shape[0])\n",
    "\n",
    "    # splitting indicies for each subset\n",
    "    training_indicies = shuffled_indices[:end_of_train]\n",
    "    validation_indicies = shuffled_indices[end_of_train: end_of_val]\n",
    "    testing_indicies = shuffled_indices[end_of_val:]\n",
    "\n",
    "    #splitting data into train/val/test\n",
    "    X_train, y_train = X[training_indicies], y[training_indicies]\n",
    "    X_val, y_val =  X[validation_indicies], y[validation_indicies]\n",
    "    X_test, y_test = X[testing_indicies], y[testing_indicies]\n",
    "\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 12000\n",
      "Validation set size: 4000\n",
      "Test set size: 4000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test= my_train_val_test_split(X, y, train_size = 0.6, val_size = 0.2, test_size= 0.2, seed = 42)\n",
    "\n",
    "\n",
    "# The only variables being used here are: X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "print(\"Training set size:\", X_train.shape[0])\n",
    "print(\"Validation set size:\", X_val.shape[0])\n",
    "print(\"Test set size:\", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testing Implementation<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000 - Train Loss: 0.6931, Validation Loss: 0.6931\n",
      "Epoch 2/1000 - Train Loss: 0.6931, Validation Loss: 0.6931\n",
      "Epoch 3/1000 - Train Loss: 0.6931, Validation Loss: 0.6931\n",
      "Epoch 4/1000 - Train Loss: 0.6931, Validation Loss: 0.6931\n",
      "Epoch 5/1000 - Train Loss: 0.6931, Validation Loss: 0.6930\n",
      "Epoch 6/1000 - Train Loss: 0.6930, Validation Loss: 0.6930\n",
      "Epoch 7/1000 - Train Loss: 0.6930, Validation Loss: 0.6930\n",
      "Epoch 8/1000 - Train Loss: 0.6930, Validation Loss: 0.6930\n",
      "Epoch 9/1000 - Train Loss: 0.6930, Validation Loss: 0.6929\n",
      "Epoch 10/1000 - Train Loss: 0.6930, Validation Loss: 0.6929\n",
      "Epoch 11/1000 - Train Loss: 0.6929, Validation Loss: 0.6929\n",
      "Epoch 12/1000 - Train Loss: 0.6929, Validation Loss: 0.6929\n",
      "Epoch 13/1000 - Train Loss: 0.6929, Validation Loss: 0.6929\n",
      "Epoch 14/1000 - Train Loss: 0.6929, Validation Loss: 0.6928\n",
      "Epoch 15/1000 - Train Loss: 0.6928, Validation Loss: 0.6928\n",
      "Epoch 16/1000 - Train Loss: 0.6928, Validation Loss: 0.6928\n",
      "Epoch 17/1000 - Train Loss: 0.6928, Validation Loss: 0.6928\n",
      "Epoch 18/1000 - Train Loss: 0.6928, Validation Loss: 0.6927\n",
      "Epoch 19/1000 - Train Loss: 0.6928, Validation Loss: 0.6927\n",
      "Epoch 20/1000 - Train Loss: 0.6927, Validation Loss: 0.6927\n",
      "Epoch 21/1000 - Train Loss: 0.6927, Validation Loss: 0.6927\n",
      "Epoch 22/1000 - Train Loss: 0.6927, Validation Loss: 0.6927\n",
      "Epoch 23/1000 - Train Loss: 0.6927, Validation Loss: 0.6926\n",
      "Epoch 24/1000 - Train Loss: 0.6926, Validation Loss: 0.6926\n",
      "Epoch 25/1000 - Train Loss: 0.6926, Validation Loss: 0.6926\n",
      "Epoch 26/1000 - Train Loss: 0.6926, Validation Loss: 0.6926\n",
      "Epoch 27/1000 - Train Loss: 0.6926, Validation Loss: 0.6925\n",
      "Epoch 28/1000 - Train Loss: 0.6926, Validation Loss: 0.6925\n",
      "Epoch 29/1000 - Train Loss: 0.6925, Validation Loss: 0.6925\n",
      "Epoch 30/1000 - Train Loss: 0.6925, Validation Loss: 0.6925\n",
      "Epoch 31/1000 - Train Loss: 0.6925, Validation Loss: 0.6925\n",
      "Epoch 32/1000 - Train Loss: 0.6925, Validation Loss: 0.6924\n",
      "Epoch 33/1000 - Train Loss: 0.6925, Validation Loss: 0.6924\n",
      "Epoch 34/1000 - Train Loss: 0.6924, Validation Loss: 0.6924\n",
      "Epoch 35/1000 - Train Loss: 0.6924, Validation Loss: 0.6924\n",
      "Epoch 36/1000 - Train Loss: 0.6924, Validation Loss: 0.6923\n",
      "Epoch 37/1000 - Train Loss: 0.6924, Validation Loss: 0.6923\n",
      "Epoch 38/1000 - Train Loss: 0.6923, Validation Loss: 0.6923\n",
      "Epoch 39/1000 - Train Loss: 0.6923, Validation Loss: 0.6923\n",
      "Epoch 40/1000 - Train Loss: 0.6923, Validation Loss: 0.6923\n",
      "Epoch 41/1000 - Train Loss: 0.6923, Validation Loss: 0.6922\n",
      "Epoch 42/1000 - Train Loss: 0.6923, Validation Loss: 0.6922\n",
      "Epoch 43/1000 - Train Loss: 0.6922, Validation Loss: 0.6922\n",
      "Epoch 44/1000 - Train Loss: 0.6922, Validation Loss: 0.6922\n",
      "Epoch 45/1000 - Train Loss: 0.6922, Validation Loss: 0.6921\n",
      "Epoch 46/1000 - Train Loss: 0.6922, Validation Loss: 0.6921\n",
      "Epoch 47/1000 - Train Loss: 0.6921, Validation Loss: 0.6921\n",
      "Epoch 48/1000 - Train Loss: 0.6921, Validation Loss: 0.6921\n",
      "Epoch 49/1000 - Train Loss: 0.6921, Validation Loss: 0.6920\n",
      "Epoch 50/1000 - Train Loss: 0.6921, Validation Loss: 0.6920\n",
      "Epoch 51/1000 - Train Loss: 0.6921, Validation Loss: 0.6920\n",
      "Epoch 52/1000 - Train Loss: 0.6920, Validation Loss: 0.6920\n",
      "Epoch 53/1000 - Train Loss: 0.6920, Validation Loss: 0.6920\n",
      "Epoch 54/1000 - Train Loss: 0.6920, Validation Loss: 0.6919\n",
      "Epoch 55/1000 - Train Loss: 0.6920, Validation Loss: 0.6919\n",
      "Epoch 56/1000 - Train Loss: 0.6920, Validation Loss: 0.6919\n",
      "Epoch 57/1000 - Train Loss: 0.6919, Validation Loss: 0.6919\n",
      "Epoch 58/1000 - Train Loss: 0.6919, Validation Loss: 0.6918\n",
      "Epoch 59/1000 - Train Loss: 0.6919, Validation Loss: 0.6918\n",
      "Epoch 60/1000 - Train Loss: 0.6919, Validation Loss: 0.6918\n",
      "Epoch 61/1000 - Train Loss: 0.6918, Validation Loss: 0.6918\n",
      "Epoch 62/1000 - Train Loss: 0.6918, Validation Loss: 0.6918\n",
      "Epoch 63/1000 - Train Loss: 0.6918, Validation Loss: 0.6917\n",
      "Epoch 64/1000 - Train Loss: 0.6918, Validation Loss: 0.6917\n",
      "Epoch 65/1000 - Train Loss: 0.6918, Validation Loss: 0.6917\n",
      "Epoch 66/1000 - Train Loss: 0.6917, Validation Loss: 0.6917\n",
      "Epoch 67/1000 - Train Loss: 0.6917, Validation Loss: 0.6916\n",
      "Epoch 68/1000 - Train Loss: 0.6917, Validation Loss: 0.6916\n",
      "Epoch 69/1000 - Train Loss: 0.6917, Validation Loss: 0.6916\n",
      "Epoch 70/1000 - Train Loss: 0.6916, Validation Loss: 0.6916\n",
      "Epoch 71/1000 - Train Loss: 0.6916, Validation Loss: 0.6916\n",
      "Epoch 72/1000 - Train Loss: 0.6916, Validation Loss: 0.6915\n",
      "Epoch 73/1000 - Train Loss: 0.6916, Validation Loss: 0.6915\n",
      "Epoch 74/1000 - Train Loss: 0.6916, Validation Loss: 0.6915\n",
      "Epoch 75/1000 - Train Loss: 0.6915, Validation Loss: 0.6915\n",
      "Epoch 76/1000 - Train Loss: 0.6915, Validation Loss: 0.6914\n",
      "Epoch 77/1000 - Train Loss: 0.6915, Validation Loss: 0.6914\n",
      "Epoch 78/1000 - Train Loss: 0.6915, Validation Loss: 0.6914\n",
      "Epoch 79/1000 - Train Loss: 0.6915, Validation Loss: 0.6914\n",
      "Epoch 80/1000 - Train Loss: 0.6914, Validation Loss: 0.6914\n",
      "Epoch 81/1000 - Train Loss: 0.6914, Validation Loss: 0.6913\n",
      "Epoch 82/1000 - Train Loss: 0.6914, Validation Loss: 0.6913\n",
      "Epoch 83/1000 - Train Loss: 0.6914, Validation Loss: 0.6913\n",
      "Epoch 84/1000 - Train Loss: 0.6913, Validation Loss: 0.6913\n",
      "Epoch 85/1000 - Train Loss: 0.6913, Validation Loss: 0.6912\n",
      "Epoch 86/1000 - Train Loss: 0.6913, Validation Loss: 0.6912\n",
      "Epoch 87/1000 - Train Loss: 0.6913, Validation Loss: 0.6912\n",
      "Epoch 88/1000 - Train Loss: 0.6913, Validation Loss: 0.6912\n",
      "Epoch 89/1000 - Train Loss: 0.6912, Validation Loss: 0.6912\n",
      "Epoch 90/1000 - Train Loss: 0.6912, Validation Loss: 0.6911\n",
      "Epoch 91/1000 - Train Loss: 0.6912, Validation Loss: 0.6911\n",
      "Epoch 92/1000 - Train Loss: 0.6912, Validation Loss: 0.6911\n",
      "Epoch 93/1000 - Train Loss: 0.6912, Validation Loss: 0.6911\n",
      "Epoch 94/1000 - Train Loss: 0.6911, Validation Loss: 0.6910\n",
      "Epoch 95/1000 - Train Loss: 0.6911, Validation Loss: 0.6910\n",
      "Epoch 96/1000 - Train Loss: 0.6911, Validation Loss: 0.6910\n",
      "Epoch 97/1000 - Train Loss: 0.6911, Validation Loss: 0.6910\n",
      "Epoch 98/1000 - Train Loss: 0.6910, Validation Loss: 0.6910\n",
      "Epoch 99/1000 - Train Loss: 0.6910, Validation Loss: 0.6909\n",
      "Epoch 100/1000 - Train Loss: 0.6910, Validation Loss: 0.6909\n",
      "Epoch 101/1000 - Train Loss: 0.6910, Validation Loss: 0.6909\n",
      "Epoch 102/1000 - Train Loss: 0.6910, Validation Loss: 0.6909\n",
      "Epoch 103/1000 - Train Loss: 0.6909, Validation Loss: 0.6908\n",
      "Epoch 104/1000 - Train Loss: 0.6909, Validation Loss: 0.6908\n",
      "Epoch 105/1000 - Train Loss: 0.6909, Validation Loss: 0.6908\n",
      "Epoch 106/1000 - Train Loss: 0.6909, Validation Loss: 0.6908\n",
      "Epoch 107/1000 - Train Loss: 0.6909, Validation Loss: 0.6908\n",
      "Epoch 108/1000 - Train Loss: 0.6908, Validation Loss: 0.6907\n",
      "Epoch 109/1000 - Train Loss: 0.6908, Validation Loss: 0.6907\n",
      "Epoch 110/1000 - Train Loss: 0.6908, Validation Loss: 0.6907\n",
      "Epoch 111/1000 - Train Loss: 0.6908, Validation Loss: 0.6907\n",
      "Epoch 112/1000 - Train Loss: 0.6907, Validation Loss: 0.6907\n",
      "Epoch 113/1000 - Train Loss: 0.6907, Validation Loss: 0.6906\n",
      "Epoch 114/1000 - Train Loss: 0.6907, Validation Loss: 0.6906\n",
      "Epoch 115/1000 - Train Loss: 0.6907, Validation Loss: 0.6906\n",
      "Epoch 116/1000 - Train Loss: 0.6907, Validation Loss: 0.6906\n",
      "Epoch 117/1000 - Train Loss: 0.6906, Validation Loss: 0.6905\n",
      "Epoch 118/1000 - Train Loss: 0.6906, Validation Loss: 0.6905\n",
      "Epoch 119/1000 - Train Loss: 0.6906, Validation Loss: 0.6905\n",
      "Epoch 120/1000 - Train Loss: 0.6906, Validation Loss: 0.6905\n",
      "Epoch 121/1000 - Train Loss: 0.6906, Validation Loss: 0.6905\n",
      "Epoch 122/1000 - Train Loss: 0.6905, Validation Loss: 0.6904\n",
      "Epoch 123/1000 - Train Loss: 0.6905, Validation Loss: 0.6904\n",
      "Epoch 124/1000 - Train Loss: 0.6905, Validation Loss: 0.6904\n",
      "Epoch 125/1000 - Train Loss: 0.6905, Validation Loss: 0.6904\n",
      "Epoch 126/1000 - Train Loss: 0.6904, Validation Loss: 0.6903\n",
      "Epoch 127/1000 - Train Loss: 0.6904, Validation Loss: 0.6903\n",
      "Epoch 128/1000 - Train Loss: 0.6904, Validation Loss: 0.6903\n",
      "Epoch 129/1000 - Train Loss: 0.6904, Validation Loss: 0.6903\n",
      "Epoch 130/1000 - Train Loss: 0.6904, Validation Loss: 0.6903\n",
      "Epoch 131/1000 - Train Loss: 0.6903, Validation Loss: 0.6902\n",
      "Epoch 132/1000 - Train Loss: 0.6903, Validation Loss: 0.6902\n",
      "Epoch 133/1000 - Train Loss: 0.6903, Validation Loss: 0.6902\n",
      "Epoch 134/1000 - Train Loss: 0.6903, Validation Loss: 0.6902\n",
      "Epoch 135/1000 - Train Loss: 0.6903, Validation Loss: 0.6901\n",
      "Epoch 136/1000 - Train Loss: 0.6902, Validation Loss: 0.6901\n",
      "Epoch 137/1000 - Train Loss: 0.6902, Validation Loss: 0.6901\n",
      "Epoch 138/1000 - Train Loss: 0.6902, Validation Loss: 0.6901\n",
      "Epoch 139/1000 - Train Loss: 0.6902, Validation Loss: 0.6901\n",
      "Epoch 140/1000 - Train Loss: 0.6901, Validation Loss: 0.6900\n",
      "Epoch 141/1000 - Train Loss: 0.6901, Validation Loss: 0.6900\n",
      "Epoch 142/1000 - Train Loss: 0.6901, Validation Loss: 0.6900\n",
      "Epoch 143/1000 - Train Loss: 0.6901, Validation Loss: 0.6900\n",
      "Epoch 144/1000 - Train Loss: 0.6901, Validation Loss: 0.6899\n",
      "Epoch 145/1000 - Train Loss: 0.6900, Validation Loss: 0.6899\n",
      "Epoch 146/1000 - Train Loss: 0.6900, Validation Loss: 0.6899\n",
      "Epoch 147/1000 - Train Loss: 0.6900, Validation Loss: 0.6899\n",
      "Epoch 148/1000 - Train Loss: 0.6900, Validation Loss: 0.6899\n",
      "Epoch 149/1000 - Train Loss: 0.6900, Validation Loss: 0.6898\n",
      "Epoch 150/1000 - Train Loss: 0.6899, Validation Loss: 0.6898\n",
      "Epoch 151/1000 - Train Loss: 0.6899, Validation Loss: 0.6898\n",
      "Epoch 152/1000 - Train Loss: 0.6899, Validation Loss: 0.6898\n",
      "Epoch 153/1000 - Train Loss: 0.6899, Validation Loss: 0.6897\n",
      "Epoch 154/1000 - Train Loss: 0.6898, Validation Loss: 0.6897\n",
      "Epoch 155/1000 - Train Loss: 0.6898, Validation Loss: 0.6897\n",
      "Epoch 156/1000 - Train Loss: 0.6898, Validation Loss: 0.6897\n",
      "Epoch 157/1000 - Train Loss: 0.6898, Validation Loss: 0.6897\n",
      "Epoch 158/1000 - Train Loss: 0.6898, Validation Loss: 0.6896\n",
      "Epoch 159/1000 - Train Loss: 0.6897, Validation Loss: 0.6896\n",
      "Epoch 160/1000 - Train Loss: 0.6897, Validation Loss: 0.6896\n",
      "Epoch 161/1000 - Train Loss: 0.6897, Validation Loss: 0.6896\n",
      "Epoch 162/1000 - Train Loss: 0.6897, Validation Loss: 0.6895\n",
      "Epoch 163/1000 - Train Loss: 0.6897, Validation Loss: 0.6895\n",
      "Epoch 164/1000 - Train Loss: 0.6896, Validation Loss: 0.6895\n",
      "Epoch 165/1000 - Train Loss: 0.6896, Validation Loss: 0.6895\n",
      "Epoch 166/1000 - Train Loss: 0.6896, Validation Loss: 0.6895\n",
      "Epoch 167/1000 - Train Loss: 0.6896, Validation Loss: 0.6894\n",
      "Epoch 168/1000 - Train Loss: 0.6895, Validation Loss: 0.6894\n",
      "Epoch 169/1000 - Train Loss: 0.6895, Validation Loss: 0.6894\n",
      "Epoch 170/1000 - Train Loss: 0.6895, Validation Loss: 0.6894\n",
      "Epoch 171/1000 - Train Loss: 0.6895, Validation Loss: 0.6894\n",
      "Epoch 172/1000 - Train Loss: 0.6895, Validation Loss: 0.6893\n",
      "Epoch 173/1000 - Train Loss: 0.6894, Validation Loss: 0.6893\n",
      "Epoch 174/1000 - Train Loss: 0.6894, Validation Loss: 0.6893\n",
      "Epoch 175/1000 - Train Loss: 0.6894, Validation Loss: 0.6893\n",
      "Epoch 176/1000 - Train Loss: 0.6894, Validation Loss: 0.6892\n",
      "Epoch 177/1000 - Train Loss: 0.6894, Validation Loss: 0.6892\n",
      "Epoch 178/1000 - Train Loss: 0.6893, Validation Loss: 0.6892\n",
      "Epoch 179/1000 - Train Loss: 0.6893, Validation Loss: 0.6892\n",
      "Epoch 180/1000 - Train Loss: 0.6893, Validation Loss: 0.6892\n",
      "Epoch 181/1000 - Train Loss: 0.6893, Validation Loss: 0.6891\n",
      "Epoch 182/1000 - Train Loss: 0.6892, Validation Loss: 0.6891\n",
      "Epoch 183/1000 - Train Loss: 0.6892, Validation Loss: 0.6891\n",
      "Epoch 184/1000 - Train Loss: 0.6892, Validation Loss: 0.6891\n",
      "Epoch 185/1000 - Train Loss: 0.6892, Validation Loss: 0.6890\n",
      "Epoch 186/1000 - Train Loss: 0.6892, Validation Loss: 0.6890\n",
      "Epoch 187/1000 - Train Loss: 0.6891, Validation Loss: 0.6890\n",
      "Epoch 188/1000 - Train Loss: 0.6891, Validation Loss: 0.6890\n",
      "Epoch 189/1000 - Train Loss: 0.6891, Validation Loss: 0.6890\n",
      "Epoch 190/1000 - Train Loss: 0.6891, Validation Loss: 0.6889\n",
      "Epoch 191/1000 - Train Loss: 0.6891, Validation Loss: 0.6889\n",
      "Epoch 192/1000 - Train Loss: 0.6890, Validation Loss: 0.6889\n",
      "Epoch 193/1000 - Train Loss: 0.6890, Validation Loss: 0.6889\n",
      "Epoch 194/1000 - Train Loss: 0.6890, Validation Loss: 0.6888\n",
      "Epoch 195/1000 - Train Loss: 0.6890, Validation Loss: 0.6888\n",
      "Epoch 196/1000 - Train Loss: 0.6889, Validation Loss: 0.6888\n",
      "Epoch 197/1000 - Train Loss: 0.6889, Validation Loss: 0.6888\n",
      "Epoch 198/1000 - Train Loss: 0.6889, Validation Loss: 0.6888\n",
      "Epoch 199/1000 - Train Loss: 0.6889, Validation Loss: 0.6887\n",
      "Epoch 200/1000 - Train Loss: 0.6889, Validation Loss: 0.6887\n",
      "Epoch 201/1000 - Train Loss: 0.6888, Validation Loss: 0.6887\n",
      "Epoch 202/1000 - Train Loss: 0.6888, Validation Loss: 0.6887\n",
      "Epoch 203/1000 - Train Loss: 0.6888, Validation Loss: 0.6886\n",
      "Epoch 204/1000 - Train Loss: 0.6888, Validation Loss: 0.6886\n",
      "Epoch 205/1000 - Train Loss: 0.6888, Validation Loss: 0.6886\n",
      "Epoch 206/1000 - Train Loss: 0.6887, Validation Loss: 0.6886\n",
      "Epoch 207/1000 - Train Loss: 0.6887, Validation Loss: 0.6886\n",
      "Epoch 208/1000 - Train Loss: 0.6887, Validation Loss: 0.6885\n",
      "Epoch 209/1000 - Train Loss: 0.6887, Validation Loss: 0.6885\n",
      "Epoch 210/1000 - Train Loss: 0.6887, Validation Loss: 0.6885\n",
      "Epoch 211/1000 - Train Loss: 0.6886, Validation Loss: 0.6885\n",
      "Epoch 212/1000 - Train Loss: 0.6886, Validation Loss: 0.6885\n",
      "Epoch 213/1000 - Train Loss: 0.6886, Validation Loss: 0.6884\n",
      "Epoch 214/1000 - Train Loss: 0.6886, Validation Loss: 0.6884\n",
      "Epoch 215/1000 - Train Loss: 0.6885, Validation Loss: 0.6884\n",
      "Epoch 216/1000 - Train Loss: 0.6885, Validation Loss: 0.6884\n",
      "Epoch 217/1000 - Train Loss: 0.6885, Validation Loss: 0.6883\n",
      "Epoch 218/1000 - Train Loss: 0.6885, Validation Loss: 0.6883\n",
      "Epoch 219/1000 - Train Loss: 0.6885, Validation Loss: 0.6883\n",
      "Epoch 220/1000 - Train Loss: 0.6884, Validation Loss: 0.6883\n",
      "Epoch 221/1000 - Train Loss: 0.6884, Validation Loss: 0.6883\n",
      "Epoch 222/1000 - Train Loss: 0.6884, Validation Loss: 0.6882\n",
      "Epoch 223/1000 - Train Loss: 0.6884, Validation Loss: 0.6882\n",
      "Epoch 224/1000 - Train Loss: 0.6884, Validation Loss: 0.6882\n",
      "Epoch 225/1000 - Train Loss: 0.6883, Validation Loss: 0.6882\n",
      "Epoch 226/1000 - Train Loss: 0.6883, Validation Loss: 0.6881\n",
      "Epoch 227/1000 - Train Loss: 0.6883, Validation Loss: 0.6881\n",
      "Epoch 228/1000 - Train Loss: 0.6883, Validation Loss: 0.6881\n",
      "Epoch 229/1000 - Train Loss: 0.6882, Validation Loss: 0.6881\n",
      "Epoch 230/1000 - Train Loss: 0.6882, Validation Loss: 0.6881\n",
      "Epoch 231/1000 - Train Loss: 0.6882, Validation Loss: 0.6880\n",
      "Epoch 232/1000 - Train Loss: 0.6882, Validation Loss: 0.6880\n",
      "Epoch 233/1000 - Train Loss: 0.6882, Validation Loss: 0.6880\n",
      "Epoch 234/1000 - Train Loss: 0.6881, Validation Loss: 0.6880\n",
      "Epoch 235/1000 - Train Loss: 0.6881, Validation Loss: 0.6880\n",
      "Epoch 236/1000 - Train Loss: 0.6881, Validation Loss: 0.6879\n",
      "Epoch 237/1000 - Train Loss: 0.6881, Validation Loss: 0.6879\n",
      "Epoch 238/1000 - Train Loss: 0.6881, Validation Loss: 0.6879\n",
      "Epoch 239/1000 - Train Loss: 0.6880, Validation Loss: 0.6879\n",
      "Epoch 240/1000 - Train Loss: 0.6880, Validation Loss: 0.6878\n",
      "Epoch 241/1000 - Train Loss: 0.6880, Validation Loss: 0.6878\n",
      "Epoch 242/1000 - Train Loss: 0.6880, Validation Loss: 0.6878\n",
      "Epoch 243/1000 - Train Loss: 0.6880, Validation Loss: 0.6878\n",
      "Epoch 244/1000 - Train Loss: 0.6879, Validation Loss: 0.6878\n",
      "Epoch 245/1000 - Train Loss: 0.6879, Validation Loss: 0.6877\n",
      "Epoch 246/1000 - Train Loss: 0.6879, Validation Loss: 0.6877\n",
      "Epoch 247/1000 - Train Loss: 0.6879, Validation Loss: 0.6877\n",
      "Epoch 248/1000 - Train Loss: 0.6878, Validation Loss: 0.6877\n",
      "Epoch 249/1000 - Train Loss: 0.6878, Validation Loss: 0.6876\n",
      "Epoch 250/1000 - Train Loss: 0.6878, Validation Loss: 0.6876\n",
      "Epoch 251/1000 - Train Loss: 0.6878, Validation Loss: 0.6876\n",
      "Epoch 252/1000 - Train Loss: 0.6878, Validation Loss: 0.6876\n",
      "Epoch 253/1000 - Train Loss: 0.6877, Validation Loss: 0.6876\n",
      "Epoch 254/1000 - Train Loss: 0.6877, Validation Loss: 0.6875\n",
      "Epoch 255/1000 - Train Loss: 0.6877, Validation Loss: 0.6875\n",
      "Epoch 256/1000 - Train Loss: 0.6877, Validation Loss: 0.6875\n",
      "Epoch 257/1000 - Train Loss: 0.6877, Validation Loss: 0.6875\n",
      "Epoch 258/1000 - Train Loss: 0.6876, Validation Loss: 0.6875\n",
      "Epoch 259/1000 - Train Loss: 0.6876, Validation Loss: 0.6874\n",
      "Epoch 260/1000 - Train Loss: 0.6876, Validation Loss: 0.6874\n",
      "Epoch 261/1000 - Train Loss: 0.6876, Validation Loss: 0.6874\n",
      "Epoch 262/1000 - Train Loss: 0.6876, Validation Loss: 0.6874\n",
      "Epoch 263/1000 - Train Loss: 0.6875, Validation Loss: 0.6873\n",
      "Epoch 264/1000 - Train Loss: 0.6875, Validation Loss: 0.6873\n",
      "Epoch 265/1000 - Train Loss: 0.6875, Validation Loss: 0.6873\n",
      "Epoch 266/1000 - Train Loss: 0.6875, Validation Loss: 0.6873\n",
      "Epoch 267/1000 - Train Loss: 0.6874, Validation Loss: 0.6873\n",
      "Epoch 268/1000 - Train Loss: 0.6874, Validation Loss: 0.6872\n",
      "Epoch 269/1000 - Train Loss: 0.6874, Validation Loss: 0.6872\n",
      "Epoch 270/1000 - Train Loss: 0.6874, Validation Loss: 0.6872\n",
      "Epoch 271/1000 - Train Loss: 0.6874, Validation Loss: 0.6872\n",
      "Epoch 272/1000 - Train Loss: 0.6873, Validation Loss: 0.6871\n",
      "Epoch 273/1000 - Train Loss: 0.6873, Validation Loss: 0.6871\n",
      "Epoch 274/1000 - Train Loss: 0.6873, Validation Loss: 0.6871\n",
      "Epoch 275/1000 - Train Loss: 0.6873, Validation Loss: 0.6871\n",
      "Epoch 276/1000 - Train Loss: 0.6873, Validation Loss: 0.6871\n",
      "Epoch 277/1000 - Train Loss: 0.6872, Validation Loss: 0.6870\n",
      "Epoch 278/1000 - Train Loss: 0.6872, Validation Loss: 0.6870\n",
      "Epoch 279/1000 - Train Loss: 0.6872, Validation Loss: 0.6870\n",
      "Epoch 280/1000 - Train Loss: 0.6872, Validation Loss: 0.6870\n",
      "Epoch 281/1000 - Train Loss: 0.6872, Validation Loss: 0.6870\n",
      "Epoch 282/1000 - Train Loss: 0.6871, Validation Loss: 0.6869\n",
      "Epoch 283/1000 - Train Loss: 0.6871, Validation Loss: 0.6869\n",
      "Epoch 284/1000 - Train Loss: 0.6871, Validation Loss: 0.6869\n",
      "Epoch 285/1000 - Train Loss: 0.6871, Validation Loss: 0.6869\n",
      "Epoch 286/1000 - Train Loss: 0.6870, Validation Loss: 0.6868\n",
      "Epoch 287/1000 - Train Loss: 0.6870, Validation Loss: 0.6868\n",
      "Epoch 288/1000 - Train Loss: 0.6870, Validation Loss: 0.6868\n",
      "Epoch 289/1000 - Train Loss: 0.6870, Validation Loss: 0.6868\n",
      "Epoch 290/1000 - Train Loss: 0.6870, Validation Loss: 0.6868\n",
      "Epoch 291/1000 - Train Loss: 0.6869, Validation Loss: 0.6867\n",
      "Epoch 292/1000 - Train Loss: 0.6869, Validation Loss: 0.6867\n",
      "Epoch 293/1000 - Train Loss: 0.6869, Validation Loss: 0.6867\n",
      "Epoch 294/1000 - Train Loss: 0.6869, Validation Loss: 0.6867\n",
      "Epoch 295/1000 - Train Loss: 0.6869, Validation Loss: 0.6867\n",
      "Epoch 296/1000 - Train Loss: 0.6868, Validation Loss: 0.6866\n",
      "Epoch 297/1000 - Train Loss: 0.6868, Validation Loss: 0.6866\n",
      "Epoch 298/1000 - Train Loss: 0.6868, Validation Loss: 0.6866\n",
      "Epoch 299/1000 - Train Loss: 0.6868, Validation Loss: 0.6866\n",
      "Epoch 300/1000 - Train Loss: 0.6868, Validation Loss: 0.6865\n",
      "Epoch 301/1000 - Train Loss: 0.6867, Validation Loss: 0.6865\n",
      "Epoch 302/1000 - Train Loss: 0.6867, Validation Loss: 0.6865\n",
      "Epoch 303/1000 - Train Loss: 0.6867, Validation Loss: 0.6865\n",
      "Epoch 304/1000 - Train Loss: 0.6867, Validation Loss: 0.6865\n",
      "Epoch 305/1000 - Train Loss: 0.6866, Validation Loss: 0.6864\n",
      "Epoch 306/1000 - Train Loss: 0.6866, Validation Loss: 0.6864\n",
      "Epoch 307/1000 - Train Loss: 0.6866, Validation Loss: 0.6864\n",
      "Epoch 308/1000 - Train Loss: 0.6866, Validation Loss: 0.6864\n",
      "Epoch 309/1000 - Train Loss: 0.6866, Validation Loss: 0.6864\n",
      "Epoch 310/1000 - Train Loss: 0.6865, Validation Loss: 0.6863\n",
      "Epoch 311/1000 - Train Loss: 0.6865, Validation Loss: 0.6863\n",
      "Epoch 312/1000 - Train Loss: 0.6865, Validation Loss: 0.6863\n",
      "Epoch 313/1000 - Train Loss: 0.6865, Validation Loss: 0.6863\n",
      "Epoch 314/1000 - Train Loss: 0.6865, Validation Loss: 0.6862\n",
      "Epoch 315/1000 - Train Loss: 0.6864, Validation Loss: 0.6862\n",
      "Epoch 316/1000 - Train Loss: 0.6864, Validation Loss: 0.6862\n",
      "Epoch 317/1000 - Train Loss: 0.6864, Validation Loss: 0.6862\n",
      "Epoch 318/1000 - Train Loss: 0.6864, Validation Loss: 0.6862\n",
      "Epoch 319/1000 - Train Loss: 0.6864, Validation Loss: 0.6861\n",
      "Epoch 320/1000 - Train Loss: 0.6863, Validation Loss: 0.6861\n",
      "Epoch 321/1000 - Train Loss: 0.6863, Validation Loss: 0.6861\n",
      "Epoch 322/1000 - Train Loss: 0.6863, Validation Loss: 0.6861\n",
      "Epoch 323/1000 - Train Loss: 0.6863, Validation Loss: 0.6860\n",
      "Epoch 324/1000 - Train Loss: 0.6863, Validation Loss: 0.6860\n",
      "Epoch 325/1000 - Train Loss: 0.6862, Validation Loss: 0.6860\n",
      "Epoch 326/1000 - Train Loss: 0.6862, Validation Loss: 0.6860\n",
      "Epoch 327/1000 - Train Loss: 0.6862, Validation Loss: 0.6860\n",
      "Epoch 328/1000 - Train Loss: 0.6862, Validation Loss: 0.6859\n",
      "Epoch 329/1000 - Train Loss: 0.6861, Validation Loss: 0.6859\n",
      "Epoch 330/1000 - Train Loss: 0.6861, Validation Loss: 0.6859\n",
      "Epoch 331/1000 - Train Loss: 0.6861, Validation Loss: 0.6859\n",
      "Epoch 332/1000 - Train Loss: 0.6861, Validation Loss: 0.6859\n",
      "Epoch 333/1000 - Train Loss: 0.6861, Validation Loss: 0.6858\n",
      "Epoch 334/1000 - Train Loss: 0.6860, Validation Loss: 0.6858\n",
      "Epoch 335/1000 - Train Loss: 0.6860, Validation Loss: 0.6858\n",
      "Epoch 336/1000 - Train Loss: 0.6860, Validation Loss: 0.6858\n",
      "Epoch 337/1000 - Train Loss: 0.6860, Validation Loss: 0.6857\n",
      "Epoch 338/1000 - Train Loss: 0.6860, Validation Loss: 0.6857\n",
      "Epoch 339/1000 - Train Loss: 0.6859, Validation Loss: 0.6857\n",
      "Epoch 340/1000 - Train Loss: 0.6859, Validation Loss: 0.6857\n",
      "Epoch 341/1000 - Train Loss: 0.6859, Validation Loss: 0.6857\n",
      "Epoch 342/1000 - Train Loss: 0.6859, Validation Loss: 0.6856\n",
      "Epoch 343/1000 - Train Loss: 0.6859, Validation Loss: 0.6856\n",
      "Epoch 344/1000 - Train Loss: 0.6858, Validation Loss: 0.6856\n",
      "Epoch 345/1000 - Train Loss: 0.6858, Validation Loss: 0.6856\n",
      "Epoch 346/1000 - Train Loss: 0.6858, Validation Loss: 0.6856\n",
      "Epoch 347/1000 - Train Loss: 0.6858, Validation Loss: 0.6855\n",
      "Epoch 348/1000 - Train Loss: 0.6857, Validation Loss: 0.6855\n",
      "Epoch 349/1000 - Train Loss: 0.6857, Validation Loss: 0.6855\n",
      "Epoch 350/1000 - Train Loss: 0.6857, Validation Loss: 0.6855\n",
      "Epoch 351/1000 - Train Loss: 0.6857, Validation Loss: 0.6854\n",
      "Epoch 352/1000 - Train Loss: 0.6857, Validation Loss: 0.6854\n",
      "Epoch 353/1000 - Train Loss: 0.6856, Validation Loss: 0.6854\n",
      "Epoch 354/1000 - Train Loss: 0.6856, Validation Loss: 0.6854\n",
      "Epoch 355/1000 - Train Loss: 0.6856, Validation Loss: 0.6854\n",
      "Epoch 356/1000 - Train Loss: 0.6856, Validation Loss: 0.6853\n",
      "Epoch 357/1000 - Train Loss: 0.6856, Validation Loss: 0.6853\n",
      "Epoch 358/1000 - Train Loss: 0.6855, Validation Loss: 0.6853\n",
      "Epoch 359/1000 - Train Loss: 0.6855, Validation Loss: 0.6853\n",
      "Epoch 360/1000 - Train Loss: 0.6855, Validation Loss: 0.6853\n",
      "Epoch 361/1000 - Train Loss: 0.6855, Validation Loss: 0.6852\n",
      "Epoch 362/1000 - Train Loss: 0.6855, Validation Loss: 0.6852\n",
      "Epoch 363/1000 - Train Loss: 0.6854, Validation Loss: 0.6852\n",
      "Epoch 364/1000 - Train Loss: 0.6854, Validation Loss: 0.6852\n",
      "Epoch 365/1000 - Train Loss: 0.6854, Validation Loss: 0.6851\n",
      "Epoch 366/1000 - Train Loss: 0.6854, Validation Loss: 0.6851\n",
      "Epoch 367/1000 - Train Loss: 0.6854, Validation Loss: 0.6851\n",
      "Epoch 368/1000 - Train Loss: 0.6853, Validation Loss: 0.6851\n",
      "Epoch 369/1000 - Train Loss: 0.6853, Validation Loss: 0.6851\n",
      "Epoch 370/1000 - Train Loss: 0.6853, Validation Loss: 0.6850\n",
      "Epoch 371/1000 - Train Loss: 0.6853, Validation Loss: 0.6850\n",
      "Epoch 372/1000 - Train Loss: 0.6852, Validation Loss: 0.6850\n",
      "Epoch 373/1000 - Train Loss: 0.6852, Validation Loss: 0.6850\n",
      "Epoch 374/1000 - Train Loss: 0.6852, Validation Loss: 0.6850\n",
      "Epoch 375/1000 - Train Loss: 0.6852, Validation Loss: 0.6849\n",
      "Epoch 376/1000 - Train Loss: 0.6852, Validation Loss: 0.6849\n",
      "Epoch 377/1000 - Train Loss: 0.6851, Validation Loss: 0.6849\n",
      "Epoch 378/1000 - Train Loss: 0.6851, Validation Loss: 0.6849\n",
      "Epoch 379/1000 - Train Loss: 0.6851, Validation Loss: 0.6849\n",
      "Epoch 380/1000 - Train Loss: 0.6851, Validation Loss: 0.6848\n",
      "Epoch 381/1000 - Train Loss: 0.6851, Validation Loss: 0.6848\n",
      "Epoch 382/1000 - Train Loss: 0.6850, Validation Loss: 0.6848\n",
      "Epoch 383/1000 - Train Loss: 0.6850, Validation Loss: 0.6848\n",
      "Epoch 384/1000 - Train Loss: 0.6850, Validation Loss: 0.6847\n",
      "Epoch 385/1000 - Train Loss: 0.6850, Validation Loss: 0.6847\n",
      "Epoch 386/1000 - Train Loss: 0.6850, Validation Loss: 0.6847\n",
      "Epoch 387/1000 - Train Loss: 0.6849, Validation Loss: 0.6847\n",
      "Epoch 388/1000 - Train Loss: 0.6849, Validation Loss: 0.6847\n",
      "Epoch 389/1000 - Train Loss: 0.6849, Validation Loss: 0.6846\n",
      "Epoch 390/1000 - Train Loss: 0.6849, Validation Loss: 0.6846\n",
      "Epoch 391/1000 - Train Loss: 0.6849, Validation Loss: 0.6846\n",
      "Epoch 392/1000 - Train Loss: 0.6848, Validation Loss: 0.6846\n",
      "Epoch 393/1000 - Train Loss: 0.6848, Validation Loss: 0.6846\n",
      "Epoch 394/1000 - Train Loss: 0.6848, Validation Loss: 0.6845\n",
      "Epoch 395/1000 - Train Loss: 0.6848, Validation Loss: 0.6845\n",
      "Epoch 396/1000 - Train Loss: 0.6848, Validation Loss: 0.6845\n",
      "Epoch 397/1000 - Train Loss: 0.6847, Validation Loss: 0.6845\n",
      "Epoch 398/1000 - Train Loss: 0.6847, Validation Loss: 0.6844\n",
      "Epoch 399/1000 - Train Loss: 0.6847, Validation Loss: 0.6844\n",
      "Epoch 400/1000 - Train Loss: 0.6847, Validation Loss: 0.6844\n",
      "Epoch 401/1000 - Train Loss: 0.6846, Validation Loss: 0.6844\n",
      "Epoch 402/1000 - Train Loss: 0.6846, Validation Loss: 0.6844\n",
      "Epoch 403/1000 - Train Loss: 0.6846, Validation Loss: 0.6843\n",
      "Epoch 404/1000 - Train Loss: 0.6846, Validation Loss: 0.6843\n",
      "Epoch 405/1000 - Train Loss: 0.6846, Validation Loss: 0.6843\n",
      "Epoch 406/1000 - Train Loss: 0.6845, Validation Loss: 0.6843\n",
      "Epoch 407/1000 - Train Loss: 0.6845, Validation Loss: 0.6843\n",
      "Epoch 408/1000 - Train Loss: 0.6845, Validation Loss: 0.6842\n",
      "Epoch 409/1000 - Train Loss: 0.6845, Validation Loss: 0.6842\n",
      "Epoch 410/1000 - Train Loss: 0.6845, Validation Loss: 0.6842\n",
      "Epoch 411/1000 - Train Loss: 0.6844, Validation Loss: 0.6842\n",
      "Epoch 412/1000 - Train Loss: 0.6844, Validation Loss: 0.6841\n",
      "Epoch 413/1000 - Train Loss: 0.6844, Validation Loss: 0.6841\n",
      "Epoch 414/1000 - Train Loss: 0.6844, Validation Loss: 0.6841\n",
      "Epoch 415/1000 - Train Loss: 0.6844, Validation Loss: 0.6841\n",
      "Epoch 416/1000 - Train Loss: 0.6843, Validation Loss: 0.6841\n",
      "Epoch 417/1000 - Train Loss: 0.6843, Validation Loss: 0.6840\n",
      "Epoch 418/1000 - Train Loss: 0.6843, Validation Loss: 0.6840\n",
      "Epoch 419/1000 - Train Loss: 0.6843, Validation Loss: 0.6840\n",
      "Epoch 420/1000 - Train Loss: 0.6843, Validation Loss: 0.6840\n",
      "Epoch 421/1000 - Train Loss: 0.6842, Validation Loss: 0.6840\n",
      "Epoch 422/1000 - Train Loss: 0.6842, Validation Loss: 0.6839\n",
      "Epoch 423/1000 - Train Loss: 0.6842, Validation Loss: 0.6839\n",
      "Epoch 424/1000 - Train Loss: 0.6842, Validation Loss: 0.6839\n",
      "Epoch 425/1000 - Train Loss: 0.6842, Validation Loss: 0.6839\n",
      "Epoch 426/1000 - Train Loss: 0.6841, Validation Loss: 0.6838\n",
      "Epoch 427/1000 - Train Loss: 0.6841, Validation Loss: 0.6838\n",
      "Epoch 428/1000 - Train Loss: 0.6841, Validation Loss: 0.6838\n",
      "Epoch 429/1000 - Train Loss: 0.6841, Validation Loss: 0.6838\n",
      "Epoch 430/1000 - Train Loss: 0.6840, Validation Loss: 0.6838\n",
      "Epoch 431/1000 - Train Loss: 0.6840, Validation Loss: 0.6837\n",
      "Epoch 432/1000 - Train Loss: 0.6840, Validation Loss: 0.6837\n",
      "Epoch 433/1000 - Train Loss: 0.6840, Validation Loss: 0.6837\n",
      "Epoch 434/1000 - Train Loss: 0.6840, Validation Loss: 0.6837\n",
      "Epoch 435/1000 - Train Loss: 0.6839, Validation Loss: 0.6837\n",
      "Epoch 436/1000 - Train Loss: 0.6839, Validation Loss: 0.6836\n",
      "Epoch 437/1000 - Train Loss: 0.6839, Validation Loss: 0.6836\n",
      "Epoch 438/1000 - Train Loss: 0.6839, Validation Loss: 0.6836\n",
      "Epoch 439/1000 - Train Loss: 0.6839, Validation Loss: 0.6836\n",
      "Epoch 440/1000 - Train Loss: 0.6838, Validation Loss: 0.6836\n",
      "Epoch 441/1000 - Train Loss: 0.6838, Validation Loss: 0.6835\n",
      "Epoch 442/1000 - Train Loss: 0.6838, Validation Loss: 0.6835\n",
      "Epoch 443/1000 - Train Loss: 0.6838, Validation Loss: 0.6835\n",
      "Epoch 444/1000 - Train Loss: 0.6838, Validation Loss: 0.6835\n",
      "Epoch 445/1000 - Train Loss: 0.6837, Validation Loss: 0.6834\n",
      "Epoch 446/1000 - Train Loss: 0.6837, Validation Loss: 0.6834\n",
      "Epoch 447/1000 - Train Loss: 0.6837, Validation Loss: 0.6834\n",
      "Epoch 448/1000 - Train Loss: 0.6837, Validation Loss: 0.6834\n",
      "Epoch 449/1000 - Train Loss: 0.6837, Validation Loss: 0.6834\n",
      "Epoch 450/1000 - Train Loss: 0.6836, Validation Loss: 0.6833\n",
      "Epoch 451/1000 - Train Loss: 0.6836, Validation Loss: 0.6833\n",
      "Epoch 452/1000 - Train Loss: 0.6836, Validation Loss: 0.6833\n",
      "Epoch 453/1000 - Train Loss: 0.6836, Validation Loss: 0.6833\n",
      "Epoch 454/1000 - Train Loss: 0.6836, Validation Loss: 0.6833\n",
      "Epoch 455/1000 - Train Loss: 0.6835, Validation Loss: 0.6832\n",
      "Epoch 456/1000 - Train Loss: 0.6835, Validation Loss: 0.6832\n",
      "Epoch 457/1000 - Train Loss: 0.6835, Validation Loss: 0.6832\n",
      "Epoch 458/1000 - Train Loss: 0.6835, Validation Loss: 0.6832\n",
      "Epoch 459/1000 - Train Loss: 0.6835, Validation Loss: 0.6832\n",
      "Epoch 460/1000 - Train Loss: 0.6834, Validation Loss: 0.6831\n",
      "Epoch 461/1000 - Train Loss: 0.6834, Validation Loss: 0.6831\n",
      "Epoch 462/1000 - Train Loss: 0.6834, Validation Loss: 0.6831\n",
      "Epoch 463/1000 - Train Loss: 0.6834, Validation Loss: 0.6831\n",
      "Epoch 464/1000 - Train Loss: 0.6833, Validation Loss: 0.6830\n",
      "Epoch 465/1000 - Train Loss: 0.6833, Validation Loss: 0.6830\n",
      "Epoch 466/1000 - Train Loss: 0.6833, Validation Loss: 0.6830\n",
      "Epoch 467/1000 - Train Loss: 0.6833, Validation Loss: 0.6830\n",
      "Epoch 468/1000 - Train Loss: 0.6833, Validation Loss: 0.6830\n",
      "Epoch 469/1000 - Train Loss: 0.6832, Validation Loss: 0.6829\n",
      "Epoch 470/1000 - Train Loss: 0.6832, Validation Loss: 0.6829\n",
      "Epoch 471/1000 - Train Loss: 0.6832, Validation Loss: 0.6829\n",
      "Epoch 472/1000 - Train Loss: 0.6832, Validation Loss: 0.6829\n",
      "Epoch 473/1000 - Train Loss: 0.6832, Validation Loss: 0.6829\n",
      "Epoch 474/1000 - Train Loss: 0.6831, Validation Loss: 0.6828\n",
      "Epoch 475/1000 - Train Loss: 0.6831, Validation Loss: 0.6828\n",
      "Epoch 476/1000 - Train Loss: 0.6831, Validation Loss: 0.6828\n",
      "Epoch 477/1000 - Train Loss: 0.6831, Validation Loss: 0.6828\n",
      "Epoch 478/1000 - Train Loss: 0.6831, Validation Loss: 0.6828\n",
      "Epoch 479/1000 - Train Loss: 0.6830, Validation Loss: 0.6827\n",
      "Epoch 480/1000 - Train Loss: 0.6830, Validation Loss: 0.6827\n",
      "Epoch 481/1000 - Train Loss: 0.6830, Validation Loss: 0.6827\n",
      "Epoch 482/1000 - Train Loss: 0.6830, Validation Loss: 0.6827\n",
      "Epoch 483/1000 - Train Loss: 0.6830, Validation Loss: 0.6826\n",
      "Epoch 484/1000 - Train Loss: 0.6829, Validation Loss: 0.6826\n",
      "Epoch 485/1000 - Train Loss: 0.6829, Validation Loss: 0.6826\n",
      "Epoch 486/1000 - Train Loss: 0.6829, Validation Loss: 0.6826\n",
      "Epoch 487/1000 - Train Loss: 0.6829, Validation Loss: 0.6826\n",
      "Epoch 488/1000 - Train Loss: 0.6829, Validation Loss: 0.6825\n",
      "Epoch 489/1000 - Train Loss: 0.6828, Validation Loss: 0.6825\n",
      "Epoch 490/1000 - Train Loss: 0.6828, Validation Loss: 0.6825\n",
      "Epoch 491/1000 - Train Loss: 0.6828, Validation Loss: 0.6825\n",
      "Epoch 492/1000 - Train Loss: 0.6828, Validation Loss: 0.6825\n",
      "Epoch 493/1000 - Train Loss: 0.6828, Validation Loss: 0.6824\n",
      "Epoch 494/1000 - Train Loss: 0.6827, Validation Loss: 0.6824\n",
      "Epoch 495/1000 - Train Loss: 0.6827, Validation Loss: 0.6824\n",
      "Epoch 496/1000 - Train Loss: 0.6827, Validation Loss: 0.6824\n",
      "Epoch 497/1000 - Train Loss: 0.6827, Validation Loss: 0.6824\n",
      "Epoch 498/1000 - Train Loss: 0.6827, Validation Loss: 0.6823\n",
      "Epoch 499/1000 - Train Loss: 0.6826, Validation Loss: 0.6823\n",
      "Epoch 500/1000 - Train Loss: 0.6826, Validation Loss: 0.6823\n",
      "Epoch 501/1000 - Train Loss: 0.6826, Validation Loss: 0.6823\n",
      "Epoch 502/1000 - Train Loss: 0.6826, Validation Loss: 0.6822\n",
      "Epoch 503/1000 - Train Loss: 0.6825, Validation Loss: 0.6822\n",
      "Epoch 504/1000 - Train Loss: 0.6825, Validation Loss: 0.6822\n",
      "Epoch 505/1000 - Train Loss: 0.6825, Validation Loss: 0.6822\n",
      "Epoch 506/1000 - Train Loss: 0.6825, Validation Loss: 0.6822\n",
      "Epoch 507/1000 - Train Loss: 0.6825, Validation Loss: 0.6821\n",
      "Epoch 508/1000 - Train Loss: 0.6824, Validation Loss: 0.6821\n",
      "Epoch 509/1000 - Train Loss: 0.6824, Validation Loss: 0.6821\n",
      "Epoch 510/1000 - Train Loss: 0.6824, Validation Loss: 0.6821\n",
      "Epoch 511/1000 - Train Loss: 0.6824, Validation Loss: 0.6821\n",
      "Epoch 512/1000 - Train Loss: 0.6824, Validation Loss: 0.6820\n",
      "Epoch 513/1000 - Train Loss: 0.6823, Validation Loss: 0.6820\n",
      "Epoch 514/1000 - Train Loss: 0.6823, Validation Loss: 0.6820\n",
      "Epoch 515/1000 - Train Loss: 0.6823, Validation Loss: 0.6820\n",
      "Epoch 516/1000 - Train Loss: 0.6823, Validation Loss: 0.6820\n",
      "Epoch 517/1000 - Train Loss: 0.6823, Validation Loss: 0.6819\n",
      "Epoch 518/1000 - Train Loss: 0.6822, Validation Loss: 0.6819\n",
      "Epoch 519/1000 - Train Loss: 0.6822, Validation Loss: 0.6819\n",
      "Epoch 520/1000 - Train Loss: 0.6822, Validation Loss: 0.6819\n",
      "Epoch 521/1000 - Train Loss: 0.6822, Validation Loss: 0.6818\n",
      "Epoch 522/1000 - Train Loss: 0.6822, Validation Loss: 0.6818\n",
      "Epoch 523/1000 - Train Loss: 0.6821, Validation Loss: 0.6818\n",
      "Epoch 524/1000 - Train Loss: 0.6821, Validation Loss: 0.6818\n",
      "Epoch 525/1000 - Train Loss: 0.6821, Validation Loss: 0.6818\n",
      "Epoch 526/1000 - Train Loss: 0.6821, Validation Loss: 0.6817\n",
      "Epoch 527/1000 - Train Loss: 0.6821, Validation Loss: 0.6817\n",
      "Epoch 528/1000 - Train Loss: 0.6820, Validation Loss: 0.6817\n",
      "Epoch 529/1000 - Train Loss: 0.6820, Validation Loss: 0.6817\n",
      "Epoch 530/1000 - Train Loss: 0.6820, Validation Loss: 0.6817\n",
      "Epoch 531/1000 - Train Loss: 0.6820, Validation Loss: 0.6816\n",
      "Epoch 532/1000 - Train Loss: 0.6820, Validation Loss: 0.6816\n",
      "Epoch 533/1000 - Train Loss: 0.6819, Validation Loss: 0.6816\n",
      "Epoch 534/1000 - Train Loss: 0.6819, Validation Loss: 0.6816\n",
      "Epoch 535/1000 - Train Loss: 0.6819, Validation Loss: 0.6816\n",
      "Epoch 536/1000 - Train Loss: 0.6819, Validation Loss: 0.6815\n",
      "Epoch 537/1000 - Train Loss: 0.6819, Validation Loss: 0.6815\n",
      "Epoch 538/1000 - Train Loss: 0.6818, Validation Loss: 0.6815\n",
      "Epoch 539/1000 - Train Loss: 0.6818, Validation Loss: 0.6815\n",
      "Epoch 540/1000 - Train Loss: 0.6818, Validation Loss: 0.6814\n",
      "Epoch 541/1000 - Train Loss: 0.6818, Validation Loss: 0.6814\n",
      "Epoch 542/1000 - Train Loss: 0.6818, Validation Loss: 0.6814\n",
      "Epoch 543/1000 - Train Loss: 0.6817, Validation Loss: 0.6814\n",
      "Epoch 544/1000 - Train Loss: 0.6817, Validation Loss: 0.6814\n",
      "Epoch 545/1000 - Train Loss: 0.6817, Validation Loss: 0.6813\n",
      "Epoch 546/1000 - Train Loss: 0.6817, Validation Loss: 0.6813\n",
      "Epoch 547/1000 - Train Loss: 0.6817, Validation Loss: 0.6813\n",
      "Epoch 548/1000 - Train Loss: 0.6816, Validation Loss: 0.6813\n",
      "Epoch 549/1000 - Train Loss: 0.6816, Validation Loss: 0.6813\n",
      "Epoch 550/1000 - Train Loss: 0.6816, Validation Loss: 0.6812\n",
      "Epoch 551/1000 - Train Loss: 0.6816, Validation Loss: 0.6812\n",
      "Epoch 552/1000 - Train Loss: 0.6815, Validation Loss: 0.6812\n",
      "Epoch 553/1000 - Train Loss: 0.6815, Validation Loss: 0.6812\n",
      "Epoch 554/1000 - Train Loss: 0.6815, Validation Loss: 0.6812\n",
      "Epoch 555/1000 - Train Loss: 0.6815, Validation Loss: 0.6811\n",
      "Epoch 556/1000 - Train Loss: 0.6815, Validation Loss: 0.6811\n",
      "Epoch 557/1000 - Train Loss: 0.6814, Validation Loss: 0.6811\n",
      "Epoch 558/1000 - Train Loss: 0.6814, Validation Loss: 0.6811\n",
      "Epoch 559/1000 - Train Loss: 0.6814, Validation Loss: 0.6811\n",
      "Epoch 560/1000 - Train Loss: 0.6814, Validation Loss: 0.6810\n",
      "Epoch 561/1000 - Train Loss: 0.6814, Validation Loss: 0.6810\n",
      "Epoch 562/1000 - Train Loss: 0.6813, Validation Loss: 0.6810\n",
      "Epoch 563/1000 - Train Loss: 0.6813, Validation Loss: 0.6810\n",
      "Epoch 564/1000 - Train Loss: 0.6813, Validation Loss: 0.6809\n",
      "Epoch 565/1000 - Train Loss: 0.6813, Validation Loss: 0.6809\n",
      "Epoch 566/1000 - Train Loss: 0.6813, Validation Loss: 0.6809\n",
      "Epoch 567/1000 - Train Loss: 0.6812, Validation Loss: 0.6809\n",
      "Epoch 568/1000 - Train Loss: 0.6812, Validation Loss: 0.6809\n",
      "Epoch 569/1000 - Train Loss: 0.6812, Validation Loss: 0.6808\n",
      "Epoch 570/1000 - Train Loss: 0.6812, Validation Loss: 0.6808\n",
      "Epoch 571/1000 - Train Loss: 0.6812, Validation Loss: 0.6808\n",
      "Epoch 572/1000 - Train Loss: 0.6811, Validation Loss: 0.6808\n",
      "Epoch 573/1000 - Train Loss: 0.6811, Validation Loss: 0.6808\n",
      "Epoch 574/1000 - Train Loss: 0.6811, Validation Loss: 0.6807\n",
      "Epoch 575/1000 - Train Loss: 0.6811, Validation Loss: 0.6807\n",
      "Epoch 576/1000 - Train Loss: 0.6811, Validation Loss: 0.6807\n",
      "Epoch 577/1000 - Train Loss: 0.6810, Validation Loss: 0.6807\n",
      "Epoch 578/1000 - Train Loss: 0.6810, Validation Loss: 0.6807\n",
      "Epoch 579/1000 - Train Loss: 0.6810, Validation Loss: 0.6806\n",
      "Epoch 580/1000 - Train Loss: 0.6810, Validation Loss: 0.6806\n",
      "Epoch 581/1000 - Train Loss: 0.6810, Validation Loss: 0.6806\n",
      "Epoch 582/1000 - Train Loss: 0.6809, Validation Loss: 0.6806\n",
      "Epoch 583/1000 - Train Loss: 0.6809, Validation Loss: 0.6806\n",
      "Epoch 584/1000 - Train Loss: 0.6809, Validation Loss: 0.6805\n",
      "Epoch 585/1000 - Train Loss: 0.6809, Validation Loss: 0.6805\n",
      "Epoch 586/1000 - Train Loss: 0.6809, Validation Loss: 0.6805\n",
      "Epoch 587/1000 - Train Loss: 0.6808, Validation Loss: 0.6805\n",
      "Epoch 588/1000 - Train Loss: 0.6808, Validation Loss: 0.6804\n",
      "Epoch 589/1000 - Train Loss: 0.6808, Validation Loss: 0.6804\n",
      "Epoch 590/1000 - Train Loss: 0.6808, Validation Loss: 0.6804\n",
      "Epoch 591/1000 - Train Loss: 0.6808, Validation Loss: 0.6804\n",
      "Epoch 592/1000 - Train Loss: 0.6807, Validation Loss: 0.6804\n",
      "Epoch 593/1000 - Train Loss: 0.6807, Validation Loss: 0.6803\n",
      "Epoch 594/1000 - Train Loss: 0.6807, Validation Loss: 0.6803\n",
      "Epoch 595/1000 - Train Loss: 0.6807, Validation Loss: 0.6803\n",
      "Epoch 596/1000 - Train Loss: 0.6807, Validation Loss: 0.6803\n",
      "Epoch 597/1000 - Train Loss: 0.6806, Validation Loss: 0.6803\n",
      "Epoch 598/1000 - Train Loss: 0.6806, Validation Loss: 0.6802\n",
      "Epoch 599/1000 - Train Loss: 0.6806, Validation Loss: 0.6802\n",
      "Epoch 600/1000 - Train Loss: 0.6806, Validation Loss: 0.6802\n",
      "Epoch 601/1000 - Train Loss: 0.6806, Validation Loss: 0.6802\n",
      "Epoch 602/1000 - Train Loss: 0.6805, Validation Loss: 0.6802\n",
      "Epoch 603/1000 - Train Loss: 0.6805, Validation Loss: 0.6801\n",
      "Epoch 604/1000 - Train Loss: 0.6805, Validation Loss: 0.6801\n",
      "Epoch 605/1000 - Train Loss: 0.6805, Validation Loss: 0.6801\n",
      "Epoch 606/1000 - Train Loss: 0.6805, Validation Loss: 0.6801\n",
      "Epoch 607/1000 - Train Loss: 0.6804, Validation Loss: 0.6801\n",
      "Epoch 608/1000 - Train Loss: 0.6804, Validation Loss: 0.6800\n",
      "Epoch 609/1000 - Train Loss: 0.6804, Validation Loss: 0.6800\n",
      "Epoch 610/1000 - Train Loss: 0.6804, Validation Loss: 0.6800\n",
      "Epoch 611/1000 - Train Loss: 0.6804, Validation Loss: 0.6800\n",
      "Epoch 612/1000 - Train Loss: 0.6803, Validation Loss: 0.6799\n",
      "Epoch 613/1000 - Train Loss: 0.6803, Validation Loss: 0.6799\n",
      "Epoch 614/1000 - Train Loss: 0.6803, Validation Loss: 0.6799\n",
      "Epoch 615/1000 - Train Loss: 0.6803, Validation Loss: 0.6799\n",
      "Epoch 616/1000 - Train Loss: 0.6803, Validation Loss: 0.6799\n",
      "Epoch 617/1000 - Train Loss: 0.6802, Validation Loss: 0.6798\n",
      "Epoch 618/1000 - Train Loss: 0.6802, Validation Loss: 0.6798\n",
      "Epoch 619/1000 - Train Loss: 0.6802, Validation Loss: 0.6798\n",
      "Epoch 620/1000 - Train Loss: 0.6802, Validation Loss: 0.6798\n",
      "Epoch 621/1000 - Train Loss: 0.6802, Validation Loss: 0.6798\n",
      "Epoch 622/1000 - Train Loss: 0.6801, Validation Loss: 0.6797\n",
      "Epoch 623/1000 - Train Loss: 0.6801, Validation Loss: 0.6797\n",
      "Epoch 624/1000 - Train Loss: 0.6801, Validation Loss: 0.6797\n",
      "Epoch 625/1000 - Train Loss: 0.6801, Validation Loss: 0.6797\n",
      "Epoch 626/1000 - Train Loss: 0.6800, Validation Loss: 0.6797\n",
      "Epoch 627/1000 - Train Loss: 0.6800, Validation Loss: 0.6796\n",
      "Epoch 628/1000 - Train Loss: 0.6800, Validation Loss: 0.6796\n",
      "Epoch 629/1000 - Train Loss: 0.6800, Validation Loss: 0.6796\n",
      "Epoch 630/1000 - Train Loss: 0.6800, Validation Loss: 0.6796\n",
      "Epoch 631/1000 - Train Loss: 0.6799, Validation Loss: 0.6796\n",
      "Epoch 632/1000 - Train Loss: 0.6799, Validation Loss: 0.6795\n",
      "Epoch 633/1000 - Train Loss: 0.6799, Validation Loss: 0.6795\n",
      "Epoch 634/1000 - Train Loss: 0.6799, Validation Loss: 0.6795\n",
      "Epoch 635/1000 - Train Loss: 0.6799, Validation Loss: 0.6795\n",
      "Epoch 636/1000 - Train Loss: 0.6798, Validation Loss: 0.6795\n",
      "Epoch 637/1000 - Train Loss: 0.6798, Validation Loss: 0.6794\n",
      "Epoch 638/1000 - Train Loss: 0.6798, Validation Loss: 0.6794\n",
      "Epoch 639/1000 - Train Loss: 0.6798, Validation Loss: 0.6794\n",
      "Epoch 640/1000 - Train Loss: 0.6798, Validation Loss: 0.6794\n",
      "Epoch 641/1000 - Train Loss: 0.6797, Validation Loss: 0.6793\n",
      "Epoch 642/1000 - Train Loss: 0.6797, Validation Loss: 0.6793\n",
      "Epoch 643/1000 - Train Loss: 0.6797, Validation Loss: 0.6793\n",
      "Epoch 644/1000 - Train Loss: 0.6797, Validation Loss: 0.6793\n",
      "Epoch 645/1000 - Train Loss: 0.6797, Validation Loss: 0.6793\n",
      "Epoch 646/1000 - Train Loss: 0.6796, Validation Loss: 0.6792\n",
      "Epoch 647/1000 - Train Loss: 0.6796, Validation Loss: 0.6792\n",
      "Epoch 648/1000 - Train Loss: 0.6796, Validation Loss: 0.6792\n",
      "Epoch 649/1000 - Train Loss: 0.6796, Validation Loss: 0.6792\n",
      "Epoch 650/1000 - Train Loss: 0.6796, Validation Loss: 0.6792\n",
      "Epoch 651/1000 - Train Loss: 0.6795, Validation Loss: 0.6791\n",
      "Epoch 652/1000 - Train Loss: 0.6795, Validation Loss: 0.6791\n",
      "Epoch 653/1000 - Train Loss: 0.6795, Validation Loss: 0.6791\n",
      "Epoch 654/1000 - Train Loss: 0.6795, Validation Loss: 0.6791\n",
      "Epoch 655/1000 - Train Loss: 0.6795, Validation Loss: 0.6791\n",
      "Epoch 656/1000 - Train Loss: 0.6794, Validation Loss: 0.6790\n",
      "Epoch 657/1000 - Train Loss: 0.6794, Validation Loss: 0.6790\n",
      "Epoch 658/1000 - Train Loss: 0.6794, Validation Loss: 0.6790\n",
      "Epoch 659/1000 - Train Loss: 0.6794, Validation Loss: 0.6790\n",
      "Epoch 660/1000 - Train Loss: 0.6794, Validation Loss: 0.6790\n",
      "Epoch 661/1000 - Train Loss: 0.6793, Validation Loss: 0.6789\n",
      "Epoch 662/1000 - Train Loss: 0.6793, Validation Loss: 0.6789\n",
      "Epoch 663/1000 - Train Loss: 0.6793, Validation Loss: 0.6789\n",
      "Epoch 664/1000 - Train Loss: 0.6793, Validation Loss: 0.6789\n",
      "Epoch 665/1000 - Train Loss: 0.6793, Validation Loss: 0.6789\n",
      "Epoch 666/1000 - Train Loss: 0.6792, Validation Loss: 0.6788\n",
      "Epoch 667/1000 - Train Loss: 0.6792, Validation Loss: 0.6788\n",
      "Epoch 668/1000 - Train Loss: 0.6792, Validation Loss: 0.6788\n",
      "Epoch 669/1000 - Train Loss: 0.6792, Validation Loss: 0.6788\n",
      "Epoch 670/1000 - Train Loss: 0.6792, Validation Loss: 0.6788\n",
      "Epoch 671/1000 - Train Loss: 0.6791, Validation Loss: 0.6787\n",
      "Epoch 672/1000 - Train Loss: 0.6791, Validation Loss: 0.6787\n",
      "Epoch 673/1000 - Train Loss: 0.6791, Validation Loss: 0.6787\n",
      "Epoch 674/1000 - Train Loss: 0.6791, Validation Loss: 0.6787\n",
      "Epoch 675/1000 - Train Loss: 0.6791, Validation Loss: 0.6786\n",
      "Epoch 676/1000 - Train Loss: 0.6790, Validation Loss: 0.6786\n",
      "Epoch 677/1000 - Train Loss: 0.6790, Validation Loss: 0.6786\n",
      "Epoch 678/1000 - Train Loss: 0.6790, Validation Loss: 0.6786\n",
      "Epoch 679/1000 - Train Loss: 0.6790, Validation Loss: 0.6786\n",
      "Epoch 680/1000 - Train Loss: 0.6790, Validation Loss: 0.6785\n",
      "Epoch 681/1000 - Train Loss: 0.6789, Validation Loss: 0.6785\n",
      "Epoch 682/1000 - Train Loss: 0.6789, Validation Loss: 0.6785\n",
      "Epoch 683/1000 - Train Loss: 0.6789, Validation Loss: 0.6785\n",
      "Epoch 684/1000 - Train Loss: 0.6789, Validation Loss: 0.6785\n",
      "Epoch 685/1000 - Train Loss: 0.6789, Validation Loss: 0.6784\n",
      "Epoch 686/1000 - Train Loss: 0.6788, Validation Loss: 0.6784\n",
      "Epoch 687/1000 - Train Loss: 0.6788, Validation Loss: 0.6784\n",
      "Epoch 688/1000 - Train Loss: 0.6788, Validation Loss: 0.6784\n",
      "Epoch 689/1000 - Train Loss: 0.6788, Validation Loss: 0.6784\n",
      "Epoch 690/1000 - Train Loss: 0.6788, Validation Loss: 0.6783\n",
      "Epoch 691/1000 - Train Loss: 0.6787, Validation Loss: 0.6783\n",
      "Epoch 692/1000 - Train Loss: 0.6787, Validation Loss: 0.6783\n",
      "Epoch 693/1000 - Train Loss: 0.6787, Validation Loss: 0.6783\n",
      "Epoch 694/1000 - Train Loss: 0.6787, Validation Loss: 0.6783\n",
      "Epoch 695/1000 - Train Loss: 0.6787, Validation Loss: 0.6782\n",
      "Epoch 696/1000 - Train Loss: 0.6786, Validation Loss: 0.6782\n",
      "Epoch 697/1000 - Train Loss: 0.6786, Validation Loss: 0.6782\n",
      "Epoch 698/1000 - Train Loss: 0.6786, Validation Loss: 0.6782\n",
      "Epoch 699/1000 - Train Loss: 0.6786, Validation Loss: 0.6782\n",
      "Epoch 700/1000 - Train Loss: 0.6786, Validation Loss: 0.6781\n",
      "Epoch 701/1000 - Train Loss: 0.6785, Validation Loss: 0.6781\n",
      "Epoch 702/1000 - Train Loss: 0.6785, Validation Loss: 0.6781\n",
      "Epoch 703/1000 - Train Loss: 0.6785, Validation Loss: 0.6781\n",
      "Epoch 704/1000 - Train Loss: 0.6785, Validation Loss: 0.6781\n",
      "Epoch 705/1000 - Train Loss: 0.6785, Validation Loss: 0.6780\n",
      "Epoch 706/1000 - Train Loss: 0.6784, Validation Loss: 0.6780\n",
      "Epoch 707/1000 - Train Loss: 0.6784, Validation Loss: 0.6780\n",
      "Epoch 708/1000 - Train Loss: 0.6784, Validation Loss: 0.6780\n",
      "Epoch 709/1000 - Train Loss: 0.6784, Validation Loss: 0.6779\n",
      "Epoch 710/1000 - Train Loss: 0.6784, Validation Loss: 0.6779\n",
      "Epoch 711/1000 - Train Loss: 0.6783, Validation Loss: 0.6779\n",
      "Epoch 712/1000 - Train Loss: 0.6783, Validation Loss: 0.6779\n",
      "Epoch 713/1000 - Train Loss: 0.6783, Validation Loss: 0.6779\n",
      "Epoch 714/1000 - Train Loss: 0.6783, Validation Loss: 0.6778\n",
      "Epoch 715/1000 - Train Loss: 0.6783, Validation Loss: 0.6778\n",
      "Epoch 716/1000 - Train Loss: 0.6782, Validation Loss: 0.6778\n",
      "Epoch 717/1000 - Train Loss: 0.6782, Validation Loss: 0.6778\n",
      "Epoch 718/1000 - Train Loss: 0.6782, Validation Loss: 0.6778\n",
      "Epoch 719/1000 - Train Loss: 0.6782, Validation Loss: 0.6777\n",
      "Epoch 720/1000 - Train Loss: 0.6782, Validation Loss: 0.6777\n",
      "Epoch 721/1000 - Train Loss: 0.6781, Validation Loss: 0.6777\n",
      "Epoch 722/1000 - Train Loss: 0.6781, Validation Loss: 0.6777\n",
      "Epoch 723/1000 - Train Loss: 0.6781, Validation Loss: 0.6777\n",
      "Epoch 724/1000 - Train Loss: 0.6781, Validation Loss: 0.6776\n",
      "Epoch 725/1000 - Train Loss: 0.6781, Validation Loss: 0.6776\n",
      "Epoch 726/1000 - Train Loss: 0.6780, Validation Loss: 0.6776\n",
      "Epoch 727/1000 - Train Loss: 0.6780, Validation Loss: 0.6776\n",
      "Epoch 728/1000 - Train Loss: 0.6780, Validation Loss: 0.6776\n",
      "Epoch 729/1000 - Train Loss: 0.6780, Validation Loss: 0.6775\n",
      "Epoch 730/1000 - Train Loss: 0.6780, Validation Loss: 0.6775\n",
      "Epoch 731/1000 - Train Loss: 0.6779, Validation Loss: 0.6775\n",
      "Epoch 732/1000 - Train Loss: 0.6779, Validation Loss: 0.6775\n",
      "Epoch 733/1000 - Train Loss: 0.6779, Validation Loss: 0.6775\n",
      "Epoch 734/1000 - Train Loss: 0.6779, Validation Loss: 0.6774\n",
      "Epoch 735/1000 - Train Loss: 0.6779, Validation Loss: 0.6774\n",
      "Epoch 736/1000 - Train Loss: 0.6778, Validation Loss: 0.6774\n",
      "Epoch 737/1000 - Train Loss: 0.6778, Validation Loss: 0.6774\n",
      "Epoch 738/1000 - Train Loss: 0.6778, Validation Loss: 0.6774\n",
      "Epoch 739/1000 - Train Loss: 0.6778, Validation Loss: 0.6773\n",
      "Epoch 740/1000 - Train Loss: 0.6778, Validation Loss: 0.6773\n",
      "Epoch 741/1000 - Train Loss: 0.6777, Validation Loss: 0.6773\n",
      "Epoch 742/1000 - Train Loss: 0.6777, Validation Loss: 0.6773\n",
      "Epoch 743/1000 - Train Loss: 0.6777, Validation Loss: 0.6773\n",
      "Epoch 744/1000 - Train Loss: 0.6777, Validation Loss: 0.6772\n",
      "Epoch 745/1000 - Train Loss: 0.6777, Validation Loss: 0.6772\n",
      "Epoch 746/1000 - Train Loss: 0.6776, Validation Loss: 0.6772\n",
      "Epoch 747/1000 - Train Loss: 0.6776, Validation Loss: 0.6772\n",
      "Epoch 748/1000 - Train Loss: 0.6776, Validation Loss: 0.6772\n",
      "Epoch 749/1000 - Train Loss: 0.6776, Validation Loss: 0.6771\n",
      "Epoch 750/1000 - Train Loss: 0.6776, Validation Loss: 0.6771\n",
      "Epoch 751/1000 - Train Loss: 0.6775, Validation Loss: 0.6771\n",
      "Epoch 752/1000 - Train Loss: 0.6775, Validation Loss: 0.6771\n",
      "Epoch 753/1000 - Train Loss: 0.6775, Validation Loss: 0.6770\n",
      "Epoch 754/1000 - Train Loss: 0.6775, Validation Loss: 0.6770\n",
      "Epoch 755/1000 - Train Loss: 0.6775, Validation Loss: 0.6770\n",
      "Epoch 756/1000 - Train Loss: 0.6774, Validation Loss: 0.6770\n",
      "Epoch 757/1000 - Train Loss: 0.6774, Validation Loss: 0.6770\n",
      "Epoch 758/1000 - Train Loss: 0.6774, Validation Loss: 0.6769\n",
      "Epoch 759/1000 - Train Loss: 0.6774, Validation Loss: 0.6769\n",
      "Epoch 760/1000 - Train Loss: 0.6774, Validation Loss: 0.6769\n",
      "Epoch 761/1000 - Train Loss: 0.6773, Validation Loss: 0.6769\n",
      "Epoch 762/1000 - Train Loss: 0.6773, Validation Loss: 0.6769\n",
      "Epoch 763/1000 - Train Loss: 0.6773, Validation Loss: 0.6768\n",
      "Epoch 764/1000 - Train Loss: 0.6773, Validation Loss: 0.6768\n",
      "Epoch 765/1000 - Train Loss: 0.6773, Validation Loss: 0.6768\n",
      "Epoch 766/1000 - Train Loss: 0.6772, Validation Loss: 0.6768\n",
      "Epoch 767/1000 - Train Loss: 0.6772, Validation Loss: 0.6768\n",
      "Epoch 768/1000 - Train Loss: 0.6772, Validation Loss: 0.6767\n",
      "Epoch 769/1000 - Train Loss: 0.6772, Validation Loss: 0.6767\n",
      "Epoch 770/1000 - Train Loss: 0.6772, Validation Loss: 0.6767\n",
      "Epoch 771/1000 - Train Loss: 0.6771, Validation Loss: 0.6767\n",
      "Epoch 772/1000 - Train Loss: 0.6771, Validation Loss: 0.6767\n",
      "Epoch 773/1000 - Train Loss: 0.6771, Validation Loss: 0.6766\n",
      "Epoch 774/1000 - Train Loss: 0.6771, Validation Loss: 0.6766\n",
      "Epoch 775/1000 - Train Loss: 0.6771, Validation Loss: 0.6766\n",
      "Epoch 776/1000 - Train Loss: 0.6770, Validation Loss: 0.6766\n",
      "Epoch 777/1000 - Train Loss: 0.6770, Validation Loss: 0.6766\n",
      "Epoch 778/1000 - Train Loss: 0.6770, Validation Loss: 0.6765\n",
      "Epoch 779/1000 - Train Loss: 0.6770, Validation Loss: 0.6765\n",
      "Epoch 780/1000 - Train Loss: 0.6770, Validation Loss: 0.6765\n",
      "Epoch 781/1000 - Train Loss: 0.6769, Validation Loss: 0.6765\n",
      "Epoch 782/1000 - Train Loss: 0.6769, Validation Loss: 0.6765\n",
      "Epoch 783/1000 - Train Loss: 0.6769, Validation Loss: 0.6764\n",
      "Epoch 784/1000 - Train Loss: 0.6769, Validation Loss: 0.6764\n",
      "Epoch 785/1000 - Train Loss: 0.6769, Validation Loss: 0.6764\n",
      "Epoch 786/1000 - Train Loss: 0.6769, Validation Loss: 0.6764\n",
      "Epoch 787/1000 - Train Loss: 0.6768, Validation Loss: 0.6764\n",
      "Epoch 788/1000 - Train Loss: 0.6768, Validation Loss: 0.6763\n",
      "Epoch 789/1000 - Train Loss: 0.6768, Validation Loss: 0.6763\n",
      "Epoch 790/1000 - Train Loss: 0.6768, Validation Loss: 0.6763\n",
      "Epoch 791/1000 - Train Loss: 0.6768, Validation Loss: 0.6763\n",
      "Epoch 792/1000 - Train Loss: 0.6767, Validation Loss: 0.6763\n",
      "Epoch 793/1000 - Train Loss: 0.6767, Validation Loss: 0.6762\n",
      "Epoch 794/1000 - Train Loss: 0.6767, Validation Loss: 0.6762\n",
      "Epoch 795/1000 - Train Loss: 0.6767, Validation Loss: 0.6762\n",
      "Epoch 796/1000 - Train Loss: 0.6767, Validation Loss: 0.6762\n",
      "Epoch 797/1000 - Train Loss: 0.6766, Validation Loss: 0.6762\n",
      "Epoch 798/1000 - Train Loss: 0.6766, Validation Loss: 0.6761\n",
      "Epoch 799/1000 - Train Loss: 0.6766, Validation Loss: 0.6761\n",
      "Epoch 800/1000 - Train Loss: 0.6766, Validation Loss: 0.6761\n",
      "Epoch 801/1000 - Train Loss: 0.6766, Validation Loss: 0.6761\n",
      "Epoch 802/1000 - Train Loss: 0.6765, Validation Loss: 0.6761\n",
      "Epoch 803/1000 - Train Loss: 0.6765, Validation Loss: 0.6760\n",
      "Epoch 804/1000 - Train Loss: 0.6765, Validation Loss: 0.6760\n",
      "Epoch 805/1000 - Train Loss: 0.6765, Validation Loss: 0.6760\n",
      "Epoch 806/1000 - Train Loss: 0.6765, Validation Loss: 0.6760\n",
      "Epoch 807/1000 - Train Loss: 0.6764, Validation Loss: 0.6760\n",
      "Epoch 808/1000 - Train Loss: 0.6764, Validation Loss: 0.6759\n",
      "Epoch 809/1000 - Train Loss: 0.6764, Validation Loss: 0.6759\n",
      "Epoch 810/1000 - Train Loss: 0.6764, Validation Loss: 0.6759\n",
      "Epoch 811/1000 - Train Loss: 0.6764, Validation Loss: 0.6759\n",
      "Epoch 812/1000 - Train Loss: 0.6763, Validation Loss: 0.6758\n",
      "Epoch 813/1000 - Train Loss: 0.6763, Validation Loss: 0.6758\n",
      "Epoch 814/1000 - Train Loss: 0.6763, Validation Loss: 0.6758\n",
      "Epoch 815/1000 - Train Loss: 0.6763, Validation Loss: 0.6758\n",
      "Epoch 816/1000 - Train Loss: 0.6763, Validation Loss: 0.6758\n",
      "Epoch 817/1000 - Train Loss: 0.6762, Validation Loss: 0.6757\n",
      "Epoch 818/1000 - Train Loss: 0.6762, Validation Loss: 0.6757\n",
      "Epoch 819/1000 - Train Loss: 0.6762, Validation Loss: 0.6757\n",
      "Epoch 820/1000 - Train Loss: 0.6762, Validation Loss: 0.6757\n",
      "Epoch 821/1000 - Train Loss: 0.6762, Validation Loss: 0.6757\n",
      "Epoch 822/1000 - Train Loss: 0.6761, Validation Loss: 0.6756\n",
      "Epoch 823/1000 - Train Loss: 0.6761, Validation Loss: 0.6756\n",
      "Epoch 824/1000 - Train Loss: 0.6761, Validation Loss: 0.6756\n",
      "Epoch 825/1000 - Train Loss: 0.6761, Validation Loss: 0.6756\n",
      "Epoch 826/1000 - Train Loss: 0.6761, Validation Loss: 0.6756\n",
      "Epoch 827/1000 - Train Loss: 0.6760, Validation Loss: 0.6755\n",
      "Epoch 828/1000 - Train Loss: 0.6760, Validation Loss: 0.6755\n",
      "Epoch 829/1000 - Train Loss: 0.6760, Validation Loss: 0.6755\n",
      "Epoch 830/1000 - Train Loss: 0.6760, Validation Loss: 0.6755\n",
      "Epoch 831/1000 - Train Loss: 0.6760, Validation Loss: 0.6755\n",
      "Epoch 832/1000 - Train Loss: 0.6759, Validation Loss: 0.6754\n",
      "Epoch 833/1000 - Train Loss: 0.6759, Validation Loss: 0.6754\n",
      "Epoch 834/1000 - Train Loss: 0.6759, Validation Loss: 0.6754\n",
      "Epoch 835/1000 - Train Loss: 0.6759, Validation Loss: 0.6754\n",
      "Epoch 836/1000 - Train Loss: 0.6759, Validation Loss: 0.6754\n",
      "Epoch 837/1000 - Train Loss: 0.6758, Validation Loss: 0.6753\n",
      "Epoch 838/1000 - Train Loss: 0.6758, Validation Loss: 0.6753\n",
      "Epoch 839/1000 - Train Loss: 0.6758, Validation Loss: 0.6753\n",
      "Epoch 840/1000 - Train Loss: 0.6758, Validation Loss: 0.6753\n",
      "Epoch 841/1000 - Train Loss: 0.6758, Validation Loss: 0.6753\n",
      "Epoch 842/1000 - Train Loss: 0.6757, Validation Loss: 0.6752\n",
      "Epoch 843/1000 - Train Loss: 0.6757, Validation Loss: 0.6752\n",
      "Epoch 844/1000 - Train Loss: 0.6757, Validation Loss: 0.6752\n",
      "Epoch 845/1000 - Train Loss: 0.6757, Validation Loss: 0.6752\n",
      "Epoch 846/1000 - Train Loss: 0.6757, Validation Loss: 0.6752\n",
      "Epoch 847/1000 - Train Loss: 0.6756, Validation Loss: 0.6751\n",
      "Epoch 848/1000 - Train Loss: 0.6756, Validation Loss: 0.6751\n",
      "Epoch 849/1000 - Train Loss: 0.6756, Validation Loss: 0.6751\n",
      "Epoch 850/1000 - Train Loss: 0.6756, Validation Loss: 0.6751\n",
      "Epoch 851/1000 - Train Loss: 0.6756, Validation Loss: 0.6751\n",
      "Epoch 852/1000 - Train Loss: 0.6755, Validation Loss: 0.6750\n",
      "Epoch 853/1000 - Train Loss: 0.6755, Validation Loss: 0.6750\n",
      "Epoch 854/1000 - Train Loss: 0.6755, Validation Loss: 0.6750\n",
      "Epoch 855/1000 - Train Loss: 0.6755, Validation Loss: 0.6750\n",
      "Epoch 856/1000 - Train Loss: 0.6755, Validation Loss: 0.6750\n",
      "Epoch 857/1000 - Train Loss: 0.6754, Validation Loss: 0.6749\n",
      "Epoch 858/1000 - Train Loss: 0.6754, Validation Loss: 0.6749\n",
      "Epoch 859/1000 - Train Loss: 0.6754, Validation Loss: 0.6749\n",
      "Epoch 860/1000 - Train Loss: 0.6754, Validation Loss: 0.6749\n",
      "Epoch 861/1000 - Train Loss: 0.6754, Validation Loss: 0.6749\n",
      "Epoch 862/1000 - Train Loss: 0.6754, Validation Loss: 0.6748\n",
      "Epoch 863/1000 - Train Loss: 0.6753, Validation Loss: 0.6748\n",
      "Epoch 864/1000 - Train Loss: 0.6753, Validation Loss: 0.6748\n",
      "Epoch 865/1000 - Train Loss: 0.6753, Validation Loss: 0.6748\n",
      "Epoch 866/1000 - Train Loss: 0.6753, Validation Loss: 0.6748\n",
      "Epoch 867/1000 - Train Loss: 0.6753, Validation Loss: 0.6747\n",
      "Epoch 868/1000 - Train Loss: 0.6752, Validation Loss: 0.6747\n",
      "Epoch 869/1000 - Train Loss: 0.6752, Validation Loss: 0.6747\n",
      "Epoch 870/1000 - Train Loss: 0.6752, Validation Loss: 0.6747\n",
      "Epoch 871/1000 - Train Loss: 0.6752, Validation Loss: 0.6747\n",
      "Epoch 872/1000 - Train Loss: 0.6752, Validation Loss: 0.6746\n",
      "Epoch 873/1000 - Train Loss: 0.6751, Validation Loss: 0.6746\n",
      "Epoch 874/1000 - Train Loss: 0.6751, Validation Loss: 0.6746\n",
      "Epoch 875/1000 - Train Loss: 0.6751, Validation Loss: 0.6746\n",
      "Epoch 876/1000 - Train Loss: 0.6751, Validation Loss: 0.6746\n",
      "Epoch 877/1000 - Train Loss: 0.6751, Validation Loss: 0.6745\n",
      "Epoch 878/1000 - Train Loss: 0.6750, Validation Loss: 0.6745\n",
      "Epoch 879/1000 - Train Loss: 0.6750, Validation Loss: 0.6745\n",
      "Epoch 880/1000 - Train Loss: 0.6750, Validation Loss: 0.6745\n",
      "Epoch 881/1000 - Train Loss: 0.6750, Validation Loss: 0.6745\n",
      "Epoch 882/1000 - Train Loss: 0.6750, Validation Loss: 0.6744\n",
      "Epoch 883/1000 - Train Loss: 0.6749, Validation Loss: 0.6744\n",
      "Epoch 884/1000 - Train Loss: 0.6749, Validation Loss: 0.6744\n",
      "Epoch 885/1000 - Train Loss: 0.6749, Validation Loss: 0.6744\n",
      "Epoch 886/1000 - Train Loss: 0.6749, Validation Loss: 0.6744\n",
      "Epoch 887/1000 - Train Loss: 0.6749, Validation Loss: 0.6743\n",
      "Epoch 888/1000 - Train Loss: 0.6748, Validation Loss: 0.6743\n",
      "Epoch 889/1000 - Train Loss: 0.6748, Validation Loss: 0.6743\n",
      "Epoch 890/1000 - Train Loss: 0.6748, Validation Loss: 0.6743\n",
      "Epoch 891/1000 - Train Loss: 0.6748, Validation Loss: 0.6743\n",
      "Epoch 892/1000 - Train Loss: 0.6748, Validation Loss: 0.6742\n",
      "Epoch 893/1000 - Train Loss: 0.6747, Validation Loss: 0.6742\n",
      "Epoch 894/1000 - Train Loss: 0.6747, Validation Loss: 0.6742\n",
      "Epoch 895/1000 - Train Loss: 0.6747, Validation Loss: 0.6742\n",
      "Epoch 896/1000 - Train Loss: 0.6747, Validation Loss: 0.6742\n",
      "Epoch 897/1000 - Train Loss: 0.6747, Validation Loss: 0.6741\n",
      "Epoch 898/1000 - Train Loss: 0.6746, Validation Loss: 0.6741\n",
      "Epoch 899/1000 - Train Loss: 0.6746, Validation Loss: 0.6741\n",
      "Epoch 900/1000 - Train Loss: 0.6746, Validation Loss: 0.6741\n",
      "Epoch 901/1000 - Train Loss: 0.6746, Validation Loss: 0.6741\n",
      "Epoch 902/1000 - Train Loss: 0.6746, Validation Loss: 0.6740\n",
      "Epoch 903/1000 - Train Loss: 0.6745, Validation Loss: 0.6740\n",
      "Epoch 904/1000 - Train Loss: 0.6745, Validation Loss: 0.6740\n",
      "Epoch 905/1000 - Train Loss: 0.6745, Validation Loss: 0.6740\n",
      "Epoch 906/1000 - Train Loss: 0.6745, Validation Loss: 0.6740\n",
      "Epoch 907/1000 - Train Loss: 0.6745, Validation Loss: 0.6739\n",
      "Epoch 908/1000 - Train Loss: 0.6744, Validation Loss: 0.6739\n",
      "Epoch 909/1000 - Train Loss: 0.6744, Validation Loss: 0.6739\n",
      "Epoch 910/1000 - Train Loss: 0.6744, Validation Loss: 0.6739\n",
      "Epoch 911/1000 - Train Loss: 0.6744, Validation Loss: 0.6739\n",
      "Epoch 912/1000 - Train Loss: 0.6744, Validation Loss: 0.6738\n",
      "Epoch 913/1000 - Train Loss: 0.6744, Validation Loss: 0.6738\n",
      "Epoch 914/1000 - Train Loss: 0.6743, Validation Loss: 0.6738\n",
      "Epoch 915/1000 - Train Loss: 0.6743, Validation Loss: 0.6738\n",
      "Epoch 916/1000 - Train Loss: 0.6743, Validation Loss: 0.6738\n",
      "Epoch 917/1000 - Train Loss: 0.6743, Validation Loss: 0.6737\n",
      "Epoch 918/1000 - Train Loss: 0.6743, Validation Loss: 0.6737\n",
      "Epoch 919/1000 - Train Loss: 0.6742, Validation Loss: 0.6737\n",
      "Epoch 920/1000 - Train Loss: 0.6742, Validation Loss: 0.6737\n",
      "Epoch 921/1000 - Train Loss: 0.6742, Validation Loss: 0.6737\n",
      "Epoch 922/1000 - Train Loss: 0.6742, Validation Loss: 0.6736\n",
      "Epoch 923/1000 - Train Loss: 0.6742, Validation Loss: 0.6736\n",
      "Epoch 924/1000 - Train Loss: 0.6741, Validation Loss: 0.6736\n",
      "Epoch 925/1000 - Train Loss: 0.6741, Validation Loss: 0.6736\n",
      "Epoch 926/1000 - Train Loss: 0.6741, Validation Loss: 0.6736\n",
      "Epoch 927/1000 - Train Loss: 0.6741, Validation Loss: 0.6735\n",
      "Epoch 928/1000 - Train Loss: 0.6741, Validation Loss: 0.6735\n",
      "Epoch 929/1000 - Train Loss: 0.6740, Validation Loss: 0.6735\n",
      "Epoch 930/1000 - Train Loss: 0.6740, Validation Loss: 0.6735\n",
      "Epoch 931/1000 - Train Loss: 0.6740, Validation Loss: 0.6735\n",
      "Epoch 932/1000 - Train Loss: 0.6740, Validation Loss: 0.6734\n",
      "Epoch 933/1000 - Train Loss: 0.6740, Validation Loss: 0.6734\n",
      "Epoch 934/1000 - Train Loss: 0.6739, Validation Loss: 0.6734\n",
      "Epoch 935/1000 - Train Loss: 0.6739, Validation Loss: 0.6734\n",
      "Epoch 936/1000 - Train Loss: 0.6739, Validation Loss: 0.6734\n",
      "Epoch 937/1000 - Train Loss: 0.6739, Validation Loss: 0.6733\n",
      "Epoch 938/1000 - Train Loss: 0.6739, Validation Loss: 0.6733\n",
      "Epoch 939/1000 - Train Loss: 0.6738, Validation Loss: 0.6733\n",
      "Epoch 940/1000 - Train Loss: 0.6738, Validation Loss: 0.6733\n",
      "Epoch 941/1000 - Train Loss: 0.6738, Validation Loss: 0.6733\n",
      "Epoch 942/1000 - Train Loss: 0.6738, Validation Loss: 0.6732\n",
      "Epoch 943/1000 - Train Loss: 0.6738, Validation Loss: 0.6732\n",
      "Epoch 944/1000 - Train Loss: 0.6737, Validation Loss: 0.6732\n",
      "Epoch 945/1000 - Train Loss: 0.6737, Validation Loss: 0.6732\n",
      "Epoch 946/1000 - Train Loss: 0.6737, Validation Loss: 0.6732\n",
      "Epoch 947/1000 - Train Loss: 0.6737, Validation Loss: 0.6731\n",
      "Epoch 948/1000 - Train Loss: 0.6737, Validation Loss: 0.6731\n",
      "Epoch 949/1000 - Train Loss: 0.6736, Validation Loss: 0.6731\n",
      "Epoch 950/1000 - Train Loss: 0.6736, Validation Loss: 0.6731\n",
      "Epoch 951/1000 - Train Loss: 0.6736, Validation Loss: 0.6731\n",
      "Epoch 952/1000 - Train Loss: 0.6736, Validation Loss: 0.6730\n",
      "Epoch 953/1000 - Train Loss: 0.6736, Validation Loss: 0.6730\n",
      "Epoch 954/1000 - Train Loss: 0.6736, Validation Loss: 0.6730\n",
      "Epoch 955/1000 - Train Loss: 0.6735, Validation Loss: 0.6730\n",
      "Epoch 956/1000 - Train Loss: 0.6735, Validation Loss: 0.6730\n",
      "Epoch 957/1000 - Train Loss: 0.6735, Validation Loss: 0.6729\n",
      "Epoch 958/1000 - Train Loss: 0.6735, Validation Loss: 0.6729\n",
      "Epoch 959/1000 - Train Loss: 0.6735, Validation Loss: 0.6729\n",
      "Epoch 960/1000 - Train Loss: 0.6734, Validation Loss: 0.6729\n",
      "Epoch 961/1000 - Train Loss: 0.6734, Validation Loss: 0.6729\n",
      "Epoch 962/1000 - Train Loss: 0.6734, Validation Loss: 0.6728\n",
      "Epoch 963/1000 - Train Loss: 0.6734, Validation Loss: 0.6728\n",
      "Epoch 964/1000 - Train Loss: 0.6734, Validation Loss: 0.6728\n",
      "Epoch 965/1000 - Train Loss: 0.6733, Validation Loss: 0.6728\n",
      "Epoch 966/1000 - Train Loss: 0.6733, Validation Loss: 0.6728\n",
      "Epoch 967/1000 - Train Loss: 0.6733, Validation Loss: 0.6727\n",
      "Epoch 968/1000 - Train Loss: 0.6733, Validation Loss: 0.6727\n",
      "Epoch 969/1000 - Train Loss: 0.6733, Validation Loss: 0.6727\n",
      "Epoch 970/1000 - Train Loss: 0.6732, Validation Loss: 0.6727\n",
      "Epoch 971/1000 - Train Loss: 0.6732, Validation Loss: 0.6727\n",
      "Epoch 972/1000 - Train Loss: 0.6732, Validation Loss: 0.6726\n",
      "Epoch 973/1000 - Train Loss: 0.6732, Validation Loss: 0.6726\n",
      "Epoch 974/1000 - Train Loss: 0.6732, Validation Loss: 0.6726\n",
      "Epoch 975/1000 - Train Loss: 0.6731, Validation Loss: 0.6726\n",
      "Epoch 976/1000 - Train Loss: 0.6731, Validation Loss: 0.6726\n",
      "Epoch 977/1000 - Train Loss: 0.6731, Validation Loss: 0.6725\n",
      "Epoch 978/1000 - Train Loss: 0.6731, Validation Loss: 0.6725\n",
      "Epoch 979/1000 - Train Loss: 0.6731, Validation Loss: 0.6725\n",
      "Epoch 980/1000 - Train Loss: 0.6730, Validation Loss: 0.6725\n",
      "Epoch 981/1000 - Train Loss: 0.6730, Validation Loss: 0.6725\n",
      "Epoch 982/1000 - Train Loss: 0.6730, Validation Loss: 0.6724\n",
      "Epoch 983/1000 - Train Loss: 0.6730, Validation Loss: 0.6724\n",
      "Epoch 984/1000 - Train Loss: 0.6730, Validation Loss: 0.6724\n",
      "Epoch 985/1000 - Train Loss: 0.6729, Validation Loss: 0.6724\n",
      "Epoch 986/1000 - Train Loss: 0.6729, Validation Loss: 0.6724\n",
      "Epoch 987/1000 - Train Loss: 0.6729, Validation Loss: 0.6723\n",
      "Epoch 988/1000 - Train Loss: 0.6729, Validation Loss: 0.6723\n",
      "Epoch 989/1000 - Train Loss: 0.6729, Validation Loss: 0.6723\n",
      "Epoch 990/1000 - Train Loss: 0.6729, Validation Loss: 0.6723\n",
      "Epoch 991/1000 - Train Loss: 0.6728, Validation Loss: 0.6723\n",
      "Epoch 992/1000 - Train Loss: 0.6728, Validation Loss: 0.6722\n",
      "Epoch 993/1000 - Train Loss: 0.6728, Validation Loss: 0.6722\n",
      "Epoch 994/1000 - Train Loss: 0.6728, Validation Loss: 0.6722\n",
      "Epoch 995/1000 - Train Loss: 0.6728, Validation Loss: 0.6722\n",
      "Epoch 996/1000 - Train Loss: 0.6727, Validation Loss: 0.6722\n",
      "Epoch 997/1000 - Train Loss: 0.6727, Validation Loss: 0.6721\n",
      "Epoch 998/1000 - Train Loss: 0.6727, Validation Loss: 0.6721\n",
      "Epoch 999/1000 - Train Loss: 0.6727, Validation Loss: 0.6721\n",
      "Epoch 1000/1000 - Train Loss: 0.6727, Validation Loss: 0.6721\n",
      "Epoch 1/1000 - Train Loss: 0.6931, Validation Loss: 0.6931\n",
      "Epoch 2/1000 - Train Loss: 0.6931, Validation Loss: 0.6930\n",
      "Epoch 3/1000 - Train Loss: 0.6930, Validation Loss: 0.6929\n",
      "Epoch 4/1000 - Train Loss: 0.6930, Validation Loss: 0.6929\n",
      "Epoch 5/1000 - Train Loss: 0.6929, Validation Loss: 0.6928\n",
      "Epoch 6/1000 - Train Loss: 0.6928, Validation Loss: 0.6927\n",
      "Epoch 7/1000 - Train Loss: 0.6928, Validation Loss: 0.6927\n",
      "Epoch 8/1000 - Train Loss: 0.6927, Validation Loss: 0.6926\n",
      "Epoch 9/1000 - Train Loss: 0.6926, Validation Loss: 0.6925\n",
      "Epoch 10/1000 - Train Loss: 0.6926, Validation Loss: 0.6925\n",
      "Epoch 11/1000 - Train Loss: 0.6925, Validation Loss: 0.6924\n",
      "Epoch 12/1000 - Train Loss: 0.6924, Validation Loss: 0.6923\n",
      "Epoch 13/1000 - Train Loss: 0.6924, Validation Loss: 0.6923\n",
      "Epoch 14/1000 - Train Loss: 0.6923, Validation Loss: 0.6922\n",
      "Epoch 15/1000 - Train Loss: 0.6922, Validation Loss: 0.6921\n",
      "Epoch 16/1000 - Train Loss: 0.6922, Validation Loss: 0.6921\n",
      "Epoch 17/1000 - Train Loss: 0.6921, Validation Loss: 0.6920\n",
      "Epoch 18/1000 - Train Loss: 0.6920, Validation Loss: 0.6919\n",
      "Epoch 19/1000 - Train Loss: 0.6920, Validation Loss: 0.6919\n",
      "Epoch 20/1000 - Train Loss: 0.6919, Validation Loss: 0.6918\n",
      "Epoch 21/1000 - Train Loss: 0.6918, Validation Loss: 0.6917\n",
      "Epoch 22/1000 - Train Loss: 0.6918, Validation Loss: 0.6917\n",
      "Epoch 23/1000 - Train Loss: 0.6917, Validation Loss: 0.6916\n",
      "Epoch 24/1000 - Train Loss: 0.6916, Validation Loss: 0.6915\n",
      "Epoch 25/1000 - Train Loss: 0.6916, Validation Loss: 0.6915\n",
      "Epoch 26/1000 - Train Loss: 0.6915, Validation Loss: 0.6914\n",
      "Epoch 27/1000 - Train Loss: 0.6915, Validation Loss: 0.6913\n",
      "Epoch 28/1000 - Train Loss: 0.6914, Validation Loss: 0.6913\n",
      "Epoch 29/1000 - Train Loss: 0.6913, Validation Loss: 0.6912\n",
      "Epoch 30/1000 - Train Loss: 0.6913, Validation Loss: 0.6911\n",
      "Epoch 31/1000 - Train Loss: 0.6912, Validation Loss: 0.6911\n",
      "Epoch 32/1000 - Train Loss: 0.6911, Validation Loss: 0.6910\n",
      "Epoch 33/1000 - Train Loss: 0.6911, Validation Loss: 0.6909\n",
      "Epoch 34/1000 - Train Loss: 0.6910, Validation Loss: 0.6909\n",
      "Epoch 35/1000 - Train Loss: 0.6909, Validation Loss: 0.6908\n",
      "Epoch 36/1000 - Train Loss: 0.6909, Validation Loss: 0.6907\n",
      "Epoch 37/1000 - Train Loss: 0.6908, Validation Loss: 0.6907\n",
      "Epoch 38/1000 - Train Loss: 0.6907, Validation Loss: 0.6906\n",
      "Epoch 39/1000 - Train Loss: 0.6907, Validation Loss: 0.6905\n",
      "Epoch 40/1000 - Train Loss: 0.6906, Validation Loss: 0.6905\n",
      "Epoch 41/1000 - Train Loss: 0.6906, Validation Loss: 0.6904\n",
      "Epoch 42/1000 - Train Loss: 0.6905, Validation Loss: 0.6903\n",
      "Epoch 43/1000 - Train Loss: 0.6904, Validation Loss: 0.6903\n",
      "Epoch 44/1000 - Train Loss: 0.6904, Validation Loss: 0.6902\n",
      "Epoch 45/1000 - Train Loss: 0.6903, Validation Loss: 0.6901\n",
      "Epoch 46/1000 - Train Loss: 0.6902, Validation Loss: 0.6901\n",
      "Epoch 47/1000 - Train Loss: 0.6902, Validation Loss: 0.6900\n",
      "Epoch 48/1000 - Train Loss: 0.6901, Validation Loss: 0.6899\n",
      "Epoch 49/1000 - Train Loss: 0.6900, Validation Loss: 0.6899\n",
      "Epoch 50/1000 - Train Loss: 0.6900, Validation Loss: 0.6898\n",
      "Epoch 51/1000 - Train Loss: 0.6899, Validation Loss: 0.6897\n",
      "Epoch 52/1000 - Train Loss: 0.6898, Validation Loss: 0.6897\n",
      "Epoch 53/1000 - Train Loss: 0.6898, Validation Loss: 0.6896\n",
      "Epoch 54/1000 - Train Loss: 0.6897, Validation Loss: 0.6895\n",
      "Epoch 55/1000 - Train Loss: 0.6897, Validation Loss: 0.6895\n",
      "Epoch 56/1000 - Train Loss: 0.6896, Validation Loss: 0.6894\n",
      "Epoch 57/1000 - Train Loss: 0.6895, Validation Loss: 0.6894\n",
      "Epoch 58/1000 - Train Loss: 0.6895, Validation Loss: 0.6893\n",
      "Epoch 59/1000 - Train Loss: 0.6894, Validation Loss: 0.6892\n",
      "Epoch 60/1000 - Train Loss: 0.6893, Validation Loss: 0.6892\n",
      "Epoch 61/1000 - Train Loss: 0.6893, Validation Loss: 0.6891\n",
      "Epoch 62/1000 - Train Loss: 0.6892, Validation Loss: 0.6890\n",
      "Epoch 63/1000 - Train Loss: 0.6891, Validation Loss: 0.6890\n",
      "Epoch 64/1000 - Train Loss: 0.6891, Validation Loss: 0.6889\n",
      "Epoch 65/1000 - Train Loss: 0.6890, Validation Loss: 0.6888\n",
      "Epoch 66/1000 - Train Loss: 0.6889, Validation Loss: 0.6888\n",
      "Epoch 67/1000 - Train Loss: 0.6889, Validation Loss: 0.6887\n",
      "Epoch 68/1000 - Train Loss: 0.6888, Validation Loss: 0.6886\n",
      "Epoch 69/1000 - Train Loss: 0.6888, Validation Loss: 0.6886\n",
      "Epoch 70/1000 - Train Loss: 0.6887, Validation Loss: 0.6885\n",
      "Epoch 71/1000 - Train Loss: 0.6886, Validation Loss: 0.6884\n",
      "Epoch 72/1000 - Train Loss: 0.6886, Validation Loss: 0.6884\n",
      "Epoch 73/1000 - Train Loss: 0.6885, Validation Loss: 0.6883\n",
      "Epoch 74/1000 - Train Loss: 0.6884, Validation Loss: 0.6882\n",
      "Epoch 75/1000 - Train Loss: 0.6884, Validation Loss: 0.6882\n",
      "Epoch 76/1000 - Train Loss: 0.6883, Validation Loss: 0.6881\n",
      "Epoch 77/1000 - Train Loss: 0.6882, Validation Loss: 0.6880\n",
      "Epoch 78/1000 - Train Loss: 0.6882, Validation Loss: 0.6880\n",
      "Epoch 79/1000 - Train Loss: 0.6881, Validation Loss: 0.6879\n",
      "Epoch 80/1000 - Train Loss: 0.6881, Validation Loss: 0.6878\n",
      "Epoch 81/1000 - Train Loss: 0.6880, Validation Loss: 0.6878\n",
      "Epoch 82/1000 - Train Loss: 0.6879, Validation Loss: 0.6877\n",
      "Epoch 83/1000 - Train Loss: 0.6879, Validation Loss: 0.6876\n",
      "Epoch 84/1000 - Train Loss: 0.6878, Validation Loss: 0.6876\n",
      "Epoch 85/1000 - Train Loss: 0.6877, Validation Loss: 0.6875\n",
      "Epoch 86/1000 - Train Loss: 0.6877, Validation Loss: 0.6875\n",
      "Epoch 87/1000 - Train Loss: 0.6876, Validation Loss: 0.6874\n",
      "Epoch 88/1000 - Train Loss: 0.6876, Validation Loss: 0.6873\n",
      "Epoch 89/1000 - Train Loss: 0.6875, Validation Loss: 0.6873\n",
      "Epoch 90/1000 - Train Loss: 0.6874, Validation Loss: 0.6872\n",
      "Epoch 91/1000 - Train Loss: 0.6874, Validation Loss: 0.6871\n",
      "Epoch 92/1000 - Train Loss: 0.6873, Validation Loss: 0.6871\n",
      "Epoch 93/1000 - Train Loss: 0.6872, Validation Loss: 0.6870\n",
      "Epoch 94/1000 - Train Loss: 0.6872, Validation Loss: 0.6869\n",
      "Epoch 95/1000 - Train Loss: 0.6871, Validation Loss: 0.6869\n",
      "Epoch 96/1000 - Train Loss: 0.6870, Validation Loss: 0.6868\n",
      "Epoch 97/1000 - Train Loss: 0.6870, Validation Loss: 0.6867\n",
      "Epoch 98/1000 - Train Loss: 0.6869, Validation Loss: 0.6867\n",
      "Epoch 99/1000 - Train Loss: 0.6869, Validation Loss: 0.6866\n",
      "Epoch 100/1000 - Train Loss: 0.6868, Validation Loss: 0.6865\n",
      "Epoch 101/1000 - Train Loss: 0.6867, Validation Loss: 0.6865\n",
      "Epoch 102/1000 - Train Loss: 0.6867, Validation Loss: 0.6864\n",
      "Epoch 103/1000 - Train Loss: 0.6866, Validation Loss: 0.6864\n",
      "Epoch 104/1000 - Train Loss: 0.6865, Validation Loss: 0.6863\n",
      "Epoch 105/1000 - Train Loss: 0.6865, Validation Loss: 0.6862\n",
      "Epoch 106/1000 - Train Loss: 0.6864, Validation Loss: 0.6862\n",
      "Epoch 107/1000 - Train Loss: 0.6864, Validation Loss: 0.6861\n",
      "Epoch 108/1000 - Train Loss: 0.6863, Validation Loss: 0.6860\n",
      "Epoch 109/1000 - Train Loss: 0.6862, Validation Loss: 0.6860\n",
      "Epoch 110/1000 - Train Loss: 0.6862, Validation Loss: 0.6859\n",
      "Epoch 111/1000 - Train Loss: 0.6861, Validation Loss: 0.6858\n",
      "Epoch 112/1000 - Train Loss: 0.6860, Validation Loss: 0.6858\n",
      "Epoch 113/1000 - Train Loss: 0.6860, Validation Loss: 0.6857\n",
      "Epoch 114/1000 - Train Loss: 0.6859, Validation Loss: 0.6856\n",
      "Epoch 115/1000 - Train Loss: 0.6859, Validation Loss: 0.6856\n",
      "Epoch 116/1000 - Train Loss: 0.6858, Validation Loss: 0.6855\n",
      "Epoch 117/1000 - Train Loss: 0.6857, Validation Loss: 0.6854\n",
      "Epoch 118/1000 - Train Loss: 0.6857, Validation Loss: 0.6854\n",
      "Epoch 119/1000 - Train Loss: 0.6856, Validation Loss: 0.6853\n",
      "Epoch 120/1000 - Train Loss: 0.6855, Validation Loss: 0.6853\n",
      "Epoch 121/1000 - Train Loss: 0.6855, Validation Loss: 0.6852\n",
      "Epoch 122/1000 - Train Loss: 0.6854, Validation Loss: 0.6851\n",
      "Epoch 123/1000 - Train Loss: 0.6854, Validation Loss: 0.6851\n",
      "Epoch 124/1000 - Train Loss: 0.6853, Validation Loss: 0.6850\n",
      "Epoch 125/1000 - Train Loss: 0.6852, Validation Loss: 0.6849\n",
      "Epoch 126/1000 - Train Loss: 0.6852, Validation Loss: 0.6849\n",
      "Epoch 127/1000 - Train Loss: 0.6851, Validation Loss: 0.6848\n",
      "Epoch 128/1000 - Train Loss: 0.6850, Validation Loss: 0.6847\n",
      "Epoch 129/1000 - Train Loss: 0.6850, Validation Loss: 0.6847\n",
      "Epoch 130/1000 - Train Loss: 0.6849, Validation Loss: 0.6846\n",
      "Epoch 131/1000 - Train Loss: 0.6849, Validation Loss: 0.6846\n",
      "Epoch 132/1000 - Train Loss: 0.6848, Validation Loss: 0.6845\n",
      "Epoch 133/1000 - Train Loss: 0.6847, Validation Loss: 0.6844\n",
      "Epoch 134/1000 - Train Loss: 0.6847, Validation Loss: 0.6844\n",
      "Epoch 135/1000 - Train Loss: 0.6846, Validation Loss: 0.6843\n",
      "Epoch 136/1000 - Train Loss: 0.6845, Validation Loss: 0.6842\n",
      "Epoch 137/1000 - Train Loss: 0.6845, Validation Loss: 0.6842\n",
      "Epoch 138/1000 - Train Loss: 0.6844, Validation Loss: 0.6841\n",
      "Epoch 139/1000 - Train Loss: 0.6844, Validation Loss: 0.6840\n",
      "Epoch 140/1000 - Train Loss: 0.6843, Validation Loss: 0.6840\n",
      "Epoch 141/1000 - Train Loss: 0.6842, Validation Loss: 0.6839\n",
      "Epoch 142/1000 - Train Loss: 0.6842, Validation Loss: 0.6838\n",
      "Epoch 143/1000 - Train Loss: 0.6841, Validation Loss: 0.6838\n",
      "Epoch 144/1000 - Train Loss: 0.6840, Validation Loss: 0.6837\n",
      "Epoch 145/1000 - Train Loss: 0.6840, Validation Loss: 0.6837\n",
      "Epoch 146/1000 - Train Loss: 0.6839, Validation Loss: 0.6836\n",
      "Epoch 147/1000 - Train Loss: 0.6839, Validation Loss: 0.6835\n",
      "Epoch 148/1000 - Train Loss: 0.6838, Validation Loss: 0.6835\n",
      "Epoch 149/1000 - Train Loss: 0.6837, Validation Loss: 0.6834\n",
      "Epoch 150/1000 - Train Loss: 0.6837, Validation Loss: 0.6833\n",
      "Epoch 151/1000 - Train Loss: 0.6836, Validation Loss: 0.6833\n",
      "Epoch 152/1000 - Train Loss: 0.6836, Validation Loss: 0.6832\n",
      "Epoch 153/1000 - Train Loss: 0.6835, Validation Loss: 0.6832\n",
      "Epoch 154/1000 - Train Loss: 0.6834, Validation Loss: 0.6831\n",
      "Epoch 155/1000 - Train Loss: 0.6834, Validation Loss: 0.6830\n",
      "Epoch 156/1000 - Train Loss: 0.6833, Validation Loss: 0.6830\n",
      "Epoch 157/1000 - Train Loss: 0.6832, Validation Loss: 0.6829\n",
      "Epoch 158/1000 - Train Loss: 0.6832, Validation Loss: 0.6828\n",
      "Epoch 159/1000 - Train Loss: 0.6831, Validation Loss: 0.6828\n",
      "Epoch 160/1000 - Train Loss: 0.6831, Validation Loss: 0.6827\n",
      "Epoch 161/1000 - Train Loss: 0.6830, Validation Loss: 0.6826\n",
      "Epoch 162/1000 - Train Loss: 0.6829, Validation Loss: 0.6826\n",
      "Epoch 163/1000 - Train Loss: 0.6829, Validation Loss: 0.6825\n",
      "Epoch 164/1000 - Train Loss: 0.6828, Validation Loss: 0.6825\n",
      "Epoch 165/1000 - Train Loss: 0.6828, Validation Loss: 0.6824\n",
      "Epoch 166/1000 - Train Loss: 0.6827, Validation Loss: 0.6823\n",
      "Epoch 167/1000 - Train Loss: 0.6826, Validation Loss: 0.6823\n",
      "Epoch 168/1000 - Train Loss: 0.6826, Validation Loss: 0.6822\n",
      "Epoch 169/1000 - Train Loss: 0.6825, Validation Loss: 0.6821\n",
      "Epoch 170/1000 - Train Loss: 0.6824, Validation Loss: 0.6821\n",
      "Epoch 171/1000 - Train Loss: 0.6824, Validation Loss: 0.6820\n",
      "Epoch 172/1000 - Train Loss: 0.6823, Validation Loss: 0.6820\n",
      "Epoch 173/1000 - Train Loss: 0.6823, Validation Loss: 0.6819\n",
      "Epoch 174/1000 - Train Loss: 0.6822, Validation Loss: 0.6818\n",
      "Epoch 175/1000 - Train Loss: 0.6821, Validation Loss: 0.6818\n",
      "Epoch 176/1000 - Train Loss: 0.6821, Validation Loss: 0.6817\n",
      "Epoch 177/1000 - Train Loss: 0.6820, Validation Loss: 0.6816\n",
      "Epoch 178/1000 - Train Loss: 0.6820, Validation Loss: 0.6816\n",
      "Epoch 179/1000 - Train Loss: 0.6819, Validation Loss: 0.6815\n",
      "Epoch 180/1000 - Train Loss: 0.6818, Validation Loss: 0.6814\n",
      "Epoch 181/1000 - Train Loss: 0.6818, Validation Loss: 0.6814\n",
      "Epoch 182/1000 - Train Loss: 0.6817, Validation Loss: 0.6813\n",
      "Epoch 183/1000 - Train Loss: 0.6816, Validation Loss: 0.6813\n",
      "Epoch 184/1000 - Train Loss: 0.6816, Validation Loss: 0.6812\n",
      "Epoch 185/1000 - Train Loss: 0.6815, Validation Loss: 0.6811\n",
      "Epoch 186/1000 - Train Loss: 0.6815, Validation Loss: 0.6811\n",
      "Epoch 187/1000 - Train Loss: 0.6814, Validation Loss: 0.6810\n",
      "Epoch 188/1000 - Train Loss: 0.6813, Validation Loss: 0.6809\n",
      "Epoch 189/1000 - Train Loss: 0.6813, Validation Loss: 0.6809\n",
      "Epoch 190/1000 - Train Loss: 0.6812, Validation Loss: 0.6808\n",
      "Epoch 191/1000 - Train Loss: 0.6812, Validation Loss: 0.6808\n",
      "Epoch 192/1000 - Train Loss: 0.6811, Validation Loss: 0.6807\n",
      "Epoch 193/1000 - Train Loss: 0.6810, Validation Loss: 0.6806\n",
      "Epoch 194/1000 - Train Loss: 0.6810, Validation Loss: 0.6806\n",
      "Epoch 195/1000 - Train Loss: 0.6809, Validation Loss: 0.6805\n",
      "Epoch 196/1000 - Train Loss: 0.6809, Validation Loss: 0.6804\n",
      "Epoch 197/1000 - Train Loss: 0.6808, Validation Loss: 0.6804\n",
      "Epoch 198/1000 - Train Loss: 0.6807, Validation Loss: 0.6803\n",
      "Epoch 199/1000 - Train Loss: 0.6807, Validation Loss: 0.6803\n",
      "Epoch 200/1000 - Train Loss: 0.6806, Validation Loss: 0.6802\n",
      "Epoch 201/1000 - Train Loss: 0.6806, Validation Loss: 0.6801\n",
      "Epoch 202/1000 - Train Loss: 0.6805, Validation Loss: 0.6801\n",
      "Epoch 203/1000 - Train Loss: 0.6804, Validation Loss: 0.6800\n",
      "Epoch 204/1000 - Train Loss: 0.6804, Validation Loss: 0.6799\n",
      "Epoch 205/1000 - Train Loss: 0.6803, Validation Loss: 0.6799\n",
      "Epoch 206/1000 - Train Loss: 0.6803, Validation Loss: 0.6798\n",
      "Epoch 207/1000 - Train Loss: 0.6802, Validation Loss: 0.6798\n",
      "Epoch 208/1000 - Train Loss: 0.6801, Validation Loss: 0.6797\n",
      "Epoch 209/1000 - Train Loss: 0.6801, Validation Loss: 0.6796\n",
      "Epoch 210/1000 - Train Loss: 0.6800, Validation Loss: 0.6796\n",
      "Epoch 211/1000 - Train Loss: 0.6799, Validation Loss: 0.6795\n",
      "Epoch 212/1000 - Train Loss: 0.6799, Validation Loss: 0.6795\n",
      "Epoch 213/1000 - Train Loss: 0.6798, Validation Loss: 0.6794\n",
      "Epoch 214/1000 - Train Loss: 0.6798, Validation Loss: 0.6793\n",
      "Epoch 215/1000 - Train Loss: 0.6797, Validation Loss: 0.6793\n",
      "Epoch 216/1000 - Train Loss: 0.6796, Validation Loss: 0.6792\n",
      "Epoch 217/1000 - Train Loss: 0.6796, Validation Loss: 0.6791\n",
      "Epoch 218/1000 - Train Loss: 0.6795, Validation Loss: 0.6791\n",
      "Epoch 219/1000 - Train Loss: 0.6795, Validation Loss: 0.6790\n",
      "Epoch 220/1000 - Train Loss: 0.6794, Validation Loss: 0.6790\n",
      "Epoch 221/1000 - Train Loss: 0.6793, Validation Loss: 0.6789\n",
      "Epoch 222/1000 - Train Loss: 0.6793, Validation Loss: 0.6788\n",
      "Epoch 223/1000 - Train Loss: 0.6792, Validation Loss: 0.6788\n",
      "Epoch 224/1000 - Train Loss: 0.6792, Validation Loss: 0.6787\n",
      "Epoch 225/1000 - Train Loss: 0.6791, Validation Loss: 0.6786\n",
      "Epoch 226/1000 - Train Loss: 0.6790, Validation Loss: 0.6786\n",
      "Epoch 227/1000 - Train Loss: 0.6790, Validation Loss: 0.6785\n",
      "Epoch 228/1000 - Train Loss: 0.6789, Validation Loss: 0.6785\n",
      "Epoch 229/1000 - Train Loss: 0.6789, Validation Loss: 0.6784\n",
      "Epoch 230/1000 - Train Loss: 0.6788, Validation Loss: 0.6783\n",
      "Epoch 231/1000 - Train Loss: 0.6787, Validation Loss: 0.6783\n",
      "Epoch 232/1000 - Train Loss: 0.6787, Validation Loss: 0.6782\n",
      "Epoch 233/1000 - Train Loss: 0.6786, Validation Loss: 0.6782\n",
      "Epoch 234/1000 - Train Loss: 0.6786, Validation Loss: 0.6781\n",
      "Epoch 235/1000 - Train Loss: 0.6785, Validation Loss: 0.6780\n",
      "Epoch 236/1000 - Train Loss: 0.6784, Validation Loss: 0.6780\n",
      "Epoch 237/1000 - Train Loss: 0.6784, Validation Loss: 0.6779\n",
      "Epoch 238/1000 - Train Loss: 0.6783, Validation Loss: 0.6778\n",
      "Epoch 239/1000 - Train Loss: 0.6783, Validation Loss: 0.6778\n",
      "Epoch 240/1000 - Train Loss: 0.6782, Validation Loss: 0.6777\n",
      "Epoch 241/1000 - Train Loss: 0.6781, Validation Loss: 0.6777\n",
      "Epoch 242/1000 - Train Loss: 0.6781, Validation Loss: 0.6776\n",
      "Epoch 243/1000 - Train Loss: 0.6780, Validation Loss: 0.6775\n",
      "Epoch 244/1000 - Train Loss: 0.6780, Validation Loss: 0.6775\n",
      "Epoch 245/1000 - Train Loss: 0.6779, Validation Loss: 0.6774\n",
      "Epoch 246/1000 - Train Loss: 0.6778, Validation Loss: 0.6774\n",
      "Epoch 247/1000 - Train Loss: 0.6778, Validation Loss: 0.6773\n",
      "Epoch 248/1000 - Train Loss: 0.6777, Validation Loss: 0.6772\n",
      "Epoch 249/1000 - Train Loss: 0.6777, Validation Loss: 0.6772\n",
      "Epoch 250/1000 - Train Loss: 0.6776, Validation Loss: 0.6771\n",
      "Epoch 251/1000 - Train Loss: 0.6775, Validation Loss: 0.6770\n",
      "Epoch 252/1000 - Train Loss: 0.6775, Validation Loss: 0.6770\n",
      "Epoch 253/1000 - Train Loss: 0.6774, Validation Loss: 0.6769\n",
      "Epoch 254/1000 - Train Loss: 0.6774, Validation Loss: 0.6769\n",
      "Epoch 255/1000 - Train Loss: 0.6773, Validation Loss: 0.6768\n",
      "Epoch 256/1000 - Train Loss: 0.6772, Validation Loss: 0.6767\n",
      "Epoch 257/1000 - Train Loss: 0.6772, Validation Loss: 0.6767\n",
      "Epoch 258/1000 - Train Loss: 0.6771, Validation Loss: 0.6766\n",
      "Epoch 259/1000 - Train Loss: 0.6771, Validation Loss: 0.6766\n",
      "Epoch 260/1000 - Train Loss: 0.6770, Validation Loss: 0.6765\n",
      "Epoch 261/1000 - Train Loss: 0.6769, Validation Loss: 0.6764\n",
      "Epoch 262/1000 - Train Loss: 0.6769, Validation Loss: 0.6764\n",
      "Epoch 263/1000 - Train Loss: 0.6768, Validation Loss: 0.6763\n",
      "Epoch 264/1000 - Train Loss: 0.6768, Validation Loss: 0.6763\n",
      "Epoch 265/1000 - Train Loss: 0.6767, Validation Loss: 0.6762\n",
      "Epoch 266/1000 - Train Loss: 0.6767, Validation Loss: 0.6761\n",
      "Epoch 267/1000 - Train Loss: 0.6766, Validation Loss: 0.6761\n",
      "Epoch 268/1000 - Train Loss: 0.6765, Validation Loss: 0.6760\n",
      "Epoch 269/1000 - Train Loss: 0.6765, Validation Loss: 0.6760\n",
      "Epoch 270/1000 - Train Loss: 0.6764, Validation Loss: 0.6759\n",
      "Epoch 271/1000 - Train Loss: 0.6764, Validation Loss: 0.6758\n",
      "Epoch 272/1000 - Train Loss: 0.6763, Validation Loss: 0.6758\n",
      "Epoch 273/1000 - Train Loss: 0.6762, Validation Loss: 0.6757\n",
      "Epoch 274/1000 - Train Loss: 0.6762, Validation Loss: 0.6756\n",
      "Epoch 275/1000 - Train Loss: 0.6761, Validation Loss: 0.6756\n",
      "Epoch 276/1000 - Train Loss: 0.6761, Validation Loss: 0.6755\n",
      "Epoch 277/1000 - Train Loss: 0.6760, Validation Loss: 0.6755\n",
      "Epoch 278/1000 - Train Loss: 0.6759, Validation Loss: 0.6754\n",
      "Epoch 279/1000 - Train Loss: 0.6759, Validation Loss: 0.6753\n",
      "Epoch 280/1000 - Train Loss: 0.6758, Validation Loss: 0.6753\n",
      "Epoch 281/1000 - Train Loss: 0.6758, Validation Loss: 0.6752\n",
      "Epoch 282/1000 - Train Loss: 0.6757, Validation Loss: 0.6752\n",
      "Epoch 283/1000 - Train Loss: 0.6756, Validation Loss: 0.6751\n",
      "Epoch 284/1000 - Train Loss: 0.6756, Validation Loss: 0.6750\n",
      "Epoch 285/1000 - Train Loss: 0.6755, Validation Loss: 0.6750\n",
      "Epoch 286/1000 - Train Loss: 0.6755, Validation Loss: 0.6749\n",
      "Epoch 287/1000 - Train Loss: 0.6754, Validation Loss: 0.6749\n",
      "Epoch 288/1000 - Train Loss: 0.6753, Validation Loss: 0.6748\n",
      "Epoch 289/1000 - Train Loss: 0.6753, Validation Loss: 0.6747\n",
      "Epoch 290/1000 - Train Loss: 0.6752, Validation Loss: 0.6747\n",
      "Epoch 291/1000 - Train Loss: 0.6752, Validation Loss: 0.6746\n",
      "Epoch 292/1000 - Train Loss: 0.6751, Validation Loss: 0.6746\n",
      "Epoch 293/1000 - Train Loss: 0.6751, Validation Loss: 0.6745\n",
      "Epoch 294/1000 - Train Loss: 0.6750, Validation Loss: 0.6744\n",
      "Epoch 295/1000 - Train Loss: 0.6749, Validation Loss: 0.6744\n",
      "Epoch 296/1000 - Train Loss: 0.6749, Validation Loss: 0.6743\n",
      "Epoch 297/1000 - Train Loss: 0.6748, Validation Loss: 0.6743\n",
      "Epoch 298/1000 - Train Loss: 0.6748, Validation Loss: 0.6742\n",
      "Epoch 299/1000 - Train Loss: 0.6747, Validation Loss: 0.6741\n",
      "Epoch 300/1000 - Train Loss: 0.6746, Validation Loss: 0.6741\n",
      "Epoch 301/1000 - Train Loss: 0.6746, Validation Loss: 0.6740\n",
      "Epoch 302/1000 - Train Loss: 0.6745, Validation Loss: 0.6740\n",
      "Epoch 303/1000 - Train Loss: 0.6745, Validation Loss: 0.6739\n",
      "Epoch 304/1000 - Train Loss: 0.6744, Validation Loss: 0.6738\n",
      "Epoch 305/1000 - Train Loss: 0.6743, Validation Loss: 0.6738\n",
      "Epoch 306/1000 - Train Loss: 0.6743, Validation Loss: 0.6737\n",
      "Epoch 307/1000 - Train Loss: 0.6742, Validation Loss: 0.6737\n",
      "Epoch 308/1000 - Train Loss: 0.6742, Validation Loss: 0.6736\n",
      "Epoch 309/1000 - Train Loss: 0.6741, Validation Loss: 0.6735\n",
      "Epoch 310/1000 - Train Loss: 0.6741, Validation Loss: 0.6735\n",
      "Epoch 311/1000 - Train Loss: 0.6740, Validation Loss: 0.6734\n",
      "Epoch 312/1000 - Train Loss: 0.6739, Validation Loss: 0.6734\n",
      "Epoch 313/1000 - Train Loss: 0.6739, Validation Loss: 0.6733\n",
      "Epoch 314/1000 - Train Loss: 0.6738, Validation Loss: 0.6732\n",
      "Epoch 315/1000 - Train Loss: 0.6738, Validation Loss: 0.6732\n",
      "Epoch 316/1000 - Train Loss: 0.6737, Validation Loss: 0.6731\n",
      "Epoch 317/1000 - Train Loss: 0.6736, Validation Loss: 0.6731\n",
      "Epoch 318/1000 - Train Loss: 0.6736, Validation Loss: 0.6730\n",
      "Epoch 319/1000 - Train Loss: 0.6735, Validation Loss: 0.6729\n",
      "Epoch 320/1000 - Train Loss: 0.6735, Validation Loss: 0.6729\n",
      "Epoch 321/1000 - Train Loss: 0.6734, Validation Loss: 0.6728\n",
      "Epoch 322/1000 - Train Loss: 0.6734, Validation Loss: 0.6728\n",
      "Epoch 323/1000 - Train Loss: 0.6733, Validation Loss: 0.6727\n",
      "Epoch 324/1000 - Train Loss: 0.6732, Validation Loss: 0.6726\n",
      "Epoch 325/1000 - Train Loss: 0.6732, Validation Loss: 0.6726\n",
      "Epoch 326/1000 - Train Loss: 0.6731, Validation Loss: 0.6725\n",
      "Epoch 327/1000 - Train Loss: 0.6731, Validation Loss: 0.6725\n",
      "Epoch 328/1000 - Train Loss: 0.6730, Validation Loss: 0.6724\n",
      "Epoch 329/1000 - Train Loss: 0.6729, Validation Loss: 0.6723\n",
      "Epoch 330/1000 - Train Loss: 0.6729, Validation Loss: 0.6723\n",
      "Epoch 331/1000 - Train Loss: 0.6728, Validation Loss: 0.6722\n",
      "Epoch 332/1000 - Train Loss: 0.6728, Validation Loss: 0.6722\n",
      "Epoch 333/1000 - Train Loss: 0.6727, Validation Loss: 0.6721\n",
      "Epoch 334/1000 - Train Loss: 0.6727, Validation Loss: 0.6720\n",
      "Epoch 335/1000 - Train Loss: 0.6726, Validation Loss: 0.6720\n",
      "Epoch 336/1000 - Train Loss: 0.6725, Validation Loss: 0.6719\n",
      "Epoch 337/1000 - Train Loss: 0.6725, Validation Loss: 0.6719\n",
      "Epoch 338/1000 - Train Loss: 0.6724, Validation Loss: 0.6718\n",
      "Epoch 339/1000 - Train Loss: 0.6724, Validation Loss: 0.6717\n",
      "Epoch 340/1000 - Train Loss: 0.6723, Validation Loss: 0.6717\n",
      "Epoch 341/1000 - Train Loss: 0.6722, Validation Loss: 0.6716\n",
      "Epoch 342/1000 - Train Loss: 0.6722, Validation Loss: 0.6716\n",
      "Epoch 343/1000 - Train Loss: 0.6721, Validation Loss: 0.6715\n",
      "Epoch 344/1000 - Train Loss: 0.6721, Validation Loss: 0.6714\n",
      "Epoch 345/1000 - Train Loss: 0.6720, Validation Loss: 0.6714\n",
      "Epoch 346/1000 - Train Loss: 0.6720, Validation Loss: 0.6713\n",
      "Epoch 347/1000 - Train Loss: 0.6719, Validation Loss: 0.6713\n",
      "Epoch 348/1000 - Train Loss: 0.6718, Validation Loss: 0.6712\n",
      "Epoch 349/1000 - Train Loss: 0.6718, Validation Loss: 0.6711\n",
      "Epoch 350/1000 - Train Loss: 0.6717, Validation Loss: 0.6711\n",
      "Epoch 351/1000 - Train Loss: 0.6717, Validation Loss: 0.6710\n",
      "Epoch 352/1000 - Train Loss: 0.6716, Validation Loss: 0.6710\n",
      "Epoch 353/1000 - Train Loss: 0.6716, Validation Loss: 0.6709\n",
      "Epoch 354/1000 - Train Loss: 0.6715, Validation Loss: 0.6709\n",
      "Epoch 355/1000 - Train Loss: 0.6714, Validation Loss: 0.6708\n",
      "Epoch 356/1000 - Train Loss: 0.6714, Validation Loss: 0.6707\n",
      "Epoch 357/1000 - Train Loss: 0.6713, Validation Loss: 0.6707\n",
      "Epoch 358/1000 - Train Loss: 0.6713, Validation Loss: 0.6706\n",
      "Epoch 359/1000 - Train Loss: 0.6712, Validation Loss: 0.6706\n",
      "Epoch 360/1000 - Train Loss: 0.6712, Validation Loss: 0.6705\n",
      "Epoch 361/1000 - Train Loss: 0.6711, Validation Loss: 0.6704\n",
      "Epoch 362/1000 - Train Loss: 0.6710, Validation Loss: 0.6704\n",
      "Epoch 363/1000 - Train Loss: 0.6710, Validation Loss: 0.6703\n",
      "Epoch 364/1000 - Train Loss: 0.6709, Validation Loss: 0.6703\n",
      "Epoch 365/1000 - Train Loss: 0.6709, Validation Loss: 0.6702\n",
      "Epoch 366/1000 - Train Loss: 0.6708, Validation Loss: 0.6701\n",
      "Epoch 367/1000 - Train Loss: 0.6707, Validation Loss: 0.6701\n",
      "Epoch 368/1000 - Train Loss: 0.6707, Validation Loss: 0.6700\n",
      "Epoch 369/1000 - Train Loss: 0.6706, Validation Loss: 0.6700\n",
      "Epoch 370/1000 - Train Loss: 0.6706, Validation Loss: 0.6699\n",
      "Epoch 371/1000 - Train Loss: 0.6705, Validation Loss: 0.6698\n",
      "Epoch 372/1000 - Train Loss: 0.6705, Validation Loss: 0.6698\n",
      "Epoch 373/1000 - Train Loss: 0.6704, Validation Loss: 0.6697\n",
      "Epoch 374/1000 - Train Loss: 0.6703, Validation Loss: 0.6697\n",
      "Epoch 375/1000 - Train Loss: 0.6703, Validation Loss: 0.6696\n",
      "Epoch 376/1000 - Train Loss: 0.6702, Validation Loss: 0.6696\n",
      "Epoch 377/1000 - Train Loss: 0.6702, Validation Loss: 0.6695\n",
      "Epoch 378/1000 - Train Loss: 0.6701, Validation Loss: 0.6694\n",
      "Epoch 379/1000 - Train Loss: 0.6701, Validation Loss: 0.6694\n",
      "Epoch 380/1000 - Train Loss: 0.6700, Validation Loss: 0.6693\n",
      "Epoch 381/1000 - Train Loss: 0.6699, Validation Loss: 0.6693\n",
      "Epoch 382/1000 - Train Loss: 0.6699, Validation Loss: 0.6692\n",
      "Epoch 383/1000 - Train Loss: 0.6698, Validation Loss: 0.6691\n",
      "Epoch 384/1000 - Train Loss: 0.6698, Validation Loss: 0.6691\n",
      "Epoch 385/1000 - Train Loss: 0.6697, Validation Loss: 0.6690\n",
      "Epoch 386/1000 - Train Loss: 0.6697, Validation Loss: 0.6690\n",
      "Epoch 387/1000 - Train Loss: 0.6696, Validation Loss: 0.6689\n",
      "Epoch 388/1000 - Train Loss: 0.6695, Validation Loss: 0.6689\n",
      "Epoch 389/1000 - Train Loss: 0.6695, Validation Loss: 0.6688\n",
      "Epoch 390/1000 - Train Loss: 0.6694, Validation Loss: 0.6687\n",
      "Epoch 391/1000 - Train Loss: 0.6694, Validation Loss: 0.6687\n",
      "Epoch 392/1000 - Train Loss: 0.6693, Validation Loss: 0.6686\n",
      "Epoch 393/1000 - Train Loss: 0.6693, Validation Loss: 0.6686\n",
      "Epoch 394/1000 - Train Loss: 0.6692, Validation Loss: 0.6685\n",
      "Epoch 395/1000 - Train Loss: 0.6691, Validation Loss: 0.6684\n",
      "Epoch 396/1000 - Train Loss: 0.6691, Validation Loss: 0.6684\n",
      "Epoch 397/1000 - Train Loss: 0.6690, Validation Loss: 0.6683\n",
      "Epoch 398/1000 - Train Loss: 0.6690, Validation Loss: 0.6683\n",
      "Epoch 399/1000 - Train Loss: 0.6689, Validation Loss: 0.6682\n",
      "Epoch 400/1000 - Train Loss: 0.6689, Validation Loss: 0.6682\n",
      "Epoch 401/1000 - Train Loss: 0.6688, Validation Loss: 0.6681\n",
      "Epoch 402/1000 - Train Loss: 0.6687, Validation Loss: 0.6680\n",
      "Epoch 403/1000 - Train Loss: 0.6687, Validation Loss: 0.6680\n",
      "Epoch 404/1000 - Train Loss: 0.6686, Validation Loss: 0.6679\n",
      "Epoch 405/1000 - Train Loss: 0.6686, Validation Loss: 0.6679\n",
      "Epoch 406/1000 - Train Loss: 0.6685, Validation Loss: 0.6678\n",
      "Epoch 407/1000 - Train Loss: 0.6685, Validation Loss: 0.6677\n",
      "Epoch 408/1000 - Train Loss: 0.6684, Validation Loss: 0.6677\n",
      "Epoch 409/1000 - Train Loss: 0.6683, Validation Loss: 0.6676\n",
      "Epoch 410/1000 - Train Loss: 0.6683, Validation Loss: 0.6676\n",
      "Epoch 411/1000 - Train Loss: 0.6682, Validation Loss: 0.6675\n",
      "Epoch 412/1000 - Train Loss: 0.6682, Validation Loss: 0.6675\n",
      "Epoch 413/1000 - Train Loss: 0.6681, Validation Loss: 0.6674\n",
      "Epoch 414/1000 - Train Loss: 0.6681, Validation Loss: 0.6673\n",
      "Epoch 415/1000 - Train Loss: 0.6680, Validation Loss: 0.6673\n",
      "Epoch 416/1000 - Train Loss: 0.6679, Validation Loss: 0.6672\n",
      "Epoch 417/1000 - Train Loss: 0.6679, Validation Loss: 0.6672\n",
      "Epoch 418/1000 - Train Loss: 0.6678, Validation Loss: 0.6671\n",
      "Epoch 419/1000 - Train Loss: 0.6678, Validation Loss: 0.6670\n",
      "Epoch 420/1000 - Train Loss: 0.6677, Validation Loss: 0.6670\n",
      "Epoch 421/1000 - Train Loss: 0.6677, Validation Loss: 0.6669\n",
      "Epoch 422/1000 - Train Loss: 0.6676, Validation Loss: 0.6669\n",
      "Epoch 423/1000 - Train Loss: 0.6675, Validation Loss: 0.6668\n",
      "Epoch 424/1000 - Train Loss: 0.6675, Validation Loss: 0.6668\n",
      "Epoch 425/1000 - Train Loss: 0.6674, Validation Loss: 0.6667\n",
      "Epoch 426/1000 - Train Loss: 0.6674, Validation Loss: 0.6666\n",
      "Epoch 427/1000 - Train Loss: 0.6673, Validation Loss: 0.6666\n",
      "Epoch 428/1000 - Train Loss: 0.6673, Validation Loss: 0.6665\n",
      "Epoch 429/1000 - Train Loss: 0.6672, Validation Loss: 0.6665\n",
      "Epoch 430/1000 - Train Loss: 0.6672, Validation Loss: 0.6664\n",
      "Epoch 431/1000 - Train Loss: 0.6671, Validation Loss: 0.6664\n",
      "Epoch 432/1000 - Train Loss: 0.6670, Validation Loss: 0.6663\n",
      "Epoch 433/1000 - Train Loss: 0.6670, Validation Loss: 0.6662\n",
      "Epoch 434/1000 - Train Loss: 0.6669, Validation Loss: 0.6662\n",
      "Epoch 435/1000 - Train Loss: 0.6669, Validation Loss: 0.6661\n",
      "Epoch 436/1000 - Train Loss: 0.6668, Validation Loss: 0.6661\n",
      "Epoch 437/1000 - Train Loss: 0.6668, Validation Loss: 0.6660\n",
      "Epoch 438/1000 - Train Loss: 0.6667, Validation Loss: 0.6659\n",
      "Epoch 439/1000 - Train Loss: 0.6666, Validation Loss: 0.6659\n",
      "Epoch 440/1000 - Train Loss: 0.6666, Validation Loss: 0.6658\n",
      "Epoch 441/1000 - Train Loss: 0.6665, Validation Loss: 0.6658\n",
      "Epoch 442/1000 - Train Loss: 0.6665, Validation Loss: 0.6657\n",
      "Epoch 443/1000 - Train Loss: 0.6664, Validation Loss: 0.6657\n",
      "Epoch 444/1000 - Train Loss: 0.6664, Validation Loss: 0.6656\n",
      "Epoch 445/1000 - Train Loss: 0.6663, Validation Loss: 0.6655\n",
      "Epoch 446/1000 - Train Loss: 0.6662, Validation Loss: 0.6655\n",
      "Epoch 447/1000 - Train Loss: 0.6662, Validation Loss: 0.6654\n",
      "Epoch 448/1000 - Train Loss: 0.6661, Validation Loss: 0.6654\n",
      "Epoch 449/1000 - Train Loss: 0.6661, Validation Loss: 0.6653\n",
      "Epoch 450/1000 - Train Loss: 0.6660, Validation Loss: 0.6653\n",
      "Epoch 451/1000 - Train Loss: 0.6660, Validation Loss: 0.6652\n",
      "Epoch 452/1000 - Train Loss: 0.6659, Validation Loss: 0.6651\n",
      "Epoch 453/1000 - Train Loss: 0.6659, Validation Loss: 0.6651\n",
      "Epoch 454/1000 - Train Loss: 0.6658, Validation Loss: 0.6650\n",
      "Epoch 455/1000 - Train Loss: 0.6657, Validation Loss: 0.6650\n",
      "Epoch 456/1000 - Train Loss: 0.6657, Validation Loss: 0.6649\n",
      "Epoch 457/1000 - Train Loss: 0.6656, Validation Loss: 0.6649\n",
      "Epoch 458/1000 - Train Loss: 0.6656, Validation Loss: 0.6648\n",
      "Epoch 459/1000 - Train Loss: 0.6655, Validation Loss: 0.6647\n",
      "Epoch 460/1000 - Train Loss: 0.6655, Validation Loss: 0.6647\n",
      "Epoch 461/1000 - Train Loss: 0.6654, Validation Loss: 0.6646\n",
      "Epoch 462/1000 - Train Loss: 0.6654, Validation Loss: 0.6646\n",
      "Epoch 463/1000 - Train Loss: 0.6653, Validation Loss: 0.6645\n",
      "Epoch 464/1000 - Train Loss: 0.6652, Validation Loss: 0.6645\n",
      "Epoch 465/1000 - Train Loss: 0.6652, Validation Loss: 0.6644\n",
      "Epoch 466/1000 - Train Loss: 0.6651, Validation Loss: 0.6643\n",
      "Epoch 467/1000 - Train Loss: 0.6651, Validation Loss: 0.6643\n",
      "Epoch 468/1000 - Train Loss: 0.6650, Validation Loss: 0.6642\n",
      "Epoch 469/1000 - Train Loss: 0.6650, Validation Loss: 0.6642\n",
      "Epoch 470/1000 - Train Loss: 0.6649, Validation Loss: 0.6641\n",
      "Epoch 471/1000 - Train Loss: 0.6648, Validation Loss: 0.6641\n",
      "Epoch 472/1000 - Train Loss: 0.6648, Validation Loss: 0.6640\n",
      "Epoch 473/1000 - Train Loss: 0.6647, Validation Loss: 0.6639\n",
      "Epoch 474/1000 - Train Loss: 0.6647, Validation Loss: 0.6639\n",
      "Epoch 475/1000 - Train Loss: 0.6646, Validation Loss: 0.6638\n",
      "Epoch 476/1000 - Train Loss: 0.6646, Validation Loss: 0.6638\n",
      "Epoch 477/1000 - Train Loss: 0.6645, Validation Loss: 0.6637\n",
      "Epoch 478/1000 - Train Loss: 0.6645, Validation Loss: 0.6637\n",
      "Epoch 479/1000 - Train Loss: 0.6644, Validation Loss: 0.6636\n",
      "Epoch 480/1000 - Train Loss: 0.6643, Validation Loss: 0.6635\n",
      "Epoch 481/1000 - Train Loss: 0.6643, Validation Loss: 0.6635\n",
      "Epoch 482/1000 - Train Loss: 0.6642, Validation Loss: 0.6634\n",
      "Epoch 483/1000 - Train Loss: 0.6642, Validation Loss: 0.6634\n",
      "Epoch 484/1000 - Train Loss: 0.6641, Validation Loss: 0.6633\n",
      "Epoch 485/1000 - Train Loss: 0.6641, Validation Loss: 0.6633\n",
      "Epoch 486/1000 - Train Loss: 0.6640, Validation Loss: 0.6632\n",
      "Epoch 487/1000 - Train Loss: 0.6640, Validation Loss: 0.6631\n",
      "Epoch 488/1000 - Train Loss: 0.6639, Validation Loss: 0.6631\n",
      "Epoch 489/1000 - Train Loss: 0.6638, Validation Loss: 0.6630\n",
      "Epoch 490/1000 - Train Loss: 0.6638, Validation Loss: 0.6630\n",
      "Epoch 491/1000 - Train Loss: 0.6637, Validation Loss: 0.6629\n",
      "Epoch 492/1000 - Train Loss: 0.6637, Validation Loss: 0.6629\n",
      "Epoch 493/1000 - Train Loss: 0.6636, Validation Loss: 0.6628\n",
      "Epoch 494/1000 - Train Loss: 0.6636, Validation Loss: 0.6627\n",
      "Epoch 495/1000 - Train Loss: 0.6635, Validation Loss: 0.6627\n",
      "Epoch 496/1000 - Train Loss: 0.6635, Validation Loss: 0.6626\n",
      "Epoch 497/1000 - Train Loss: 0.6634, Validation Loss: 0.6626\n",
      "Epoch 498/1000 - Train Loss: 0.6633, Validation Loss: 0.6625\n",
      "Epoch 499/1000 - Train Loss: 0.6633, Validation Loss: 0.6625\n",
      "Epoch 500/1000 - Train Loss: 0.6632, Validation Loss: 0.6624\n",
      "Epoch 501/1000 - Train Loss: 0.6632, Validation Loss: 0.6623\n",
      "Epoch 502/1000 - Train Loss: 0.6631, Validation Loss: 0.6623\n",
      "Epoch 503/1000 - Train Loss: 0.6631, Validation Loss: 0.6622\n",
      "Epoch 504/1000 - Train Loss: 0.6630, Validation Loss: 0.6622\n",
      "Epoch 505/1000 - Train Loss: 0.6630, Validation Loss: 0.6621\n",
      "Epoch 506/1000 - Train Loss: 0.6629, Validation Loss: 0.6621\n",
      "Epoch 507/1000 - Train Loss: 0.6628, Validation Loss: 0.6620\n",
      "Epoch 508/1000 - Train Loss: 0.6628, Validation Loss: 0.6620\n",
      "Epoch 509/1000 - Train Loss: 0.6627, Validation Loss: 0.6619\n",
      "Epoch 510/1000 - Train Loss: 0.6627, Validation Loss: 0.6618\n",
      "Epoch 511/1000 - Train Loss: 0.6626, Validation Loss: 0.6618\n",
      "Epoch 512/1000 - Train Loss: 0.6626, Validation Loss: 0.6617\n",
      "Epoch 513/1000 - Train Loss: 0.6625, Validation Loss: 0.6617\n",
      "Epoch 514/1000 - Train Loss: 0.6625, Validation Loss: 0.6616\n",
      "Epoch 515/1000 - Train Loss: 0.6624, Validation Loss: 0.6616\n",
      "Epoch 516/1000 - Train Loss: 0.6623, Validation Loss: 0.6615\n",
      "Epoch 517/1000 - Train Loss: 0.6623, Validation Loss: 0.6614\n",
      "Epoch 518/1000 - Train Loss: 0.6622, Validation Loss: 0.6614\n",
      "Epoch 519/1000 - Train Loss: 0.6622, Validation Loss: 0.6613\n",
      "Epoch 520/1000 - Train Loss: 0.6621, Validation Loss: 0.6613\n",
      "Epoch 521/1000 - Train Loss: 0.6621, Validation Loss: 0.6612\n",
      "Epoch 522/1000 - Train Loss: 0.6620, Validation Loss: 0.6612\n",
      "Epoch 523/1000 - Train Loss: 0.6620, Validation Loss: 0.6611\n",
      "Epoch 524/1000 - Train Loss: 0.6619, Validation Loss: 0.6610\n",
      "Epoch 525/1000 - Train Loss: 0.6618, Validation Loss: 0.6610\n",
      "Epoch 526/1000 - Train Loss: 0.6618, Validation Loss: 0.6609\n",
      "Epoch 527/1000 - Train Loss: 0.6617, Validation Loss: 0.6609\n",
      "Epoch 528/1000 - Train Loss: 0.6617, Validation Loss: 0.6608\n",
      "Epoch 529/1000 - Train Loss: 0.6616, Validation Loss: 0.6608\n",
      "Epoch 530/1000 - Train Loss: 0.6616, Validation Loss: 0.6607\n",
      "Epoch 531/1000 - Train Loss: 0.6615, Validation Loss: 0.6607\n",
      "Epoch 532/1000 - Train Loss: 0.6615, Validation Loss: 0.6606\n",
      "Epoch 533/1000 - Train Loss: 0.6614, Validation Loss: 0.6605\n",
      "Epoch 534/1000 - Train Loss: 0.6614, Validation Loss: 0.6605\n",
      "Epoch 535/1000 - Train Loss: 0.6613, Validation Loss: 0.6604\n",
      "Epoch 536/1000 - Train Loss: 0.6612, Validation Loss: 0.6604\n",
      "Epoch 537/1000 - Train Loss: 0.6612, Validation Loss: 0.6603\n",
      "Epoch 538/1000 - Train Loss: 0.6611, Validation Loss: 0.6603\n",
      "Epoch 539/1000 - Train Loss: 0.6611, Validation Loss: 0.6602\n",
      "Epoch 540/1000 - Train Loss: 0.6610, Validation Loss: 0.6602\n",
      "Epoch 541/1000 - Train Loss: 0.6610, Validation Loss: 0.6601\n",
      "Epoch 542/1000 - Train Loss: 0.6609, Validation Loss: 0.6600\n",
      "Epoch 543/1000 - Train Loss: 0.6609, Validation Loss: 0.6600\n",
      "Epoch 544/1000 - Train Loss: 0.6608, Validation Loss: 0.6599\n",
      "Epoch 545/1000 - Train Loss: 0.6608, Validation Loss: 0.6599\n",
      "Epoch 546/1000 - Train Loss: 0.6607, Validation Loss: 0.6598\n",
      "Epoch 547/1000 - Train Loss: 0.6606, Validation Loss: 0.6598\n",
      "Epoch 548/1000 - Train Loss: 0.6606, Validation Loss: 0.6597\n",
      "Epoch 549/1000 - Train Loss: 0.6605, Validation Loss: 0.6596\n",
      "Epoch 550/1000 - Train Loss: 0.6605, Validation Loss: 0.6596\n",
      "Epoch 551/1000 - Train Loss: 0.6604, Validation Loss: 0.6595\n",
      "Epoch 552/1000 - Train Loss: 0.6604, Validation Loss: 0.6595\n",
      "Epoch 553/1000 - Train Loss: 0.6603, Validation Loss: 0.6594\n",
      "Epoch 554/1000 - Train Loss: 0.6603, Validation Loss: 0.6594\n",
      "Epoch 555/1000 - Train Loss: 0.6602, Validation Loss: 0.6593\n",
      "Epoch 556/1000 - Train Loss: 0.6601, Validation Loss: 0.6593\n",
      "Epoch 557/1000 - Train Loss: 0.6601, Validation Loss: 0.6592\n",
      "Epoch 558/1000 - Train Loss: 0.6600, Validation Loss: 0.6591\n",
      "Epoch 559/1000 - Train Loss: 0.6600, Validation Loss: 0.6591\n",
      "Epoch 560/1000 - Train Loss: 0.6599, Validation Loss: 0.6590\n",
      "Epoch 561/1000 - Train Loss: 0.6599, Validation Loss: 0.6590\n",
      "Epoch 562/1000 - Train Loss: 0.6598, Validation Loss: 0.6589\n",
      "Epoch 563/1000 - Train Loss: 0.6598, Validation Loss: 0.6589\n",
      "Epoch 564/1000 - Train Loss: 0.6597, Validation Loss: 0.6588\n",
      "Epoch 565/1000 - Train Loss: 0.6597, Validation Loss: 0.6588\n",
      "Epoch 566/1000 - Train Loss: 0.6596, Validation Loss: 0.6587\n",
      "Epoch 567/1000 - Train Loss: 0.6595, Validation Loss: 0.6586\n",
      "Epoch 568/1000 - Train Loss: 0.6595, Validation Loss: 0.6586\n",
      "Epoch 569/1000 - Train Loss: 0.6594, Validation Loss: 0.6585\n",
      "Epoch 570/1000 - Train Loss: 0.6594, Validation Loss: 0.6585\n",
      "Epoch 571/1000 - Train Loss: 0.6593, Validation Loss: 0.6584\n",
      "Epoch 572/1000 - Train Loss: 0.6593, Validation Loss: 0.6584\n",
      "Epoch 573/1000 - Train Loss: 0.6592, Validation Loss: 0.6583\n",
      "Epoch 574/1000 - Train Loss: 0.6592, Validation Loss: 0.6583\n",
      "Epoch 575/1000 - Train Loss: 0.6591, Validation Loss: 0.6582\n",
      "Epoch 576/1000 - Train Loss: 0.6591, Validation Loss: 0.6581\n",
      "Epoch 577/1000 - Train Loss: 0.6590, Validation Loss: 0.6581\n",
      "Epoch 578/1000 - Train Loss: 0.6589, Validation Loss: 0.6580\n",
      "Epoch 579/1000 - Train Loss: 0.6589, Validation Loss: 0.6580\n",
      "Epoch 580/1000 - Train Loss: 0.6588, Validation Loss: 0.6579\n",
      "Epoch 581/1000 - Train Loss: 0.6588, Validation Loss: 0.6579\n",
      "Epoch 582/1000 - Train Loss: 0.6587, Validation Loss: 0.6578\n",
      "Epoch 583/1000 - Train Loss: 0.6587, Validation Loss: 0.6578\n",
      "Epoch 584/1000 - Train Loss: 0.6586, Validation Loss: 0.6577\n",
      "Epoch 585/1000 - Train Loss: 0.6586, Validation Loss: 0.6576\n",
      "Epoch 586/1000 - Train Loss: 0.6585, Validation Loss: 0.6576\n",
      "Epoch 587/1000 - Train Loss: 0.6585, Validation Loss: 0.6575\n",
      "Epoch 588/1000 - Train Loss: 0.6584, Validation Loss: 0.6575\n",
      "Epoch 589/1000 - Train Loss: 0.6584, Validation Loss: 0.6574\n",
      "Epoch 590/1000 - Train Loss: 0.6583, Validation Loss: 0.6574\n",
      "Epoch 591/1000 - Train Loss: 0.6582, Validation Loss: 0.6573\n",
      "Epoch 592/1000 - Train Loss: 0.6582, Validation Loss: 0.6573\n",
      "Epoch 593/1000 - Train Loss: 0.6581, Validation Loss: 0.6572\n",
      "Epoch 594/1000 - Train Loss: 0.6581, Validation Loss: 0.6571\n",
      "Epoch 595/1000 - Train Loss: 0.6580, Validation Loss: 0.6571\n",
      "Epoch 596/1000 - Train Loss: 0.6580, Validation Loss: 0.6570\n",
      "Epoch 597/1000 - Train Loss: 0.6579, Validation Loss: 0.6570\n",
      "Epoch 598/1000 - Train Loss: 0.6579, Validation Loss: 0.6569\n",
      "Epoch 599/1000 - Train Loss: 0.6578, Validation Loss: 0.6569\n",
      "Epoch 600/1000 - Train Loss: 0.6578, Validation Loss: 0.6568\n",
      "Epoch 601/1000 - Train Loss: 0.6577, Validation Loss: 0.6568\n",
      "Epoch 602/1000 - Train Loss: 0.6576, Validation Loss: 0.6567\n",
      "Epoch 603/1000 - Train Loss: 0.6576, Validation Loss: 0.6567\n",
      "Epoch 604/1000 - Train Loss: 0.6575, Validation Loss: 0.6566\n",
      "Epoch 605/1000 - Train Loss: 0.6575, Validation Loss: 0.6565\n",
      "Epoch 606/1000 - Train Loss: 0.6574, Validation Loss: 0.6565\n",
      "Epoch 607/1000 - Train Loss: 0.6574, Validation Loss: 0.6564\n",
      "Epoch 608/1000 - Train Loss: 0.6573, Validation Loss: 0.6564\n",
      "Epoch 609/1000 - Train Loss: 0.6573, Validation Loss: 0.6563\n",
      "Epoch 610/1000 - Train Loss: 0.6572, Validation Loss: 0.6563\n",
      "Epoch 611/1000 - Train Loss: 0.6572, Validation Loss: 0.6562\n",
      "Epoch 612/1000 - Train Loss: 0.6571, Validation Loss: 0.6562\n",
      "Epoch 613/1000 - Train Loss: 0.6571, Validation Loss: 0.6561\n",
      "Epoch 614/1000 - Train Loss: 0.6570, Validation Loss: 0.6560\n",
      "Epoch 615/1000 - Train Loss: 0.6569, Validation Loss: 0.6560\n",
      "Epoch 616/1000 - Train Loss: 0.6569, Validation Loss: 0.6559\n",
      "Epoch 617/1000 - Train Loss: 0.6568, Validation Loss: 0.6559\n",
      "Epoch 618/1000 - Train Loss: 0.6568, Validation Loss: 0.6558\n",
      "Epoch 619/1000 - Train Loss: 0.6567, Validation Loss: 0.6558\n",
      "Epoch 620/1000 - Train Loss: 0.6567, Validation Loss: 0.6557\n",
      "Epoch 621/1000 - Train Loss: 0.6566, Validation Loss: 0.6557\n",
      "Epoch 622/1000 - Train Loss: 0.6566, Validation Loss: 0.6556\n",
      "Epoch 623/1000 - Train Loss: 0.6565, Validation Loss: 0.6556\n",
      "Epoch 624/1000 - Train Loss: 0.6565, Validation Loss: 0.6555\n",
      "Epoch 625/1000 - Train Loss: 0.6564, Validation Loss: 0.6554\n",
      "Epoch 626/1000 - Train Loss: 0.6564, Validation Loss: 0.6554\n",
      "Epoch 627/1000 - Train Loss: 0.6563, Validation Loss: 0.6553\n",
      "Epoch 628/1000 - Train Loss: 0.6562, Validation Loss: 0.6553\n",
      "Epoch 629/1000 - Train Loss: 0.6562, Validation Loss: 0.6552\n",
      "Epoch 630/1000 - Train Loss: 0.6561, Validation Loss: 0.6552\n",
      "Epoch 631/1000 - Train Loss: 0.6561, Validation Loss: 0.6551\n",
      "Epoch 632/1000 - Train Loss: 0.6560, Validation Loss: 0.6551\n",
      "Epoch 633/1000 - Train Loss: 0.6560, Validation Loss: 0.6550\n",
      "Epoch 634/1000 - Train Loss: 0.6559, Validation Loss: 0.6549\n",
      "Epoch 635/1000 - Train Loss: 0.6559, Validation Loss: 0.6549\n",
      "Epoch 636/1000 - Train Loss: 0.6558, Validation Loss: 0.6548\n",
      "Epoch 637/1000 - Train Loss: 0.6558, Validation Loss: 0.6548\n",
      "Epoch 638/1000 - Train Loss: 0.6557, Validation Loss: 0.6547\n",
      "Epoch 639/1000 - Train Loss: 0.6557, Validation Loss: 0.6547\n",
      "Epoch 640/1000 - Train Loss: 0.6556, Validation Loss: 0.6546\n",
      "Epoch 641/1000 - Train Loss: 0.6555, Validation Loss: 0.6546\n",
      "Epoch 642/1000 - Train Loss: 0.6555, Validation Loss: 0.6545\n",
      "Epoch 643/1000 - Train Loss: 0.6554, Validation Loss: 0.6545\n",
      "Epoch 644/1000 - Train Loss: 0.6554, Validation Loss: 0.6544\n",
      "Epoch 645/1000 - Train Loss: 0.6553, Validation Loss: 0.6543\n",
      "Epoch 646/1000 - Train Loss: 0.6553, Validation Loss: 0.6543\n",
      "Epoch 647/1000 - Train Loss: 0.6552, Validation Loss: 0.6542\n",
      "Epoch 648/1000 - Train Loss: 0.6552, Validation Loss: 0.6542\n",
      "Epoch 649/1000 - Train Loss: 0.6551, Validation Loss: 0.6541\n",
      "Epoch 650/1000 - Train Loss: 0.6551, Validation Loss: 0.6541\n",
      "Epoch 651/1000 - Train Loss: 0.6550, Validation Loss: 0.6540\n",
      "Epoch 652/1000 - Train Loss: 0.6550, Validation Loss: 0.6540\n",
      "Epoch 653/1000 - Train Loss: 0.6549, Validation Loss: 0.6539\n",
      "Epoch 654/1000 - Train Loss: 0.6549, Validation Loss: 0.6539\n",
      "Epoch 655/1000 - Train Loss: 0.6548, Validation Loss: 0.6538\n",
      "Epoch 656/1000 - Train Loss: 0.6547, Validation Loss: 0.6537\n",
      "Epoch 657/1000 - Train Loss: 0.6547, Validation Loss: 0.6537\n",
      "Epoch 658/1000 - Train Loss: 0.6546, Validation Loss: 0.6536\n",
      "Epoch 659/1000 - Train Loss: 0.6546, Validation Loss: 0.6536\n",
      "Epoch 660/1000 - Train Loss: 0.6545, Validation Loss: 0.6535\n",
      "Epoch 661/1000 - Train Loss: 0.6545, Validation Loss: 0.6535\n",
      "Epoch 662/1000 - Train Loss: 0.6544, Validation Loss: 0.6534\n",
      "Epoch 663/1000 - Train Loss: 0.6544, Validation Loss: 0.6534\n",
      "Epoch 664/1000 - Train Loss: 0.6543, Validation Loss: 0.6533\n",
      "Epoch 665/1000 - Train Loss: 0.6543, Validation Loss: 0.6533\n",
      "Epoch 666/1000 - Train Loss: 0.6542, Validation Loss: 0.6532\n",
      "Epoch 667/1000 - Train Loss: 0.6542, Validation Loss: 0.6532\n",
      "Epoch 668/1000 - Train Loss: 0.6541, Validation Loss: 0.6531\n",
      "Epoch 669/1000 - Train Loss: 0.6541, Validation Loss: 0.6530\n",
      "Epoch 670/1000 - Train Loss: 0.6540, Validation Loss: 0.6530\n",
      "Epoch 671/1000 - Train Loss: 0.6539, Validation Loss: 0.6529\n",
      "Epoch 672/1000 - Train Loss: 0.6539, Validation Loss: 0.6529\n",
      "Epoch 673/1000 - Train Loss: 0.6538, Validation Loss: 0.6528\n",
      "Epoch 674/1000 - Train Loss: 0.6538, Validation Loss: 0.6528\n",
      "Epoch 675/1000 - Train Loss: 0.6537, Validation Loss: 0.6527\n",
      "Epoch 676/1000 - Train Loss: 0.6537, Validation Loss: 0.6527\n",
      "Epoch 677/1000 - Train Loss: 0.6536, Validation Loss: 0.6526\n",
      "Epoch 678/1000 - Train Loss: 0.6536, Validation Loss: 0.6526\n",
      "Epoch 679/1000 - Train Loss: 0.6535, Validation Loss: 0.6525\n",
      "Epoch 680/1000 - Train Loss: 0.6535, Validation Loss: 0.6524\n",
      "Epoch 681/1000 - Train Loss: 0.6534, Validation Loss: 0.6524\n",
      "Epoch 682/1000 - Train Loss: 0.6534, Validation Loss: 0.6523\n",
      "Epoch 683/1000 - Train Loss: 0.6533, Validation Loss: 0.6523\n",
      "Epoch 684/1000 - Train Loss: 0.6533, Validation Loss: 0.6522\n",
      "Epoch 685/1000 - Train Loss: 0.6532, Validation Loss: 0.6522\n",
      "Epoch 686/1000 - Train Loss: 0.6531, Validation Loss: 0.6521\n",
      "Epoch 687/1000 - Train Loss: 0.6531, Validation Loss: 0.6521\n",
      "Epoch 688/1000 - Train Loss: 0.6530, Validation Loss: 0.6520\n",
      "Epoch 689/1000 - Train Loss: 0.6530, Validation Loss: 0.6520\n",
      "Epoch 690/1000 - Train Loss: 0.6529, Validation Loss: 0.6519\n",
      "Epoch 691/1000 - Train Loss: 0.6529, Validation Loss: 0.6519\n",
      "Epoch 692/1000 - Train Loss: 0.6528, Validation Loss: 0.6518\n",
      "Epoch 693/1000 - Train Loss: 0.6528, Validation Loss: 0.6517\n",
      "Epoch 694/1000 - Train Loss: 0.6527, Validation Loss: 0.6517\n",
      "Epoch 695/1000 - Train Loss: 0.6527, Validation Loss: 0.6516\n",
      "Epoch 696/1000 - Train Loss: 0.6526, Validation Loss: 0.6516\n",
      "Epoch 697/1000 - Train Loss: 0.6526, Validation Loss: 0.6515\n",
      "Epoch 698/1000 - Train Loss: 0.6525, Validation Loss: 0.6515\n",
      "Epoch 699/1000 - Train Loss: 0.6525, Validation Loss: 0.6514\n",
      "Epoch 700/1000 - Train Loss: 0.6524, Validation Loss: 0.6514\n",
      "Epoch 701/1000 - Train Loss: 0.6524, Validation Loss: 0.6513\n",
      "Epoch 702/1000 - Train Loss: 0.6523, Validation Loss: 0.6513\n",
      "Epoch 703/1000 - Train Loss: 0.6523, Validation Loss: 0.6512\n",
      "Epoch 704/1000 - Train Loss: 0.6522, Validation Loss: 0.6512\n",
      "Epoch 705/1000 - Train Loss: 0.6521, Validation Loss: 0.6511\n",
      "Epoch 706/1000 - Train Loss: 0.6521, Validation Loss: 0.6510\n",
      "Epoch 707/1000 - Train Loss: 0.6520, Validation Loss: 0.6510\n",
      "Epoch 708/1000 - Train Loss: 0.6520, Validation Loss: 0.6509\n",
      "Epoch 709/1000 - Train Loss: 0.6519, Validation Loss: 0.6509\n",
      "Epoch 710/1000 - Train Loss: 0.6519, Validation Loss: 0.6508\n",
      "Epoch 711/1000 - Train Loss: 0.6518, Validation Loss: 0.6508\n",
      "Epoch 712/1000 - Train Loss: 0.6518, Validation Loss: 0.6507\n",
      "Epoch 713/1000 - Train Loss: 0.6517, Validation Loss: 0.6507\n",
      "Epoch 714/1000 - Train Loss: 0.6517, Validation Loss: 0.6506\n",
      "Epoch 715/1000 - Train Loss: 0.6516, Validation Loss: 0.6506\n",
      "Epoch 716/1000 - Train Loss: 0.6516, Validation Loss: 0.6505\n",
      "Epoch 717/1000 - Train Loss: 0.6515, Validation Loss: 0.6505\n",
      "Epoch 718/1000 - Train Loss: 0.6515, Validation Loss: 0.6504\n",
      "Epoch 719/1000 - Train Loss: 0.6514, Validation Loss: 0.6503\n",
      "Epoch 720/1000 - Train Loss: 0.6514, Validation Loss: 0.6503\n",
      "Epoch 721/1000 - Train Loss: 0.6513, Validation Loss: 0.6502\n",
      "Epoch 722/1000 - Train Loss: 0.6512, Validation Loss: 0.6502\n",
      "Epoch 723/1000 - Train Loss: 0.6512, Validation Loss: 0.6501\n",
      "Epoch 724/1000 - Train Loss: 0.6511, Validation Loss: 0.6501\n",
      "Epoch 725/1000 - Train Loss: 0.6511, Validation Loss: 0.6500\n",
      "Epoch 726/1000 - Train Loss: 0.6510, Validation Loss: 0.6500\n",
      "Epoch 727/1000 - Train Loss: 0.6510, Validation Loss: 0.6499\n",
      "Epoch 728/1000 - Train Loss: 0.6509, Validation Loss: 0.6499\n",
      "Epoch 729/1000 - Train Loss: 0.6509, Validation Loss: 0.6498\n",
      "Epoch 730/1000 - Train Loss: 0.6508, Validation Loss: 0.6498\n",
      "Epoch 731/1000 - Train Loss: 0.6508, Validation Loss: 0.6497\n",
      "Epoch 732/1000 - Train Loss: 0.6507, Validation Loss: 0.6497\n",
      "Epoch 733/1000 - Train Loss: 0.6507, Validation Loss: 0.6496\n",
      "Epoch 734/1000 - Train Loss: 0.6506, Validation Loss: 0.6495\n",
      "Epoch 735/1000 - Train Loss: 0.6506, Validation Loss: 0.6495\n",
      "Epoch 736/1000 - Train Loss: 0.6505, Validation Loss: 0.6494\n",
      "Epoch 737/1000 - Train Loss: 0.6505, Validation Loss: 0.6494\n",
      "Epoch 738/1000 - Train Loss: 0.6504, Validation Loss: 0.6493\n",
      "Epoch 739/1000 - Train Loss: 0.6504, Validation Loss: 0.6493\n",
      "Epoch 740/1000 - Train Loss: 0.6503, Validation Loss: 0.6492\n",
      "Epoch 741/1000 - Train Loss: 0.6503, Validation Loss: 0.6492\n",
      "Epoch 742/1000 - Train Loss: 0.6502, Validation Loss: 0.6491\n",
      "Epoch 743/1000 - Train Loss: 0.6501, Validation Loss: 0.6491\n",
      "Epoch 744/1000 - Train Loss: 0.6501, Validation Loss: 0.6490\n",
      "Epoch 745/1000 - Train Loss: 0.6500, Validation Loss: 0.6490\n",
      "Epoch 746/1000 - Train Loss: 0.6500, Validation Loss: 0.6489\n",
      "Epoch 747/1000 - Train Loss: 0.6499, Validation Loss: 0.6489\n",
      "Epoch 748/1000 - Train Loss: 0.6499, Validation Loss: 0.6488\n",
      "Epoch 749/1000 - Train Loss: 0.6498, Validation Loss: 0.6487\n",
      "Epoch 750/1000 - Train Loss: 0.6498, Validation Loss: 0.6487\n",
      "Epoch 751/1000 - Train Loss: 0.6497, Validation Loss: 0.6486\n",
      "Epoch 752/1000 - Train Loss: 0.6497, Validation Loss: 0.6486\n",
      "Epoch 753/1000 - Train Loss: 0.6496, Validation Loss: 0.6485\n",
      "Epoch 754/1000 - Train Loss: 0.6496, Validation Loss: 0.6485\n",
      "Epoch 755/1000 - Train Loss: 0.6495, Validation Loss: 0.6484\n",
      "Epoch 756/1000 - Train Loss: 0.6495, Validation Loss: 0.6484\n",
      "Epoch 757/1000 - Train Loss: 0.6494, Validation Loss: 0.6483\n",
      "Epoch 758/1000 - Train Loss: 0.6494, Validation Loss: 0.6483\n",
      "Epoch 759/1000 - Train Loss: 0.6493, Validation Loss: 0.6482\n",
      "Epoch 760/1000 - Train Loss: 0.6493, Validation Loss: 0.6482\n",
      "Epoch 761/1000 - Train Loss: 0.6492, Validation Loss: 0.6481\n",
      "Epoch 762/1000 - Train Loss: 0.6492, Validation Loss: 0.6481\n",
      "Epoch 763/1000 - Train Loss: 0.6491, Validation Loss: 0.6480\n",
      "Epoch 764/1000 - Train Loss: 0.6491, Validation Loss: 0.6480\n",
      "Epoch 765/1000 - Train Loss: 0.6490, Validation Loss: 0.6479\n",
      "Epoch 766/1000 - Train Loss: 0.6489, Validation Loss: 0.6478\n",
      "Epoch 767/1000 - Train Loss: 0.6489, Validation Loss: 0.6478\n",
      "Epoch 768/1000 - Train Loss: 0.6488, Validation Loss: 0.6477\n",
      "Epoch 769/1000 - Train Loss: 0.6488, Validation Loss: 0.6477\n",
      "Epoch 770/1000 - Train Loss: 0.6487, Validation Loss: 0.6476\n",
      "Epoch 771/1000 - Train Loss: 0.6487, Validation Loss: 0.6476\n",
      "Epoch 772/1000 - Train Loss: 0.6486, Validation Loss: 0.6475\n",
      "Epoch 773/1000 - Train Loss: 0.6486, Validation Loss: 0.6475\n",
      "Epoch 774/1000 - Train Loss: 0.6485, Validation Loss: 0.6474\n",
      "Epoch 775/1000 - Train Loss: 0.6485, Validation Loss: 0.6474\n",
      "Epoch 776/1000 - Train Loss: 0.6484, Validation Loss: 0.6473\n",
      "Epoch 777/1000 - Train Loss: 0.6484, Validation Loss: 0.6473\n",
      "Epoch 778/1000 - Train Loss: 0.6483, Validation Loss: 0.6472\n",
      "Epoch 779/1000 - Train Loss: 0.6483, Validation Loss: 0.6472\n",
      "Epoch 780/1000 - Train Loss: 0.6482, Validation Loss: 0.6471\n",
      "Epoch 781/1000 - Train Loss: 0.6482, Validation Loss: 0.6471\n",
      "Epoch 782/1000 - Train Loss: 0.6481, Validation Loss: 0.6470\n",
      "Epoch 783/1000 - Train Loss: 0.6481, Validation Loss: 0.6469\n",
      "Epoch 784/1000 - Train Loss: 0.6480, Validation Loss: 0.6469\n",
      "Epoch 785/1000 - Train Loss: 0.6480, Validation Loss: 0.6468\n",
      "Epoch 786/1000 - Train Loss: 0.6479, Validation Loss: 0.6468\n",
      "Epoch 787/1000 - Train Loss: 0.6479, Validation Loss: 0.6467\n",
      "Epoch 788/1000 - Train Loss: 0.6478, Validation Loss: 0.6467\n",
      "Epoch 789/1000 - Train Loss: 0.6478, Validation Loss: 0.6466\n",
      "Epoch 790/1000 - Train Loss: 0.6477, Validation Loss: 0.6466\n",
      "Epoch 791/1000 - Train Loss: 0.6476, Validation Loss: 0.6465\n",
      "Epoch 792/1000 - Train Loss: 0.6476, Validation Loss: 0.6465\n",
      "Epoch 793/1000 - Train Loss: 0.6475, Validation Loss: 0.6464\n",
      "Epoch 794/1000 - Train Loss: 0.6475, Validation Loss: 0.6464\n",
      "Epoch 795/1000 - Train Loss: 0.6474, Validation Loss: 0.6463\n",
      "Epoch 796/1000 - Train Loss: 0.6474, Validation Loss: 0.6463\n",
      "Epoch 797/1000 - Train Loss: 0.6473, Validation Loss: 0.6462\n",
      "Epoch 798/1000 - Train Loss: 0.6473, Validation Loss: 0.6462\n",
      "Epoch 799/1000 - Train Loss: 0.6472, Validation Loss: 0.6461\n",
      "Epoch 800/1000 - Train Loss: 0.6472, Validation Loss: 0.6461\n",
      "Epoch 801/1000 - Train Loss: 0.6471, Validation Loss: 0.6460\n",
      "Epoch 802/1000 - Train Loss: 0.6471, Validation Loss: 0.6459\n",
      "Epoch 803/1000 - Train Loss: 0.6470, Validation Loss: 0.6459\n",
      "Epoch 804/1000 - Train Loss: 0.6470, Validation Loss: 0.6458\n",
      "Epoch 805/1000 - Train Loss: 0.6469, Validation Loss: 0.6458\n",
      "Epoch 806/1000 - Train Loss: 0.6469, Validation Loss: 0.6457\n",
      "Epoch 807/1000 - Train Loss: 0.6468, Validation Loss: 0.6457\n",
      "Epoch 808/1000 - Train Loss: 0.6468, Validation Loss: 0.6456\n",
      "Epoch 809/1000 - Train Loss: 0.6467, Validation Loss: 0.6456\n",
      "Epoch 810/1000 - Train Loss: 0.6467, Validation Loss: 0.6455\n",
      "Epoch 811/1000 - Train Loss: 0.6466, Validation Loss: 0.6455\n",
      "Epoch 812/1000 - Train Loss: 0.6466, Validation Loss: 0.6454\n",
      "Epoch 813/1000 - Train Loss: 0.6465, Validation Loss: 0.6454\n",
      "Epoch 814/1000 - Train Loss: 0.6465, Validation Loss: 0.6453\n",
      "Epoch 815/1000 - Train Loss: 0.6464, Validation Loss: 0.6453\n",
      "Epoch 816/1000 - Train Loss: 0.6464, Validation Loss: 0.6452\n",
      "Epoch 817/1000 - Train Loss: 0.6463, Validation Loss: 0.6452\n",
      "Epoch 818/1000 - Train Loss: 0.6463, Validation Loss: 0.6451\n",
      "Epoch 819/1000 - Train Loss: 0.6462, Validation Loss: 0.6451\n",
      "Epoch 820/1000 - Train Loss: 0.6461, Validation Loss: 0.6450\n",
      "Epoch 821/1000 - Train Loss: 0.6461, Validation Loss: 0.6450\n",
      "Epoch 822/1000 - Train Loss: 0.6460, Validation Loss: 0.6449\n",
      "Epoch 823/1000 - Train Loss: 0.6460, Validation Loss: 0.6448\n",
      "Epoch 824/1000 - Train Loss: 0.6459, Validation Loss: 0.6448\n",
      "Epoch 825/1000 - Train Loss: 0.6459, Validation Loss: 0.6447\n",
      "Epoch 826/1000 - Train Loss: 0.6458, Validation Loss: 0.6447\n",
      "Epoch 827/1000 - Train Loss: 0.6458, Validation Loss: 0.6446\n",
      "Epoch 828/1000 - Train Loss: 0.6457, Validation Loss: 0.6446\n",
      "Epoch 829/1000 - Train Loss: 0.6457, Validation Loss: 0.6445\n",
      "Epoch 830/1000 - Train Loss: 0.6456, Validation Loss: 0.6445\n",
      "Epoch 831/1000 - Train Loss: 0.6456, Validation Loss: 0.6444\n",
      "Epoch 832/1000 - Train Loss: 0.6455, Validation Loss: 0.6444\n",
      "Epoch 833/1000 - Train Loss: 0.6455, Validation Loss: 0.6443\n",
      "Epoch 834/1000 - Train Loss: 0.6454, Validation Loss: 0.6443\n",
      "Epoch 835/1000 - Train Loss: 0.6454, Validation Loss: 0.6442\n",
      "Epoch 836/1000 - Train Loss: 0.6453, Validation Loss: 0.6442\n",
      "Epoch 837/1000 - Train Loss: 0.6453, Validation Loss: 0.6441\n",
      "Epoch 838/1000 - Train Loss: 0.6452, Validation Loss: 0.6441\n",
      "Epoch 839/1000 - Train Loss: 0.6452, Validation Loss: 0.6440\n",
      "Epoch 840/1000 - Train Loss: 0.6451, Validation Loss: 0.6440\n",
      "Epoch 841/1000 - Train Loss: 0.6451, Validation Loss: 0.6439\n",
      "Epoch 842/1000 - Train Loss: 0.6450, Validation Loss: 0.6439\n",
      "Epoch 843/1000 - Train Loss: 0.6450, Validation Loss: 0.6438\n",
      "Epoch 844/1000 - Train Loss: 0.6449, Validation Loss: 0.6438\n",
      "Epoch 845/1000 - Train Loss: 0.6449, Validation Loss: 0.6437\n",
      "Epoch 846/1000 - Train Loss: 0.6448, Validation Loss: 0.6436\n",
      "Epoch 847/1000 - Train Loss: 0.6448, Validation Loss: 0.6436\n",
      "Epoch 848/1000 - Train Loss: 0.6447, Validation Loss: 0.6435\n",
      "Epoch 849/1000 - Train Loss: 0.6447, Validation Loss: 0.6435\n",
      "Epoch 850/1000 - Train Loss: 0.6446, Validation Loss: 0.6434\n",
      "Epoch 851/1000 - Train Loss: 0.6446, Validation Loss: 0.6434\n",
      "Epoch 852/1000 - Train Loss: 0.6445, Validation Loss: 0.6433\n",
      "Epoch 853/1000 - Train Loss: 0.6445, Validation Loss: 0.6433\n",
      "Epoch 854/1000 - Train Loss: 0.6444, Validation Loss: 0.6432\n",
      "Epoch 855/1000 - Train Loss: 0.6444, Validation Loss: 0.6432\n",
      "Epoch 856/1000 - Train Loss: 0.6443, Validation Loss: 0.6431\n",
      "Epoch 857/1000 - Train Loss: 0.6443, Validation Loss: 0.6431\n",
      "Epoch 858/1000 - Train Loss: 0.6442, Validation Loss: 0.6430\n",
      "Epoch 859/1000 - Train Loss: 0.6441, Validation Loss: 0.6430\n",
      "Epoch 860/1000 - Train Loss: 0.6441, Validation Loss: 0.6429\n",
      "Epoch 861/1000 - Train Loss: 0.6440, Validation Loss: 0.6429\n",
      "Epoch 862/1000 - Train Loss: 0.6440, Validation Loss: 0.6428\n",
      "Epoch 863/1000 - Train Loss: 0.6439, Validation Loss: 0.6428\n",
      "Epoch 864/1000 - Train Loss: 0.6439, Validation Loss: 0.6427\n",
      "Epoch 865/1000 - Train Loss: 0.6438, Validation Loss: 0.6427\n",
      "Epoch 866/1000 - Train Loss: 0.6438, Validation Loss: 0.6426\n",
      "Epoch 867/1000 - Train Loss: 0.6437, Validation Loss: 0.6426\n",
      "Epoch 868/1000 - Train Loss: 0.6437, Validation Loss: 0.6425\n",
      "Epoch 869/1000 - Train Loss: 0.6436, Validation Loss: 0.6425\n",
      "Epoch 870/1000 - Train Loss: 0.6436, Validation Loss: 0.6424\n",
      "Epoch 871/1000 - Train Loss: 0.6435, Validation Loss: 0.6423\n",
      "Epoch 872/1000 - Train Loss: 0.6435, Validation Loss: 0.6423\n",
      "Epoch 873/1000 - Train Loss: 0.6434, Validation Loss: 0.6422\n",
      "Epoch 874/1000 - Train Loss: 0.6434, Validation Loss: 0.6422\n",
      "Epoch 875/1000 - Train Loss: 0.6433, Validation Loss: 0.6421\n",
      "Epoch 876/1000 - Train Loss: 0.6433, Validation Loss: 0.6421\n",
      "Epoch 877/1000 - Train Loss: 0.6432, Validation Loss: 0.6420\n",
      "Epoch 878/1000 - Train Loss: 0.6432, Validation Loss: 0.6420\n",
      "Epoch 879/1000 - Train Loss: 0.6431, Validation Loss: 0.6419\n",
      "Epoch 880/1000 - Train Loss: 0.6431, Validation Loss: 0.6419\n",
      "Epoch 881/1000 - Train Loss: 0.6430, Validation Loss: 0.6418\n",
      "Epoch 882/1000 - Train Loss: 0.6430, Validation Loss: 0.6418\n",
      "Epoch 883/1000 - Train Loss: 0.6429, Validation Loss: 0.6417\n",
      "Epoch 884/1000 - Train Loss: 0.6429, Validation Loss: 0.6417\n",
      "Epoch 885/1000 - Train Loss: 0.6428, Validation Loss: 0.6416\n",
      "Epoch 886/1000 - Train Loss: 0.6428, Validation Loss: 0.6416\n",
      "Epoch 887/1000 - Train Loss: 0.6427, Validation Loss: 0.6415\n",
      "Epoch 888/1000 - Train Loss: 0.6427, Validation Loss: 0.6415\n",
      "Epoch 889/1000 - Train Loss: 0.6426, Validation Loss: 0.6414\n",
      "Epoch 890/1000 - Train Loss: 0.6426, Validation Loss: 0.6414\n",
      "Epoch 891/1000 - Train Loss: 0.6425, Validation Loss: 0.6413\n",
      "Epoch 892/1000 - Train Loss: 0.6425, Validation Loss: 0.6413\n",
      "Epoch 893/1000 - Train Loss: 0.6424, Validation Loss: 0.6412\n",
      "Epoch 894/1000 - Train Loss: 0.6424, Validation Loss: 0.6412\n",
      "Epoch 895/1000 - Train Loss: 0.6423, Validation Loss: 0.6411\n",
      "Epoch 896/1000 - Train Loss: 0.6423, Validation Loss: 0.6411\n",
      "Epoch 897/1000 - Train Loss: 0.6422, Validation Loss: 0.6410\n",
      "Epoch 898/1000 - Train Loss: 0.6422, Validation Loss: 0.6410\n",
      "Epoch 899/1000 - Train Loss: 0.6421, Validation Loss: 0.6409\n",
      "Epoch 900/1000 - Train Loss: 0.6421, Validation Loss: 0.6409\n",
      "Epoch 901/1000 - Train Loss: 0.6420, Validation Loss: 0.6408\n",
      "Epoch 902/1000 - Train Loss: 0.6420, Validation Loss: 0.6407\n",
      "Epoch 903/1000 - Train Loss: 0.6419, Validation Loss: 0.6407\n",
      "Epoch 904/1000 - Train Loss: 0.6419, Validation Loss: 0.6406\n",
      "Epoch 905/1000 - Train Loss: 0.6418, Validation Loss: 0.6406\n",
      "Epoch 906/1000 - Train Loss: 0.6418, Validation Loss: 0.6405\n",
      "Epoch 907/1000 - Train Loss: 0.6417, Validation Loss: 0.6405\n",
      "Epoch 908/1000 - Train Loss: 0.6417, Validation Loss: 0.6404\n",
      "Epoch 909/1000 - Train Loss: 0.6416, Validation Loss: 0.6404\n",
      "Epoch 910/1000 - Train Loss: 0.6416, Validation Loss: 0.6403\n",
      "Epoch 911/1000 - Train Loss: 0.6415, Validation Loss: 0.6403\n",
      "Epoch 912/1000 - Train Loss: 0.6415, Validation Loss: 0.6402\n",
      "Epoch 913/1000 - Train Loss: 0.6414, Validation Loss: 0.6402\n",
      "Epoch 914/1000 - Train Loss: 0.6414, Validation Loss: 0.6401\n",
      "Epoch 915/1000 - Train Loss: 0.6413, Validation Loss: 0.6401\n",
      "Epoch 916/1000 - Train Loss: 0.6413, Validation Loss: 0.6400\n",
      "Epoch 917/1000 - Train Loss: 0.6412, Validation Loss: 0.6400\n",
      "Epoch 918/1000 - Train Loss: 0.6412, Validation Loss: 0.6399\n",
      "Epoch 919/1000 - Train Loss: 0.6411, Validation Loss: 0.6399\n",
      "Epoch 920/1000 - Train Loss: 0.6411, Validation Loss: 0.6398\n",
      "Epoch 921/1000 - Train Loss: 0.6410, Validation Loss: 0.6398\n",
      "Epoch 922/1000 - Train Loss: 0.6410, Validation Loss: 0.6397\n",
      "Epoch 923/1000 - Train Loss: 0.6409, Validation Loss: 0.6397\n",
      "Epoch 924/1000 - Train Loss: 0.6408, Validation Loss: 0.6396\n",
      "Epoch 925/1000 - Train Loss: 0.6408, Validation Loss: 0.6396\n",
      "Epoch 926/1000 - Train Loss: 0.6407, Validation Loss: 0.6395\n",
      "Epoch 927/1000 - Train Loss: 0.6407, Validation Loss: 0.6395\n",
      "Epoch 928/1000 - Train Loss: 0.6406, Validation Loss: 0.6394\n",
      "Epoch 929/1000 - Train Loss: 0.6406, Validation Loss: 0.6394\n",
      "Epoch 930/1000 - Train Loss: 0.6405, Validation Loss: 0.6393\n",
      "Epoch 931/1000 - Train Loss: 0.6405, Validation Loss: 0.6393\n",
      "Epoch 932/1000 - Train Loss: 0.6404, Validation Loss: 0.6392\n",
      "Epoch 933/1000 - Train Loss: 0.6404, Validation Loss: 0.6392\n",
      "Epoch 934/1000 - Train Loss: 0.6403, Validation Loss: 0.6391\n",
      "Epoch 935/1000 - Train Loss: 0.6403, Validation Loss: 0.6391\n",
      "Epoch 936/1000 - Train Loss: 0.6402, Validation Loss: 0.6390\n",
      "Epoch 937/1000 - Train Loss: 0.6402, Validation Loss: 0.6390\n",
      "Epoch 938/1000 - Train Loss: 0.6401, Validation Loss: 0.6389\n",
      "Epoch 939/1000 - Train Loss: 0.6401, Validation Loss: 0.6389\n",
      "Epoch 940/1000 - Train Loss: 0.6400, Validation Loss: 0.6388\n",
      "Epoch 941/1000 - Train Loss: 0.6400, Validation Loss: 0.6388\n",
      "Epoch 942/1000 - Train Loss: 0.6399, Validation Loss: 0.6387\n",
      "Epoch 943/1000 - Train Loss: 0.6399, Validation Loss: 0.6387\n",
      "Epoch 944/1000 - Train Loss: 0.6398, Validation Loss: 0.6386\n",
      "Epoch 945/1000 - Train Loss: 0.6398, Validation Loss: 0.6385\n",
      "Epoch 946/1000 - Train Loss: 0.6397, Validation Loss: 0.6385\n",
      "Epoch 947/1000 - Train Loss: 0.6397, Validation Loss: 0.6384\n",
      "Epoch 948/1000 - Train Loss: 0.6396, Validation Loss: 0.6384\n",
      "Epoch 949/1000 - Train Loss: 0.6396, Validation Loss: 0.6383\n",
      "Epoch 950/1000 - Train Loss: 0.6395, Validation Loss: 0.6383\n",
      "Epoch 951/1000 - Train Loss: 0.6395, Validation Loss: 0.6382\n",
      "Epoch 952/1000 - Train Loss: 0.6394, Validation Loss: 0.6382\n",
      "Epoch 953/1000 - Train Loss: 0.6394, Validation Loss: 0.6381\n",
      "Epoch 954/1000 - Train Loss: 0.6393, Validation Loss: 0.6381\n",
      "Epoch 955/1000 - Train Loss: 0.6393, Validation Loss: 0.6380\n",
      "Epoch 956/1000 - Train Loss: 0.6392, Validation Loss: 0.6380\n",
      "Epoch 957/1000 - Train Loss: 0.6392, Validation Loss: 0.6379\n",
      "Epoch 958/1000 - Train Loss: 0.6391, Validation Loss: 0.6379\n",
      "Epoch 959/1000 - Train Loss: 0.6391, Validation Loss: 0.6378\n",
      "Epoch 960/1000 - Train Loss: 0.6390, Validation Loss: 0.6378\n",
      "Epoch 961/1000 - Train Loss: 0.6390, Validation Loss: 0.6377\n",
      "Epoch 962/1000 - Train Loss: 0.6389, Validation Loss: 0.6377\n",
      "Epoch 963/1000 - Train Loss: 0.6389, Validation Loss: 0.6376\n",
      "Epoch 964/1000 - Train Loss: 0.6388, Validation Loss: 0.6376\n",
      "Epoch 965/1000 - Train Loss: 0.6388, Validation Loss: 0.6375\n",
      "Epoch 966/1000 - Train Loss: 0.6387, Validation Loss: 0.6375\n",
      "Epoch 967/1000 - Train Loss: 0.6387, Validation Loss: 0.6374\n",
      "Epoch 968/1000 - Train Loss: 0.6386, Validation Loss: 0.6374\n",
      "Epoch 969/1000 - Train Loss: 0.6386, Validation Loss: 0.6373\n",
      "Epoch 970/1000 - Train Loss: 0.6385, Validation Loss: 0.6373\n",
      "Epoch 971/1000 - Train Loss: 0.6385, Validation Loss: 0.6372\n",
      "Epoch 972/1000 - Train Loss: 0.6384, Validation Loss: 0.6372\n",
      "Epoch 973/1000 - Train Loss: 0.6384, Validation Loss: 0.6371\n",
      "Epoch 974/1000 - Train Loss: 0.6383, Validation Loss: 0.6371\n",
      "Epoch 975/1000 - Train Loss: 0.6383, Validation Loss: 0.6370\n",
      "Epoch 976/1000 - Train Loss: 0.6382, Validation Loss: 0.6370\n",
      "Epoch 977/1000 - Train Loss: 0.6382, Validation Loss: 0.6369\n",
      "Epoch 978/1000 - Train Loss: 0.6381, Validation Loss: 0.6369\n",
      "Epoch 979/1000 - Train Loss: 0.6381, Validation Loss: 0.6368\n",
      "Epoch 980/1000 - Train Loss: 0.6380, Validation Loss: 0.6368\n",
      "Epoch 981/1000 - Train Loss: 0.6380, Validation Loss: 0.6367\n",
      "Epoch 982/1000 - Train Loss: 0.6379, Validation Loss: 0.6367\n",
      "Epoch 983/1000 - Train Loss: 0.6379, Validation Loss: 0.6366\n",
      "Epoch 984/1000 - Train Loss: 0.6378, Validation Loss: 0.6366\n",
      "Epoch 985/1000 - Train Loss: 0.6378, Validation Loss: 0.6365\n",
      "Epoch 986/1000 - Train Loss: 0.6377, Validation Loss: 0.6365\n",
      "Epoch 987/1000 - Train Loss: 0.6377, Validation Loss: 0.6364\n",
      "Epoch 988/1000 - Train Loss: 0.6376, Validation Loss: 0.6364\n",
      "Epoch 989/1000 - Train Loss: 0.6376, Validation Loss: 0.6363\n",
      "Epoch 990/1000 - Train Loss: 0.6375, Validation Loss: 0.6363\n",
      "Epoch 991/1000 - Train Loss: 0.6375, Validation Loss: 0.6362\n",
      "Epoch 992/1000 - Train Loss: 0.6374, Validation Loss: 0.6362\n",
      "Epoch 993/1000 - Train Loss: 0.6374, Validation Loss: 0.6361\n",
      "Epoch 994/1000 - Train Loss: 0.6373, Validation Loss: 0.6361\n",
      "Epoch 995/1000 - Train Loss: 0.6373, Validation Loss: 0.6360\n",
      "Epoch 996/1000 - Train Loss: 0.6372, Validation Loss: 0.6360\n",
      "Epoch 997/1000 - Train Loss: 0.6372, Validation Loss: 0.6359\n",
      "Epoch 998/1000 - Train Loss: 0.6371, Validation Loss: 0.6359\n",
      "Epoch 999/1000 - Train Loss: 0.6371, Validation Loss: 0.6358\n",
      "Epoch 1000/1000 - Train Loss: 0.6370, Validation Loss: 0.6358\n",
      "Epoch 1/1000 - Train Loss: 0.6931, Validation Loss: 0.6929\n",
      "Epoch 2/1000 - Train Loss: 0.6929, Validation Loss: 0.6927\n",
      "Epoch 3/1000 - Train Loss: 0.6927, Validation Loss: 0.6925\n",
      "Epoch 4/1000 - Train Loss: 0.6925, Validation Loss: 0.6923\n",
      "Epoch 5/1000 - Train Loss: 0.6923, Validation Loss: 0.6920\n",
      "Epoch 6/1000 - Train Loss: 0.6921, Validation Loss: 0.6918\n",
      "Epoch 7/1000 - Train Loss: 0.6918, Validation Loss: 0.6916\n",
      "Epoch 8/1000 - Train Loss: 0.6916, Validation Loss: 0.6914\n",
      "Epoch 9/1000 - Train Loss: 0.6914, Validation Loss: 0.6911\n",
      "Epoch 10/1000 - Train Loss: 0.6912, Validation Loss: 0.6909\n",
      "Epoch 11/1000 - Train Loss: 0.6910, Validation Loss: 0.6907\n",
      "Epoch 12/1000 - Train Loss: 0.6908, Validation Loss: 0.6905\n",
      "Epoch 13/1000 - Train Loss: 0.6905, Validation Loss: 0.6903\n",
      "Epoch 14/1000 - Train Loss: 0.6903, Validation Loss: 0.6900\n",
      "Epoch 15/1000 - Train Loss: 0.6901, Validation Loss: 0.6898\n",
      "Epoch 16/1000 - Train Loss: 0.6899, Validation Loss: 0.6896\n",
      "Epoch 17/1000 - Train Loss: 0.6897, Validation Loss: 0.6894\n",
      "Epoch 18/1000 - Train Loss: 0.6895, Validation Loss: 0.6892\n",
      "Epoch 19/1000 - Train Loss: 0.6893, Validation Loss: 0.6889\n",
      "Epoch 20/1000 - Train Loss: 0.6891, Validation Loss: 0.6887\n",
      "Epoch 21/1000 - Train Loss: 0.6888, Validation Loss: 0.6885\n",
      "Epoch 22/1000 - Train Loss: 0.6886, Validation Loss: 0.6883\n",
      "Epoch 23/1000 - Train Loss: 0.6884, Validation Loss: 0.6881\n",
      "Epoch 24/1000 - Train Loss: 0.6882, Validation Loss: 0.6878\n",
      "Epoch 25/1000 - Train Loss: 0.6880, Validation Loss: 0.6876\n",
      "Epoch 26/1000 - Train Loss: 0.6878, Validation Loss: 0.6874\n",
      "Epoch 27/1000 - Train Loss: 0.6876, Validation Loss: 0.6872\n",
      "Epoch 28/1000 - Train Loss: 0.6874, Validation Loss: 0.6870\n",
      "Epoch 29/1000 - Train Loss: 0.6872, Validation Loss: 0.6868\n",
      "Epoch 30/1000 - Train Loss: 0.6869, Validation Loss: 0.6865\n",
      "Epoch 31/1000 - Train Loss: 0.6867, Validation Loss: 0.6863\n",
      "Epoch 32/1000 - Train Loss: 0.6865, Validation Loss: 0.6861\n",
      "Epoch 33/1000 - Train Loss: 0.6863, Validation Loss: 0.6859\n",
      "Epoch 34/1000 - Train Loss: 0.6861, Validation Loss: 0.6857\n",
      "Epoch 35/1000 - Train Loss: 0.6859, Validation Loss: 0.6855\n",
      "Epoch 36/1000 - Train Loss: 0.6857, Validation Loss: 0.6853\n",
      "Epoch 37/1000 - Train Loss: 0.6855, Validation Loss: 0.6850\n",
      "Epoch 38/1000 - Train Loss: 0.6853, Validation Loss: 0.6848\n",
      "Epoch 39/1000 - Train Loss: 0.6851, Validation Loss: 0.6846\n",
      "Epoch 40/1000 - Train Loss: 0.6849, Validation Loss: 0.6844\n",
      "Epoch 41/1000 - Train Loss: 0.6846, Validation Loss: 0.6842\n",
      "Epoch 42/1000 - Train Loss: 0.6844, Validation Loss: 0.6840\n",
      "Epoch 43/1000 - Train Loss: 0.6842, Validation Loss: 0.6838\n",
      "Epoch 44/1000 - Train Loss: 0.6840, Validation Loss: 0.6836\n",
      "Epoch 45/1000 - Train Loss: 0.6838, Validation Loss: 0.6833\n",
      "Epoch 46/1000 - Train Loss: 0.6836, Validation Loss: 0.6831\n",
      "Epoch 47/1000 - Train Loss: 0.6834, Validation Loss: 0.6829\n",
      "Epoch 48/1000 - Train Loss: 0.6832, Validation Loss: 0.6827\n",
      "Epoch 49/1000 - Train Loss: 0.6830, Validation Loss: 0.6825\n",
      "Epoch 50/1000 - Train Loss: 0.6828, Validation Loss: 0.6823\n",
      "Epoch 51/1000 - Train Loss: 0.6826, Validation Loss: 0.6821\n",
      "Epoch 52/1000 - Train Loss: 0.6824, Validation Loss: 0.6819\n",
      "Epoch 53/1000 - Train Loss: 0.6822, Validation Loss: 0.6817\n",
      "Epoch 54/1000 - Train Loss: 0.6820, Validation Loss: 0.6814\n",
      "Epoch 55/1000 - Train Loss: 0.6818, Validation Loss: 0.6812\n",
      "Epoch 56/1000 - Train Loss: 0.6816, Validation Loss: 0.6810\n",
      "Epoch 57/1000 - Train Loss: 0.6814, Validation Loss: 0.6808\n",
      "Epoch 58/1000 - Train Loss: 0.6812, Validation Loss: 0.6806\n",
      "Epoch 59/1000 - Train Loss: 0.6810, Validation Loss: 0.6804\n",
      "Epoch 60/1000 - Train Loss: 0.6808, Validation Loss: 0.6802\n",
      "Epoch 61/1000 - Train Loss: 0.6806, Validation Loss: 0.6800\n",
      "Epoch 62/1000 - Train Loss: 0.6803, Validation Loss: 0.6798\n",
      "Epoch 63/1000 - Train Loss: 0.6801, Validation Loss: 0.6796\n",
      "Epoch 64/1000 - Train Loss: 0.6799, Validation Loss: 0.6794\n",
      "Epoch 65/1000 - Train Loss: 0.6797, Validation Loss: 0.6792\n",
      "Epoch 66/1000 - Train Loss: 0.6795, Validation Loss: 0.6790\n",
      "Epoch 67/1000 - Train Loss: 0.6793, Validation Loss: 0.6787\n",
      "Epoch 68/1000 - Train Loss: 0.6791, Validation Loss: 0.6785\n",
      "Epoch 69/1000 - Train Loss: 0.6789, Validation Loss: 0.6783\n",
      "Epoch 70/1000 - Train Loss: 0.6787, Validation Loss: 0.6781\n",
      "Epoch 71/1000 - Train Loss: 0.6785, Validation Loss: 0.6779\n",
      "Epoch 72/1000 - Train Loss: 0.6783, Validation Loss: 0.6777\n",
      "Epoch 73/1000 - Train Loss: 0.6781, Validation Loss: 0.6775\n",
      "Epoch 74/1000 - Train Loss: 0.6779, Validation Loss: 0.6773\n",
      "Epoch 75/1000 - Train Loss: 0.6777, Validation Loss: 0.6771\n",
      "Epoch 76/1000 - Train Loss: 0.6775, Validation Loss: 0.6769\n",
      "Epoch 77/1000 - Train Loss: 0.6773, Validation Loss: 0.6767\n",
      "Epoch 78/1000 - Train Loss: 0.6771, Validation Loss: 0.6765\n",
      "Epoch 79/1000 - Train Loss: 0.6769, Validation Loss: 0.6763\n",
      "Epoch 80/1000 - Train Loss: 0.6767, Validation Loss: 0.6761\n",
      "Epoch 81/1000 - Train Loss: 0.6765, Validation Loss: 0.6759\n",
      "Epoch 82/1000 - Train Loss: 0.6764, Validation Loss: 0.6757\n",
      "Epoch 83/1000 - Train Loss: 0.6762, Validation Loss: 0.6755\n",
      "Epoch 84/1000 - Train Loss: 0.6760, Validation Loss: 0.6753\n",
      "Epoch 85/1000 - Train Loss: 0.6758, Validation Loss: 0.6751\n",
      "Epoch 86/1000 - Train Loss: 0.6756, Validation Loss: 0.6749\n",
      "Epoch 87/1000 - Train Loss: 0.6754, Validation Loss: 0.6747\n",
      "Epoch 88/1000 - Train Loss: 0.6752, Validation Loss: 0.6745\n",
      "Epoch 89/1000 - Train Loss: 0.6750, Validation Loss: 0.6743\n",
      "Epoch 90/1000 - Train Loss: 0.6748, Validation Loss: 0.6741\n",
      "Epoch 91/1000 - Train Loss: 0.6746, Validation Loss: 0.6739\n",
      "Epoch 92/1000 - Train Loss: 0.6744, Validation Loss: 0.6737\n",
      "Epoch 93/1000 - Train Loss: 0.6742, Validation Loss: 0.6735\n",
      "Epoch 94/1000 - Train Loss: 0.6740, Validation Loss: 0.6733\n",
      "Epoch 95/1000 - Train Loss: 0.6738, Validation Loss: 0.6731\n",
      "Epoch 96/1000 - Train Loss: 0.6736, Validation Loss: 0.6729\n",
      "Epoch 97/1000 - Train Loss: 0.6734, Validation Loss: 0.6727\n",
      "Epoch 98/1000 - Train Loss: 0.6732, Validation Loss: 0.6725\n",
      "Epoch 99/1000 - Train Loss: 0.6730, Validation Loss: 0.6723\n",
      "Epoch 100/1000 - Train Loss: 0.6728, Validation Loss: 0.6721\n",
      "Epoch 101/1000 - Train Loss: 0.6726, Validation Loss: 0.6719\n",
      "Epoch 102/1000 - Train Loss: 0.6724, Validation Loss: 0.6717\n",
      "Epoch 103/1000 - Train Loss: 0.6722, Validation Loss: 0.6715\n",
      "Epoch 104/1000 - Train Loss: 0.6721, Validation Loss: 0.6713\n",
      "Epoch 105/1000 - Train Loss: 0.6719, Validation Loss: 0.6711\n",
      "Epoch 106/1000 - Train Loss: 0.6717, Validation Loss: 0.6709\n",
      "Epoch 107/1000 - Train Loss: 0.6715, Validation Loss: 0.6707\n",
      "Epoch 108/1000 - Train Loss: 0.6713, Validation Loss: 0.6705\n",
      "Epoch 109/1000 - Train Loss: 0.6711, Validation Loss: 0.6703\n",
      "Epoch 110/1000 - Train Loss: 0.6709, Validation Loss: 0.6701\n",
      "Epoch 111/1000 - Train Loss: 0.6707, Validation Loss: 0.6699\n",
      "Epoch 112/1000 - Train Loss: 0.6705, Validation Loss: 0.6697\n",
      "Epoch 113/1000 - Train Loss: 0.6703, Validation Loss: 0.6695\n",
      "Epoch 114/1000 - Train Loss: 0.6701, Validation Loss: 0.6693\n",
      "Epoch 115/1000 - Train Loss: 0.6699, Validation Loss: 0.6691\n",
      "Epoch 116/1000 - Train Loss: 0.6697, Validation Loss: 0.6689\n",
      "Epoch 117/1000 - Train Loss: 0.6696, Validation Loss: 0.6687\n",
      "Epoch 118/1000 - Train Loss: 0.6694, Validation Loss: 0.6685\n",
      "Epoch 119/1000 - Train Loss: 0.6692, Validation Loss: 0.6683\n",
      "Epoch 120/1000 - Train Loss: 0.6690, Validation Loss: 0.6681\n",
      "Epoch 121/1000 - Train Loss: 0.6688, Validation Loss: 0.6680\n",
      "Epoch 122/1000 - Train Loss: 0.6686, Validation Loss: 0.6678\n",
      "Epoch 123/1000 - Train Loss: 0.6684, Validation Loss: 0.6676\n",
      "Epoch 124/1000 - Train Loss: 0.6682, Validation Loss: 0.6674\n",
      "Epoch 125/1000 - Train Loss: 0.6680, Validation Loss: 0.6672\n",
      "Epoch 126/1000 - Train Loss: 0.6678, Validation Loss: 0.6670\n",
      "Epoch 127/1000 - Train Loss: 0.6677, Validation Loss: 0.6668\n",
      "Epoch 128/1000 - Train Loss: 0.6675, Validation Loss: 0.6666\n",
      "Epoch 129/1000 - Train Loss: 0.6673, Validation Loss: 0.6664\n",
      "Epoch 130/1000 - Train Loss: 0.6671, Validation Loss: 0.6662\n",
      "Epoch 131/1000 - Train Loss: 0.6669, Validation Loss: 0.6660\n",
      "Epoch 132/1000 - Train Loss: 0.6667, Validation Loss: 0.6658\n",
      "Epoch 133/1000 - Train Loss: 0.6665, Validation Loss: 0.6656\n",
      "Epoch 134/1000 - Train Loss: 0.6663, Validation Loss: 0.6654\n",
      "Epoch 135/1000 - Train Loss: 0.6662, Validation Loss: 0.6653\n",
      "Epoch 136/1000 - Train Loss: 0.6660, Validation Loss: 0.6651\n",
      "Epoch 137/1000 - Train Loss: 0.6658, Validation Loss: 0.6649\n",
      "Epoch 138/1000 - Train Loss: 0.6656, Validation Loss: 0.6647\n",
      "Epoch 139/1000 - Train Loss: 0.6654, Validation Loss: 0.6645\n",
      "Epoch 140/1000 - Train Loss: 0.6652, Validation Loss: 0.6643\n",
      "Epoch 141/1000 - Train Loss: 0.6650, Validation Loss: 0.6641\n",
      "Epoch 142/1000 - Train Loss: 0.6648, Validation Loss: 0.6639\n",
      "Epoch 143/1000 - Train Loss: 0.6647, Validation Loss: 0.6637\n",
      "Epoch 144/1000 - Train Loss: 0.6645, Validation Loss: 0.6635\n",
      "Epoch 145/1000 - Train Loss: 0.6643, Validation Loss: 0.6633\n",
      "Epoch 146/1000 - Train Loss: 0.6641, Validation Loss: 0.6632\n",
      "Epoch 147/1000 - Train Loss: 0.6639, Validation Loss: 0.6630\n",
      "Epoch 148/1000 - Train Loss: 0.6637, Validation Loss: 0.6628\n",
      "Epoch 149/1000 - Train Loss: 0.6635, Validation Loss: 0.6626\n",
      "Epoch 150/1000 - Train Loss: 0.6634, Validation Loss: 0.6624\n",
      "Epoch 151/1000 - Train Loss: 0.6632, Validation Loss: 0.6622\n",
      "Epoch 152/1000 - Train Loss: 0.6630, Validation Loss: 0.6620\n",
      "Epoch 153/1000 - Train Loss: 0.6628, Validation Loss: 0.6618\n",
      "Epoch 154/1000 - Train Loss: 0.6626, Validation Loss: 0.6616\n",
      "Epoch 155/1000 - Train Loss: 0.6624, Validation Loss: 0.6615\n",
      "Epoch 156/1000 - Train Loss: 0.6623, Validation Loss: 0.6613\n",
      "Epoch 157/1000 - Train Loss: 0.6621, Validation Loss: 0.6611\n",
      "Epoch 158/1000 - Train Loss: 0.6619, Validation Loss: 0.6609\n",
      "Epoch 159/1000 - Train Loss: 0.6617, Validation Loss: 0.6607\n",
      "Epoch 160/1000 - Train Loss: 0.6615, Validation Loss: 0.6605\n",
      "Epoch 161/1000 - Train Loss: 0.6613, Validation Loss: 0.6603\n",
      "Epoch 162/1000 - Train Loss: 0.6611, Validation Loss: 0.6601\n",
      "Epoch 163/1000 - Train Loss: 0.6610, Validation Loss: 0.6600\n",
      "Epoch 164/1000 - Train Loss: 0.6608, Validation Loss: 0.6598\n",
      "Epoch 165/1000 - Train Loss: 0.6606, Validation Loss: 0.6596\n",
      "Epoch 166/1000 - Train Loss: 0.6604, Validation Loss: 0.6594\n",
      "Epoch 167/1000 - Train Loss: 0.6602, Validation Loss: 0.6592\n",
      "Epoch 168/1000 - Train Loss: 0.6601, Validation Loss: 0.6590\n",
      "Epoch 169/1000 - Train Loss: 0.6599, Validation Loss: 0.6588\n",
      "Epoch 170/1000 - Train Loss: 0.6597, Validation Loss: 0.6587\n",
      "Epoch 171/1000 - Train Loss: 0.6595, Validation Loss: 0.6585\n",
      "Epoch 172/1000 - Train Loss: 0.6593, Validation Loss: 0.6583\n",
      "Epoch 173/1000 - Train Loss: 0.6591, Validation Loss: 0.6581\n",
      "Epoch 174/1000 - Train Loss: 0.6590, Validation Loss: 0.6579\n",
      "Epoch 175/1000 - Train Loss: 0.6588, Validation Loss: 0.6577\n",
      "Epoch 176/1000 - Train Loss: 0.6586, Validation Loss: 0.6575\n",
      "Epoch 177/1000 - Train Loss: 0.6584, Validation Loss: 0.6574\n",
      "Epoch 178/1000 - Train Loss: 0.6582, Validation Loss: 0.6572\n",
      "Epoch 179/1000 - Train Loss: 0.6581, Validation Loss: 0.6570\n",
      "Epoch 180/1000 - Train Loss: 0.6579, Validation Loss: 0.6568\n",
      "Epoch 181/1000 - Train Loss: 0.6577, Validation Loss: 0.6566\n",
      "Epoch 182/1000 - Train Loss: 0.6575, Validation Loss: 0.6564\n",
      "Epoch 183/1000 - Train Loss: 0.6573, Validation Loss: 0.6563\n",
      "Epoch 184/1000 - Train Loss: 0.6572, Validation Loss: 0.6561\n",
      "Epoch 185/1000 - Train Loss: 0.6570, Validation Loss: 0.6559\n",
      "Epoch 186/1000 - Train Loss: 0.6568, Validation Loss: 0.6557\n",
      "Epoch 187/1000 - Train Loss: 0.6566, Validation Loss: 0.6555\n",
      "Epoch 188/1000 - Train Loss: 0.6564, Validation Loss: 0.6553\n",
      "Epoch 189/1000 - Train Loss: 0.6563, Validation Loss: 0.6552\n",
      "Epoch 190/1000 - Train Loss: 0.6561, Validation Loss: 0.6550\n",
      "Epoch 191/1000 - Train Loss: 0.6559, Validation Loss: 0.6548\n",
      "Epoch 192/1000 - Train Loss: 0.6557, Validation Loss: 0.6546\n",
      "Epoch 193/1000 - Train Loss: 0.6555, Validation Loss: 0.6544\n",
      "Epoch 194/1000 - Train Loss: 0.6554, Validation Loss: 0.6543\n",
      "Epoch 195/1000 - Train Loss: 0.6552, Validation Loss: 0.6541\n",
      "Epoch 196/1000 - Train Loss: 0.6550, Validation Loss: 0.6539\n",
      "Epoch 197/1000 - Train Loss: 0.6548, Validation Loss: 0.6537\n",
      "Epoch 198/1000 - Train Loss: 0.6547, Validation Loss: 0.6535\n",
      "Epoch 199/1000 - Train Loss: 0.6545, Validation Loss: 0.6533\n",
      "Epoch 200/1000 - Train Loss: 0.6543, Validation Loss: 0.6532\n",
      "Epoch 201/1000 - Train Loss: 0.6541, Validation Loss: 0.6530\n",
      "Epoch 202/1000 - Train Loss: 0.6539, Validation Loss: 0.6528\n",
      "Epoch 203/1000 - Train Loss: 0.6538, Validation Loss: 0.6526\n",
      "Epoch 204/1000 - Train Loss: 0.6536, Validation Loss: 0.6524\n",
      "Epoch 205/1000 - Train Loss: 0.6534, Validation Loss: 0.6523\n",
      "Epoch 206/1000 - Train Loss: 0.6532, Validation Loss: 0.6521\n",
      "Epoch 207/1000 - Train Loss: 0.6531, Validation Loss: 0.6519\n",
      "Epoch 208/1000 - Train Loss: 0.6529, Validation Loss: 0.6517\n",
      "Epoch 209/1000 - Train Loss: 0.6527, Validation Loss: 0.6515\n",
      "Epoch 210/1000 - Train Loss: 0.6525, Validation Loss: 0.6514\n",
      "Epoch 211/1000 - Train Loss: 0.6524, Validation Loss: 0.6512\n",
      "Epoch 212/1000 - Train Loss: 0.6522, Validation Loss: 0.6510\n",
      "Epoch 213/1000 - Train Loss: 0.6520, Validation Loss: 0.6508\n",
      "Epoch 214/1000 - Train Loss: 0.6518, Validation Loss: 0.6506\n",
      "Epoch 215/1000 - Train Loss: 0.6516, Validation Loss: 0.6505\n",
      "Epoch 216/1000 - Train Loss: 0.6515, Validation Loss: 0.6503\n",
      "Epoch 217/1000 - Train Loss: 0.6513, Validation Loss: 0.6501\n",
      "Epoch 218/1000 - Train Loss: 0.6511, Validation Loss: 0.6499\n",
      "Epoch 219/1000 - Train Loss: 0.6509, Validation Loss: 0.6498\n",
      "Epoch 220/1000 - Train Loss: 0.6508, Validation Loss: 0.6496\n",
      "Epoch 221/1000 - Train Loss: 0.6506, Validation Loss: 0.6494\n",
      "Epoch 222/1000 - Train Loss: 0.6504, Validation Loss: 0.6492\n",
      "Epoch 223/1000 - Train Loss: 0.6502, Validation Loss: 0.6490\n",
      "Epoch 224/1000 - Train Loss: 0.6501, Validation Loss: 0.6489\n",
      "Epoch 225/1000 - Train Loss: 0.6499, Validation Loss: 0.6487\n",
      "Epoch 226/1000 - Train Loss: 0.6497, Validation Loss: 0.6485\n",
      "Epoch 227/1000 - Train Loss: 0.6495, Validation Loss: 0.6483\n",
      "Epoch 228/1000 - Train Loss: 0.6494, Validation Loss: 0.6482\n",
      "Epoch 229/1000 - Train Loss: 0.6492, Validation Loss: 0.6480\n",
      "Epoch 230/1000 - Train Loss: 0.6490, Validation Loss: 0.6478\n",
      "Epoch 231/1000 - Train Loss: 0.6489, Validation Loss: 0.6476\n",
      "Epoch 232/1000 - Train Loss: 0.6487, Validation Loss: 0.6475\n",
      "Epoch 233/1000 - Train Loss: 0.6485, Validation Loss: 0.6473\n",
      "Epoch 234/1000 - Train Loss: 0.6483, Validation Loss: 0.6471\n",
      "Epoch 235/1000 - Train Loss: 0.6482, Validation Loss: 0.6469\n",
      "Epoch 236/1000 - Train Loss: 0.6480, Validation Loss: 0.6467\n",
      "Epoch 237/1000 - Train Loss: 0.6478, Validation Loss: 0.6466\n",
      "Epoch 238/1000 - Train Loss: 0.6476, Validation Loss: 0.6464\n",
      "Epoch 239/1000 - Train Loss: 0.6475, Validation Loss: 0.6462\n",
      "Epoch 240/1000 - Train Loss: 0.6473, Validation Loss: 0.6460\n",
      "Epoch 241/1000 - Train Loss: 0.6471, Validation Loss: 0.6459\n",
      "Epoch 242/1000 - Train Loss: 0.6470, Validation Loss: 0.6457\n",
      "Epoch 243/1000 - Train Loss: 0.6468, Validation Loss: 0.6455\n",
      "Epoch 244/1000 - Train Loss: 0.6466, Validation Loss: 0.6453\n",
      "Epoch 245/1000 - Train Loss: 0.6464, Validation Loss: 0.6452\n",
      "Epoch 246/1000 - Train Loss: 0.6463, Validation Loss: 0.6450\n",
      "Epoch 247/1000 - Train Loss: 0.6461, Validation Loss: 0.6448\n",
      "Epoch 248/1000 - Train Loss: 0.6459, Validation Loss: 0.6446\n",
      "Epoch 249/1000 - Train Loss: 0.6457, Validation Loss: 0.6445\n",
      "Epoch 250/1000 - Train Loss: 0.6456, Validation Loss: 0.6443\n",
      "Epoch 251/1000 - Train Loss: 0.6454, Validation Loss: 0.6441\n",
      "Epoch 252/1000 - Train Loss: 0.6452, Validation Loss: 0.6440\n",
      "Epoch 253/1000 - Train Loss: 0.6451, Validation Loss: 0.6438\n",
      "Epoch 254/1000 - Train Loss: 0.6449, Validation Loss: 0.6436\n",
      "Epoch 255/1000 - Train Loss: 0.6447, Validation Loss: 0.6434\n",
      "Epoch 256/1000 - Train Loss: 0.6446, Validation Loss: 0.6433\n",
      "Epoch 257/1000 - Train Loss: 0.6444, Validation Loss: 0.6431\n",
      "Epoch 258/1000 - Train Loss: 0.6442, Validation Loss: 0.6429\n",
      "Epoch 259/1000 - Train Loss: 0.6440, Validation Loss: 0.6427\n",
      "Epoch 260/1000 - Train Loss: 0.6439, Validation Loss: 0.6426\n",
      "Epoch 261/1000 - Train Loss: 0.6437, Validation Loss: 0.6424\n",
      "Epoch 262/1000 - Train Loss: 0.6435, Validation Loss: 0.6422\n",
      "Epoch 263/1000 - Train Loss: 0.6434, Validation Loss: 0.6420\n",
      "Epoch 264/1000 - Train Loss: 0.6432, Validation Loss: 0.6419\n",
      "Epoch 265/1000 - Train Loss: 0.6430, Validation Loss: 0.6417\n",
      "Epoch 266/1000 - Train Loss: 0.6429, Validation Loss: 0.6415\n",
      "Epoch 267/1000 - Train Loss: 0.6427, Validation Loss: 0.6414\n",
      "Epoch 268/1000 - Train Loss: 0.6425, Validation Loss: 0.6412\n",
      "Epoch 269/1000 - Train Loss: 0.6423, Validation Loss: 0.6410\n",
      "Epoch 270/1000 - Train Loss: 0.6422, Validation Loss: 0.6408\n",
      "Epoch 271/1000 - Train Loss: 0.6420, Validation Loss: 0.6407\n",
      "Epoch 272/1000 - Train Loss: 0.6418, Validation Loss: 0.6405\n",
      "Epoch 273/1000 - Train Loss: 0.6417, Validation Loss: 0.6403\n",
      "Epoch 274/1000 - Train Loss: 0.6415, Validation Loss: 0.6402\n",
      "Epoch 275/1000 - Train Loss: 0.6413, Validation Loss: 0.6400\n",
      "Epoch 276/1000 - Train Loss: 0.6412, Validation Loss: 0.6398\n",
      "Epoch 277/1000 - Train Loss: 0.6410, Validation Loss: 0.6396\n",
      "Epoch 278/1000 - Train Loss: 0.6408, Validation Loss: 0.6395\n",
      "Epoch 279/1000 - Train Loss: 0.6407, Validation Loss: 0.6393\n",
      "Epoch 280/1000 - Train Loss: 0.6405, Validation Loss: 0.6391\n",
      "Epoch 281/1000 - Train Loss: 0.6403, Validation Loss: 0.6390\n",
      "Epoch 282/1000 - Train Loss: 0.6402, Validation Loss: 0.6388\n",
      "Epoch 283/1000 - Train Loss: 0.6400, Validation Loss: 0.6386\n",
      "Epoch 284/1000 - Train Loss: 0.6398, Validation Loss: 0.6385\n",
      "Epoch 285/1000 - Train Loss: 0.6397, Validation Loss: 0.6383\n",
      "Epoch 286/1000 - Train Loss: 0.6395, Validation Loss: 0.6381\n",
      "Epoch 287/1000 - Train Loss: 0.6393, Validation Loss: 0.6379\n",
      "Epoch 288/1000 - Train Loss: 0.6392, Validation Loss: 0.6378\n",
      "Epoch 289/1000 - Train Loss: 0.6390, Validation Loss: 0.6376\n",
      "Epoch 290/1000 - Train Loss: 0.6388, Validation Loss: 0.6374\n",
      "Epoch 291/1000 - Train Loss: 0.6387, Validation Loss: 0.6373\n",
      "Epoch 292/1000 - Train Loss: 0.6385, Validation Loss: 0.6371\n",
      "Epoch 293/1000 - Train Loss: 0.6383, Validation Loss: 0.6369\n",
      "Epoch 294/1000 - Train Loss: 0.6382, Validation Loss: 0.6368\n",
      "Epoch 295/1000 - Train Loss: 0.6380, Validation Loss: 0.6366\n",
      "Epoch 296/1000 - Train Loss: 0.6378, Validation Loss: 0.6364\n",
      "Epoch 297/1000 - Train Loss: 0.6377, Validation Loss: 0.6363\n",
      "Epoch 298/1000 - Train Loss: 0.6375, Validation Loss: 0.6361\n",
      "Epoch 299/1000 - Train Loss: 0.6373, Validation Loss: 0.6359\n",
      "Epoch 300/1000 - Train Loss: 0.6372, Validation Loss: 0.6358\n",
      "Epoch 301/1000 - Train Loss: 0.6370, Validation Loss: 0.6356\n",
      "Epoch 302/1000 - Train Loss: 0.6368, Validation Loss: 0.6354\n",
      "Epoch 303/1000 - Train Loss: 0.6367, Validation Loss: 0.6353\n",
      "Epoch 304/1000 - Train Loss: 0.6365, Validation Loss: 0.6351\n",
      "Epoch 305/1000 - Train Loss: 0.6363, Validation Loss: 0.6349\n",
      "Epoch 306/1000 - Train Loss: 0.6362, Validation Loss: 0.6347\n",
      "Epoch 307/1000 - Train Loss: 0.6360, Validation Loss: 0.6346\n",
      "Epoch 308/1000 - Train Loss: 0.6358, Validation Loss: 0.6344\n",
      "Epoch 309/1000 - Train Loss: 0.6357, Validation Loss: 0.6342\n",
      "Epoch 310/1000 - Train Loss: 0.6355, Validation Loss: 0.6341\n",
      "Epoch 311/1000 - Train Loss: 0.6353, Validation Loss: 0.6339\n",
      "Epoch 312/1000 - Train Loss: 0.6352, Validation Loss: 0.6337\n",
      "Epoch 313/1000 - Train Loss: 0.6350, Validation Loss: 0.6336\n",
      "Epoch 314/1000 - Train Loss: 0.6348, Validation Loss: 0.6334\n",
      "Epoch 315/1000 - Train Loss: 0.6347, Validation Loss: 0.6332\n",
      "Epoch 316/1000 - Train Loss: 0.6345, Validation Loss: 0.6331\n",
      "Epoch 317/1000 - Train Loss: 0.6344, Validation Loss: 0.6329\n",
      "Epoch 318/1000 - Train Loss: 0.6342, Validation Loss: 0.6327\n",
      "Epoch 319/1000 - Train Loss: 0.6340, Validation Loss: 0.6326\n",
      "Epoch 320/1000 - Train Loss: 0.6339, Validation Loss: 0.6324\n",
      "Epoch 321/1000 - Train Loss: 0.6337, Validation Loss: 0.6322\n",
      "Epoch 322/1000 - Train Loss: 0.6335, Validation Loss: 0.6321\n",
      "Epoch 323/1000 - Train Loss: 0.6334, Validation Loss: 0.6319\n",
      "Epoch 324/1000 - Train Loss: 0.6332, Validation Loss: 0.6318\n",
      "Epoch 325/1000 - Train Loss: 0.6330, Validation Loss: 0.6316\n",
      "Epoch 326/1000 - Train Loss: 0.6329, Validation Loss: 0.6314\n",
      "Epoch 327/1000 - Train Loss: 0.6327, Validation Loss: 0.6313\n",
      "Epoch 328/1000 - Train Loss: 0.6326, Validation Loss: 0.6311\n",
      "Epoch 329/1000 - Train Loss: 0.6324, Validation Loss: 0.6309\n",
      "Epoch 330/1000 - Train Loss: 0.6322, Validation Loss: 0.6308\n",
      "Epoch 331/1000 - Train Loss: 0.6321, Validation Loss: 0.6306\n",
      "Epoch 332/1000 - Train Loss: 0.6319, Validation Loss: 0.6304\n",
      "Epoch 333/1000 - Train Loss: 0.6317, Validation Loss: 0.6303\n",
      "Epoch 334/1000 - Train Loss: 0.6316, Validation Loss: 0.6301\n",
      "Epoch 335/1000 - Train Loss: 0.6314, Validation Loss: 0.6299\n",
      "Epoch 336/1000 - Train Loss: 0.6313, Validation Loss: 0.6298\n",
      "Epoch 337/1000 - Train Loss: 0.6311, Validation Loss: 0.6296\n",
      "Epoch 338/1000 - Train Loss: 0.6309, Validation Loss: 0.6294\n",
      "Epoch 339/1000 - Train Loss: 0.6308, Validation Loss: 0.6293\n",
      "Epoch 340/1000 - Train Loss: 0.6306, Validation Loss: 0.6291\n",
      "Epoch 341/1000 - Train Loss: 0.6304, Validation Loss: 0.6290\n",
      "Epoch 342/1000 - Train Loss: 0.6303, Validation Loss: 0.6288\n",
      "Epoch 343/1000 - Train Loss: 0.6301, Validation Loss: 0.6286\n",
      "Epoch 344/1000 - Train Loss: 0.6300, Validation Loss: 0.6285\n",
      "Epoch 345/1000 - Train Loss: 0.6298, Validation Loss: 0.6283\n",
      "Epoch 346/1000 - Train Loss: 0.6296, Validation Loss: 0.6281\n",
      "Epoch 347/1000 - Train Loss: 0.6295, Validation Loss: 0.6280\n",
      "Epoch 348/1000 - Train Loss: 0.6293, Validation Loss: 0.6278\n",
      "Epoch 349/1000 - Train Loss: 0.6292, Validation Loss: 0.6276\n",
      "Epoch 350/1000 - Train Loss: 0.6290, Validation Loss: 0.6275\n",
      "Epoch 351/1000 - Train Loss: 0.6288, Validation Loss: 0.6273\n",
      "Epoch 352/1000 - Train Loss: 0.6287, Validation Loss: 0.6272\n",
      "Epoch 353/1000 - Train Loss: 0.6285, Validation Loss: 0.6270\n",
      "Epoch 354/1000 - Train Loss: 0.6283, Validation Loss: 0.6268\n",
      "Epoch 355/1000 - Train Loss: 0.6282, Validation Loss: 0.6267\n",
      "Epoch 356/1000 - Train Loss: 0.6280, Validation Loss: 0.6265\n",
      "Epoch 357/1000 - Train Loss: 0.6279, Validation Loss: 0.6263\n",
      "Epoch 358/1000 - Train Loss: 0.6277, Validation Loss: 0.6262\n",
      "Epoch 359/1000 - Train Loss: 0.6275, Validation Loss: 0.6260\n",
      "Epoch 360/1000 - Train Loss: 0.6274, Validation Loss: 0.6259\n",
      "Epoch 361/1000 - Train Loss: 0.6272, Validation Loss: 0.6257\n",
      "Epoch 362/1000 - Train Loss: 0.6271, Validation Loss: 0.6255\n",
      "Epoch 363/1000 - Train Loss: 0.6269, Validation Loss: 0.6254\n",
      "Epoch 364/1000 - Train Loss: 0.6267, Validation Loss: 0.6252\n",
      "Epoch 365/1000 - Train Loss: 0.6266, Validation Loss: 0.6251\n",
      "Epoch 366/1000 - Train Loss: 0.6264, Validation Loss: 0.6249\n",
      "Epoch 367/1000 - Train Loss: 0.6263, Validation Loss: 0.6247\n",
      "Epoch 368/1000 - Train Loss: 0.6261, Validation Loss: 0.6246\n",
      "Epoch 369/1000 - Train Loss: 0.6259, Validation Loss: 0.6244\n",
      "Epoch 370/1000 - Train Loss: 0.6258, Validation Loss: 0.6242\n",
      "Epoch 371/1000 - Train Loss: 0.6256, Validation Loss: 0.6241\n",
      "Epoch 372/1000 - Train Loss: 0.6255, Validation Loss: 0.6239\n",
      "Epoch 373/1000 - Train Loss: 0.6253, Validation Loss: 0.6238\n",
      "Epoch 374/1000 - Train Loss: 0.6252, Validation Loss: 0.6236\n",
      "Epoch 375/1000 - Train Loss: 0.6250, Validation Loss: 0.6234\n",
      "Epoch 376/1000 - Train Loss: 0.6248, Validation Loss: 0.6233\n",
      "Epoch 377/1000 - Train Loss: 0.6247, Validation Loss: 0.6231\n",
      "Epoch 378/1000 - Train Loss: 0.6245, Validation Loss: 0.6230\n",
      "Epoch 379/1000 - Train Loss: 0.6244, Validation Loss: 0.6228\n",
      "Epoch 380/1000 - Train Loss: 0.6242, Validation Loss: 0.6226\n",
      "Epoch 381/1000 - Train Loss: 0.6240, Validation Loss: 0.6225\n",
      "Epoch 382/1000 - Train Loss: 0.6239, Validation Loss: 0.6223\n",
      "Epoch 383/1000 - Train Loss: 0.6237, Validation Loss: 0.6222\n",
      "Epoch 384/1000 - Train Loss: 0.6236, Validation Loss: 0.6220\n",
      "Epoch 385/1000 - Train Loss: 0.6234, Validation Loss: 0.6218\n",
      "Epoch 386/1000 - Train Loss: 0.6233, Validation Loss: 0.6217\n",
      "Epoch 387/1000 - Train Loss: 0.6231, Validation Loss: 0.6215\n",
      "Epoch 388/1000 - Train Loss: 0.6229, Validation Loss: 0.6214\n",
      "Epoch 389/1000 - Train Loss: 0.6228, Validation Loss: 0.6212\n",
      "Epoch 390/1000 - Train Loss: 0.6226, Validation Loss: 0.6210\n",
      "Epoch 391/1000 - Train Loss: 0.6225, Validation Loss: 0.6209\n",
      "Epoch 392/1000 - Train Loss: 0.6223, Validation Loss: 0.6207\n",
      "Epoch 393/1000 - Train Loss: 0.6222, Validation Loss: 0.6206\n",
      "Epoch 394/1000 - Train Loss: 0.6220, Validation Loss: 0.6204\n",
      "Epoch 395/1000 - Train Loss: 0.6218, Validation Loss: 0.6203\n",
      "Epoch 396/1000 - Train Loss: 0.6217, Validation Loss: 0.6201\n",
      "Epoch 397/1000 - Train Loss: 0.6215, Validation Loss: 0.6199\n",
      "Epoch 398/1000 - Train Loss: 0.6214, Validation Loss: 0.6198\n",
      "Epoch 399/1000 - Train Loss: 0.6212, Validation Loss: 0.6196\n",
      "Epoch 400/1000 - Train Loss: 0.6211, Validation Loss: 0.6195\n",
      "Epoch 401/1000 - Train Loss: 0.6209, Validation Loss: 0.6193\n",
      "Epoch 402/1000 - Train Loss: 0.6207, Validation Loss: 0.6191\n",
      "Epoch 403/1000 - Train Loss: 0.6206, Validation Loss: 0.6190\n",
      "Epoch 404/1000 - Train Loss: 0.6204, Validation Loss: 0.6188\n",
      "Epoch 405/1000 - Train Loss: 0.6203, Validation Loss: 0.6187\n",
      "Epoch 406/1000 - Train Loss: 0.6201, Validation Loss: 0.6185\n",
      "Epoch 407/1000 - Train Loss: 0.6200, Validation Loss: 0.6184\n",
      "Epoch 408/1000 - Train Loss: 0.6198, Validation Loss: 0.6182\n",
      "Epoch 409/1000 - Train Loss: 0.6196, Validation Loss: 0.6180\n",
      "Epoch 410/1000 - Train Loss: 0.6195, Validation Loss: 0.6179\n",
      "Epoch 411/1000 - Train Loss: 0.6193, Validation Loss: 0.6177\n",
      "Epoch 412/1000 - Train Loss: 0.6192, Validation Loss: 0.6176\n",
      "Epoch 413/1000 - Train Loss: 0.6190, Validation Loss: 0.6174\n",
      "Epoch 414/1000 - Train Loss: 0.6189, Validation Loss: 0.6173\n",
      "Epoch 415/1000 - Train Loss: 0.6187, Validation Loss: 0.6171\n",
      "Epoch 416/1000 - Train Loss: 0.6186, Validation Loss: 0.6169\n",
      "Epoch 417/1000 - Train Loss: 0.6184, Validation Loss: 0.6168\n",
      "Epoch 418/1000 - Train Loss: 0.6182, Validation Loss: 0.6166\n",
      "Epoch 419/1000 - Train Loss: 0.6181, Validation Loss: 0.6165\n",
      "Epoch 420/1000 - Train Loss: 0.6179, Validation Loss: 0.6163\n",
      "Epoch 421/1000 - Train Loss: 0.6178, Validation Loss: 0.6162\n",
      "Epoch 422/1000 - Train Loss: 0.6176, Validation Loss: 0.6160\n",
      "Epoch 423/1000 - Train Loss: 0.6175, Validation Loss: 0.6158\n",
      "Epoch 424/1000 - Train Loss: 0.6173, Validation Loss: 0.6157\n",
      "Epoch 425/1000 - Train Loss: 0.6172, Validation Loss: 0.6155\n",
      "Epoch 426/1000 - Train Loss: 0.6170, Validation Loss: 0.6154\n",
      "Epoch 427/1000 - Train Loss: 0.6169, Validation Loss: 0.6152\n",
      "Epoch 428/1000 - Train Loss: 0.6167, Validation Loss: 0.6151\n",
      "Epoch 429/1000 - Train Loss: 0.6165, Validation Loss: 0.6149\n",
      "Epoch 430/1000 - Train Loss: 0.6164, Validation Loss: 0.6148\n",
      "Epoch 431/1000 - Train Loss: 0.6162, Validation Loss: 0.6146\n",
      "Epoch 432/1000 - Train Loss: 0.6161, Validation Loss: 0.6144\n",
      "Epoch 433/1000 - Train Loss: 0.6159, Validation Loss: 0.6143\n",
      "Epoch 434/1000 - Train Loss: 0.6158, Validation Loss: 0.6141\n",
      "Epoch 435/1000 - Train Loss: 0.6156, Validation Loss: 0.6140\n",
      "Epoch 436/1000 - Train Loss: 0.6155, Validation Loss: 0.6138\n",
      "Epoch 437/1000 - Train Loss: 0.6153, Validation Loss: 0.6137\n",
      "Epoch 438/1000 - Train Loss: 0.6152, Validation Loss: 0.6135\n",
      "Epoch 439/1000 - Train Loss: 0.6150, Validation Loss: 0.6134\n",
      "Epoch 440/1000 - Train Loss: 0.6149, Validation Loss: 0.6132\n",
      "Epoch 441/1000 - Train Loss: 0.6147, Validation Loss: 0.6131\n",
      "Epoch 442/1000 - Train Loss: 0.6145, Validation Loss: 0.6129\n",
      "Epoch 443/1000 - Train Loss: 0.6144, Validation Loss: 0.6127\n",
      "Epoch 444/1000 - Train Loss: 0.6142, Validation Loss: 0.6126\n",
      "Epoch 445/1000 - Train Loss: 0.6141, Validation Loss: 0.6124\n",
      "Epoch 446/1000 - Train Loss: 0.6139, Validation Loss: 0.6123\n",
      "Epoch 447/1000 - Train Loss: 0.6138, Validation Loss: 0.6121\n",
      "Epoch 448/1000 - Train Loss: 0.6136, Validation Loss: 0.6120\n",
      "Epoch 449/1000 - Train Loss: 0.6135, Validation Loss: 0.6118\n",
      "Epoch 450/1000 - Train Loss: 0.6133, Validation Loss: 0.6117\n",
      "Epoch 451/1000 - Train Loss: 0.6132, Validation Loss: 0.6115\n",
      "Epoch 452/1000 - Train Loss: 0.6130, Validation Loss: 0.6114\n",
      "Epoch 453/1000 - Train Loss: 0.6129, Validation Loss: 0.6112\n",
      "Epoch 454/1000 - Train Loss: 0.6127, Validation Loss: 0.6110\n",
      "Epoch 455/1000 - Train Loss: 0.6126, Validation Loss: 0.6109\n",
      "Epoch 456/1000 - Train Loss: 0.6124, Validation Loss: 0.6107\n",
      "Epoch 457/1000 - Train Loss: 0.6123, Validation Loss: 0.6106\n",
      "Epoch 458/1000 - Train Loss: 0.6121, Validation Loss: 0.6104\n",
      "Epoch 459/1000 - Train Loss: 0.6120, Validation Loss: 0.6103\n",
      "Epoch 460/1000 - Train Loss: 0.6118, Validation Loss: 0.6101\n",
      "Epoch 461/1000 - Train Loss: 0.6116, Validation Loss: 0.6100\n",
      "Epoch 462/1000 - Train Loss: 0.6115, Validation Loss: 0.6098\n",
      "Epoch 463/1000 - Train Loss: 0.6113, Validation Loss: 0.6097\n",
      "Epoch 464/1000 - Train Loss: 0.6112, Validation Loss: 0.6095\n",
      "Epoch 465/1000 - Train Loss: 0.6110, Validation Loss: 0.6094\n",
      "Epoch 466/1000 - Train Loss: 0.6109, Validation Loss: 0.6092\n",
      "Epoch 467/1000 - Train Loss: 0.6107, Validation Loss: 0.6091\n",
      "Epoch 468/1000 - Train Loss: 0.6106, Validation Loss: 0.6089\n",
      "Epoch 469/1000 - Train Loss: 0.6104, Validation Loss: 0.6088\n",
      "Epoch 470/1000 - Train Loss: 0.6103, Validation Loss: 0.6086\n",
      "Epoch 471/1000 - Train Loss: 0.6101, Validation Loss: 0.6084\n",
      "Epoch 472/1000 - Train Loss: 0.6100, Validation Loss: 0.6083\n",
      "Epoch 473/1000 - Train Loss: 0.6098, Validation Loss: 0.6081\n",
      "Epoch 474/1000 - Train Loss: 0.6097, Validation Loss: 0.6080\n",
      "Epoch 475/1000 - Train Loss: 0.6095, Validation Loss: 0.6078\n",
      "Epoch 476/1000 - Train Loss: 0.6094, Validation Loss: 0.6077\n",
      "Epoch 477/1000 - Train Loss: 0.6092, Validation Loss: 0.6075\n",
      "Epoch 478/1000 - Train Loss: 0.6091, Validation Loss: 0.6074\n",
      "Epoch 479/1000 - Train Loss: 0.6089, Validation Loss: 0.6072\n",
      "Epoch 480/1000 - Train Loss: 0.6088, Validation Loss: 0.6071\n",
      "Epoch 481/1000 - Train Loss: 0.6086, Validation Loss: 0.6069\n",
      "Epoch 482/1000 - Train Loss: 0.6085, Validation Loss: 0.6068\n",
      "Epoch 483/1000 - Train Loss: 0.6083, Validation Loss: 0.6066\n",
      "Epoch 484/1000 - Train Loss: 0.6082, Validation Loss: 0.6065\n",
      "Epoch 485/1000 - Train Loss: 0.6080, Validation Loss: 0.6063\n",
      "Epoch 486/1000 - Train Loss: 0.6079, Validation Loss: 0.6062\n",
      "Epoch 487/1000 - Train Loss: 0.6077, Validation Loss: 0.6060\n",
      "Epoch 488/1000 - Train Loss: 0.6076, Validation Loss: 0.6059\n",
      "Epoch 489/1000 - Train Loss: 0.6074, Validation Loss: 0.6057\n",
      "Epoch 490/1000 - Train Loss: 0.6073, Validation Loss: 0.6056\n",
      "Epoch 491/1000 - Train Loss: 0.6071, Validation Loss: 0.6054\n",
      "Epoch 492/1000 - Train Loss: 0.6070, Validation Loss: 0.6053\n",
      "Epoch 493/1000 - Train Loss: 0.6068, Validation Loss: 0.6051\n",
      "Epoch 494/1000 - Train Loss: 0.6067, Validation Loss: 0.6050\n",
      "Epoch 495/1000 - Train Loss: 0.6065, Validation Loss: 0.6048\n",
      "Epoch 496/1000 - Train Loss: 0.6064, Validation Loss: 0.6047\n",
      "Epoch 497/1000 - Train Loss: 0.6062, Validation Loss: 0.6045\n",
      "Epoch 498/1000 - Train Loss: 0.6061, Validation Loss: 0.6044\n",
      "Epoch 499/1000 - Train Loss: 0.6059, Validation Loss: 0.6042\n",
      "Epoch 500/1000 - Train Loss: 0.6058, Validation Loss: 0.6041\n",
      "Epoch 501/1000 - Train Loss: 0.6056, Validation Loss: 0.6039\n",
      "Epoch 502/1000 - Train Loss: 0.6055, Validation Loss: 0.6038\n",
      "Epoch 503/1000 - Train Loss: 0.6053, Validation Loss: 0.6036\n",
      "Epoch 504/1000 - Train Loss: 0.6052, Validation Loss: 0.6035\n",
      "Epoch 505/1000 - Train Loss: 0.6050, Validation Loss: 0.6033\n",
      "Epoch 506/1000 - Train Loss: 0.6049, Validation Loss: 0.6032\n",
      "Epoch 507/1000 - Train Loss: 0.6047, Validation Loss: 0.6030\n",
      "Epoch 508/1000 - Train Loss: 0.6046, Validation Loss: 0.6029\n",
      "Epoch 509/1000 - Train Loss: 0.6044, Validation Loss: 0.6027\n",
      "Epoch 510/1000 - Train Loss: 0.6043, Validation Loss: 0.6026\n",
      "Epoch 511/1000 - Train Loss: 0.6041, Validation Loss: 0.6024\n",
      "Epoch 512/1000 - Train Loss: 0.6040, Validation Loss: 0.6023\n",
      "Epoch 513/1000 - Train Loss: 0.6039, Validation Loss: 0.6021\n",
      "Epoch 514/1000 - Train Loss: 0.6037, Validation Loss: 0.6020\n",
      "Epoch 515/1000 - Train Loss: 0.6036, Validation Loss: 0.6018\n",
      "Epoch 516/1000 - Train Loss: 0.6034, Validation Loss: 0.6017\n",
      "Epoch 517/1000 - Train Loss: 0.6033, Validation Loss: 0.6015\n",
      "Epoch 518/1000 - Train Loss: 0.6031, Validation Loss: 0.6014\n",
      "Epoch 519/1000 - Train Loss: 0.6030, Validation Loss: 0.6012\n",
      "Epoch 520/1000 - Train Loss: 0.6028, Validation Loss: 0.6011\n",
      "Epoch 521/1000 - Train Loss: 0.6027, Validation Loss: 0.6009\n",
      "Epoch 522/1000 - Train Loss: 0.6025, Validation Loss: 0.6008\n",
      "Epoch 523/1000 - Train Loss: 0.6024, Validation Loss: 0.6006\n",
      "Epoch 524/1000 - Train Loss: 0.6022, Validation Loss: 0.6005\n",
      "Epoch 525/1000 - Train Loss: 0.6021, Validation Loss: 0.6003\n",
      "Epoch 526/1000 - Train Loss: 0.6019, Validation Loss: 0.6002\n",
      "Epoch 527/1000 - Train Loss: 0.6018, Validation Loss: 0.6000\n",
      "Epoch 528/1000 - Train Loss: 0.6016, Validation Loss: 0.5999\n",
      "Epoch 529/1000 - Train Loss: 0.6015, Validation Loss: 0.5997\n",
      "Epoch 530/1000 - Train Loss: 0.6013, Validation Loss: 0.5996\n",
      "Epoch 531/1000 - Train Loss: 0.6012, Validation Loss: 0.5994\n",
      "Epoch 532/1000 - Train Loss: 0.6011, Validation Loss: 0.5993\n",
      "Epoch 533/1000 - Train Loss: 0.6009, Validation Loss: 0.5992\n",
      "Epoch 534/1000 - Train Loss: 0.6008, Validation Loss: 0.5990\n",
      "Epoch 535/1000 - Train Loss: 0.6006, Validation Loss: 0.5989\n",
      "Epoch 536/1000 - Train Loss: 0.6005, Validation Loss: 0.5987\n",
      "Epoch 537/1000 - Train Loss: 0.6003, Validation Loss: 0.5986\n",
      "Epoch 538/1000 - Train Loss: 0.6002, Validation Loss: 0.5984\n",
      "Epoch 539/1000 - Train Loss: 0.6000, Validation Loss: 0.5983\n",
      "Epoch 540/1000 - Train Loss: 0.5999, Validation Loss: 0.5981\n",
      "Epoch 541/1000 - Train Loss: 0.5997, Validation Loss: 0.5980\n",
      "Epoch 542/1000 - Train Loss: 0.5996, Validation Loss: 0.5978\n",
      "Epoch 543/1000 - Train Loss: 0.5994, Validation Loss: 0.5977\n",
      "Epoch 544/1000 - Train Loss: 0.5993, Validation Loss: 0.5975\n",
      "Epoch 545/1000 - Train Loss: 0.5991, Validation Loss: 0.5974\n",
      "Epoch 546/1000 - Train Loss: 0.5990, Validation Loss: 0.5972\n",
      "Epoch 547/1000 - Train Loss: 0.5989, Validation Loss: 0.5971\n",
      "Epoch 548/1000 - Train Loss: 0.5987, Validation Loss: 0.5969\n",
      "Epoch 549/1000 - Train Loss: 0.5986, Validation Loss: 0.5968\n",
      "Epoch 550/1000 - Train Loss: 0.5984, Validation Loss: 0.5967\n",
      "Epoch 551/1000 - Train Loss: 0.5983, Validation Loss: 0.5965\n",
      "Epoch 552/1000 - Train Loss: 0.5981, Validation Loss: 0.5964\n",
      "Epoch 553/1000 - Train Loss: 0.5980, Validation Loss: 0.5962\n",
      "Epoch 554/1000 - Train Loss: 0.5978, Validation Loss: 0.5961\n",
      "Epoch 555/1000 - Train Loss: 0.5977, Validation Loss: 0.5959\n",
      "Epoch 556/1000 - Train Loss: 0.5975, Validation Loss: 0.5958\n",
      "Epoch 557/1000 - Train Loss: 0.5974, Validation Loss: 0.5956\n",
      "Epoch 558/1000 - Train Loss: 0.5973, Validation Loss: 0.5955\n",
      "Epoch 559/1000 - Train Loss: 0.5971, Validation Loss: 0.5953\n",
      "Epoch 560/1000 - Train Loss: 0.5970, Validation Loss: 0.5952\n",
      "Epoch 561/1000 - Train Loss: 0.5968, Validation Loss: 0.5950\n",
      "Epoch 562/1000 - Train Loss: 0.5967, Validation Loss: 0.5949\n",
      "Epoch 563/1000 - Train Loss: 0.5965, Validation Loss: 0.5948\n",
      "Epoch 564/1000 - Train Loss: 0.5964, Validation Loss: 0.5946\n",
      "Epoch 565/1000 - Train Loss: 0.5962, Validation Loss: 0.5945\n",
      "Epoch 566/1000 - Train Loss: 0.5961, Validation Loss: 0.5943\n",
      "Epoch 567/1000 - Train Loss: 0.5960, Validation Loss: 0.5942\n",
      "Epoch 568/1000 - Train Loss: 0.5958, Validation Loss: 0.5940\n",
      "Epoch 569/1000 - Train Loss: 0.5957, Validation Loss: 0.5939\n",
      "Epoch 570/1000 - Train Loss: 0.5955, Validation Loss: 0.5937\n",
      "Epoch 571/1000 - Train Loss: 0.5954, Validation Loss: 0.5936\n",
      "Epoch 572/1000 - Train Loss: 0.5952, Validation Loss: 0.5934\n",
      "Epoch 573/1000 - Train Loss: 0.5951, Validation Loss: 0.5933\n",
      "Epoch 574/1000 - Train Loss: 0.5949, Validation Loss: 0.5932\n",
      "Epoch 575/1000 - Train Loss: 0.5948, Validation Loss: 0.5930\n",
      "Epoch 576/1000 - Train Loss: 0.5947, Validation Loss: 0.5929\n",
      "Epoch 577/1000 - Train Loss: 0.5945, Validation Loss: 0.5927\n",
      "Epoch 578/1000 - Train Loss: 0.5944, Validation Loss: 0.5926\n",
      "Epoch 579/1000 - Train Loss: 0.5942, Validation Loss: 0.5924\n",
      "Epoch 580/1000 - Train Loss: 0.5941, Validation Loss: 0.5923\n",
      "Epoch 581/1000 - Train Loss: 0.5939, Validation Loss: 0.5921\n",
      "Epoch 582/1000 - Train Loss: 0.5938, Validation Loss: 0.5920\n",
      "Epoch 583/1000 - Train Loss: 0.5937, Validation Loss: 0.5919\n",
      "Epoch 584/1000 - Train Loss: 0.5935, Validation Loss: 0.5917\n",
      "Epoch 585/1000 - Train Loss: 0.5934, Validation Loss: 0.5916\n",
      "Epoch 586/1000 - Train Loss: 0.5932, Validation Loss: 0.5914\n",
      "Epoch 587/1000 - Train Loss: 0.5931, Validation Loss: 0.5913\n",
      "Epoch 588/1000 - Train Loss: 0.5929, Validation Loss: 0.5911\n",
      "Epoch 589/1000 - Train Loss: 0.5928, Validation Loss: 0.5910\n",
      "Epoch 590/1000 - Train Loss: 0.5926, Validation Loss: 0.5908\n",
      "Epoch 591/1000 - Train Loss: 0.5925, Validation Loss: 0.5907\n",
      "Epoch 592/1000 - Train Loss: 0.5924, Validation Loss: 0.5906\n",
      "Epoch 593/1000 - Train Loss: 0.5922, Validation Loss: 0.5904\n",
      "Epoch 594/1000 - Train Loss: 0.5921, Validation Loss: 0.5903\n",
      "Epoch 595/1000 - Train Loss: 0.5919, Validation Loss: 0.5901\n",
      "Epoch 596/1000 - Train Loss: 0.5918, Validation Loss: 0.5900\n",
      "Epoch 597/1000 - Train Loss: 0.5916, Validation Loss: 0.5898\n",
      "Epoch 598/1000 - Train Loss: 0.5915, Validation Loss: 0.5897\n",
      "Epoch 599/1000 - Train Loss: 0.5914, Validation Loss: 0.5896\n",
      "Epoch 600/1000 - Train Loss: 0.5912, Validation Loss: 0.5894\n",
      "Epoch 601/1000 - Train Loss: 0.5911, Validation Loss: 0.5893\n",
      "Epoch 602/1000 - Train Loss: 0.5909, Validation Loss: 0.5891\n",
      "Epoch 603/1000 - Train Loss: 0.5908, Validation Loss: 0.5890\n",
      "Epoch 604/1000 - Train Loss: 0.5907, Validation Loss: 0.5888\n",
      "Epoch 605/1000 - Train Loss: 0.5905, Validation Loss: 0.5887\n",
      "Epoch 606/1000 - Train Loss: 0.5904, Validation Loss: 0.5886\n",
      "Epoch 607/1000 - Train Loss: 0.5902, Validation Loss: 0.5884\n",
      "Epoch 608/1000 - Train Loss: 0.5901, Validation Loss: 0.5883\n",
      "Epoch 609/1000 - Train Loss: 0.5899, Validation Loss: 0.5881\n",
      "Epoch 610/1000 - Train Loss: 0.5898, Validation Loss: 0.5880\n",
      "Epoch 611/1000 - Train Loss: 0.5897, Validation Loss: 0.5878\n",
      "Epoch 612/1000 - Train Loss: 0.5895, Validation Loss: 0.5877\n",
      "Epoch 613/1000 - Train Loss: 0.5894, Validation Loss: 0.5876\n",
      "Epoch 614/1000 - Train Loss: 0.5892, Validation Loss: 0.5874\n",
      "Epoch 615/1000 - Train Loss: 0.5891, Validation Loss: 0.5873\n",
      "Epoch 616/1000 - Train Loss: 0.5890, Validation Loss: 0.5871\n",
      "Epoch 617/1000 - Train Loss: 0.5888, Validation Loss: 0.5870\n",
      "Epoch 618/1000 - Train Loss: 0.5887, Validation Loss: 0.5869\n",
      "Epoch 619/1000 - Train Loss: 0.5885, Validation Loss: 0.5867\n",
      "Epoch 620/1000 - Train Loss: 0.5884, Validation Loss: 0.5866\n",
      "Epoch 621/1000 - Train Loss: 0.5882, Validation Loss: 0.5864\n",
      "Epoch 622/1000 - Train Loss: 0.5881, Validation Loss: 0.5863\n",
      "Epoch 623/1000 - Train Loss: 0.5880, Validation Loss: 0.5861\n",
      "Epoch 624/1000 - Train Loss: 0.5878, Validation Loss: 0.5860\n",
      "Epoch 625/1000 - Train Loss: 0.5877, Validation Loss: 0.5859\n",
      "Epoch 626/1000 - Train Loss: 0.5875, Validation Loss: 0.5857\n",
      "Epoch 627/1000 - Train Loss: 0.5874, Validation Loss: 0.5856\n",
      "Epoch 628/1000 - Train Loss: 0.5873, Validation Loss: 0.5854\n",
      "Epoch 629/1000 - Train Loss: 0.5871, Validation Loss: 0.5853\n",
      "Epoch 630/1000 - Train Loss: 0.5870, Validation Loss: 0.5852\n",
      "Epoch 631/1000 - Train Loss: 0.5868, Validation Loss: 0.5850\n",
      "Epoch 632/1000 - Train Loss: 0.5867, Validation Loss: 0.5849\n",
      "Epoch 633/1000 - Train Loss: 0.5866, Validation Loss: 0.5847\n",
      "Epoch 634/1000 - Train Loss: 0.5864, Validation Loss: 0.5846\n",
      "Epoch 635/1000 - Train Loss: 0.5863, Validation Loss: 0.5844\n",
      "Epoch 636/1000 - Train Loss: 0.5861, Validation Loss: 0.5843\n",
      "Epoch 637/1000 - Train Loss: 0.5860, Validation Loss: 0.5842\n",
      "Epoch 638/1000 - Train Loss: 0.5859, Validation Loss: 0.5840\n",
      "Epoch 639/1000 - Train Loss: 0.5857, Validation Loss: 0.5839\n",
      "Epoch 640/1000 - Train Loss: 0.5856, Validation Loss: 0.5837\n",
      "Epoch 641/1000 - Train Loss: 0.5854, Validation Loss: 0.5836\n",
      "Epoch 642/1000 - Train Loss: 0.5853, Validation Loss: 0.5835\n",
      "Epoch 643/1000 - Train Loss: 0.5852, Validation Loss: 0.5833\n",
      "Epoch 644/1000 - Train Loss: 0.5850, Validation Loss: 0.5832\n",
      "Epoch 645/1000 - Train Loss: 0.5849, Validation Loss: 0.5830\n",
      "Epoch 646/1000 - Train Loss: 0.5847, Validation Loss: 0.5829\n",
      "Epoch 647/1000 - Train Loss: 0.5846, Validation Loss: 0.5828\n",
      "Epoch 648/1000 - Train Loss: 0.5845, Validation Loss: 0.5826\n",
      "Epoch 649/1000 - Train Loss: 0.5843, Validation Loss: 0.5825\n",
      "Epoch 650/1000 - Train Loss: 0.5842, Validation Loss: 0.5823\n",
      "Epoch 651/1000 - Train Loss: 0.5840, Validation Loss: 0.5822\n",
      "Epoch 652/1000 - Train Loss: 0.5839, Validation Loss: 0.5821\n",
      "Epoch 653/1000 - Train Loss: 0.5838, Validation Loss: 0.5819\n",
      "Epoch 654/1000 - Train Loss: 0.5836, Validation Loss: 0.5818\n",
      "Epoch 655/1000 - Train Loss: 0.5835, Validation Loss: 0.5816\n",
      "Epoch 656/1000 - Train Loss: 0.5833, Validation Loss: 0.5815\n",
      "Epoch 657/1000 - Train Loss: 0.5832, Validation Loss: 0.5814\n",
      "Epoch 658/1000 - Train Loss: 0.5831, Validation Loss: 0.5812\n",
      "Epoch 659/1000 - Train Loss: 0.5829, Validation Loss: 0.5811\n",
      "Epoch 660/1000 - Train Loss: 0.5828, Validation Loss: 0.5809\n",
      "Epoch 661/1000 - Train Loss: 0.5827, Validation Loss: 0.5808\n",
      "Epoch 662/1000 - Train Loss: 0.5825, Validation Loss: 0.5807\n",
      "Epoch 663/1000 - Train Loss: 0.5824, Validation Loss: 0.5805\n",
      "Epoch 664/1000 - Train Loss: 0.5822, Validation Loss: 0.5804\n",
      "Epoch 665/1000 - Train Loss: 0.5821, Validation Loss: 0.5803\n",
      "Epoch 666/1000 - Train Loss: 0.5820, Validation Loss: 0.5801\n",
      "Epoch 667/1000 - Train Loss: 0.5818, Validation Loss: 0.5800\n",
      "Epoch 668/1000 - Train Loss: 0.5817, Validation Loss: 0.5798\n",
      "Epoch 669/1000 - Train Loss: 0.5815, Validation Loss: 0.5797\n",
      "Epoch 670/1000 - Train Loss: 0.5814, Validation Loss: 0.5796\n",
      "Epoch 671/1000 - Train Loss: 0.5813, Validation Loss: 0.5794\n",
      "Epoch 672/1000 - Train Loss: 0.5811, Validation Loss: 0.5793\n",
      "Epoch 673/1000 - Train Loss: 0.5810, Validation Loss: 0.5791\n",
      "Epoch 674/1000 - Train Loss: 0.5809, Validation Loss: 0.5790\n",
      "Epoch 675/1000 - Train Loss: 0.5807, Validation Loss: 0.5789\n",
      "Epoch 676/1000 - Train Loss: 0.5806, Validation Loss: 0.5787\n",
      "Epoch 677/1000 - Train Loss: 0.5804, Validation Loss: 0.5786\n",
      "Epoch 678/1000 - Train Loss: 0.5803, Validation Loss: 0.5785\n",
      "Epoch 679/1000 - Train Loss: 0.5802, Validation Loss: 0.5783\n",
      "Epoch 680/1000 - Train Loss: 0.5800, Validation Loss: 0.5782\n",
      "Epoch 681/1000 - Train Loss: 0.5799, Validation Loss: 0.5780\n",
      "Epoch 682/1000 - Train Loss: 0.5798, Validation Loss: 0.5779\n",
      "Epoch 683/1000 - Train Loss: 0.5796, Validation Loss: 0.5778\n",
      "Epoch 684/1000 - Train Loss: 0.5795, Validation Loss: 0.5776\n",
      "Epoch 685/1000 - Train Loss: 0.5793, Validation Loss: 0.5775\n",
      "Epoch 686/1000 - Train Loss: 0.5792, Validation Loss: 0.5773\n",
      "Epoch 687/1000 - Train Loss: 0.5791, Validation Loss: 0.5772\n",
      "Epoch 688/1000 - Train Loss: 0.5789, Validation Loss: 0.5771\n",
      "Epoch 689/1000 - Train Loss: 0.5788, Validation Loss: 0.5769\n",
      "Epoch 690/1000 - Train Loss: 0.5787, Validation Loss: 0.5768\n",
      "Epoch 691/1000 - Train Loss: 0.5785, Validation Loss: 0.5767\n",
      "Epoch 692/1000 - Train Loss: 0.5784, Validation Loss: 0.5765\n",
      "Epoch 693/1000 - Train Loss: 0.5782, Validation Loss: 0.5764\n",
      "Epoch 694/1000 - Train Loss: 0.5781, Validation Loss: 0.5762\n",
      "Epoch 695/1000 - Train Loss: 0.5780, Validation Loss: 0.5761\n",
      "Epoch 696/1000 - Train Loss: 0.5778, Validation Loss: 0.5760\n",
      "Epoch 697/1000 - Train Loss: 0.5777, Validation Loss: 0.5758\n",
      "Epoch 698/1000 - Train Loss: 0.5776, Validation Loss: 0.5757\n",
      "Epoch 699/1000 - Train Loss: 0.5774, Validation Loss: 0.5756\n",
      "Epoch 700/1000 - Train Loss: 0.5773, Validation Loss: 0.5754\n",
      "Epoch 701/1000 - Train Loss: 0.5772, Validation Loss: 0.5753\n",
      "Epoch 702/1000 - Train Loss: 0.5770, Validation Loss: 0.5752\n",
      "Epoch 703/1000 - Train Loss: 0.5769, Validation Loss: 0.5750\n",
      "Epoch 704/1000 - Train Loss: 0.5767, Validation Loss: 0.5749\n",
      "Epoch 705/1000 - Train Loss: 0.5766, Validation Loss: 0.5747\n",
      "Epoch 706/1000 - Train Loss: 0.5765, Validation Loss: 0.5746\n",
      "Epoch 707/1000 - Train Loss: 0.5763, Validation Loss: 0.5745\n",
      "Epoch 708/1000 - Train Loss: 0.5762, Validation Loss: 0.5743\n",
      "Epoch 709/1000 - Train Loss: 0.5761, Validation Loss: 0.5742\n",
      "Epoch 710/1000 - Train Loss: 0.5759, Validation Loss: 0.5741\n",
      "Epoch 711/1000 - Train Loss: 0.5758, Validation Loss: 0.5739\n",
      "Epoch 712/1000 - Train Loss: 0.5757, Validation Loss: 0.5738\n",
      "Epoch 713/1000 - Train Loss: 0.5755, Validation Loss: 0.5737\n",
      "Epoch 714/1000 - Train Loss: 0.5754, Validation Loss: 0.5735\n",
      "Epoch 715/1000 - Train Loss: 0.5753, Validation Loss: 0.5734\n",
      "Epoch 716/1000 - Train Loss: 0.5751, Validation Loss: 0.5732\n",
      "Epoch 717/1000 - Train Loss: 0.5750, Validation Loss: 0.5731\n",
      "Epoch 718/1000 - Train Loss: 0.5748, Validation Loss: 0.5730\n",
      "Epoch 719/1000 - Train Loss: 0.5747, Validation Loss: 0.5728\n",
      "Epoch 720/1000 - Train Loss: 0.5746, Validation Loss: 0.5727\n",
      "Epoch 721/1000 - Train Loss: 0.5744, Validation Loss: 0.5726\n",
      "Epoch 722/1000 - Train Loss: 0.5743, Validation Loss: 0.5724\n",
      "Epoch 723/1000 - Train Loss: 0.5742, Validation Loss: 0.5723\n",
      "Epoch 724/1000 - Train Loss: 0.5740, Validation Loss: 0.5722\n",
      "Epoch 725/1000 - Train Loss: 0.5739, Validation Loss: 0.5720\n",
      "Epoch 726/1000 - Train Loss: 0.5738, Validation Loss: 0.5719\n",
      "Epoch 727/1000 - Train Loss: 0.5736, Validation Loss: 0.5718\n",
      "Epoch 728/1000 - Train Loss: 0.5735, Validation Loss: 0.5716\n",
      "Epoch 729/1000 - Train Loss: 0.5734, Validation Loss: 0.5715\n",
      "Epoch 730/1000 - Train Loss: 0.5732, Validation Loss: 0.5713\n",
      "Epoch 731/1000 - Train Loss: 0.5731, Validation Loss: 0.5712\n",
      "Epoch 732/1000 - Train Loss: 0.5730, Validation Loss: 0.5711\n",
      "Epoch 733/1000 - Train Loss: 0.5728, Validation Loss: 0.5709\n",
      "Epoch 734/1000 - Train Loss: 0.5727, Validation Loss: 0.5708\n",
      "Epoch 735/1000 - Train Loss: 0.5726, Validation Loss: 0.5707\n",
      "Epoch 736/1000 - Train Loss: 0.5724, Validation Loss: 0.5705\n",
      "Epoch 737/1000 - Train Loss: 0.5723, Validation Loss: 0.5704\n",
      "Epoch 738/1000 - Train Loss: 0.5722, Validation Loss: 0.5703\n",
      "Epoch 739/1000 - Train Loss: 0.5720, Validation Loss: 0.5701\n",
      "Epoch 740/1000 - Train Loss: 0.5719, Validation Loss: 0.5700\n",
      "Epoch 741/1000 - Train Loss: 0.5717, Validation Loss: 0.5699\n",
      "Epoch 742/1000 - Train Loss: 0.5716, Validation Loss: 0.5697\n",
      "Epoch 743/1000 - Train Loss: 0.5715, Validation Loss: 0.5696\n",
      "Epoch 744/1000 - Train Loss: 0.5713, Validation Loss: 0.5695\n",
      "Epoch 745/1000 - Train Loss: 0.5712, Validation Loss: 0.5693\n",
      "Epoch 746/1000 - Train Loss: 0.5711, Validation Loss: 0.5692\n",
      "Epoch 747/1000 - Train Loss: 0.5709, Validation Loss: 0.5691\n",
      "Epoch 748/1000 - Train Loss: 0.5708, Validation Loss: 0.5689\n",
      "Epoch 749/1000 - Train Loss: 0.5707, Validation Loss: 0.5688\n",
      "Epoch 750/1000 - Train Loss: 0.5705, Validation Loss: 0.5687\n",
      "Epoch 751/1000 - Train Loss: 0.5704, Validation Loss: 0.5685\n",
      "Epoch 752/1000 - Train Loss: 0.5703, Validation Loss: 0.5684\n",
      "Epoch 753/1000 - Train Loss: 0.5701, Validation Loss: 0.5683\n",
      "Epoch 754/1000 - Train Loss: 0.5700, Validation Loss: 0.5681\n",
      "Epoch 755/1000 - Train Loss: 0.5699, Validation Loss: 0.5680\n",
      "Epoch 756/1000 - Train Loss: 0.5697, Validation Loss: 0.5679\n",
      "Epoch 757/1000 - Train Loss: 0.5696, Validation Loss: 0.5677\n",
      "Epoch 758/1000 - Train Loss: 0.5695, Validation Loss: 0.5676\n",
      "Epoch 759/1000 - Train Loss: 0.5693, Validation Loss: 0.5675\n",
      "Epoch 760/1000 - Train Loss: 0.5692, Validation Loss: 0.5673\n",
      "Epoch 761/1000 - Train Loss: 0.5691, Validation Loss: 0.5672\n",
      "Epoch 762/1000 - Train Loss: 0.5689, Validation Loss: 0.5671\n",
      "Epoch 763/1000 - Train Loss: 0.5688, Validation Loss: 0.5669\n",
      "Epoch 764/1000 - Train Loss: 0.5687, Validation Loss: 0.5668\n",
      "Epoch 765/1000 - Train Loss: 0.5685, Validation Loss: 0.5667\n",
      "Epoch 766/1000 - Train Loss: 0.5684, Validation Loss: 0.5665\n",
      "Epoch 767/1000 - Train Loss: 0.5683, Validation Loss: 0.5664\n",
      "Epoch 768/1000 - Train Loss: 0.5682, Validation Loss: 0.5663\n",
      "Epoch 769/1000 - Train Loss: 0.5680, Validation Loss: 0.5661\n",
      "Epoch 770/1000 - Train Loss: 0.5679, Validation Loss: 0.5660\n",
      "Epoch 771/1000 - Train Loss: 0.5678, Validation Loss: 0.5659\n",
      "Epoch 772/1000 - Train Loss: 0.5676, Validation Loss: 0.5657\n",
      "Epoch 773/1000 - Train Loss: 0.5675, Validation Loss: 0.5656\n",
      "Epoch 774/1000 - Train Loss: 0.5674, Validation Loss: 0.5655\n",
      "Epoch 775/1000 - Train Loss: 0.5672, Validation Loss: 0.5653\n",
      "Epoch 776/1000 - Train Loss: 0.5671, Validation Loss: 0.5652\n",
      "Epoch 777/1000 - Train Loss: 0.5670, Validation Loss: 0.5651\n",
      "Epoch 778/1000 - Train Loss: 0.5668, Validation Loss: 0.5649\n",
      "Epoch 779/1000 - Train Loss: 0.5667, Validation Loss: 0.5648\n",
      "Epoch 780/1000 - Train Loss: 0.5666, Validation Loss: 0.5647\n",
      "Epoch 781/1000 - Train Loss: 0.5664, Validation Loss: 0.5645\n",
      "Epoch 782/1000 - Train Loss: 0.5663, Validation Loss: 0.5644\n",
      "Epoch 783/1000 - Train Loss: 0.5662, Validation Loss: 0.5643\n",
      "Epoch 784/1000 - Train Loss: 0.5660, Validation Loss: 0.5641\n",
      "Epoch 785/1000 - Train Loss: 0.5659, Validation Loss: 0.5640\n",
      "Epoch 786/1000 - Train Loss: 0.5658, Validation Loss: 0.5639\n",
      "Epoch 787/1000 - Train Loss: 0.5656, Validation Loss: 0.5637\n",
      "Epoch 788/1000 - Train Loss: 0.5655, Validation Loss: 0.5636\n",
      "Epoch 789/1000 - Train Loss: 0.5654, Validation Loss: 0.5635\n",
      "Epoch 790/1000 - Train Loss: 0.5652, Validation Loss: 0.5633\n",
      "Epoch 791/1000 - Train Loss: 0.5651, Validation Loss: 0.5632\n",
      "Epoch 792/1000 - Train Loss: 0.5650, Validation Loss: 0.5631\n",
      "Epoch 793/1000 - Train Loss: 0.5649, Validation Loss: 0.5630\n",
      "Epoch 794/1000 - Train Loss: 0.5647, Validation Loss: 0.5628\n",
      "Epoch 795/1000 - Train Loss: 0.5646, Validation Loss: 0.5627\n",
      "Epoch 796/1000 - Train Loss: 0.5645, Validation Loss: 0.5626\n",
      "Epoch 797/1000 - Train Loss: 0.5643, Validation Loss: 0.5624\n",
      "Epoch 798/1000 - Train Loss: 0.5642, Validation Loss: 0.5623\n",
      "Epoch 799/1000 - Train Loss: 0.5641, Validation Loss: 0.5622\n",
      "Epoch 800/1000 - Train Loss: 0.5639, Validation Loss: 0.5620\n",
      "Epoch 801/1000 - Train Loss: 0.5638, Validation Loss: 0.5619\n",
      "Epoch 802/1000 - Train Loss: 0.5637, Validation Loss: 0.5618\n",
      "Epoch 803/1000 - Train Loss: 0.5635, Validation Loss: 0.5616\n",
      "Epoch 804/1000 - Train Loss: 0.5634, Validation Loss: 0.5615\n",
      "Epoch 805/1000 - Train Loss: 0.5633, Validation Loss: 0.5614\n",
      "Epoch 806/1000 - Train Loss: 0.5632, Validation Loss: 0.5613\n",
      "Epoch 807/1000 - Train Loss: 0.5630, Validation Loss: 0.5611\n",
      "Epoch 808/1000 - Train Loss: 0.5629, Validation Loss: 0.5610\n",
      "Epoch 809/1000 - Train Loss: 0.5628, Validation Loss: 0.5609\n",
      "Epoch 810/1000 - Train Loss: 0.5626, Validation Loss: 0.5607\n",
      "Epoch 811/1000 - Train Loss: 0.5625, Validation Loss: 0.5606\n",
      "Epoch 812/1000 - Train Loss: 0.5624, Validation Loss: 0.5605\n",
      "Epoch 813/1000 - Train Loss: 0.5622, Validation Loss: 0.5603\n",
      "Epoch 814/1000 - Train Loss: 0.5621, Validation Loss: 0.5602\n",
      "Epoch 815/1000 - Train Loss: 0.5620, Validation Loss: 0.5601\n",
      "Epoch 816/1000 - Train Loss: 0.5619, Validation Loss: 0.5599\n",
      "Epoch 817/1000 - Train Loss: 0.5617, Validation Loss: 0.5598\n",
      "Epoch 818/1000 - Train Loss: 0.5616, Validation Loss: 0.5597\n",
      "Epoch 819/1000 - Train Loss: 0.5615, Validation Loss: 0.5596\n",
      "Epoch 820/1000 - Train Loss: 0.5613, Validation Loss: 0.5594\n",
      "Epoch 821/1000 - Train Loss: 0.5612, Validation Loss: 0.5593\n",
      "Epoch 822/1000 - Train Loss: 0.5611, Validation Loss: 0.5592\n",
      "Epoch 823/1000 - Train Loss: 0.5609, Validation Loss: 0.5590\n",
      "Epoch 824/1000 - Train Loss: 0.5608, Validation Loss: 0.5589\n",
      "Epoch 825/1000 - Train Loss: 0.5607, Validation Loss: 0.5588\n",
      "Epoch 826/1000 - Train Loss: 0.5606, Validation Loss: 0.5586\n",
      "Epoch 827/1000 - Train Loss: 0.5604, Validation Loss: 0.5585\n",
      "Epoch 828/1000 - Train Loss: 0.5603, Validation Loss: 0.5584\n",
      "Epoch 829/1000 - Train Loss: 0.5602, Validation Loss: 0.5583\n",
      "Epoch 830/1000 - Train Loss: 0.5600, Validation Loss: 0.5581\n",
      "Epoch 831/1000 - Train Loss: 0.5599, Validation Loss: 0.5580\n",
      "Epoch 832/1000 - Train Loss: 0.5598, Validation Loss: 0.5579\n",
      "Epoch 833/1000 - Train Loss: 0.5597, Validation Loss: 0.5577\n",
      "Epoch 834/1000 - Train Loss: 0.5595, Validation Loss: 0.5576\n",
      "Epoch 835/1000 - Train Loss: 0.5594, Validation Loss: 0.5575\n",
      "Epoch 836/1000 - Train Loss: 0.5593, Validation Loss: 0.5574\n",
      "Epoch 837/1000 - Train Loss: 0.5591, Validation Loss: 0.5572\n",
      "Epoch 838/1000 - Train Loss: 0.5590, Validation Loss: 0.5571\n",
      "Epoch 839/1000 - Train Loss: 0.5589, Validation Loss: 0.5570\n",
      "Epoch 840/1000 - Train Loss: 0.5587, Validation Loss: 0.5568\n",
      "Epoch 841/1000 - Train Loss: 0.5586, Validation Loss: 0.5567\n",
      "Epoch 842/1000 - Train Loss: 0.5585, Validation Loss: 0.5566\n",
      "Epoch 843/1000 - Train Loss: 0.5584, Validation Loss: 0.5565\n",
      "Epoch 844/1000 - Train Loss: 0.5582, Validation Loss: 0.5563\n",
      "Epoch 845/1000 - Train Loss: 0.5581, Validation Loss: 0.5562\n",
      "Epoch 846/1000 - Train Loss: 0.5580, Validation Loss: 0.5561\n",
      "Epoch 847/1000 - Train Loss: 0.5578, Validation Loss: 0.5559\n",
      "Epoch 848/1000 - Train Loss: 0.5577, Validation Loss: 0.5558\n",
      "Epoch 849/1000 - Train Loss: 0.5576, Validation Loss: 0.5557\n",
      "Epoch 850/1000 - Train Loss: 0.5575, Validation Loss: 0.5556\n",
      "Epoch 851/1000 - Train Loss: 0.5573, Validation Loss: 0.5554\n",
      "Epoch 852/1000 - Train Loss: 0.5572, Validation Loss: 0.5553\n",
      "Epoch 853/1000 - Train Loss: 0.5571, Validation Loss: 0.5552\n",
      "Epoch 854/1000 - Train Loss: 0.5570, Validation Loss: 0.5550\n",
      "Epoch 855/1000 - Train Loss: 0.5568, Validation Loss: 0.5549\n",
      "Epoch 856/1000 - Train Loss: 0.5567, Validation Loss: 0.5548\n",
      "Epoch 857/1000 - Train Loss: 0.5566, Validation Loss: 0.5547\n",
      "Epoch 858/1000 - Train Loss: 0.5564, Validation Loss: 0.5545\n",
      "Epoch 859/1000 - Train Loss: 0.5563, Validation Loss: 0.5544\n",
      "Epoch 860/1000 - Train Loss: 0.5562, Validation Loss: 0.5543\n",
      "Epoch 861/1000 - Train Loss: 0.5561, Validation Loss: 0.5541\n",
      "Epoch 862/1000 - Train Loss: 0.5559, Validation Loss: 0.5540\n",
      "Epoch 863/1000 - Train Loss: 0.5558, Validation Loss: 0.5539\n",
      "Epoch 864/1000 - Train Loss: 0.5557, Validation Loss: 0.5538\n",
      "Epoch 865/1000 - Train Loss: 0.5555, Validation Loss: 0.5536\n",
      "Epoch 866/1000 - Train Loss: 0.5554, Validation Loss: 0.5535\n",
      "Epoch 867/1000 - Train Loss: 0.5553, Validation Loss: 0.5534\n",
      "Epoch 868/1000 - Train Loss: 0.5552, Validation Loss: 0.5532\n",
      "Epoch 869/1000 - Train Loss: 0.5550, Validation Loss: 0.5531\n",
      "Epoch 870/1000 - Train Loss: 0.5549, Validation Loss: 0.5530\n",
      "Epoch 871/1000 - Train Loss: 0.5548, Validation Loss: 0.5529\n",
      "Epoch 872/1000 - Train Loss: 0.5547, Validation Loss: 0.5527\n",
      "Epoch 873/1000 - Train Loss: 0.5545, Validation Loss: 0.5526\n",
      "Epoch 874/1000 - Train Loss: 0.5544, Validation Loss: 0.5525\n",
      "Epoch 875/1000 - Train Loss: 0.5543, Validation Loss: 0.5524\n",
      "Epoch 876/1000 - Train Loss: 0.5541, Validation Loss: 0.5522\n",
      "Epoch 877/1000 - Train Loss: 0.5540, Validation Loss: 0.5521\n",
      "Epoch 878/1000 - Train Loss: 0.5539, Validation Loss: 0.5520\n",
      "Epoch 879/1000 - Train Loss: 0.5538, Validation Loss: 0.5518\n",
      "Epoch 880/1000 - Train Loss: 0.5536, Validation Loss: 0.5517\n",
      "Epoch 881/1000 - Train Loss: 0.5535, Validation Loss: 0.5516\n",
      "Epoch 882/1000 - Train Loss: 0.5534, Validation Loss: 0.5515\n",
      "Epoch 883/1000 - Train Loss: 0.5533, Validation Loss: 0.5513\n",
      "Epoch 884/1000 - Train Loss: 0.5531, Validation Loss: 0.5512\n",
      "Epoch 885/1000 - Train Loss: 0.5530, Validation Loss: 0.5511\n",
      "Epoch 886/1000 - Train Loss: 0.5529, Validation Loss: 0.5510\n",
      "Epoch 887/1000 - Train Loss: 0.5528, Validation Loss: 0.5508\n",
      "Epoch 888/1000 - Train Loss: 0.5526, Validation Loss: 0.5507\n",
      "Epoch 889/1000 - Train Loss: 0.5525, Validation Loss: 0.5506\n",
      "Epoch 890/1000 - Train Loss: 0.5524, Validation Loss: 0.5505\n",
      "Epoch 891/1000 - Train Loss: 0.5523, Validation Loss: 0.5503\n",
      "Epoch 892/1000 - Train Loss: 0.5521, Validation Loss: 0.5502\n",
      "Epoch 893/1000 - Train Loss: 0.5520, Validation Loss: 0.5501\n",
      "Epoch 894/1000 - Train Loss: 0.5519, Validation Loss: 0.5500\n",
      "Epoch 895/1000 - Train Loss: 0.5517, Validation Loss: 0.5498\n",
      "Epoch 896/1000 - Train Loss: 0.5516, Validation Loss: 0.5497\n",
      "Epoch 897/1000 - Train Loss: 0.5515, Validation Loss: 0.5496\n",
      "Epoch 898/1000 - Train Loss: 0.5514, Validation Loss: 0.5494\n",
      "Epoch 899/1000 - Train Loss: 0.5512, Validation Loss: 0.5493\n",
      "Epoch 900/1000 - Train Loss: 0.5511, Validation Loss: 0.5492\n",
      "Epoch 901/1000 - Train Loss: 0.5510, Validation Loss: 0.5491\n",
      "Epoch 902/1000 - Train Loss: 0.5509, Validation Loss: 0.5489\n",
      "Epoch 903/1000 - Train Loss: 0.5507, Validation Loss: 0.5488\n",
      "Epoch 904/1000 - Train Loss: 0.5506, Validation Loss: 0.5487\n",
      "Epoch 905/1000 - Train Loss: 0.5505, Validation Loss: 0.5486\n",
      "Epoch 906/1000 - Train Loss: 0.5504, Validation Loss: 0.5484\n",
      "Epoch 907/1000 - Train Loss: 0.5502, Validation Loss: 0.5483\n",
      "Epoch 908/1000 - Train Loss: 0.5501, Validation Loss: 0.5482\n",
      "Epoch 909/1000 - Train Loss: 0.5500, Validation Loss: 0.5481\n",
      "Epoch 910/1000 - Train Loss: 0.5499, Validation Loss: 0.5479\n",
      "Epoch 911/1000 - Train Loss: 0.5497, Validation Loss: 0.5478\n",
      "Epoch 912/1000 - Train Loss: 0.5496, Validation Loss: 0.5477\n",
      "Epoch 913/1000 - Train Loss: 0.5495, Validation Loss: 0.5476\n",
      "Epoch 914/1000 - Train Loss: 0.5494, Validation Loss: 0.5474\n",
      "Epoch 915/1000 - Train Loss: 0.5492, Validation Loss: 0.5473\n",
      "Epoch 916/1000 - Train Loss: 0.5491, Validation Loss: 0.5472\n",
      "Epoch 917/1000 - Train Loss: 0.5490, Validation Loss: 0.5471\n",
      "Epoch 918/1000 - Train Loss: 0.5489, Validation Loss: 0.5469\n",
      "Epoch 919/1000 - Train Loss: 0.5487, Validation Loss: 0.5468\n",
      "Epoch 920/1000 - Train Loss: 0.5486, Validation Loss: 0.5467\n",
      "Epoch 921/1000 - Train Loss: 0.5485, Validation Loss: 0.5466\n",
      "Epoch 922/1000 - Train Loss: 0.5484, Validation Loss: 0.5464\n",
      "Epoch 923/1000 - Train Loss: 0.5482, Validation Loss: 0.5463\n",
      "Epoch 924/1000 - Train Loss: 0.5481, Validation Loss: 0.5462\n",
      "Epoch 925/1000 - Train Loss: 0.5480, Validation Loss: 0.5461\n",
      "Epoch 926/1000 - Train Loss: 0.5479, Validation Loss: 0.5459\n",
      "Epoch 927/1000 - Train Loss: 0.5477, Validation Loss: 0.5458\n",
      "Epoch 928/1000 - Train Loss: 0.5476, Validation Loss: 0.5457\n",
      "Epoch 929/1000 - Train Loss: 0.5475, Validation Loss: 0.5456\n",
      "Epoch 930/1000 - Train Loss: 0.5474, Validation Loss: 0.5454\n",
      "Epoch 931/1000 - Train Loss: 0.5473, Validation Loss: 0.5453\n",
      "Epoch 932/1000 - Train Loss: 0.5471, Validation Loss: 0.5452\n",
      "Epoch 933/1000 - Train Loss: 0.5470, Validation Loss: 0.5451\n",
      "Epoch 934/1000 - Train Loss: 0.5469, Validation Loss: 0.5450\n",
      "Epoch 935/1000 - Train Loss: 0.5468, Validation Loss: 0.5448\n",
      "Epoch 936/1000 - Train Loss: 0.5466, Validation Loss: 0.5447\n",
      "Epoch 937/1000 - Train Loss: 0.5465, Validation Loss: 0.5446\n",
      "Epoch 938/1000 - Train Loss: 0.5464, Validation Loss: 0.5445\n",
      "Epoch 939/1000 - Train Loss: 0.5463, Validation Loss: 0.5443\n",
      "Epoch 940/1000 - Train Loss: 0.5461, Validation Loss: 0.5442\n",
      "Epoch 941/1000 - Train Loss: 0.5460, Validation Loss: 0.5441\n",
      "Epoch 942/1000 - Train Loss: 0.5459, Validation Loss: 0.5440\n",
      "Epoch 943/1000 - Train Loss: 0.5458, Validation Loss: 0.5438\n",
      "Epoch 944/1000 - Train Loss: 0.5456, Validation Loss: 0.5437\n",
      "Epoch 945/1000 - Train Loss: 0.5455, Validation Loss: 0.5436\n",
      "Epoch 946/1000 - Train Loss: 0.5454, Validation Loss: 0.5435\n",
      "Epoch 947/1000 - Train Loss: 0.5453, Validation Loss: 0.5433\n",
      "Epoch 948/1000 - Train Loss: 0.5451, Validation Loss: 0.5432\n",
      "Epoch 949/1000 - Train Loss: 0.5450, Validation Loss: 0.5431\n",
      "Epoch 950/1000 - Train Loss: 0.5449, Validation Loss: 0.5430\n",
      "Epoch 951/1000 - Train Loss: 0.5448, Validation Loss: 0.5428\n",
      "Epoch 952/1000 - Train Loss: 0.5447, Validation Loss: 0.5427\n",
      "Epoch 953/1000 - Train Loss: 0.5445, Validation Loss: 0.5426\n",
      "Epoch 954/1000 - Train Loss: 0.5444, Validation Loss: 0.5425\n",
      "Epoch 955/1000 - Train Loss: 0.5443, Validation Loss: 0.5424\n",
      "Epoch 956/1000 - Train Loss: 0.5442, Validation Loss: 0.5422\n",
      "Epoch 957/1000 - Train Loss: 0.5440, Validation Loss: 0.5421\n",
      "Epoch 958/1000 - Train Loss: 0.5439, Validation Loss: 0.5420\n",
      "Epoch 959/1000 - Train Loss: 0.5438, Validation Loss: 0.5419\n",
      "Epoch 960/1000 - Train Loss: 0.5437, Validation Loss: 0.5417\n",
      "Epoch 961/1000 - Train Loss: 0.5436, Validation Loss: 0.5416\n",
      "Epoch 962/1000 - Train Loss: 0.5434, Validation Loss: 0.5415\n",
      "Epoch 963/1000 - Train Loss: 0.5433, Validation Loss: 0.5414\n",
      "Epoch 964/1000 - Train Loss: 0.5432, Validation Loss: 0.5413\n",
      "Epoch 965/1000 - Train Loss: 0.5431, Validation Loss: 0.5411\n",
      "Epoch 966/1000 - Train Loss: 0.5429, Validation Loss: 0.5410\n",
      "Epoch 967/1000 - Train Loss: 0.5428, Validation Loss: 0.5409\n",
      "Epoch 968/1000 - Train Loss: 0.5427, Validation Loss: 0.5408\n",
      "Epoch 969/1000 - Train Loss: 0.5426, Validation Loss: 0.5406\n",
      "Epoch 970/1000 - Train Loss: 0.5424, Validation Loss: 0.5405\n",
      "Epoch 971/1000 - Train Loss: 0.5423, Validation Loss: 0.5404\n",
      "Epoch 972/1000 - Train Loss: 0.5422, Validation Loss: 0.5403\n",
      "Epoch 973/1000 - Train Loss: 0.5421, Validation Loss: 0.5402\n",
      "Epoch 974/1000 - Train Loss: 0.5420, Validation Loss: 0.5400\n",
      "Epoch 975/1000 - Train Loss: 0.5418, Validation Loss: 0.5399\n",
      "Epoch 976/1000 - Train Loss: 0.5417, Validation Loss: 0.5398\n",
      "Epoch 977/1000 - Train Loss: 0.5416, Validation Loss: 0.5397\n",
      "Epoch 978/1000 - Train Loss: 0.5415, Validation Loss: 0.5395\n",
      "Epoch 979/1000 - Train Loss: 0.5414, Validation Loss: 0.5394\n",
      "Epoch 980/1000 - Train Loss: 0.5412, Validation Loss: 0.5393\n",
      "Epoch 981/1000 - Train Loss: 0.5411, Validation Loss: 0.5392\n",
      "Epoch 982/1000 - Train Loss: 0.5410, Validation Loss: 0.5391\n",
      "Epoch 983/1000 - Train Loss: 0.5409, Validation Loss: 0.5389\n",
      "Epoch 984/1000 - Train Loss: 0.5407, Validation Loss: 0.5388\n",
      "Epoch 985/1000 - Train Loss: 0.5406, Validation Loss: 0.5387\n",
      "Epoch 986/1000 - Train Loss: 0.5405, Validation Loss: 0.5386\n",
      "Epoch 987/1000 - Train Loss: 0.5404, Validation Loss: 0.5384\n",
      "Epoch 988/1000 - Train Loss: 0.5403, Validation Loss: 0.5383\n",
      "Epoch 989/1000 - Train Loss: 0.5401, Validation Loss: 0.5382\n",
      "Epoch 990/1000 - Train Loss: 0.5400, Validation Loss: 0.5381\n",
      "Epoch 991/1000 - Train Loss: 0.5399, Validation Loss: 0.5380\n",
      "Epoch 992/1000 - Train Loss: 0.5398, Validation Loss: 0.5378\n",
      "Epoch 993/1000 - Train Loss: 0.5397, Validation Loss: 0.5377\n",
      "Epoch 994/1000 - Train Loss: 0.5395, Validation Loss: 0.5376\n",
      "Epoch 995/1000 - Train Loss: 0.5394, Validation Loss: 0.5375\n",
      "Epoch 996/1000 - Train Loss: 0.5393, Validation Loss: 0.5374\n",
      "Epoch 997/1000 - Train Loss: 0.5392, Validation Loss: 0.5372\n",
      "Epoch 998/1000 - Train Loss: 0.5390, Validation Loss: 0.5371\n",
      "Epoch 999/1000 - Train Loss: 0.5389, Validation Loss: 0.5370\n",
      "Epoch 1000/1000 - Train Loss: 0.5388, Validation Loss: 0.5369\n",
      "Epoch 1/1000 - Train Loss: 0.6931, Validation Loss: 0.6925\n",
      "Epoch 2/1000 - Train Loss: 0.6925, Validation Loss: 0.6918\n",
      "Epoch 3/1000 - Train Loss: 0.6918, Validation Loss: 0.6911\n",
      "Epoch 4/1000 - Train Loss: 0.6912, Validation Loss: 0.6905\n",
      "Epoch 5/1000 - Train Loss: 0.6905, Validation Loss: 0.6898\n",
      "Epoch 6/1000 - Train Loss: 0.6899, Validation Loss: 0.6891\n",
      "Epoch 7/1000 - Train Loss: 0.6893, Validation Loss: 0.6885\n",
      "Epoch 8/1000 - Train Loss: 0.6886, Validation Loss: 0.6878\n",
      "Epoch 9/1000 - Train Loss: 0.6880, Validation Loss: 0.6872\n",
      "Epoch 10/1000 - Train Loss: 0.6874, Validation Loss: 0.6865\n",
      "Epoch 11/1000 - Train Loss: 0.6867, Validation Loss: 0.6859\n",
      "Epoch 12/1000 - Train Loss: 0.6861, Validation Loss: 0.6852\n",
      "Epoch 13/1000 - Train Loss: 0.6855, Validation Loss: 0.6846\n",
      "Epoch 14/1000 - Train Loss: 0.6848, Validation Loss: 0.6840\n",
      "Epoch 15/1000 - Train Loss: 0.6842, Validation Loss: 0.6833\n",
      "Epoch 16/1000 - Train Loss: 0.6836, Validation Loss: 0.6827\n",
      "Epoch 17/1000 - Train Loss: 0.6830, Validation Loss: 0.6821\n",
      "Epoch 18/1000 - Train Loss: 0.6824, Validation Loss: 0.6814\n",
      "Epoch 19/1000 - Train Loss: 0.6818, Validation Loss: 0.6808\n",
      "Epoch 20/1000 - Train Loss: 0.6812, Validation Loss: 0.6802\n",
      "Epoch 21/1000 - Train Loss: 0.6805, Validation Loss: 0.6796\n",
      "Epoch 22/1000 - Train Loss: 0.6799, Validation Loss: 0.6789\n",
      "Epoch 23/1000 - Train Loss: 0.6793, Validation Loss: 0.6783\n",
      "Epoch 24/1000 - Train Loss: 0.6787, Validation Loss: 0.6777\n",
      "Epoch 25/1000 - Train Loss: 0.6781, Validation Loss: 0.6771\n",
      "Epoch 26/1000 - Train Loss: 0.6775, Validation Loss: 0.6765\n",
      "Epoch 27/1000 - Train Loss: 0.6769, Validation Loss: 0.6759\n",
      "Epoch 28/1000 - Train Loss: 0.6763, Validation Loss: 0.6753\n",
      "Epoch 29/1000 - Train Loss: 0.6758, Validation Loss: 0.6747\n",
      "Epoch 30/1000 - Train Loss: 0.6752, Validation Loss: 0.6741\n",
      "Epoch 31/1000 - Train Loss: 0.6746, Validation Loss: 0.6735\n",
      "Epoch 32/1000 - Train Loss: 0.6740, Validation Loss: 0.6729\n",
      "Epoch 33/1000 - Train Loss: 0.6734, Validation Loss: 0.6723\n",
      "Epoch 34/1000 - Train Loss: 0.6728, Validation Loss: 0.6717\n",
      "Epoch 35/1000 - Train Loss: 0.6722, Validation Loss: 0.6711\n",
      "Epoch 36/1000 - Train Loss: 0.6717, Validation Loss: 0.6705\n",
      "Epoch 37/1000 - Train Loss: 0.6711, Validation Loss: 0.6699\n",
      "Epoch 38/1000 - Train Loss: 0.6705, Validation Loss: 0.6693\n",
      "Epoch 39/1000 - Train Loss: 0.6699, Validation Loss: 0.6687\n",
      "Epoch 40/1000 - Train Loss: 0.6694, Validation Loss: 0.6681\n",
      "Epoch 41/1000 - Train Loss: 0.6688, Validation Loss: 0.6676\n",
      "Epoch 42/1000 - Train Loss: 0.6682, Validation Loss: 0.6670\n",
      "Epoch 43/1000 - Train Loss: 0.6676, Validation Loss: 0.6664\n",
      "Epoch 44/1000 - Train Loss: 0.6671, Validation Loss: 0.6658\n",
      "Epoch 45/1000 - Train Loss: 0.6665, Validation Loss: 0.6652\n",
      "Epoch 46/1000 - Train Loss: 0.6660, Validation Loss: 0.6647\n",
      "Epoch 47/1000 - Train Loss: 0.6654, Validation Loss: 0.6641\n",
      "Epoch 48/1000 - Train Loss: 0.6648, Validation Loss: 0.6635\n",
      "Epoch 49/1000 - Train Loss: 0.6643, Validation Loss: 0.6630\n",
      "Epoch 50/1000 - Train Loss: 0.6637, Validation Loss: 0.6624\n",
      "Epoch 51/1000 - Train Loss: 0.6632, Validation Loss: 0.6618\n",
      "Epoch 52/1000 - Train Loss: 0.6626, Validation Loss: 0.6613\n",
      "Epoch 53/1000 - Train Loss: 0.6621, Validation Loss: 0.6607\n",
      "Epoch 54/1000 - Train Loss: 0.6615, Validation Loss: 0.6601\n",
      "Epoch 55/1000 - Train Loss: 0.6610, Validation Loss: 0.6596\n",
      "Epoch 56/1000 - Train Loss: 0.6604, Validation Loss: 0.6590\n",
      "Epoch 57/1000 - Train Loss: 0.6599, Validation Loss: 0.6585\n",
      "Epoch 58/1000 - Train Loss: 0.6593, Validation Loss: 0.6579\n",
      "Epoch 59/1000 - Train Loss: 0.6588, Validation Loss: 0.6573\n",
      "Epoch 60/1000 - Train Loss: 0.6582, Validation Loss: 0.6568\n",
      "Epoch 61/1000 - Train Loss: 0.6577, Validation Loss: 0.6562\n",
      "Epoch 62/1000 - Train Loss: 0.6571, Validation Loss: 0.6557\n",
      "Epoch 63/1000 - Train Loss: 0.6566, Validation Loss: 0.6551\n",
      "Epoch 64/1000 - Train Loss: 0.6561, Validation Loss: 0.6546\n",
      "Epoch 65/1000 - Train Loss: 0.6555, Validation Loss: 0.6541\n",
      "Epoch 66/1000 - Train Loss: 0.6550, Validation Loss: 0.6535\n",
      "Epoch 67/1000 - Train Loss: 0.6545, Validation Loss: 0.6530\n",
      "Epoch 68/1000 - Train Loss: 0.6539, Validation Loss: 0.6524\n",
      "Epoch 69/1000 - Train Loss: 0.6534, Validation Loss: 0.6519\n",
      "Epoch 70/1000 - Train Loss: 0.6529, Validation Loss: 0.6513\n",
      "Epoch 71/1000 - Train Loss: 0.6523, Validation Loss: 0.6508\n",
      "Epoch 72/1000 - Train Loss: 0.6518, Validation Loss: 0.6503\n",
      "Epoch 73/1000 - Train Loss: 0.6513, Validation Loss: 0.6497\n",
      "Epoch 74/1000 - Train Loss: 0.6508, Validation Loss: 0.6492\n",
      "Epoch 75/1000 - Train Loss: 0.6502, Validation Loss: 0.6487\n",
      "Epoch 76/1000 - Train Loss: 0.6497, Validation Loss: 0.6481\n",
      "Epoch 77/1000 - Train Loss: 0.6492, Validation Loss: 0.6476\n",
      "Epoch 78/1000 - Train Loss: 0.6487, Validation Loss: 0.6471\n",
      "Epoch 79/1000 - Train Loss: 0.6481, Validation Loss: 0.6466\n",
      "Epoch 80/1000 - Train Loss: 0.6476, Validation Loss: 0.6460\n",
      "Epoch 81/1000 - Train Loss: 0.6471, Validation Loss: 0.6455\n",
      "Epoch 82/1000 - Train Loss: 0.6466, Validation Loss: 0.6450\n",
      "Epoch 83/1000 - Train Loss: 0.6461, Validation Loss: 0.6445\n",
      "Epoch 84/1000 - Train Loss: 0.6456, Validation Loss: 0.6439\n",
      "Epoch 85/1000 - Train Loss: 0.6451, Validation Loss: 0.6434\n",
      "Epoch 86/1000 - Train Loss: 0.6445, Validation Loss: 0.6429\n",
      "Epoch 87/1000 - Train Loss: 0.6440, Validation Loss: 0.6424\n",
      "Epoch 88/1000 - Train Loss: 0.6435, Validation Loss: 0.6419\n",
      "Epoch 89/1000 - Train Loss: 0.6430, Validation Loss: 0.6413\n",
      "Epoch 90/1000 - Train Loss: 0.6425, Validation Loss: 0.6408\n",
      "Epoch 91/1000 - Train Loss: 0.6420, Validation Loss: 0.6403\n",
      "Epoch 92/1000 - Train Loss: 0.6415, Validation Loss: 0.6398\n",
      "Epoch 93/1000 - Train Loss: 0.6410, Validation Loss: 0.6393\n",
      "Epoch 94/1000 - Train Loss: 0.6405, Validation Loss: 0.6388\n",
      "Epoch 95/1000 - Train Loss: 0.6400, Validation Loss: 0.6383\n",
      "Epoch 96/1000 - Train Loss: 0.6395, Validation Loss: 0.6378\n",
      "Epoch 97/1000 - Train Loss: 0.6390, Validation Loss: 0.6373\n",
      "Epoch 98/1000 - Train Loss: 0.6385, Validation Loss: 0.6367\n",
      "Epoch 99/1000 - Train Loss: 0.6380, Validation Loss: 0.6362\n",
      "Epoch 100/1000 - Train Loss: 0.6375, Validation Loss: 0.6357\n",
      "Epoch 101/1000 - Train Loss: 0.6370, Validation Loss: 0.6352\n",
      "Epoch 102/1000 - Train Loss: 0.6365, Validation Loss: 0.6347\n",
      "Epoch 103/1000 - Train Loss: 0.6360, Validation Loss: 0.6342\n",
      "Epoch 104/1000 - Train Loss: 0.6355, Validation Loss: 0.6337\n",
      "Epoch 105/1000 - Train Loss: 0.6350, Validation Loss: 0.6332\n",
      "Epoch 106/1000 - Train Loss: 0.6345, Validation Loss: 0.6327\n",
      "Epoch 107/1000 - Train Loss: 0.6340, Validation Loss: 0.6322\n",
      "Epoch 108/1000 - Train Loss: 0.6335, Validation Loss: 0.6317\n",
      "Epoch 109/1000 - Train Loss: 0.6330, Validation Loss: 0.6312\n",
      "Epoch 110/1000 - Train Loss: 0.6325, Validation Loss: 0.6307\n",
      "Epoch 111/1000 - Train Loss: 0.6320, Validation Loss: 0.6302\n",
      "Epoch 112/1000 - Train Loss: 0.6316, Validation Loss: 0.6298\n",
      "Epoch 113/1000 - Train Loss: 0.6311, Validation Loss: 0.6293\n",
      "Epoch 114/1000 - Train Loss: 0.6306, Validation Loss: 0.6288\n",
      "Epoch 115/1000 - Train Loss: 0.6301, Validation Loss: 0.6283\n",
      "Epoch 116/1000 - Train Loss: 0.6296, Validation Loss: 0.6278\n",
      "Epoch 117/1000 - Train Loss: 0.6291, Validation Loss: 0.6273\n",
      "Epoch 118/1000 - Train Loss: 0.6287, Validation Loss: 0.6268\n",
      "Epoch 119/1000 - Train Loss: 0.6282, Validation Loss: 0.6263\n",
      "Epoch 120/1000 - Train Loss: 0.6277, Validation Loss: 0.6258\n",
      "Epoch 121/1000 - Train Loss: 0.6272, Validation Loss: 0.6254\n",
      "Epoch 122/1000 - Train Loss: 0.6267, Validation Loss: 0.6249\n",
      "Epoch 123/1000 - Train Loss: 0.6262, Validation Loss: 0.6244\n",
      "Epoch 124/1000 - Train Loss: 0.6258, Validation Loss: 0.6239\n",
      "Epoch 125/1000 - Train Loss: 0.6253, Validation Loss: 0.6234\n",
      "Epoch 126/1000 - Train Loss: 0.6248, Validation Loss: 0.6229\n",
      "Epoch 127/1000 - Train Loss: 0.6243, Validation Loss: 0.6225\n",
      "Epoch 128/1000 - Train Loss: 0.6239, Validation Loss: 0.6220\n",
      "Epoch 129/1000 - Train Loss: 0.6234, Validation Loss: 0.6215\n",
      "Epoch 130/1000 - Train Loss: 0.6229, Validation Loss: 0.6210\n",
      "Epoch 131/1000 - Train Loss: 0.6224, Validation Loss: 0.6206\n",
      "Epoch 132/1000 - Train Loss: 0.6220, Validation Loss: 0.6201\n",
      "Epoch 133/1000 - Train Loss: 0.6215, Validation Loss: 0.6196\n",
      "Epoch 134/1000 - Train Loss: 0.6210, Validation Loss: 0.6191\n",
      "Epoch 135/1000 - Train Loss: 0.6206, Validation Loss: 0.6187\n",
      "Epoch 136/1000 - Train Loss: 0.6201, Validation Loss: 0.6182\n",
      "Epoch 137/1000 - Train Loss: 0.6196, Validation Loss: 0.6177\n",
      "Epoch 138/1000 - Train Loss: 0.6192, Validation Loss: 0.6172\n",
      "Epoch 139/1000 - Train Loss: 0.6187, Validation Loss: 0.6168\n",
      "Epoch 140/1000 - Train Loss: 0.6182, Validation Loss: 0.6163\n",
      "Epoch 141/1000 - Train Loss: 0.6178, Validation Loss: 0.6158\n",
      "Epoch 142/1000 - Train Loss: 0.6173, Validation Loss: 0.6154\n",
      "Epoch 143/1000 - Train Loss: 0.6168, Validation Loss: 0.6149\n",
      "Epoch 144/1000 - Train Loss: 0.6164, Validation Loss: 0.6144\n",
      "Epoch 145/1000 - Train Loss: 0.6159, Validation Loss: 0.6140\n",
      "Epoch 146/1000 - Train Loss: 0.6154, Validation Loss: 0.6135\n",
      "Epoch 147/1000 - Train Loss: 0.6150, Validation Loss: 0.6130\n",
      "Epoch 148/1000 - Train Loss: 0.6145, Validation Loss: 0.6126\n",
      "Epoch 149/1000 - Train Loss: 0.6141, Validation Loss: 0.6121\n",
      "Epoch 150/1000 - Train Loss: 0.6136, Validation Loss: 0.6116\n",
      "Epoch 151/1000 - Train Loss: 0.6132, Validation Loss: 0.6112\n",
      "Epoch 152/1000 - Train Loss: 0.6127, Validation Loss: 0.6107\n",
      "Epoch 153/1000 - Train Loss: 0.6122, Validation Loss: 0.6103\n",
      "Epoch 154/1000 - Train Loss: 0.6118, Validation Loss: 0.6098\n",
      "Epoch 155/1000 - Train Loss: 0.6113, Validation Loss: 0.6093\n",
      "Epoch 156/1000 - Train Loss: 0.6109, Validation Loss: 0.6089\n",
      "Epoch 157/1000 - Train Loss: 0.6104, Validation Loss: 0.6084\n",
      "Epoch 158/1000 - Train Loss: 0.6100, Validation Loss: 0.6080\n",
      "Epoch 159/1000 - Train Loss: 0.6095, Validation Loss: 0.6075\n",
      "Epoch 160/1000 - Train Loss: 0.6091, Validation Loss: 0.6071\n",
      "Epoch 161/1000 - Train Loss: 0.6086, Validation Loss: 0.6066\n",
      "Epoch 162/1000 - Train Loss: 0.6082, Validation Loss: 0.6062\n",
      "Epoch 163/1000 - Train Loss: 0.6077, Validation Loss: 0.6057\n",
      "Epoch 164/1000 - Train Loss: 0.6073, Validation Loss: 0.6052\n",
      "Epoch 165/1000 - Train Loss: 0.6068, Validation Loss: 0.6048\n",
      "Epoch 166/1000 - Train Loss: 0.6064, Validation Loss: 0.6043\n",
      "Epoch 167/1000 - Train Loss: 0.6059, Validation Loss: 0.6039\n",
      "Epoch 168/1000 - Train Loss: 0.6055, Validation Loss: 0.6034\n",
      "Epoch 169/1000 - Train Loss: 0.6050, Validation Loss: 0.6030\n",
      "Epoch 170/1000 - Train Loss: 0.6046, Validation Loss: 0.6025\n",
      "Epoch 171/1000 - Train Loss: 0.6041, Validation Loss: 0.6021\n",
      "Epoch 172/1000 - Train Loss: 0.6037, Validation Loss: 0.6017\n",
      "Epoch 173/1000 - Train Loss: 0.6032, Validation Loss: 0.6012\n",
      "Epoch 174/1000 - Train Loss: 0.6028, Validation Loss: 0.6008\n",
      "Epoch 175/1000 - Train Loss: 0.6024, Validation Loss: 0.6003\n",
      "Epoch 176/1000 - Train Loss: 0.6019, Validation Loss: 0.5999\n",
      "Epoch 177/1000 - Train Loss: 0.6015, Validation Loss: 0.5994\n",
      "Epoch 178/1000 - Train Loss: 0.6010, Validation Loss: 0.5990\n",
      "Epoch 179/1000 - Train Loss: 0.6006, Validation Loss: 0.5985\n",
      "Epoch 180/1000 - Train Loss: 0.6002, Validation Loss: 0.5981\n",
      "Epoch 181/1000 - Train Loss: 0.5997, Validation Loss: 0.5977\n",
      "Epoch 182/1000 - Train Loss: 0.5993, Validation Loss: 0.5972\n",
      "Epoch 183/1000 - Train Loss: 0.5988, Validation Loss: 0.5968\n",
      "Epoch 184/1000 - Train Loss: 0.5984, Validation Loss: 0.5963\n",
      "Epoch 185/1000 - Train Loss: 0.5980, Validation Loss: 0.5959\n",
      "Epoch 186/1000 - Train Loss: 0.5975, Validation Loss: 0.5955\n",
      "Epoch 187/1000 - Train Loss: 0.5971, Validation Loss: 0.5950\n",
      "Epoch 188/1000 - Train Loss: 0.5967, Validation Loss: 0.5946\n",
      "Epoch 189/1000 - Train Loss: 0.5962, Validation Loss: 0.5942\n",
      "Epoch 190/1000 - Train Loss: 0.5958, Validation Loss: 0.5937\n",
      "Epoch 191/1000 - Train Loss: 0.5954, Validation Loss: 0.5933\n",
      "Epoch 192/1000 - Train Loss: 0.5949, Validation Loss: 0.5928\n",
      "Epoch 193/1000 - Train Loss: 0.5945, Validation Loss: 0.5924\n",
      "Epoch 194/1000 - Train Loss: 0.5941, Validation Loss: 0.5920\n",
      "Epoch 195/1000 - Train Loss: 0.5936, Validation Loss: 0.5915\n",
      "Epoch 196/1000 - Train Loss: 0.5932, Validation Loss: 0.5911\n",
      "Epoch 197/1000 - Train Loss: 0.5928, Validation Loss: 0.5907\n",
      "Epoch 198/1000 - Train Loss: 0.5923, Validation Loss: 0.5903\n",
      "Epoch 199/1000 - Train Loss: 0.5919, Validation Loss: 0.5898\n",
      "Epoch 200/1000 - Train Loss: 0.5915, Validation Loss: 0.5894\n",
      "Epoch 201/1000 - Train Loss: 0.5911, Validation Loss: 0.5890\n",
      "Epoch 202/1000 - Train Loss: 0.5906, Validation Loss: 0.5885\n",
      "Epoch 203/1000 - Train Loss: 0.5902, Validation Loss: 0.5881\n",
      "Epoch 204/1000 - Train Loss: 0.5898, Validation Loss: 0.5877\n",
      "Epoch 205/1000 - Train Loss: 0.5894, Validation Loss: 0.5873\n",
      "Epoch 206/1000 - Train Loss: 0.5889, Validation Loss: 0.5868\n",
      "Epoch 207/1000 - Train Loss: 0.5885, Validation Loss: 0.5864\n",
      "Epoch 208/1000 - Train Loss: 0.5881, Validation Loss: 0.5860\n",
      "Epoch 209/1000 - Train Loss: 0.5877, Validation Loss: 0.5856\n",
      "Epoch 210/1000 - Train Loss: 0.5872, Validation Loss: 0.5851\n",
      "Epoch 211/1000 - Train Loss: 0.5868, Validation Loss: 0.5847\n",
      "Epoch 212/1000 - Train Loss: 0.5864, Validation Loss: 0.5843\n",
      "Epoch 213/1000 - Train Loss: 0.5860, Validation Loss: 0.5839\n",
      "Epoch 214/1000 - Train Loss: 0.5856, Validation Loss: 0.5834\n",
      "Epoch 215/1000 - Train Loss: 0.5851, Validation Loss: 0.5830\n",
      "Epoch 216/1000 - Train Loss: 0.5847, Validation Loss: 0.5826\n",
      "Epoch 217/1000 - Train Loss: 0.5843, Validation Loss: 0.5822\n",
      "Epoch 218/1000 - Train Loss: 0.5839, Validation Loss: 0.5818\n",
      "Epoch 219/1000 - Train Loss: 0.5835, Validation Loss: 0.5813\n",
      "Epoch 220/1000 - Train Loss: 0.5830, Validation Loss: 0.5809\n",
      "Epoch 221/1000 - Train Loss: 0.5826, Validation Loss: 0.5805\n",
      "Epoch 222/1000 - Train Loss: 0.5822, Validation Loss: 0.5801\n",
      "Epoch 223/1000 - Train Loss: 0.5818, Validation Loss: 0.5797\n",
      "Epoch 224/1000 - Train Loss: 0.5814, Validation Loss: 0.5793\n",
      "Epoch 225/1000 - Train Loss: 0.5810, Validation Loss: 0.5788\n",
      "Epoch 226/1000 - Train Loss: 0.5806, Validation Loss: 0.5784\n",
      "Epoch 227/1000 - Train Loss: 0.5801, Validation Loss: 0.5780\n",
      "Epoch 228/1000 - Train Loss: 0.5797, Validation Loss: 0.5776\n",
      "Epoch 229/1000 - Train Loss: 0.5793, Validation Loss: 0.5772\n",
      "Epoch 230/1000 - Train Loss: 0.5789, Validation Loss: 0.5768\n",
      "Epoch 231/1000 - Train Loss: 0.5785, Validation Loss: 0.5764\n",
      "Epoch 232/1000 - Train Loss: 0.5781, Validation Loss: 0.5760\n",
      "Epoch 233/1000 - Train Loss: 0.5777, Validation Loss: 0.5755\n",
      "Epoch 234/1000 - Train Loss: 0.5773, Validation Loss: 0.5751\n",
      "Epoch 235/1000 - Train Loss: 0.5769, Validation Loss: 0.5747\n",
      "Epoch 236/1000 - Train Loss: 0.5765, Validation Loss: 0.5743\n",
      "Epoch 237/1000 - Train Loss: 0.5760, Validation Loss: 0.5739\n",
      "Epoch 238/1000 - Train Loss: 0.5756, Validation Loss: 0.5735\n",
      "Epoch 239/1000 - Train Loss: 0.5752, Validation Loss: 0.5731\n",
      "Epoch 240/1000 - Train Loss: 0.5748, Validation Loss: 0.5727\n",
      "Epoch 241/1000 - Train Loss: 0.5744, Validation Loss: 0.5723\n",
      "Epoch 242/1000 - Train Loss: 0.5740, Validation Loss: 0.5719\n",
      "Epoch 243/1000 - Train Loss: 0.5736, Validation Loss: 0.5715\n",
      "Epoch 244/1000 - Train Loss: 0.5732, Validation Loss: 0.5711\n",
      "Epoch 245/1000 - Train Loss: 0.5728, Validation Loss: 0.5707\n",
      "Epoch 246/1000 - Train Loss: 0.5724, Validation Loss: 0.5702\n",
      "Epoch 247/1000 - Train Loss: 0.5720, Validation Loss: 0.5698\n",
      "Epoch 248/1000 - Train Loss: 0.5716, Validation Loss: 0.5694\n",
      "Epoch 249/1000 - Train Loss: 0.5712, Validation Loss: 0.5690\n",
      "Epoch 250/1000 - Train Loss: 0.5708, Validation Loss: 0.5686\n",
      "Epoch 251/1000 - Train Loss: 0.5704, Validation Loss: 0.5682\n",
      "Epoch 252/1000 - Train Loss: 0.5700, Validation Loss: 0.5678\n",
      "Epoch 253/1000 - Train Loss: 0.5696, Validation Loss: 0.5674\n",
      "Epoch 254/1000 - Train Loss: 0.5692, Validation Loss: 0.5670\n",
      "Epoch 255/1000 - Train Loss: 0.5688, Validation Loss: 0.5666\n",
      "Epoch 256/1000 - Train Loss: 0.5684, Validation Loss: 0.5662\n",
      "Epoch 257/1000 - Train Loss: 0.5680, Validation Loss: 0.5658\n",
      "Epoch 258/1000 - Train Loss: 0.5676, Validation Loss: 0.5654\n",
      "Epoch 259/1000 - Train Loss: 0.5672, Validation Loss: 0.5650\n",
      "Epoch 260/1000 - Train Loss: 0.5668, Validation Loss: 0.5646\n",
      "Epoch 261/1000 - Train Loss: 0.5664, Validation Loss: 0.5642\n",
      "Epoch 262/1000 - Train Loss: 0.5660, Validation Loss: 0.5639\n",
      "Epoch 263/1000 - Train Loss: 0.5656, Validation Loss: 0.5635\n",
      "Epoch 264/1000 - Train Loss: 0.5652, Validation Loss: 0.5631\n",
      "Epoch 265/1000 - Train Loss: 0.5648, Validation Loss: 0.5627\n",
      "Epoch 266/1000 - Train Loss: 0.5644, Validation Loss: 0.5623\n",
      "Epoch 267/1000 - Train Loss: 0.5640, Validation Loss: 0.5619\n",
      "Epoch 268/1000 - Train Loss: 0.5637, Validation Loss: 0.5615\n",
      "Epoch 269/1000 - Train Loss: 0.5633, Validation Loss: 0.5611\n",
      "Epoch 270/1000 - Train Loss: 0.5629, Validation Loss: 0.5607\n",
      "Epoch 271/1000 - Train Loss: 0.5625, Validation Loss: 0.5603\n",
      "Epoch 272/1000 - Train Loss: 0.5621, Validation Loss: 0.5599\n",
      "Epoch 273/1000 - Train Loss: 0.5617, Validation Loss: 0.5595\n",
      "Epoch 274/1000 - Train Loss: 0.5613, Validation Loss: 0.5591\n",
      "Epoch 275/1000 - Train Loss: 0.5609, Validation Loss: 0.5588\n",
      "Epoch 276/1000 - Train Loss: 0.5605, Validation Loss: 0.5584\n",
      "Epoch 277/1000 - Train Loss: 0.5601, Validation Loss: 0.5580\n",
      "Epoch 278/1000 - Train Loss: 0.5598, Validation Loss: 0.5576\n",
      "Epoch 279/1000 - Train Loss: 0.5594, Validation Loss: 0.5572\n",
      "Epoch 280/1000 - Train Loss: 0.5590, Validation Loss: 0.5568\n",
      "Epoch 281/1000 - Train Loss: 0.5586, Validation Loss: 0.5564\n",
      "Epoch 282/1000 - Train Loss: 0.5582, Validation Loss: 0.5560\n",
      "Epoch 283/1000 - Train Loss: 0.5578, Validation Loss: 0.5557\n",
      "Epoch 284/1000 - Train Loss: 0.5574, Validation Loss: 0.5553\n",
      "Epoch 285/1000 - Train Loss: 0.5571, Validation Loss: 0.5549\n",
      "Epoch 286/1000 - Train Loss: 0.5567, Validation Loss: 0.5545\n",
      "Epoch 287/1000 - Train Loss: 0.5563, Validation Loss: 0.5541\n",
      "Epoch 288/1000 - Train Loss: 0.5559, Validation Loss: 0.5537\n",
      "Epoch 289/1000 - Train Loss: 0.5555, Validation Loss: 0.5534\n",
      "Epoch 290/1000 - Train Loss: 0.5551, Validation Loss: 0.5530\n",
      "Epoch 291/1000 - Train Loss: 0.5548, Validation Loss: 0.5526\n",
      "Epoch 292/1000 - Train Loss: 0.5544, Validation Loss: 0.5522\n",
      "Epoch 293/1000 - Train Loss: 0.5540, Validation Loss: 0.5518\n",
      "Epoch 294/1000 - Train Loss: 0.5536, Validation Loss: 0.5514\n",
      "Epoch 295/1000 - Train Loss: 0.5532, Validation Loss: 0.5511\n",
      "Epoch 296/1000 - Train Loss: 0.5529, Validation Loss: 0.5507\n",
      "Epoch 297/1000 - Train Loss: 0.5525, Validation Loss: 0.5503\n",
      "Epoch 298/1000 - Train Loss: 0.5521, Validation Loss: 0.5499\n",
      "Epoch 299/1000 - Train Loss: 0.5517, Validation Loss: 0.5496\n",
      "Epoch 300/1000 - Train Loss: 0.5513, Validation Loss: 0.5492\n",
      "Epoch 301/1000 - Train Loss: 0.5510, Validation Loss: 0.5488\n",
      "Epoch 302/1000 - Train Loss: 0.5506, Validation Loss: 0.5484\n",
      "Epoch 303/1000 - Train Loss: 0.5502, Validation Loss: 0.5480\n",
      "Epoch 304/1000 - Train Loss: 0.5498, Validation Loss: 0.5477\n",
      "Epoch 305/1000 - Train Loss: 0.5495, Validation Loss: 0.5473\n",
      "Epoch 306/1000 - Train Loss: 0.5491, Validation Loss: 0.5469\n",
      "Epoch 307/1000 - Train Loss: 0.5487, Validation Loss: 0.5465\n",
      "Epoch 308/1000 - Train Loss: 0.5483, Validation Loss: 0.5462\n",
      "Epoch 309/1000 - Train Loss: 0.5480, Validation Loss: 0.5458\n",
      "Epoch 310/1000 - Train Loss: 0.5476, Validation Loss: 0.5454\n",
      "Epoch 311/1000 - Train Loss: 0.5472, Validation Loss: 0.5451\n",
      "Epoch 312/1000 - Train Loss: 0.5469, Validation Loss: 0.5447\n",
      "Epoch 313/1000 - Train Loss: 0.5465, Validation Loss: 0.5443\n",
      "Epoch 314/1000 - Train Loss: 0.5461, Validation Loss: 0.5439\n",
      "Epoch 315/1000 - Train Loss: 0.5457, Validation Loss: 0.5436\n",
      "Epoch 316/1000 - Train Loss: 0.5454, Validation Loss: 0.5432\n",
      "Epoch 317/1000 - Train Loss: 0.5450, Validation Loss: 0.5428\n",
      "Epoch 318/1000 - Train Loss: 0.5446, Validation Loss: 0.5425\n",
      "Epoch 319/1000 - Train Loss: 0.5443, Validation Loss: 0.5421\n",
      "Epoch 320/1000 - Train Loss: 0.5439, Validation Loss: 0.5417\n",
      "Epoch 321/1000 - Train Loss: 0.5435, Validation Loss: 0.5414\n",
      "Epoch 322/1000 - Train Loss: 0.5432, Validation Loss: 0.5410\n",
      "Epoch 323/1000 - Train Loss: 0.5428, Validation Loss: 0.5406\n",
      "Epoch 324/1000 - Train Loss: 0.5424, Validation Loss: 0.5402\n",
      "Epoch 325/1000 - Train Loss: 0.5421, Validation Loss: 0.5399\n",
      "Epoch 326/1000 - Train Loss: 0.5417, Validation Loss: 0.5395\n",
      "Epoch 327/1000 - Train Loss: 0.5413, Validation Loss: 0.5392\n",
      "Epoch 328/1000 - Train Loss: 0.5410, Validation Loss: 0.5388\n",
      "Epoch 329/1000 - Train Loss: 0.5406, Validation Loss: 0.5384\n",
      "Epoch 330/1000 - Train Loss: 0.5402, Validation Loss: 0.5381\n",
      "Epoch 331/1000 - Train Loss: 0.5399, Validation Loss: 0.5377\n",
      "Epoch 332/1000 - Train Loss: 0.5395, Validation Loss: 0.5373\n",
      "Epoch 333/1000 - Train Loss: 0.5391, Validation Loss: 0.5370\n",
      "Epoch 334/1000 - Train Loss: 0.5388, Validation Loss: 0.5366\n",
      "Epoch 335/1000 - Train Loss: 0.5384, Validation Loss: 0.5362\n",
      "Epoch 336/1000 - Train Loss: 0.5381, Validation Loss: 0.5359\n",
      "Epoch 337/1000 - Train Loss: 0.5377, Validation Loss: 0.5355\n",
      "Epoch 338/1000 - Train Loss: 0.5373, Validation Loss: 0.5352\n",
      "Epoch 339/1000 - Train Loss: 0.5370, Validation Loss: 0.5348\n",
      "Epoch 340/1000 - Train Loss: 0.5366, Validation Loss: 0.5344\n",
      "Epoch 341/1000 - Train Loss: 0.5363, Validation Loss: 0.5341\n",
      "Epoch 342/1000 - Train Loss: 0.5359, Validation Loss: 0.5337\n",
      "Epoch 343/1000 - Train Loss: 0.5355, Validation Loss: 0.5334\n",
      "Epoch 344/1000 - Train Loss: 0.5352, Validation Loss: 0.5330\n",
      "Epoch 345/1000 - Train Loss: 0.5348, Validation Loss: 0.5326\n",
      "Epoch 346/1000 - Train Loss: 0.5345, Validation Loss: 0.5323\n",
      "Epoch 347/1000 - Train Loss: 0.5341, Validation Loss: 0.5319\n",
      "Epoch 348/1000 - Train Loss: 0.5338, Validation Loss: 0.5316\n",
      "Epoch 349/1000 - Train Loss: 0.5334, Validation Loss: 0.5312\n",
      "Epoch 350/1000 - Train Loss: 0.5330, Validation Loss: 0.5309\n",
      "Epoch 351/1000 - Train Loss: 0.5327, Validation Loss: 0.5305\n",
      "Epoch 352/1000 - Train Loss: 0.5323, Validation Loss: 0.5302\n",
      "Epoch 353/1000 - Train Loss: 0.5320, Validation Loss: 0.5298\n",
      "Epoch 354/1000 - Train Loss: 0.5316, Validation Loss: 0.5295\n",
      "Epoch 355/1000 - Train Loss: 0.5313, Validation Loss: 0.5291\n",
      "Epoch 356/1000 - Train Loss: 0.5309, Validation Loss: 0.5287\n",
      "Epoch 357/1000 - Train Loss: 0.5306, Validation Loss: 0.5284\n",
      "Epoch 358/1000 - Train Loss: 0.5302, Validation Loss: 0.5280\n",
      "Epoch 359/1000 - Train Loss: 0.5299, Validation Loss: 0.5277\n",
      "Epoch 360/1000 - Train Loss: 0.5295, Validation Loss: 0.5273\n",
      "Epoch 361/1000 - Train Loss: 0.5292, Validation Loss: 0.5270\n",
      "Epoch 362/1000 - Train Loss: 0.5288, Validation Loss: 0.5266\n",
      "Epoch 363/1000 - Train Loss: 0.5285, Validation Loss: 0.5263\n",
      "Epoch 364/1000 - Train Loss: 0.5281, Validation Loss: 0.5259\n",
      "Epoch 365/1000 - Train Loss: 0.5278, Validation Loss: 0.5256\n",
      "Epoch 366/1000 - Train Loss: 0.5274, Validation Loss: 0.5252\n",
      "Epoch 367/1000 - Train Loss: 0.5271, Validation Loss: 0.5249\n",
      "Epoch 368/1000 - Train Loss: 0.5267, Validation Loss: 0.5245\n",
      "Epoch 369/1000 - Train Loss: 0.5264, Validation Loss: 0.5242\n",
      "Epoch 370/1000 - Train Loss: 0.5260, Validation Loss: 0.5238\n",
      "Epoch 371/1000 - Train Loss: 0.5257, Validation Loss: 0.5235\n",
      "Epoch 372/1000 - Train Loss: 0.5253, Validation Loss: 0.5232\n",
      "Epoch 373/1000 - Train Loss: 0.5250, Validation Loss: 0.5228\n",
      "Epoch 374/1000 - Train Loss: 0.5246, Validation Loss: 0.5225\n",
      "Epoch 375/1000 - Train Loss: 0.5243, Validation Loss: 0.5221\n",
      "Epoch 376/1000 - Train Loss: 0.5239, Validation Loss: 0.5218\n",
      "Epoch 377/1000 - Train Loss: 0.5236, Validation Loss: 0.5214\n",
      "Epoch 378/1000 - Train Loss: 0.5233, Validation Loss: 0.5211\n",
      "Epoch 379/1000 - Train Loss: 0.5229, Validation Loss: 0.5207\n",
      "Epoch 380/1000 - Train Loss: 0.5226, Validation Loss: 0.5204\n",
      "Epoch 381/1000 - Train Loss: 0.5222, Validation Loss: 0.5201\n",
      "Epoch 382/1000 - Train Loss: 0.5219, Validation Loss: 0.5197\n",
      "Epoch 383/1000 - Train Loss: 0.5215, Validation Loss: 0.5194\n",
      "Epoch 384/1000 - Train Loss: 0.5212, Validation Loss: 0.5190\n",
      "Epoch 385/1000 - Train Loss: 0.5209, Validation Loss: 0.5187\n",
      "Epoch 386/1000 - Train Loss: 0.5205, Validation Loss: 0.5184\n",
      "Epoch 387/1000 - Train Loss: 0.5202, Validation Loss: 0.5180\n",
      "Epoch 388/1000 - Train Loss: 0.5198, Validation Loss: 0.5177\n",
      "Epoch 389/1000 - Train Loss: 0.5195, Validation Loss: 0.5173\n",
      "Epoch 390/1000 - Train Loss: 0.5192, Validation Loss: 0.5170\n",
      "Epoch 391/1000 - Train Loss: 0.5188, Validation Loss: 0.5167\n",
      "Epoch 392/1000 - Train Loss: 0.5185, Validation Loss: 0.5163\n",
      "Epoch 393/1000 - Train Loss: 0.5181, Validation Loss: 0.5160\n",
      "Epoch 394/1000 - Train Loss: 0.5178, Validation Loss: 0.5156\n",
      "Epoch 395/1000 - Train Loss: 0.5175, Validation Loss: 0.5153\n",
      "Epoch 396/1000 - Train Loss: 0.5171, Validation Loss: 0.5150\n",
      "Epoch 397/1000 - Train Loss: 0.5168, Validation Loss: 0.5146\n",
      "Epoch 398/1000 - Train Loss: 0.5165, Validation Loss: 0.5143\n",
      "Epoch 399/1000 - Train Loss: 0.5161, Validation Loss: 0.5140\n",
      "Epoch 400/1000 - Train Loss: 0.5158, Validation Loss: 0.5136\n",
      "Epoch 401/1000 - Train Loss: 0.5154, Validation Loss: 0.5133\n",
      "Epoch 402/1000 - Train Loss: 0.5151, Validation Loss: 0.5130\n",
      "Epoch 403/1000 - Train Loss: 0.5148, Validation Loss: 0.5126\n",
      "Epoch 404/1000 - Train Loss: 0.5144, Validation Loss: 0.5123\n",
      "Epoch 405/1000 - Train Loss: 0.5141, Validation Loss: 0.5120\n",
      "Epoch 406/1000 - Train Loss: 0.5138, Validation Loss: 0.5116\n",
      "Epoch 407/1000 - Train Loss: 0.5134, Validation Loss: 0.5113\n",
      "Epoch 408/1000 - Train Loss: 0.5131, Validation Loss: 0.5110\n",
      "Epoch 409/1000 - Train Loss: 0.5128, Validation Loss: 0.5106\n",
      "Epoch 410/1000 - Train Loss: 0.5124, Validation Loss: 0.5103\n",
      "Epoch 411/1000 - Train Loss: 0.5121, Validation Loss: 0.5100\n",
      "Epoch 412/1000 - Train Loss: 0.5118, Validation Loss: 0.5096\n",
      "Epoch 413/1000 - Train Loss: 0.5115, Validation Loss: 0.5093\n",
      "Epoch 414/1000 - Train Loss: 0.5111, Validation Loss: 0.5090\n",
      "Epoch 415/1000 - Train Loss: 0.5108, Validation Loss: 0.5086\n",
      "Epoch 416/1000 - Train Loss: 0.5105, Validation Loss: 0.5083\n",
      "Epoch 417/1000 - Train Loss: 0.5101, Validation Loss: 0.5080\n",
      "Epoch 418/1000 - Train Loss: 0.5098, Validation Loss: 0.5077\n",
      "Epoch 419/1000 - Train Loss: 0.5095, Validation Loss: 0.5073\n",
      "Epoch 420/1000 - Train Loss: 0.5092, Validation Loss: 0.5070\n",
      "Epoch 421/1000 - Train Loss: 0.5088, Validation Loss: 0.5067\n",
      "Epoch 422/1000 - Train Loss: 0.5085, Validation Loss: 0.5064\n",
      "Epoch 423/1000 - Train Loss: 0.5082, Validation Loss: 0.5060\n",
      "Epoch 424/1000 - Train Loss: 0.5078, Validation Loss: 0.5057\n",
      "Epoch 425/1000 - Train Loss: 0.5075, Validation Loss: 0.5054\n",
      "Epoch 426/1000 - Train Loss: 0.5072, Validation Loss: 0.5050\n",
      "Epoch 427/1000 - Train Loss: 0.5069, Validation Loss: 0.5047\n",
      "Epoch 428/1000 - Train Loss: 0.5065, Validation Loss: 0.5044\n",
      "Epoch 429/1000 - Train Loss: 0.5062, Validation Loss: 0.5041\n",
      "Epoch 430/1000 - Train Loss: 0.5059, Validation Loss: 0.5038\n",
      "Epoch 431/1000 - Train Loss: 0.5056, Validation Loss: 0.5034\n",
      "Epoch 432/1000 - Train Loss: 0.5052, Validation Loss: 0.5031\n",
      "Epoch 433/1000 - Train Loss: 0.5049, Validation Loss: 0.5028\n",
      "Epoch 434/1000 - Train Loss: 0.5046, Validation Loss: 0.5025\n",
      "Epoch 435/1000 - Train Loss: 0.5043, Validation Loss: 0.5021\n",
      "Epoch 436/1000 - Train Loss: 0.5040, Validation Loss: 0.5018\n",
      "Epoch 437/1000 - Train Loss: 0.5036, Validation Loss: 0.5015\n",
      "Epoch 438/1000 - Train Loss: 0.5033, Validation Loss: 0.5012\n",
      "Epoch 439/1000 - Train Loss: 0.5030, Validation Loss: 0.5009\n",
      "Epoch 440/1000 - Train Loss: 0.5027, Validation Loss: 0.5005\n",
      "Epoch 441/1000 - Train Loss: 0.5024, Validation Loss: 0.5002\n",
      "Epoch 442/1000 - Train Loss: 0.5020, Validation Loss: 0.4999\n",
      "Epoch 443/1000 - Train Loss: 0.5017, Validation Loss: 0.4996\n",
      "Epoch 444/1000 - Train Loss: 0.5014, Validation Loss: 0.4993\n",
      "Epoch 445/1000 - Train Loss: 0.5011, Validation Loss: 0.4989\n",
      "Epoch 446/1000 - Train Loss: 0.5008, Validation Loss: 0.4986\n",
      "Epoch 447/1000 - Train Loss: 0.5004, Validation Loss: 0.4983\n",
      "Epoch 448/1000 - Train Loss: 0.5001, Validation Loss: 0.4980\n",
      "Epoch 449/1000 - Train Loss: 0.4998, Validation Loss: 0.4977\n",
      "Epoch 450/1000 - Train Loss: 0.4995, Validation Loss: 0.4974\n",
      "Epoch 451/1000 - Train Loss: 0.4992, Validation Loss: 0.4970\n",
      "Epoch 452/1000 - Train Loss: 0.4989, Validation Loss: 0.4967\n",
      "Epoch 453/1000 - Train Loss: 0.4985, Validation Loss: 0.4964\n",
      "Epoch 454/1000 - Train Loss: 0.4982, Validation Loss: 0.4961\n",
      "Epoch 455/1000 - Train Loss: 0.4979, Validation Loss: 0.4958\n",
      "Epoch 456/1000 - Train Loss: 0.4976, Validation Loss: 0.4955\n",
      "Epoch 457/1000 - Train Loss: 0.4973, Validation Loss: 0.4952\n",
      "Epoch 458/1000 - Train Loss: 0.4970, Validation Loss: 0.4948\n",
      "Epoch 459/1000 - Train Loss: 0.4967, Validation Loss: 0.4945\n",
      "Epoch 460/1000 - Train Loss: 0.4963, Validation Loss: 0.4942\n",
      "Epoch 461/1000 - Train Loss: 0.4960, Validation Loss: 0.4939\n",
      "Epoch 462/1000 - Train Loss: 0.4957, Validation Loss: 0.4936\n",
      "Epoch 463/1000 - Train Loss: 0.4954, Validation Loss: 0.4933\n",
      "Epoch 464/1000 - Train Loss: 0.4951, Validation Loss: 0.4930\n",
      "Epoch 465/1000 - Train Loss: 0.4948, Validation Loss: 0.4927\n",
      "Epoch 466/1000 - Train Loss: 0.4945, Validation Loss: 0.4923\n",
      "Epoch 467/1000 - Train Loss: 0.4942, Validation Loss: 0.4920\n",
      "Epoch 468/1000 - Train Loss: 0.4938, Validation Loss: 0.4917\n",
      "Epoch 469/1000 - Train Loss: 0.4935, Validation Loss: 0.4914\n",
      "Epoch 470/1000 - Train Loss: 0.4932, Validation Loss: 0.4911\n",
      "Epoch 471/1000 - Train Loss: 0.4929, Validation Loss: 0.4908\n",
      "Epoch 472/1000 - Train Loss: 0.4926, Validation Loss: 0.4905\n",
      "Epoch 473/1000 - Train Loss: 0.4923, Validation Loss: 0.4902\n",
      "Epoch 474/1000 - Train Loss: 0.4920, Validation Loss: 0.4899\n",
      "Epoch 475/1000 - Train Loss: 0.4917, Validation Loss: 0.4896\n",
      "Epoch 476/1000 - Train Loss: 0.4914, Validation Loss: 0.4893\n",
      "Epoch 477/1000 - Train Loss: 0.4911, Validation Loss: 0.4890\n",
      "Epoch 478/1000 - Train Loss: 0.4908, Validation Loss: 0.4886\n",
      "Epoch 479/1000 - Train Loss: 0.4905, Validation Loss: 0.4883\n",
      "Epoch 480/1000 - Train Loss: 0.4902, Validation Loss: 0.4880\n",
      "Epoch 481/1000 - Train Loss: 0.4898, Validation Loss: 0.4877\n",
      "Epoch 482/1000 - Train Loss: 0.4895, Validation Loss: 0.4874\n",
      "Epoch 483/1000 - Train Loss: 0.4892, Validation Loss: 0.4871\n",
      "Epoch 484/1000 - Train Loss: 0.4889, Validation Loss: 0.4868\n",
      "Epoch 485/1000 - Train Loss: 0.4886, Validation Loss: 0.4865\n",
      "Epoch 486/1000 - Train Loss: 0.4883, Validation Loss: 0.4862\n",
      "Epoch 487/1000 - Train Loss: 0.4880, Validation Loss: 0.4859\n",
      "Epoch 488/1000 - Train Loss: 0.4877, Validation Loss: 0.4856\n",
      "Epoch 489/1000 - Train Loss: 0.4874, Validation Loss: 0.4853\n",
      "Epoch 490/1000 - Train Loss: 0.4871, Validation Loss: 0.4850\n",
      "Epoch 491/1000 - Train Loss: 0.4868, Validation Loss: 0.4847\n",
      "Epoch 492/1000 - Train Loss: 0.4865, Validation Loss: 0.4844\n",
      "Epoch 493/1000 - Train Loss: 0.4862, Validation Loss: 0.4841\n",
      "Epoch 494/1000 - Train Loss: 0.4859, Validation Loss: 0.4838\n",
      "Epoch 495/1000 - Train Loss: 0.4856, Validation Loss: 0.4835\n",
      "Epoch 496/1000 - Train Loss: 0.4853, Validation Loss: 0.4832\n",
      "Epoch 497/1000 - Train Loss: 0.4850, Validation Loss: 0.4829\n",
      "Epoch 498/1000 - Train Loss: 0.4847, Validation Loss: 0.4826\n",
      "Epoch 499/1000 - Train Loss: 0.4844, Validation Loss: 0.4823\n",
      "Epoch 500/1000 - Train Loss: 0.4841, Validation Loss: 0.4820\n",
      "Epoch 501/1000 - Train Loss: 0.4838, Validation Loss: 0.4817\n",
      "Epoch 502/1000 - Train Loss: 0.4835, Validation Loss: 0.4814\n",
      "Epoch 503/1000 - Train Loss: 0.4832, Validation Loss: 0.4811\n",
      "Epoch 504/1000 - Train Loss: 0.4829, Validation Loss: 0.4808\n",
      "Epoch 505/1000 - Train Loss: 0.4826, Validation Loss: 0.4805\n",
      "Epoch 506/1000 - Train Loss: 0.4823, Validation Loss: 0.4802\n",
      "Epoch 507/1000 - Train Loss: 0.4820, Validation Loss: 0.4799\n",
      "Epoch 508/1000 - Train Loss: 0.4817, Validation Loss: 0.4796\n",
      "Epoch 509/1000 - Train Loss: 0.4814, Validation Loss: 0.4793\n",
      "Epoch 510/1000 - Train Loss: 0.4811, Validation Loss: 0.4790\n",
      "Epoch 511/1000 - Train Loss: 0.4808, Validation Loss: 0.4787\n",
      "Epoch 512/1000 - Train Loss: 0.4805, Validation Loss: 0.4784\n",
      "Epoch 513/1000 - Train Loss: 0.4802, Validation Loss: 0.4781\n",
      "Epoch 514/1000 - Train Loss: 0.4799, Validation Loss: 0.4778\n",
      "Epoch 515/1000 - Train Loss: 0.4796, Validation Loss: 0.4776\n",
      "Epoch 516/1000 - Train Loss: 0.4794, Validation Loss: 0.4773\n",
      "Epoch 517/1000 - Train Loss: 0.4791, Validation Loss: 0.4770\n",
      "Epoch 518/1000 - Train Loss: 0.4788, Validation Loss: 0.4767\n",
      "Epoch 519/1000 - Train Loss: 0.4785, Validation Loss: 0.4764\n",
      "Epoch 520/1000 - Train Loss: 0.4782, Validation Loss: 0.4761\n",
      "Epoch 521/1000 - Train Loss: 0.4779, Validation Loss: 0.4758\n",
      "Epoch 522/1000 - Train Loss: 0.4776, Validation Loss: 0.4755\n",
      "Epoch 523/1000 - Train Loss: 0.4773, Validation Loss: 0.4752\n",
      "Epoch 524/1000 - Train Loss: 0.4770, Validation Loss: 0.4749\n",
      "Epoch 525/1000 - Train Loss: 0.4767, Validation Loss: 0.4746\n",
      "Epoch 526/1000 - Train Loss: 0.4764, Validation Loss: 0.4743\n",
      "Epoch 527/1000 - Train Loss: 0.4761, Validation Loss: 0.4741\n",
      "Epoch 528/1000 - Train Loss: 0.4759, Validation Loss: 0.4738\n",
      "Epoch 529/1000 - Train Loss: 0.4756, Validation Loss: 0.4735\n",
      "Epoch 530/1000 - Train Loss: 0.4753, Validation Loss: 0.4732\n",
      "Epoch 531/1000 - Train Loss: 0.4750, Validation Loss: 0.4729\n",
      "Epoch 532/1000 - Train Loss: 0.4747, Validation Loss: 0.4726\n",
      "Epoch 533/1000 - Train Loss: 0.4744, Validation Loss: 0.4723\n",
      "Epoch 534/1000 - Train Loss: 0.4741, Validation Loss: 0.4720\n",
      "Epoch 535/1000 - Train Loss: 0.4738, Validation Loss: 0.4717\n",
      "Epoch 536/1000 - Train Loss: 0.4735, Validation Loss: 0.4715\n",
      "Epoch 537/1000 - Train Loss: 0.4733, Validation Loss: 0.4712\n",
      "Epoch 538/1000 - Train Loss: 0.4730, Validation Loss: 0.4709\n",
      "Epoch 539/1000 - Train Loss: 0.4727, Validation Loss: 0.4706\n",
      "Epoch 540/1000 - Train Loss: 0.4724, Validation Loss: 0.4703\n",
      "Epoch 541/1000 - Train Loss: 0.4721, Validation Loss: 0.4700\n",
      "Epoch 542/1000 - Train Loss: 0.4718, Validation Loss: 0.4697\n",
      "Epoch 543/1000 - Train Loss: 0.4715, Validation Loss: 0.4695\n",
      "Epoch 544/1000 - Train Loss: 0.4713, Validation Loss: 0.4692\n",
      "Epoch 545/1000 - Train Loss: 0.4710, Validation Loss: 0.4689\n",
      "Epoch 546/1000 - Train Loss: 0.4707, Validation Loss: 0.4686\n",
      "Epoch 547/1000 - Train Loss: 0.4704, Validation Loss: 0.4683\n",
      "Epoch 548/1000 - Train Loss: 0.4701, Validation Loss: 0.4680\n",
      "Epoch 549/1000 - Train Loss: 0.4698, Validation Loss: 0.4678\n",
      "Epoch 550/1000 - Train Loss: 0.4696, Validation Loss: 0.4675\n",
      "Epoch 551/1000 - Train Loss: 0.4693, Validation Loss: 0.4672\n",
      "Epoch 552/1000 - Train Loss: 0.4690, Validation Loss: 0.4669\n",
      "Epoch 553/1000 - Train Loss: 0.4687, Validation Loss: 0.4666\n",
      "Epoch 554/1000 - Train Loss: 0.4684, Validation Loss: 0.4663\n",
      "Epoch 555/1000 - Train Loss: 0.4681, Validation Loss: 0.4661\n",
      "Epoch 556/1000 - Train Loss: 0.4679, Validation Loss: 0.4658\n",
      "Epoch 557/1000 - Train Loss: 0.4676, Validation Loss: 0.4655\n",
      "Epoch 558/1000 - Train Loss: 0.4673, Validation Loss: 0.4652\n",
      "Epoch 559/1000 - Train Loss: 0.4670, Validation Loss: 0.4649\n",
      "Epoch 560/1000 - Train Loss: 0.4667, Validation Loss: 0.4647\n",
      "Epoch 561/1000 - Train Loss: 0.4665, Validation Loss: 0.4644\n",
      "Epoch 562/1000 - Train Loss: 0.4662, Validation Loss: 0.4641\n",
      "Epoch 563/1000 - Train Loss: 0.4659, Validation Loss: 0.4638\n",
      "Epoch 564/1000 - Train Loss: 0.4656, Validation Loss: 0.4636\n",
      "Epoch 565/1000 - Train Loss: 0.4653, Validation Loss: 0.4633\n",
      "Epoch 566/1000 - Train Loss: 0.4651, Validation Loss: 0.4630\n",
      "Epoch 567/1000 - Train Loss: 0.4648, Validation Loss: 0.4627\n",
      "Epoch 568/1000 - Train Loss: 0.4645, Validation Loss: 0.4624\n",
      "Epoch 569/1000 - Train Loss: 0.4642, Validation Loss: 0.4622\n",
      "Epoch 570/1000 - Train Loss: 0.4640, Validation Loss: 0.4619\n",
      "Epoch 571/1000 - Train Loss: 0.4637, Validation Loss: 0.4616\n",
      "Epoch 572/1000 - Train Loss: 0.4634, Validation Loss: 0.4613\n",
      "Epoch 573/1000 - Train Loss: 0.4631, Validation Loss: 0.4611\n",
      "Epoch 574/1000 - Train Loss: 0.4628, Validation Loss: 0.4608\n",
      "Epoch 575/1000 - Train Loss: 0.4626, Validation Loss: 0.4605\n",
      "Epoch 576/1000 - Train Loss: 0.4623, Validation Loss: 0.4602\n",
      "Epoch 577/1000 - Train Loss: 0.4620, Validation Loss: 0.4600\n",
      "Epoch 578/1000 - Train Loss: 0.4617, Validation Loss: 0.4597\n",
      "Epoch 579/1000 - Train Loss: 0.4615, Validation Loss: 0.4594\n",
      "Epoch 580/1000 - Train Loss: 0.4612, Validation Loss: 0.4591\n",
      "Epoch 581/1000 - Train Loss: 0.4609, Validation Loss: 0.4589\n",
      "Epoch 582/1000 - Train Loss: 0.4607, Validation Loss: 0.4586\n",
      "Epoch 583/1000 - Train Loss: 0.4604, Validation Loss: 0.4583\n",
      "Epoch 584/1000 - Train Loss: 0.4601, Validation Loss: 0.4581\n",
      "Epoch 585/1000 - Train Loss: 0.4598, Validation Loss: 0.4578\n",
      "Epoch 586/1000 - Train Loss: 0.4596, Validation Loss: 0.4575\n",
      "Epoch 587/1000 - Train Loss: 0.4593, Validation Loss: 0.4572\n",
      "Epoch 588/1000 - Train Loss: 0.4590, Validation Loss: 0.4570\n",
      "Epoch 589/1000 - Train Loss: 0.4587, Validation Loss: 0.4567\n",
      "Epoch 590/1000 - Train Loss: 0.4585, Validation Loss: 0.4564\n",
      "Epoch 591/1000 - Train Loss: 0.4582, Validation Loss: 0.4562\n",
      "Epoch 592/1000 - Train Loss: 0.4579, Validation Loss: 0.4559\n",
      "Epoch 593/1000 - Train Loss: 0.4577, Validation Loss: 0.4556\n",
      "Epoch 594/1000 - Train Loss: 0.4574, Validation Loss: 0.4553\n",
      "Epoch 595/1000 - Train Loss: 0.4571, Validation Loss: 0.4551\n",
      "Epoch 596/1000 - Train Loss: 0.4569, Validation Loss: 0.4548\n",
      "Epoch 597/1000 - Train Loss: 0.4566, Validation Loss: 0.4545\n",
      "Epoch 598/1000 - Train Loss: 0.4563, Validation Loss: 0.4543\n",
      "Epoch 599/1000 - Train Loss: 0.4561, Validation Loss: 0.4540\n",
      "Epoch 600/1000 - Train Loss: 0.4558, Validation Loss: 0.4537\n",
      "Epoch 601/1000 - Train Loss: 0.4555, Validation Loss: 0.4535\n",
      "Epoch 602/1000 - Train Loss: 0.4552, Validation Loss: 0.4532\n",
      "Epoch 603/1000 - Train Loss: 0.4550, Validation Loss: 0.4529\n",
      "Epoch 604/1000 - Train Loss: 0.4547, Validation Loss: 0.4527\n",
      "Epoch 605/1000 - Train Loss: 0.4544, Validation Loss: 0.4524\n",
      "Epoch 606/1000 - Train Loss: 0.4542, Validation Loss: 0.4521\n",
      "Epoch 607/1000 - Train Loss: 0.4539, Validation Loss: 0.4519\n",
      "Epoch 608/1000 - Train Loss: 0.4536, Validation Loss: 0.4516\n",
      "Epoch 609/1000 - Train Loss: 0.4534, Validation Loss: 0.4513\n",
      "Epoch 610/1000 - Train Loss: 0.4531, Validation Loss: 0.4511\n",
      "Epoch 611/1000 - Train Loss: 0.4529, Validation Loss: 0.4508\n",
      "Epoch 612/1000 - Train Loss: 0.4526, Validation Loss: 0.4506\n",
      "Epoch 613/1000 - Train Loss: 0.4523, Validation Loss: 0.4503\n",
      "Epoch 614/1000 - Train Loss: 0.4521, Validation Loss: 0.4500\n",
      "Epoch 615/1000 - Train Loss: 0.4518, Validation Loss: 0.4498\n",
      "Epoch 616/1000 - Train Loss: 0.4515, Validation Loss: 0.4495\n",
      "Epoch 617/1000 - Train Loss: 0.4513, Validation Loss: 0.4492\n",
      "Epoch 618/1000 - Train Loss: 0.4510, Validation Loss: 0.4490\n",
      "Epoch 619/1000 - Train Loss: 0.4507, Validation Loss: 0.4487\n",
      "Epoch 620/1000 - Train Loss: 0.4505, Validation Loss: 0.4484\n",
      "Epoch 621/1000 - Train Loss: 0.4502, Validation Loss: 0.4482\n",
      "Epoch 622/1000 - Train Loss: 0.4500, Validation Loss: 0.4479\n",
      "Epoch 623/1000 - Train Loss: 0.4497, Validation Loss: 0.4477\n",
      "Epoch 624/1000 - Train Loss: 0.4494, Validation Loss: 0.4474\n",
      "Epoch 625/1000 - Train Loss: 0.4492, Validation Loss: 0.4471\n",
      "Epoch 626/1000 - Train Loss: 0.4489, Validation Loss: 0.4469\n",
      "Epoch 627/1000 - Train Loss: 0.4487, Validation Loss: 0.4466\n",
      "Epoch 628/1000 - Train Loss: 0.4484, Validation Loss: 0.4464\n",
      "Epoch 629/1000 - Train Loss: 0.4481, Validation Loss: 0.4461\n",
      "Epoch 630/1000 - Train Loss: 0.4479, Validation Loss: 0.4458\n",
      "Epoch 631/1000 - Train Loss: 0.4476, Validation Loss: 0.4456\n",
      "Epoch 632/1000 - Train Loss: 0.4474, Validation Loss: 0.4453\n",
      "Epoch 633/1000 - Train Loss: 0.4471, Validation Loss: 0.4451\n",
      "Epoch 634/1000 - Train Loss: 0.4468, Validation Loss: 0.4448\n",
      "Epoch 635/1000 - Train Loss: 0.4466, Validation Loss: 0.4446\n",
      "Epoch 636/1000 - Train Loss: 0.4463, Validation Loss: 0.4443\n",
      "Epoch 637/1000 - Train Loss: 0.4461, Validation Loss: 0.4440\n",
      "Epoch 638/1000 - Train Loss: 0.4458, Validation Loss: 0.4438\n",
      "Epoch 639/1000 - Train Loss: 0.4456, Validation Loss: 0.4435\n",
      "Epoch 640/1000 - Train Loss: 0.4453, Validation Loss: 0.4433\n",
      "Epoch 641/1000 - Train Loss: 0.4450, Validation Loss: 0.4430\n",
      "Epoch 642/1000 - Train Loss: 0.4448, Validation Loss: 0.4428\n",
      "Epoch 643/1000 - Train Loss: 0.4445, Validation Loss: 0.4425\n",
      "Epoch 644/1000 - Train Loss: 0.4443, Validation Loss: 0.4423\n",
      "Epoch 645/1000 - Train Loss: 0.4440, Validation Loss: 0.4420\n",
      "Epoch 646/1000 - Train Loss: 0.4438, Validation Loss: 0.4417\n",
      "Epoch 647/1000 - Train Loss: 0.4435, Validation Loss: 0.4415\n",
      "Epoch 648/1000 - Train Loss: 0.4433, Validation Loss: 0.4412\n",
      "Epoch 649/1000 - Train Loss: 0.4430, Validation Loss: 0.4410\n",
      "Epoch 650/1000 - Train Loss: 0.4427, Validation Loss: 0.4407\n",
      "Epoch 651/1000 - Train Loss: 0.4425, Validation Loss: 0.4405\n",
      "Epoch 652/1000 - Train Loss: 0.4422, Validation Loss: 0.4402\n",
      "Epoch 653/1000 - Train Loss: 0.4420, Validation Loss: 0.4400\n",
      "Epoch 654/1000 - Train Loss: 0.4417, Validation Loss: 0.4397\n",
      "Epoch 655/1000 - Train Loss: 0.4415, Validation Loss: 0.4395\n",
      "Epoch 656/1000 - Train Loss: 0.4412, Validation Loss: 0.4392\n",
      "Epoch 657/1000 - Train Loss: 0.4410, Validation Loss: 0.4390\n",
      "Epoch 658/1000 - Train Loss: 0.4407, Validation Loss: 0.4387\n",
      "Epoch 659/1000 - Train Loss: 0.4405, Validation Loss: 0.4385\n",
      "Epoch 660/1000 - Train Loss: 0.4402, Validation Loss: 0.4382\n",
      "Epoch 661/1000 - Train Loss: 0.4400, Validation Loss: 0.4380\n",
      "Epoch 662/1000 - Train Loss: 0.4397, Validation Loss: 0.4377\n",
      "Epoch 663/1000 - Train Loss: 0.4395, Validation Loss: 0.4375\n",
      "Epoch 664/1000 - Train Loss: 0.4392, Validation Loss: 0.4372\n",
      "Epoch 665/1000 - Train Loss: 0.4390, Validation Loss: 0.4370\n",
      "Epoch 666/1000 - Train Loss: 0.4387, Validation Loss: 0.4367\n",
      "Epoch 667/1000 - Train Loss: 0.4385, Validation Loss: 0.4365\n",
      "Epoch 668/1000 - Train Loss: 0.4382, Validation Loss: 0.4362\n",
      "Epoch 669/1000 - Train Loss: 0.4380, Validation Loss: 0.4360\n",
      "Epoch 670/1000 - Train Loss: 0.4377, Validation Loss: 0.4357\n",
      "Epoch 671/1000 - Train Loss: 0.4375, Validation Loss: 0.4355\n",
      "Epoch 672/1000 - Train Loss: 0.4372, Validation Loss: 0.4352\n",
      "Epoch 673/1000 - Train Loss: 0.4370, Validation Loss: 0.4350\n",
      "Epoch 674/1000 - Train Loss: 0.4367, Validation Loss: 0.4347\n",
      "Epoch 675/1000 - Train Loss: 0.4365, Validation Loss: 0.4345\n",
      "Epoch 676/1000 - Train Loss: 0.4362, Validation Loss: 0.4342\n",
      "Epoch 677/1000 - Train Loss: 0.4360, Validation Loss: 0.4340\n",
      "Epoch 678/1000 - Train Loss: 0.4357, Validation Loss: 0.4337\n",
      "Epoch 679/1000 - Train Loss: 0.4355, Validation Loss: 0.4335\n",
      "Epoch 680/1000 - Train Loss: 0.4352, Validation Loss: 0.4333\n",
      "Epoch 681/1000 - Train Loss: 0.4350, Validation Loss: 0.4330\n",
      "Epoch 682/1000 - Train Loss: 0.4348, Validation Loss: 0.4328\n",
      "Epoch 683/1000 - Train Loss: 0.4345, Validation Loss: 0.4325\n",
      "Epoch 684/1000 - Train Loss: 0.4343, Validation Loss: 0.4323\n",
      "Epoch 685/1000 - Train Loss: 0.4340, Validation Loss: 0.4320\n",
      "Epoch 686/1000 - Train Loss: 0.4338, Validation Loss: 0.4318\n",
      "Epoch 687/1000 - Train Loss: 0.4335, Validation Loss: 0.4315\n",
      "Epoch 688/1000 - Train Loss: 0.4333, Validation Loss: 0.4313\n",
      "Epoch 689/1000 - Train Loss: 0.4330, Validation Loss: 0.4311\n",
      "Epoch 690/1000 - Train Loss: 0.4328, Validation Loss: 0.4308\n",
      "Epoch 691/1000 - Train Loss: 0.4326, Validation Loss: 0.4306\n",
      "Epoch 692/1000 - Train Loss: 0.4323, Validation Loss: 0.4303\n",
      "Epoch 693/1000 - Train Loss: 0.4321, Validation Loss: 0.4301\n",
      "Epoch 694/1000 - Train Loss: 0.4318, Validation Loss: 0.4298\n",
      "Epoch 695/1000 - Train Loss: 0.4316, Validation Loss: 0.4296\n",
      "Epoch 696/1000 - Train Loss: 0.4313, Validation Loss: 0.4294\n",
      "Epoch 697/1000 - Train Loss: 0.4311, Validation Loss: 0.4291\n",
      "Epoch 698/1000 - Train Loss: 0.4309, Validation Loss: 0.4289\n",
      "Epoch 699/1000 - Train Loss: 0.4306, Validation Loss: 0.4286\n",
      "Epoch 700/1000 - Train Loss: 0.4304, Validation Loss: 0.4284\n",
      "Epoch 701/1000 - Train Loss: 0.4301, Validation Loss: 0.4282\n",
      "Epoch 702/1000 - Train Loss: 0.4299, Validation Loss: 0.4279\n",
      "Epoch 703/1000 - Train Loss: 0.4297, Validation Loss: 0.4277\n",
      "Epoch 704/1000 - Train Loss: 0.4294, Validation Loss: 0.4274\n",
      "Epoch 705/1000 - Train Loss: 0.4292, Validation Loss: 0.4272\n",
      "Epoch 706/1000 - Train Loss: 0.4289, Validation Loss: 0.4270\n",
      "Epoch 707/1000 - Train Loss: 0.4287, Validation Loss: 0.4267\n",
      "Epoch 708/1000 - Train Loss: 0.4285, Validation Loss: 0.4265\n",
      "Epoch 709/1000 - Train Loss: 0.4282, Validation Loss: 0.4262\n",
      "Epoch 710/1000 - Train Loss: 0.4280, Validation Loss: 0.4260\n",
      "Epoch 711/1000 - Train Loss: 0.4278, Validation Loss: 0.4258\n",
      "Epoch 712/1000 - Train Loss: 0.4275, Validation Loss: 0.4255\n",
      "Epoch 713/1000 - Train Loss: 0.4273, Validation Loss: 0.4253\n",
      "Epoch 714/1000 - Train Loss: 0.4270, Validation Loss: 0.4251\n",
      "Epoch 715/1000 - Train Loss: 0.4268, Validation Loss: 0.4248\n",
      "Epoch 716/1000 - Train Loss: 0.4266, Validation Loss: 0.4246\n",
      "Epoch 717/1000 - Train Loss: 0.4263, Validation Loss: 0.4243\n",
      "Epoch 718/1000 - Train Loss: 0.4261, Validation Loss: 0.4241\n",
      "Epoch 719/1000 - Train Loss: 0.4259, Validation Loss: 0.4239\n",
      "Epoch 720/1000 - Train Loss: 0.4256, Validation Loss: 0.4236\n",
      "Epoch 721/1000 - Train Loss: 0.4254, Validation Loss: 0.4234\n",
      "Epoch 722/1000 - Train Loss: 0.4251, Validation Loss: 0.4232\n",
      "Epoch 723/1000 - Train Loss: 0.4249, Validation Loss: 0.4229\n",
      "Epoch 724/1000 - Train Loss: 0.4247, Validation Loss: 0.4227\n",
      "Epoch 725/1000 - Train Loss: 0.4244, Validation Loss: 0.4225\n",
      "Epoch 726/1000 - Train Loss: 0.4242, Validation Loss: 0.4222\n",
      "Epoch 727/1000 - Train Loss: 0.4240, Validation Loss: 0.4220\n",
      "Epoch 728/1000 - Train Loss: 0.4237, Validation Loss: 0.4218\n",
      "Epoch 729/1000 - Train Loss: 0.4235, Validation Loss: 0.4215\n",
      "Epoch 730/1000 - Train Loss: 0.4233, Validation Loss: 0.4213\n",
      "Epoch 731/1000 - Train Loss: 0.4230, Validation Loss: 0.4211\n",
      "Epoch 732/1000 - Train Loss: 0.4228, Validation Loss: 0.4208\n",
      "Epoch 733/1000 - Train Loss: 0.4226, Validation Loss: 0.4206\n",
      "Epoch 734/1000 - Train Loss: 0.4223, Validation Loss: 0.4204\n",
      "Epoch 735/1000 - Train Loss: 0.4221, Validation Loss: 0.4201\n",
      "Epoch 736/1000 - Train Loss: 0.4219, Validation Loss: 0.4199\n",
      "Epoch 737/1000 - Train Loss: 0.4216, Validation Loss: 0.4197\n",
      "Epoch 738/1000 - Train Loss: 0.4214, Validation Loss: 0.4194\n",
      "Epoch 739/1000 - Train Loss: 0.4212, Validation Loss: 0.4192\n",
      "Epoch 740/1000 - Train Loss: 0.4210, Validation Loss: 0.4190\n",
      "Epoch 741/1000 - Train Loss: 0.4207, Validation Loss: 0.4188\n",
      "Epoch 742/1000 - Train Loss: 0.4205, Validation Loss: 0.4185\n",
      "Epoch 743/1000 - Train Loss: 0.4203, Validation Loss: 0.4183\n",
      "Epoch 744/1000 - Train Loss: 0.4200, Validation Loss: 0.4181\n",
      "Epoch 745/1000 - Train Loss: 0.4198, Validation Loss: 0.4178\n",
      "Epoch 746/1000 - Train Loss: 0.4196, Validation Loss: 0.4176\n",
      "Epoch 747/1000 - Train Loss: 0.4193, Validation Loss: 0.4174\n",
      "Epoch 748/1000 - Train Loss: 0.4191, Validation Loss: 0.4172\n",
      "Epoch 749/1000 - Train Loss: 0.4189, Validation Loss: 0.4169\n",
      "Epoch 750/1000 - Train Loss: 0.4187, Validation Loss: 0.4167\n",
      "Epoch 751/1000 - Train Loss: 0.4184, Validation Loss: 0.4165\n",
      "Epoch 752/1000 - Train Loss: 0.4182, Validation Loss: 0.4162\n",
      "Epoch 753/1000 - Train Loss: 0.4180, Validation Loss: 0.4160\n",
      "Epoch 754/1000 - Train Loss: 0.4177, Validation Loss: 0.4158\n",
      "Epoch 755/1000 - Train Loss: 0.4175, Validation Loss: 0.4156\n",
      "Epoch 756/1000 - Train Loss: 0.4173, Validation Loss: 0.4153\n",
      "Epoch 757/1000 - Train Loss: 0.4171, Validation Loss: 0.4151\n",
      "Epoch 758/1000 - Train Loss: 0.4168, Validation Loss: 0.4149\n",
      "Epoch 759/1000 - Train Loss: 0.4166, Validation Loss: 0.4147\n",
      "Epoch 760/1000 - Train Loss: 0.4164, Validation Loss: 0.4144\n",
      "Epoch 761/1000 - Train Loss: 0.4162, Validation Loss: 0.4142\n",
      "Epoch 762/1000 - Train Loss: 0.4159, Validation Loss: 0.4140\n",
      "Epoch 763/1000 - Train Loss: 0.4157, Validation Loss: 0.4138\n",
      "Epoch 764/1000 - Train Loss: 0.4155, Validation Loss: 0.4135\n",
      "Epoch 765/1000 - Train Loss: 0.4153, Validation Loss: 0.4133\n",
      "Epoch 766/1000 - Train Loss: 0.4150, Validation Loss: 0.4131\n",
      "Epoch 767/1000 - Train Loss: 0.4148, Validation Loss: 0.4129\n",
      "Epoch 768/1000 - Train Loss: 0.4146, Validation Loss: 0.4126\n",
      "Epoch 769/1000 - Train Loss: 0.4144, Validation Loss: 0.4124\n",
      "Epoch 770/1000 - Train Loss: 0.4141, Validation Loss: 0.4122\n",
      "Epoch 771/1000 - Train Loss: 0.4139, Validation Loss: 0.4120\n",
      "Epoch 772/1000 - Train Loss: 0.4137, Validation Loss: 0.4117\n",
      "Epoch 773/1000 - Train Loss: 0.4135, Validation Loss: 0.4115\n",
      "Epoch 774/1000 - Train Loss: 0.4132, Validation Loss: 0.4113\n",
      "Epoch 775/1000 - Train Loss: 0.4130, Validation Loss: 0.4111\n",
      "Epoch 776/1000 - Train Loss: 0.4128, Validation Loss: 0.4108\n",
      "Epoch 777/1000 - Train Loss: 0.4126, Validation Loss: 0.4106\n",
      "Epoch 778/1000 - Train Loss: 0.4124, Validation Loss: 0.4104\n",
      "Epoch 779/1000 - Train Loss: 0.4121, Validation Loss: 0.4102\n",
      "Epoch 780/1000 - Train Loss: 0.4119, Validation Loss: 0.4100\n",
      "Epoch 781/1000 - Train Loss: 0.4117, Validation Loss: 0.4097\n",
      "Epoch 782/1000 - Train Loss: 0.4115, Validation Loss: 0.4095\n",
      "Epoch 783/1000 - Train Loss: 0.4112, Validation Loss: 0.4093\n",
      "Epoch 784/1000 - Train Loss: 0.4110, Validation Loss: 0.4091\n",
      "Epoch 785/1000 - Train Loss: 0.4108, Validation Loss: 0.4089\n",
      "Epoch 786/1000 - Train Loss: 0.4106, Validation Loss: 0.4086\n",
      "Epoch 787/1000 - Train Loss: 0.4104, Validation Loss: 0.4084\n",
      "Epoch 788/1000 - Train Loss: 0.4101, Validation Loss: 0.4082\n",
      "Epoch 789/1000 - Train Loss: 0.4099, Validation Loss: 0.4080\n",
      "Epoch 790/1000 - Train Loss: 0.4097, Validation Loss: 0.4078\n",
      "Epoch 791/1000 - Train Loss: 0.4095, Validation Loss: 0.4075\n",
      "Epoch 792/1000 - Train Loss: 0.4093, Validation Loss: 0.4073\n",
      "Epoch 793/1000 - Train Loss: 0.4090, Validation Loss: 0.4071\n",
      "Epoch 794/1000 - Train Loss: 0.4088, Validation Loss: 0.4069\n",
      "Epoch 795/1000 - Train Loss: 0.4086, Validation Loss: 0.4067\n",
      "Epoch 796/1000 - Train Loss: 0.4084, Validation Loss: 0.4065\n",
      "Epoch 797/1000 - Train Loss: 0.4082, Validation Loss: 0.4062\n",
      "Epoch 798/1000 - Train Loss: 0.4080, Validation Loss: 0.4060\n",
      "Epoch 799/1000 - Train Loss: 0.4077, Validation Loss: 0.4058\n",
      "Epoch 800/1000 - Train Loss: 0.4075, Validation Loss: 0.4056\n",
      "Epoch 801/1000 - Train Loss: 0.4073, Validation Loss: 0.4054\n",
      "Epoch 802/1000 - Train Loss: 0.4071, Validation Loss: 0.4052\n",
      "Epoch 803/1000 - Train Loss: 0.4069, Validation Loss: 0.4049\n",
      "Epoch 804/1000 - Train Loss: 0.4067, Validation Loss: 0.4047\n",
      "Epoch 805/1000 - Train Loss: 0.4064, Validation Loss: 0.4045\n",
      "Epoch 806/1000 - Train Loss: 0.4062, Validation Loss: 0.4043\n",
      "Epoch 807/1000 - Train Loss: 0.4060, Validation Loss: 0.4041\n",
      "Epoch 808/1000 - Train Loss: 0.4058, Validation Loss: 0.4039\n",
      "Epoch 809/1000 - Train Loss: 0.4056, Validation Loss: 0.4036\n",
      "Epoch 810/1000 - Train Loss: 0.4054, Validation Loss: 0.4034\n",
      "Epoch 811/1000 - Train Loss: 0.4052, Validation Loss: 0.4032\n",
      "Epoch 812/1000 - Train Loss: 0.4049, Validation Loss: 0.4030\n",
      "Epoch 813/1000 - Train Loss: 0.4047, Validation Loss: 0.4028\n",
      "Epoch 814/1000 - Train Loss: 0.4045, Validation Loss: 0.4026\n",
      "Epoch 815/1000 - Train Loss: 0.4043, Validation Loss: 0.4024\n",
      "Epoch 816/1000 - Train Loss: 0.4041, Validation Loss: 0.4022\n",
      "Epoch 817/1000 - Train Loss: 0.4039, Validation Loss: 0.4019\n",
      "Epoch 818/1000 - Train Loss: 0.4037, Validation Loss: 0.4017\n",
      "Epoch 819/1000 - Train Loss: 0.4034, Validation Loss: 0.4015\n",
      "Epoch 820/1000 - Train Loss: 0.4032, Validation Loss: 0.4013\n",
      "Epoch 821/1000 - Train Loss: 0.4030, Validation Loss: 0.4011\n",
      "Epoch 822/1000 - Train Loss: 0.4028, Validation Loss: 0.4009\n",
      "Epoch 823/1000 - Train Loss: 0.4026, Validation Loss: 0.4007\n",
      "Epoch 824/1000 - Train Loss: 0.4024, Validation Loss: 0.4005\n",
      "Epoch 825/1000 - Train Loss: 0.4022, Validation Loss: 0.4002\n",
      "Epoch 826/1000 - Train Loss: 0.4020, Validation Loss: 0.4000\n",
      "Epoch 827/1000 - Train Loss: 0.4017, Validation Loss: 0.3998\n",
      "Epoch 828/1000 - Train Loss: 0.4015, Validation Loss: 0.3996\n",
      "Epoch 829/1000 - Train Loss: 0.4013, Validation Loss: 0.3994\n",
      "Epoch 830/1000 - Train Loss: 0.4011, Validation Loss: 0.3992\n",
      "Epoch 831/1000 - Train Loss: 0.4009, Validation Loss: 0.3990\n",
      "Epoch 832/1000 - Train Loss: 0.4007, Validation Loss: 0.3988\n",
      "Epoch 833/1000 - Train Loss: 0.4005, Validation Loss: 0.3986\n",
      "Epoch 834/1000 - Train Loss: 0.4003, Validation Loss: 0.3983\n",
      "Epoch 835/1000 - Train Loss: 0.4001, Validation Loss: 0.3981\n",
      "Epoch 836/1000 - Train Loss: 0.3999, Validation Loss: 0.3979\n",
      "Epoch 837/1000 - Train Loss: 0.3996, Validation Loss: 0.3977\n",
      "Epoch 838/1000 - Train Loss: 0.3994, Validation Loss: 0.3975\n",
      "Epoch 839/1000 - Train Loss: 0.3992, Validation Loss: 0.3973\n",
      "Epoch 840/1000 - Train Loss: 0.3990, Validation Loss: 0.3971\n",
      "Epoch 841/1000 - Train Loss: 0.3988, Validation Loss: 0.3969\n",
      "Epoch 842/1000 - Train Loss: 0.3986, Validation Loss: 0.3967\n",
      "Epoch 843/1000 - Train Loss: 0.3984, Validation Loss: 0.3965\n",
      "Epoch 844/1000 - Train Loss: 0.3982, Validation Loss: 0.3963\n",
      "Epoch 845/1000 - Train Loss: 0.3980, Validation Loss: 0.3961\n",
      "Epoch 846/1000 - Train Loss: 0.3978, Validation Loss: 0.3959\n",
      "Epoch 847/1000 - Train Loss: 0.3976, Validation Loss: 0.3956\n",
      "Epoch 848/1000 - Train Loss: 0.3974, Validation Loss: 0.3954\n",
      "Epoch 849/1000 - Train Loss: 0.3971, Validation Loss: 0.3952\n",
      "Epoch 850/1000 - Train Loss: 0.3969, Validation Loss: 0.3950\n",
      "Epoch 851/1000 - Train Loss: 0.3967, Validation Loss: 0.3948\n",
      "Epoch 852/1000 - Train Loss: 0.3965, Validation Loss: 0.3946\n",
      "Epoch 853/1000 - Train Loss: 0.3963, Validation Loss: 0.3944\n",
      "Epoch 854/1000 - Train Loss: 0.3961, Validation Loss: 0.3942\n",
      "Epoch 855/1000 - Train Loss: 0.3959, Validation Loss: 0.3940\n",
      "Epoch 856/1000 - Train Loss: 0.3957, Validation Loss: 0.3938\n",
      "Epoch 857/1000 - Train Loss: 0.3955, Validation Loss: 0.3936\n",
      "Epoch 858/1000 - Train Loss: 0.3953, Validation Loss: 0.3934\n",
      "Epoch 859/1000 - Train Loss: 0.3951, Validation Loss: 0.3932\n",
      "Epoch 860/1000 - Train Loss: 0.3949, Validation Loss: 0.3930\n",
      "Epoch 861/1000 - Train Loss: 0.3947, Validation Loss: 0.3928\n",
      "Epoch 862/1000 - Train Loss: 0.3945, Validation Loss: 0.3926\n",
      "Epoch 863/1000 - Train Loss: 0.3943, Validation Loss: 0.3924\n",
      "Epoch 864/1000 - Train Loss: 0.3941, Validation Loss: 0.3922\n",
      "Epoch 865/1000 - Train Loss: 0.3939, Validation Loss: 0.3920\n",
      "Epoch 866/1000 - Train Loss: 0.3937, Validation Loss: 0.3918\n",
      "Epoch 867/1000 - Train Loss: 0.3935, Validation Loss: 0.3916\n",
      "Epoch 868/1000 - Train Loss: 0.3933, Validation Loss: 0.3914\n",
      "Epoch 869/1000 - Train Loss: 0.3931, Validation Loss: 0.3912\n",
      "Epoch 870/1000 - Train Loss: 0.3929, Validation Loss: 0.3910\n",
      "Epoch 871/1000 - Train Loss: 0.3927, Validation Loss: 0.3908\n",
      "Epoch 872/1000 - Train Loss: 0.3925, Validation Loss: 0.3905\n",
      "Epoch 873/1000 - Train Loss: 0.3923, Validation Loss: 0.3903\n",
      "Epoch 874/1000 - Train Loss: 0.3920, Validation Loss: 0.3901\n",
      "Epoch 875/1000 - Train Loss: 0.3918, Validation Loss: 0.3899\n",
      "Epoch 876/1000 - Train Loss: 0.3916, Validation Loss: 0.3897\n",
      "Epoch 877/1000 - Train Loss: 0.3914, Validation Loss: 0.3895\n",
      "Epoch 878/1000 - Train Loss: 0.3912, Validation Loss: 0.3893\n",
      "Epoch 879/1000 - Train Loss: 0.3910, Validation Loss: 0.3891\n",
      "Epoch 880/1000 - Train Loss: 0.3908, Validation Loss: 0.3889\n",
      "Epoch 881/1000 - Train Loss: 0.3906, Validation Loss: 0.3887\n",
      "Epoch 882/1000 - Train Loss: 0.3904, Validation Loss: 0.3885\n",
      "Epoch 883/1000 - Train Loss: 0.3902, Validation Loss: 0.3883\n",
      "Epoch 884/1000 - Train Loss: 0.3900, Validation Loss: 0.3881\n",
      "Epoch 885/1000 - Train Loss: 0.3898, Validation Loss: 0.3879\n",
      "Epoch 886/1000 - Train Loss: 0.3896, Validation Loss: 0.3877\n",
      "Epoch 887/1000 - Train Loss: 0.3894, Validation Loss: 0.3875\n",
      "Epoch 888/1000 - Train Loss: 0.3892, Validation Loss: 0.3874\n",
      "Epoch 889/1000 - Train Loss: 0.3890, Validation Loss: 0.3872\n",
      "Epoch 890/1000 - Train Loss: 0.3889, Validation Loss: 0.3870\n",
      "Epoch 891/1000 - Train Loss: 0.3887, Validation Loss: 0.3868\n",
      "Epoch 892/1000 - Train Loss: 0.3885, Validation Loss: 0.3866\n",
      "Epoch 893/1000 - Train Loss: 0.3883, Validation Loss: 0.3864\n",
      "Epoch 894/1000 - Train Loss: 0.3881, Validation Loss: 0.3862\n",
      "Epoch 895/1000 - Train Loss: 0.3879, Validation Loss: 0.3860\n",
      "Epoch 896/1000 - Train Loss: 0.3877, Validation Loss: 0.3858\n",
      "Epoch 897/1000 - Train Loss: 0.3875, Validation Loss: 0.3856\n",
      "Epoch 898/1000 - Train Loss: 0.3873, Validation Loss: 0.3854\n",
      "Epoch 899/1000 - Train Loss: 0.3871, Validation Loss: 0.3852\n",
      "Epoch 900/1000 - Train Loss: 0.3869, Validation Loss: 0.3850\n",
      "Epoch 901/1000 - Train Loss: 0.3867, Validation Loss: 0.3848\n",
      "Epoch 902/1000 - Train Loss: 0.3865, Validation Loss: 0.3846\n",
      "Epoch 903/1000 - Train Loss: 0.3863, Validation Loss: 0.3844\n",
      "Epoch 904/1000 - Train Loss: 0.3861, Validation Loss: 0.3842\n",
      "Epoch 905/1000 - Train Loss: 0.3859, Validation Loss: 0.3840\n",
      "Epoch 906/1000 - Train Loss: 0.3857, Validation Loss: 0.3838\n",
      "Epoch 907/1000 - Train Loss: 0.3855, Validation Loss: 0.3836\n",
      "Epoch 908/1000 - Train Loss: 0.3853, Validation Loss: 0.3834\n",
      "Epoch 909/1000 - Train Loss: 0.3851, Validation Loss: 0.3832\n",
      "Epoch 910/1000 - Train Loss: 0.3849, Validation Loss: 0.3830\n",
      "Epoch 911/1000 - Train Loss: 0.3847, Validation Loss: 0.3828\n",
      "Epoch 912/1000 - Train Loss: 0.3845, Validation Loss: 0.3826\n",
      "Epoch 913/1000 - Train Loss: 0.3843, Validation Loss: 0.3825\n",
      "Epoch 914/1000 - Train Loss: 0.3841, Validation Loss: 0.3823\n",
      "Epoch 915/1000 - Train Loss: 0.3840, Validation Loss: 0.3821\n",
      "Epoch 916/1000 - Train Loss: 0.3838, Validation Loss: 0.3819\n",
      "Epoch 917/1000 - Train Loss: 0.3836, Validation Loss: 0.3817\n",
      "Epoch 918/1000 - Train Loss: 0.3834, Validation Loss: 0.3815\n",
      "Epoch 919/1000 - Train Loss: 0.3832, Validation Loss: 0.3813\n",
      "Epoch 920/1000 - Train Loss: 0.3830, Validation Loss: 0.3811\n",
      "Epoch 921/1000 - Train Loss: 0.3828, Validation Loss: 0.3809\n",
      "Epoch 922/1000 - Train Loss: 0.3826, Validation Loss: 0.3807\n",
      "Epoch 923/1000 - Train Loss: 0.3824, Validation Loss: 0.3805\n",
      "Epoch 924/1000 - Train Loss: 0.3822, Validation Loss: 0.3803\n",
      "Epoch 925/1000 - Train Loss: 0.3820, Validation Loss: 0.3801\n",
      "Epoch 926/1000 - Train Loss: 0.3818, Validation Loss: 0.3800\n",
      "Epoch 927/1000 - Train Loss: 0.3816, Validation Loss: 0.3798\n",
      "Epoch 928/1000 - Train Loss: 0.3815, Validation Loss: 0.3796\n",
      "Epoch 929/1000 - Train Loss: 0.3813, Validation Loss: 0.3794\n",
      "Epoch 930/1000 - Train Loss: 0.3811, Validation Loss: 0.3792\n",
      "Epoch 931/1000 - Train Loss: 0.3809, Validation Loss: 0.3790\n",
      "Epoch 932/1000 - Train Loss: 0.3807, Validation Loss: 0.3788\n",
      "Epoch 933/1000 - Train Loss: 0.3805, Validation Loss: 0.3786\n",
      "Epoch 934/1000 - Train Loss: 0.3803, Validation Loss: 0.3784\n",
      "Epoch 935/1000 - Train Loss: 0.3801, Validation Loss: 0.3782\n",
      "Epoch 936/1000 - Train Loss: 0.3799, Validation Loss: 0.3781\n",
      "Epoch 937/1000 - Train Loss: 0.3797, Validation Loss: 0.3779\n",
      "Epoch 938/1000 - Train Loss: 0.3796, Validation Loss: 0.3777\n",
      "Epoch 939/1000 - Train Loss: 0.3794, Validation Loss: 0.3775\n",
      "Epoch 940/1000 - Train Loss: 0.3792, Validation Loss: 0.3773\n",
      "Epoch 941/1000 - Train Loss: 0.3790, Validation Loss: 0.3771\n",
      "Epoch 942/1000 - Train Loss: 0.3788, Validation Loss: 0.3769\n",
      "Epoch 943/1000 - Train Loss: 0.3786, Validation Loss: 0.3767\n",
      "Epoch 944/1000 - Train Loss: 0.3784, Validation Loss: 0.3765\n",
      "Epoch 945/1000 - Train Loss: 0.3782, Validation Loss: 0.3764\n",
      "Epoch 946/1000 - Train Loss: 0.3780, Validation Loss: 0.3762\n",
      "Epoch 947/1000 - Train Loss: 0.3779, Validation Loss: 0.3760\n",
      "Epoch 948/1000 - Train Loss: 0.3777, Validation Loss: 0.3758\n",
      "Epoch 949/1000 - Train Loss: 0.3775, Validation Loss: 0.3756\n",
      "Epoch 950/1000 - Train Loss: 0.3773, Validation Loss: 0.3754\n",
      "Epoch 951/1000 - Train Loss: 0.3771, Validation Loss: 0.3752\n",
      "Epoch 952/1000 - Train Loss: 0.3769, Validation Loss: 0.3751\n",
      "Epoch 953/1000 - Train Loss: 0.3767, Validation Loss: 0.3749\n",
      "Epoch 954/1000 - Train Loss: 0.3765, Validation Loss: 0.3747\n",
      "Epoch 955/1000 - Train Loss: 0.3764, Validation Loss: 0.3745\n",
      "Epoch 956/1000 - Train Loss: 0.3762, Validation Loss: 0.3743\n",
      "Epoch 957/1000 - Train Loss: 0.3760, Validation Loss: 0.3741\n",
      "Epoch 958/1000 - Train Loss: 0.3758, Validation Loss: 0.3739\n",
      "Epoch 959/1000 - Train Loss: 0.3756, Validation Loss: 0.3738\n",
      "Epoch 960/1000 - Train Loss: 0.3754, Validation Loss: 0.3736\n",
      "Epoch 961/1000 - Train Loss: 0.3752, Validation Loss: 0.3734\n",
      "Epoch 962/1000 - Train Loss: 0.3751, Validation Loss: 0.3732\n",
      "Epoch 963/1000 - Train Loss: 0.3749, Validation Loss: 0.3730\n",
      "Epoch 964/1000 - Train Loss: 0.3747, Validation Loss: 0.3728\n",
      "Epoch 965/1000 - Train Loss: 0.3745, Validation Loss: 0.3726\n",
      "Epoch 966/1000 - Train Loss: 0.3743, Validation Loss: 0.3725\n",
      "Epoch 967/1000 - Train Loss: 0.3741, Validation Loss: 0.3723\n",
      "Epoch 968/1000 - Train Loss: 0.3740, Validation Loss: 0.3721\n",
      "Epoch 969/1000 - Train Loss: 0.3738, Validation Loss: 0.3719\n",
      "Epoch 970/1000 - Train Loss: 0.3736, Validation Loss: 0.3717\n",
      "Epoch 971/1000 - Train Loss: 0.3734, Validation Loss: 0.3715\n",
      "Epoch 972/1000 - Train Loss: 0.3732, Validation Loss: 0.3714\n",
      "Epoch 973/1000 - Train Loss: 0.3730, Validation Loss: 0.3712\n",
      "Epoch 974/1000 - Train Loss: 0.3729, Validation Loss: 0.3710\n",
      "Epoch 975/1000 - Train Loss: 0.3727, Validation Loss: 0.3708\n",
      "Epoch 976/1000 - Train Loss: 0.3725, Validation Loss: 0.3706\n",
      "Epoch 977/1000 - Train Loss: 0.3723, Validation Loss: 0.3705\n",
      "Epoch 978/1000 - Train Loss: 0.3721, Validation Loss: 0.3703\n",
      "Epoch 979/1000 - Train Loss: 0.3719, Validation Loss: 0.3701\n",
      "Epoch 980/1000 - Train Loss: 0.3718, Validation Loss: 0.3699\n",
      "Epoch 981/1000 - Train Loss: 0.3716, Validation Loss: 0.3697\n",
      "Epoch 982/1000 - Train Loss: 0.3714, Validation Loss: 0.3695\n",
      "Epoch 983/1000 - Train Loss: 0.3712, Validation Loss: 0.3694\n",
      "Epoch 984/1000 - Train Loss: 0.3710, Validation Loss: 0.3692\n",
      "Epoch 985/1000 - Train Loss: 0.3709, Validation Loss: 0.3690\n",
      "Epoch 986/1000 - Train Loss: 0.3707, Validation Loss: 0.3688\n",
      "Epoch 987/1000 - Train Loss: 0.3705, Validation Loss: 0.3686\n",
      "Epoch 988/1000 - Train Loss: 0.3703, Validation Loss: 0.3685\n",
      "Epoch 989/1000 - Train Loss: 0.3701, Validation Loss: 0.3683\n",
      "Epoch 990/1000 - Train Loss: 0.3700, Validation Loss: 0.3681\n",
      "Epoch 991/1000 - Train Loss: 0.3698, Validation Loss: 0.3679\n",
      "Epoch 992/1000 - Train Loss: 0.3696, Validation Loss: 0.3677\n",
      "Epoch 993/1000 - Train Loss: 0.3694, Validation Loss: 0.3676\n",
      "Epoch 994/1000 - Train Loss: 0.3692, Validation Loss: 0.3674\n",
      "Epoch 995/1000 - Train Loss: 0.3691, Validation Loss: 0.3672\n",
      "Epoch 996/1000 - Train Loss: 0.3689, Validation Loss: 0.3670\n",
      "Epoch 997/1000 - Train Loss: 0.3687, Validation Loss: 0.3668\n",
      "Epoch 998/1000 - Train Loss: 0.3685, Validation Loss: 0.3667\n",
      "Epoch 999/1000 - Train Loss: 0.3683, Validation Loss: 0.3665\n",
      "Epoch 1000/1000 - Train Loss: 0.3682, Validation Loss: 0.3663\n",
      "Epoch 1/1000 - Train Loss: 0.6931, Validation Loss: 0.6909\n",
      "Epoch 2/1000 - Train Loss: 0.6910, Validation Loss: 0.6887\n",
      "Epoch 3/1000 - Train Loss: 0.6888, Validation Loss: 0.6865\n",
      "Epoch 4/1000 - Train Loss: 0.6867, Validation Loss: 0.6844\n",
      "Epoch 5/1000 - Train Loss: 0.6846, Validation Loss: 0.6823\n",
      "Epoch 6/1000 - Train Loss: 0.6826, Validation Loss: 0.6802\n",
      "Epoch 7/1000 - Train Loss: 0.6805, Validation Loss: 0.6781\n",
      "Epoch 8/1000 - Train Loss: 0.6785, Validation Loss: 0.6760\n",
      "Epoch 9/1000 - Train Loss: 0.6765, Validation Loss: 0.6740\n",
      "Epoch 10/1000 - Train Loss: 0.6745, Validation Loss: 0.6720\n",
      "Epoch 11/1000 - Train Loss: 0.6726, Validation Loss: 0.6700\n",
      "Epoch 12/1000 - Train Loss: 0.6707, Validation Loss: 0.6681\n",
      "Epoch 13/1000 - Train Loss: 0.6687, Validation Loss: 0.6662\n",
      "Epoch 14/1000 - Train Loss: 0.6669, Validation Loss: 0.6642\n",
      "Epoch 15/1000 - Train Loss: 0.6650, Validation Loss: 0.6623\n",
      "Epoch 16/1000 - Train Loss: 0.6631, Validation Loss: 0.6605\n",
      "Epoch 17/1000 - Train Loss: 0.6613, Validation Loss: 0.6586\n",
      "Epoch 18/1000 - Train Loss: 0.6594, Validation Loss: 0.6567\n",
      "Epoch 19/1000 - Train Loss: 0.6576, Validation Loss: 0.6549\n",
      "Epoch 20/1000 - Train Loss: 0.6558, Validation Loss: 0.6531\n",
      "Epoch 21/1000 - Train Loss: 0.6541, Validation Loss: 0.6513\n",
      "Epoch 22/1000 - Train Loss: 0.6523, Validation Loss: 0.6495\n",
      "Epoch 23/1000 - Train Loss: 0.6505, Validation Loss: 0.6477\n",
      "Epoch 24/1000 - Train Loss: 0.6488, Validation Loss: 0.6460\n",
      "Epoch 25/1000 - Train Loss: 0.6471, Validation Loss: 0.6442\n",
      "Epoch 26/1000 - Train Loss: 0.6453, Validation Loss: 0.6425\n",
      "Epoch 27/1000 - Train Loss: 0.6436, Validation Loss: 0.6408\n",
      "Epoch 28/1000 - Train Loss: 0.6419, Validation Loss: 0.6391\n",
      "Epoch 29/1000 - Train Loss: 0.6403, Validation Loss: 0.6374\n",
      "Epoch 30/1000 - Train Loss: 0.6386, Validation Loss: 0.6357\n",
      "Epoch 31/1000 - Train Loss: 0.6369, Validation Loss: 0.6340\n",
      "Epoch 32/1000 - Train Loss: 0.6353, Validation Loss: 0.6323\n",
      "Epoch 33/1000 - Train Loss: 0.6336, Validation Loss: 0.6307\n",
      "Epoch 34/1000 - Train Loss: 0.6320, Validation Loss: 0.6290\n",
      "Epoch 35/1000 - Train Loss: 0.6304, Validation Loss: 0.6274\n",
      "Epoch 36/1000 - Train Loss: 0.6288, Validation Loss: 0.6258\n",
      "Epoch 37/1000 - Train Loss: 0.6272, Validation Loss: 0.6242\n",
      "Epoch 38/1000 - Train Loss: 0.6256, Validation Loss: 0.6226\n",
      "Epoch 39/1000 - Train Loss: 0.6240, Validation Loss: 0.6210\n",
      "Epoch 40/1000 - Train Loss: 0.6224, Validation Loss: 0.6194\n",
      "Epoch 41/1000 - Train Loss: 0.6208, Validation Loss: 0.6178\n",
      "Epoch 42/1000 - Train Loss: 0.6193, Validation Loss: 0.6162\n",
      "Epoch 43/1000 - Train Loss: 0.6177, Validation Loss: 0.6147\n",
      "Epoch 44/1000 - Train Loss: 0.6162, Validation Loss: 0.6131\n",
      "Epoch 45/1000 - Train Loss: 0.6146, Validation Loss: 0.6116\n",
      "Epoch 46/1000 - Train Loss: 0.6131, Validation Loss: 0.6100\n",
      "Epoch 47/1000 - Train Loss: 0.6116, Validation Loss: 0.6085\n",
      "Epoch 48/1000 - Train Loss: 0.6101, Validation Loss: 0.6070\n",
      "Epoch 49/1000 - Train Loss: 0.6085, Validation Loss: 0.6055\n",
      "Epoch 50/1000 - Train Loss: 0.6070, Validation Loss: 0.6040\n",
      "Epoch 51/1000 - Train Loss: 0.6056, Validation Loss: 0.6025\n",
      "Epoch 52/1000 - Train Loss: 0.6041, Validation Loss: 0.6010\n",
      "Epoch 53/1000 - Train Loss: 0.6026, Validation Loss: 0.5995\n",
      "Epoch 54/1000 - Train Loss: 0.6011, Validation Loss: 0.5980\n",
      "Epoch 55/1000 - Train Loss: 0.5996, Validation Loss: 0.5966\n",
      "Epoch 56/1000 - Train Loss: 0.5982, Validation Loss: 0.5951\n",
      "Epoch 57/1000 - Train Loss: 0.5967, Validation Loss: 0.5936\n",
      "Epoch 58/1000 - Train Loss: 0.5953, Validation Loss: 0.5922\n",
      "Epoch 59/1000 - Train Loss: 0.5939, Validation Loss: 0.5908\n",
      "Epoch 60/1000 - Train Loss: 0.5924, Validation Loss: 0.5893\n",
      "Epoch 61/1000 - Train Loss: 0.5910, Validation Loss: 0.5879\n",
      "Epoch 62/1000 - Train Loss: 0.5896, Validation Loss: 0.5865\n",
      "Epoch 63/1000 - Train Loss: 0.5882, Validation Loss: 0.5851\n",
      "Epoch 64/1000 - Train Loss: 0.5868, Validation Loss: 0.5836\n",
      "Epoch 65/1000 - Train Loss: 0.5853, Validation Loss: 0.5822\n",
      "Epoch 66/1000 - Train Loss: 0.5840, Validation Loss: 0.5808\n",
      "Epoch 67/1000 - Train Loss: 0.5826, Validation Loss: 0.5795\n",
      "Epoch 68/1000 - Train Loss: 0.5812, Validation Loss: 0.5781\n",
      "Epoch 69/1000 - Train Loss: 0.5798, Validation Loss: 0.5767\n",
      "Epoch 70/1000 - Train Loss: 0.5784, Validation Loss: 0.5753\n",
      "Epoch 71/1000 - Train Loss: 0.5771, Validation Loss: 0.5740\n",
      "Epoch 72/1000 - Train Loss: 0.5757, Validation Loss: 0.5726\n",
      "Epoch 73/1000 - Train Loss: 0.5743, Validation Loss: 0.5712\n",
      "Epoch 74/1000 - Train Loss: 0.5730, Validation Loss: 0.5699\n",
      "Epoch 75/1000 - Train Loss: 0.5717, Validation Loss: 0.5686\n",
      "Epoch 76/1000 - Train Loss: 0.5703, Validation Loss: 0.5672\n",
      "Epoch 77/1000 - Train Loss: 0.5690, Validation Loss: 0.5659\n",
      "Epoch 78/1000 - Train Loss: 0.5677, Validation Loss: 0.5646\n",
      "Epoch 79/1000 - Train Loss: 0.5663, Validation Loss: 0.5632\n",
      "Epoch 80/1000 - Train Loss: 0.5650, Validation Loss: 0.5619\n",
      "Epoch 81/1000 - Train Loss: 0.5637, Validation Loss: 0.5606\n",
      "Epoch 82/1000 - Train Loss: 0.5624, Validation Loss: 0.5593\n",
      "Epoch 83/1000 - Train Loss: 0.5611, Validation Loss: 0.5580\n",
      "Epoch 84/1000 - Train Loss: 0.5598, Validation Loss: 0.5567\n",
      "Epoch 85/1000 - Train Loss: 0.5585, Validation Loss: 0.5554\n",
      "Epoch 86/1000 - Train Loss: 0.5572, Validation Loss: 0.5542\n",
      "Epoch 87/1000 - Train Loss: 0.5560, Validation Loss: 0.5529\n",
      "Epoch 88/1000 - Train Loss: 0.5547, Validation Loss: 0.5516\n",
      "Epoch 89/1000 - Train Loss: 0.5534, Validation Loss: 0.5503\n",
      "Epoch 90/1000 - Train Loss: 0.5521, Validation Loss: 0.5491\n",
      "Epoch 91/1000 - Train Loss: 0.5509, Validation Loss: 0.5478\n",
      "Epoch 92/1000 - Train Loss: 0.5496, Validation Loss: 0.5466\n",
      "Epoch 93/1000 - Train Loss: 0.5484, Validation Loss: 0.5453\n",
      "Epoch 94/1000 - Train Loss: 0.5471, Validation Loss: 0.5441\n",
      "Epoch 95/1000 - Train Loss: 0.5459, Validation Loss: 0.5429\n",
      "Epoch 96/1000 - Train Loss: 0.5447, Validation Loss: 0.5416\n",
      "Epoch 97/1000 - Train Loss: 0.5434, Validation Loss: 0.5404\n",
      "Epoch 98/1000 - Train Loss: 0.5422, Validation Loss: 0.5392\n",
      "Epoch 99/1000 - Train Loss: 0.5410, Validation Loss: 0.5380\n",
      "Epoch 100/1000 - Train Loss: 0.5398, Validation Loss: 0.5368\n",
      "Epoch 101/1000 - Train Loss: 0.5386, Validation Loss: 0.5356\n",
      "Epoch 102/1000 - Train Loss: 0.5374, Validation Loss: 0.5344\n",
      "Epoch 103/1000 - Train Loss: 0.5362, Validation Loss: 0.5332\n",
      "Epoch 104/1000 - Train Loss: 0.5350, Validation Loss: 0.5320\n",
      "Epoch 105/1000 - Train Loss: 0.5338, Validation Loss: 0.5308\n",
      "Epoch 106/1000 - Train Loss: 0.5326, Validation Loss: 0.5296\n",
      "Epoch 107/1000 - Train Loss: 0.5314, Validation Loss: 0.5284\n",
      "Epoch 108/1000 - Train Loss: 0.5302, Validation Loss: 0.5272\n",
      "Epoch 109/1000 - Train Loss: 0.5291, Validation Loss: 0.5261\n",
      "Epoch 110/1000 - Train Loss: 0.5279, Validation Loss: 0.5249\n",
      "Epoch 111/1000 - Train Loss: 0.5267, Validation Loss: 0.5238\n",
      "Epoch 112/1000 - Train Loss: 0.5256, Validation Loss: 0.5226\n",
      "Epoch 113/1000 - Train Loss: 0.5244, Validation Loss: 0.5215\n",
      "Epoch 114/1000 - Train Loss: 0.5233, Validation Loss: 0.5203\n",
      "Epoch 115/1000 - Train Loss: 0.5221, Validation Loss: 0.5192\n",
      "Epoch 116/1000 - Train Loss: 0.5210, Validation Loss: 0.5180\n",
      "Epoch 117/1000 - Train Loss: 0.5199, Validation Loss: 0.5169\n",
      "Epoch 118/1000 - Train Loss: 0.5187, Validation Loss: 0.5158\n",
      "Epoch 119/1000 - Train Loss: 0.5176, Validation Loss: 0.5146\n",
      "Epoch 120/1000 - Train Loss: 0.5165, Validation Loss: 0.5135\n",
      "Epoch 121/1000 - Train Loss: 0.5153, Validation Loss: 0.5124\n",
      "Epoch 122/1000 - Train Loss: 0.5142, Validation Loss: 0.5113\n",
      "Epoch 123/1000 - Train Loss: 0.5131, Validation Loss: 0.5102\n",
      "Epoch 124/1000 - Train Loss: 0.5120, Validation Loss: 0.5091\n",
      "Epoch 125/1000 - Train Loss: 0.5109, Validation Loss: 0.5080\n",
      "Epoch 126/1000 - Train Loss: 0.5098, Validation Loss: 0.5069\n",
      "Epoch 127/1000 - Train Loss: 0.5087, Validation Loss: 0.5058\n",
      "Epoch 128/1000 - Train Loss: 0.5076, Validation Loss: 0.5047\n",
      "Epoch 129/1000 - Train Loss: 0.5066, Validation Loss: 0.5037\n",
      "Epoch 130/1000 - Train Loss: 0.5055, Validation Loss: 0.5026\n",
      "Epoch 131/1000 - Train Loss: 0.5044, Validation Loss: 0.5015\n",
      "Epoch 132/1000 - Train Loss: 0.5033, Validation Loss: 0.5004\n",
      "Epoch 133/1000 - Train Loss: 0.5023, Validation Loss: 0.4994\n",
      "Epoch 134/1000 - Train Loss: 0.5012, Validation Loss: 0.4983\n",
      "Epoch 135/1000 - Train Loss: 0.5001, Validation Loss: 0.4973\n",
      "Epoch 136/1000 - Train Loss: 0.4991, Validation Loss: 0.4962\n",
      "Epoch 137/1000 - Train Loss: 0.4980, Validation Loss: 0.4952\n",
      "Epoch 138/1000 - Train Loss: 0.4970, Validation Loss: 0.4941\n",
      "Epoch 139/1000 - Train Loss: 0.4959, Validation Loss: 0.4931\n",
      "Epoch 140/1000 - Train Loss: 0.4949, Validation Loss: 0.4920\n",
      "Epoch 141/1000 - Train Loss: 0.4939, Validation Loss: 0.4910\n",
      "Epoch 142/1000 - Train Loss: 0.4928, Validation Loss: 0.4900\n",
      "Epoch 143/1000 - Train Loss: 0.4918, Validation Loss: 0.4890\n",
      "Epoch 144/1000 - Train Loss: 0.4908, Validation Loss: 0.4879\n",
      "Epoch 145/1000 - Train Loss: 0.4897, Validation Loss: 0.4869\n",
      "Epoch 146/1000 - Train Loss: 0.4887, Validation Loss: 0.4859\n",
      "Epoch 147/1000 - Train Loss: 0.4877, Validation Loss: 0.4849\n",
      "Epoch 148/1000 - Train Loss: 0.4867, Validation Loss: 0.4839\n",
      "Epoch 149/1000 - Train Loss: 0.4857, Validation Loss: 0.4829\n",
      "Epoch 150/1000 - Train Loss: 0.4847, Validation Loss: 0.4819\n",
      "Epoch 151/1000 - Train Loss: 0.4837, Validation Loss: 0.4809\n",
      "Epoch 152/1000 - Train Loss: 0.4827, Validation Loss: 0.4799\n",
      "Epoch 153/1000 - Train Loss: 0.4817, Validation Loss: 0.4789\n",
      "Epoch 154/1000 - Train Loss: 0.4807, Validation Loss: 0.4779\n",
      "Epoch 155/1000 - Train Loss: 0.4797, Validation Loss: 0.4770\n",
      "Epoch 156/1000 - Train Loss: 0.4788, Validation Loss: 0.4760\n",
      "Epoch 157/1000 - Train Loss: 0.4778, Validation Loss: 0.4750\n",
      "Epoch 158/1000 - Train Loss: 0.4768, Validation Loss: 0.4740\n",
      "Epoch 159/1000 - Train Loss: 0.4758, Validation Loss: 0.4731\n",
      "Epoch 160/1000 - Train Loss: 0.4749, Validation Loss: 0.4721\n",
      "Epoch 161/1000 - Train Loss: 0.4739, Validation Loss: 0.4712\n",
      "Epoch 162/1000 - Train Loss: 0.4730, Validation Loss: 0.4702\n",
      "Epoch 163/1000 - Train Loss: 0.4720, Validation Loss: 0.4693\n",
      "Epoch 164/1000 - Train Loss: 0.4711, Validation Loss: 0.4683\n",
      "Epoch 165/1000 - Train Loss: 0.4701, Validation Loss: 0.4674\n",
      "Epoch 166/1000 - Train Loss: 0.4692, Validation Loss: 0.4664\n",
      "Epoch 167/1000 - Train Loss: 0.4682, Validation Loss: 0.4655\n",
      "Epoch 168/1000 - Train Loss: 0.4673, Validation Loss: 0.4646\n",
      "Epoch 169/1000 - Train Loss: 0.4663, Validation Loss: 0.4636\n",
      "Epoch 170/1000 - Train Loss: 0.4654, Validation Loss: 0.4627\n",
      "Epoch 171/1000 - Train Loss: 0.4645, Validation Loss: 0.4618\n",
      "Epoch 172/1000 - Train Loss: 0.4636, Validation Loss: 0.4609\n",
      "Epoch 173/1000 - Train Loss: 0.4626, Validation Loss: 0.4599\n",
      "Epoch 174/1000 - Train Loss: 0.4617, Validation Loss: 0.4590\n",
      "Epoch 175/1000 - Train Loss: 0.4608, Validation Loss: 0.4581\n",
      "Epoch 176/1000 - Train Loss: 0.4599, Validation Loss: 0.4572\n",
      "Epoch 177/1000 - Train Loss: 0.4590, Validation Loss: 0.4563\n",
      "Epoch 178/1000 - Train Loss: 0.4581, Validation Loss: 0.4554\n",
      "Epoch 179/1000 - Train Loss: 0.4572, Validation Loss: 0.4545\n",
      "Epoch 180/1000 - Train Loss: 0.4563, Validation Loss: 0.4536\n",
      "Epoch 181/1000 - Train Loss: 0.4554, Validation Loss: 0.4527\n",
      "Epoch 182/1000 - Train Loss: 0.4545, Validation Loss: 0.4519\n",
      "Epoch 183/1000 - Train Loss: 0.4536, Validation Loss: 0.4510\n",
      "Epoch 184/1000 - Train Loss: 0.4527, Validation Loss: 0.4501\n",
      "Epoch 185/1000 - Train Loss: 0.4519, Validation Loss: 0.4492\n",
      "Epoch 186/1000 - Train Loss: 0.4510, Validation Loss: 0.4483\n",
      "Epoch 187/1000 - Train Loss: 0.4501, Validation Loss: 0.4475\n",
      "Epoch 188/1000 - Train Loss: 0.4492, Validation Loss: 0.4466\n",
      "Epoch 189/1000 - Train Loss: 0.4484, Validation Loss: 0.4457\n",
      "Epoch 190/1000 - Train Loss: 0.4475, Validation Loss: 0.4449\n",
      "Epoch 191/1000 - Train Loss: 0.4466, Validation Loss: 0.4440\n",
      "Epoch 192/1000 - Train Loss: 0.4458, Validation Loss: 0.4432\n",
      "Epoch 193/1000 - Train Loss: 0.4449, Validation Loss: 0.4423\n",
      "Epoch 194/1000 - Train Loss: 0.4441, Validation Loss: 0.4415\n",
      "Epoch 195/1000 - Train Loss: 0.4432, Validation Loss: 0.4406\n",
      "Epoch 196/1000 - Train Loss: 0.4424, Validation Loss: 0.4398\n",
      "Epoch 197/1000 - Train Loss: 0.4415, Validation Loss: 0.4389\n",
      "Epoch 198/1000 - Train Loss: 0.4407, Validation Loss: 0.4381\n",
      "Epoch 199/1000 - Train Loss: 0.4399, Validation Loss: 0.4373\n",
      "Epoch 200/1000 - Train Loss: 0.4390, Validation Loss: 0.4364\n",
      "Epoch 201/1000 - Train Loss: 0.4382, Validation Loss: 0.4356\n",
      "Epoch 202/1000 - Train Loss: 0.4374, Validation Loss: 0.4348\n",
      "Epoch 203/1000 - Train Loss: 0.4365, Validation Loss: 0.4340\n",
      "Epoch 204/1000 - Train Loss: 0.4357, Validation Loss: 0.4331\n",
      "Epoch 205/1000 - Train Loss: 0.4349, Validation Loss: 0.4323\n",
      "Epoch 206/1000 - Train Loss: 0.4341, Validation Loss: 0.4315\n",
      "Epoch 207/1000 - Train Loss: 0.4333, Validation Loss: 0.4307\n",
      "Epoch 208/1000 - Train Loss: 0.4324, Validation Loss: 0.4299\n",
      "Epoch 209/1000 - Train Loss: 0.4316, Validation Loss: 0.4291\n",
      "Epoch 210/1000 - Train Loss: 0.4308, Validation Loss: 0.4283\n",
      "Epoch 211/1000 - Train Loss: 0.4300, Validation Loss: 0.4275\n",
      "Epoch 212/1000 - Train Loss: 0.4292, Validation Loss: 0.4267\n",
      "Epoch 213/1000 - Train Loss: 0.4284, Validation Loss: 0.4259\n",
      "Epoch 214/1000 - Train Loss: 0.4276, Validation Loss: 0.4251\n",
      "Epoch 215/1000 - Train Loss: 0.4268, Validation Loss: 0.4243\n",
      "Epoch 216/1000 - Train Loss: 0.4261, Validation Loss: 0.4235\n",
      "Epoch 217/1000 - Train Loss: 0.4253, Validation Loss: 0.4227\n",
      "Epoch 218/1000 - Train Loss: 0.4245, Validation Loss: 0.4220\n",
      "Epoch 219/1000 - Train Loss: 0.4237, Validation Loss: 0.4212\n",
      "Epoch 220/1000 - Train Loss: 0.4229, Validation Loss: 0.4204\n",
      "Epoch 221/1000 - Train Loss: 0.4222, Validation Loss: 0.4196\n",
      "Epoch 222/1000 - Train Loss: 0.4214, Validation Loss: 0.4189\n",
      "Epoch 223/1000 - Train Loss: 0.4206, Validation Loss: 0.4181\n",
      "Epoch 224/1000 - Train Loss: 0.4198, Validation Loss: 0.4173\n",
      "Epoch 225/1000 - Train Loss: 0.4191, Validation Loss: 0.4166\n",
      "Epoch 226/1000 - Train Loss: 0.4183, Validation Loss: 0.4158\n",
      "Epoch 227/1000 - Train Loss: 0.4176, Validation Loss: 0.4151\n",
      "Epoch 228/1000 - Train Loss: 0.4168, Validation Loss: 0.4143\n",
      "Epoch 229/1000 - Train Loss: 0.4160, Validation Loss: 0.4136\n",
      "Epoch 230/1000 - Train Loss: 0.4153, Validation Loss: 0.4128\n",
      "Epoch 231/1000 - Train Loss: 0.4145, Validation Loss: 0.4121\n",
      "Epoch 232/1000 - Train Loss: 0.4138, Validation Loss: 0.4113\n",
      "Epoch 233/1000 - Train Loss: 0.4131, Validation Loss: 0.4106\n",
      "Epoch 234/1000 - Train Loss: 0.4123, Validation Loss: 0.4098\n",
      "Epoch 235/1000 - Train Loss: 0.4116, Validation Loss: 0.4091\n",
      "Epoch 236/1000 - Train Loss: 0.4108, Validation Loss: 0.4084\n",
      "Epoch 237/1000 - Train Loss: 0.4101, Validation Loss: 0.4076\n",
      "Epoch 238/1000 - Train Loss: 0.4094, Validation Loss: 0.4069\n",
      "Epoch 239/1000 - Train Loss: 0.4086, Validation Loss: 0.4062\n",
      "Epoch 240/1000 - Train Loss: 0.4079, Validation Loss: 0.4055\n",
      "Epoch 241/1000 - Train Loss: 0.4072, Validation Loss: 0.4047\n",
      "Epoch 242/1000 - Train Loss: 0.4065, Validation Loss: 0.4040\n",
      "Epoch 243/1000 - Train Loss: 0.4058, Validation Loss: 0.4033\n",
      "Epoch 244/1000 - Train Loss: 0.4050, Validation Loss: 0.4026\n",
      "Epoch 245/1000 - Train Loss: 0.4043, Validation Loss: 0.4019\n",
      "Epoch 246/1000 - Train Loss: 0.4036, Validation Loss: 0.4012\n",
      "Epoch 247/1000 - Train Loss: 0.4029, Validation Loss: 0.4005\n",
      "Epoch 248/1000 - Train Loss: 0.4022, Validation Loss: 0.3998\n",
      "Epoch 249/1000 - Train Loss: 0.4015, Validation Loss: 0.3991\n",
      "Epoch 250/1000 - Train Loss: 0.4008, Validation Loss: 0.3984\n",
      "Epoch 251/1000 - Train Loss: 0.4001, Validation Loss: 0.3977\n",
      "Epoch 252/1000 - Train Loss: 0.3994, Validation Loss: 0.3970\n",
      "Epoch 253/1000 - Train Loss: 0.3987, Validation Loss: 0.3963\n",
      "Epoch 254/1000 - Train Loss: 0.3980, Validation Loss: 0.3956\n",
      "Epoch 255/1000 - Train Loss: 0.3973, Validation Loss: 0.3949\n",
      "Epoch 256/1000 - Train Loss: 0.3966, Validation Loss: 0.3942\n",
      "Epoch 257/1000 - Train Loss: 0.3959, Validation Loss: 0.3935\n",
      "Epoch 258/1000 - Train Loss: 0.3952, Validation Loss: 0.3929\n",
      "Epoch 259/1000 - Train Loss: 0.3946, Validation Loss: 0.3922\n",
      "Epoch 260/1000 - Train Loss: 0.3939, Validation Loss: 0.3915\n",
      "Epoch 261/1000 - Train Loss: 0.3932, Validation Loss: 0.3908\n",
      "Epoch 262/1000 - Train Loss: 0.3925, Validation Loss: 0.3902\n",
      "Epoch 263/1000 - Train Loss: 0.3919, Validation Loss: 0.3895\n",
      "Epoch 264/1000 - Train Loss: 0.3912, Validation Loss: 0.3888\n",
      "Epoch 265/1000 - Train Loss: 0.3905, Validation Loss: 0.3882\n",
      "Epoch 266/1000 - Train Loss: 0.3899, Validation Loss: 0.3875\n",
      "Epoch 267/1000 - Train Loss: 0.3892, Validation Loss: 0.3868\n",
      "Epoch 268/1000 - Train Loss: 0.3885, Validation Loss: 0.3862\n",
      "Epoch 269/1000 - Train Loss: 0.3879, Validation Loss: 0.3855\n",
      "Epoch 270/1000 - Train Loss: 0.3872, Validation Loss: 0.3849\n",
      "Epoch 271/1000 - Train Loss: 0.3866, Validation Loss: 0.3842\n",
      "Epoch 272/1000 - Train Loss: 0.3859, Validation Loss: 0.3836\n",
      "Epoch 273/1000 - Train Loss: 0.3853, Validation Loss: 0.3829\n",
      "Epoch 274/1000 - Train Loss: 0.3846, Validation Loss: 0.3823\n",
      "Epoch 275/1000 - Train Loss: 0.3840, Validation Loss: 0.3816\n",
      "Epoch 276/1000 - Train Loss: 0.3833, Validation Loss: 0.3810\n",
      "Epoch 277/1000 - Train Loss: 0.3827, Validation Loss: 0.3803\n",
      "Epoch 278/1000 - Train Loss: 0.3820, Validation Loss: 0.3797\n",
      "Epoch 279/1000 - Train Loss: 0.3814, Validation Loss: 0.3791\n",
      "Epoch 280/1000 - Train Loss: 0.3808, Validation Loss: 0.3784\n",
      "Epoch 281/1000 - Train Loss: 0.3801, Validation Loss: 0.3778\n",
      "Epoch 282/1000 - Train Loss: 0.3795, Validation Loss: 0.3772\n",
      "Epoch 283/1000 - Train Loss: 0.3789, Validation Loss: 0.3766\n",
      "Epoch 284/1000 - Train Loss: 0.3782, Validation Loss: 0.3759\n",
      "Epoch 285/1000 - Train Loss: 0.3776, Validation Loss: 0.3753\n",
      "Epoch 286/1000 - Train Loss: 0.3770, Validation Loss: 0.3747\n",
      "Epoch 287/1000 - Train Loss: 0.3764, Validation Loss: 0.3741\n",
      "Epoch 288/1000 - Train Loss: 0.3757, Validation Loss: 0.3735\n",
      "Epoch 289/1000 - Train Loss: 0.3751, Validation Loss: 0.3728\n",
      "Epoch 290/1000 - Train Loss: 0.3745, Validation Loss: 0.3722\n",
      "Epoch 291/1000 - Train Loss: 0.3739, Validation Loss: 0.3716\n",
      "Epoch 292/1000 - Train Loss: 0.3733, Validation Loss: 0.3710\n",
      "Epoch 293/1000 - Train Loss: 0.3727, Validation Loss: 0.3704\n",
      "Epoch 294/1000 - Train Loss: 0.3721, Validation Loss: 0.3698\n",
      "Epoch 295/1000 - Train Loss: 0.3715, Validation Loss: 0.3692\n",
      "Epoch 296/1000 - Train Loss: 0.3709, Validation Loss: 0.3686\n",
      "Epoch 297/1000 - Train Loss: 0.3703, Validation Loss: 0.3680\n",
      "Epoch 298/1000 - Train Loss: 0.3697, Validation Loss: 0.3674\n",
      "Epoch 299/1000 - Train Loss: 0.3691, Validation Loss: 0.3668\n",
      "Epoch 300/1000 - Train Loss: 0.3685, Validation Loss: 0.3662\n",
      "Epoch 301/1000 - Train Loss: 0.3679, Validation Loss: 0.3656\n",
      "Epoch 302/1000 - Train Loss: 0.3673, Validation Loss: 0.3650\n",
      "Epoch 303/1000 - Train Loss: 0.3667, Validation Loss: 0.3644\n",
      "Epoch 304/1000 - Train Loss: 0.3661, Validation Loss: 0.3638\n",
      "Epoch 305/1000 - Train Loss: 0.3655, Validation Loss: 0.3633\n",
      "Epoch 306/1000 - Train Loss: 0.3649, Validation Loss: 0.3627\n",
      "Epoch 307/1000 - Train Loss: 0.3643, Validation Loss: 0.3621\n",
      "Epoch 308/1000 - Train Loss: 0.3638, Validation Loss: 0.3615\n",
      "Epoch 309/1000 - Train Loss: 0.3632, Validation Loss: 0.3609\n",
      "Epoch 310/1000 - Train Loss: 0.3626, Validation Loss: 0.3604\n",
      "Epoch 311/1000 - Train Loss: 0.3620, Validation Loss: 0.3598\n",
      "Epoch 312/1000 - Train Loss: 0.3615, Validation Loss: 0.3592\n",
      "Epoch 313/1000 - Train Loss: 0.3609, Validation Loss: 0.3586\n",
      "Epoch 314/1000 - Train Loss: 0.3603, Validation Loss: 0.3581\n",
      "Epoch 315/1000 - Train Loss: 0.3597, Validation Loss: 0.3575\n",
      "Epoch 316/1000 - Train Loss: 0.3592, Validation Loss: 0.3569\n",
      "Epoch 317/1000 - Train Loss: 0.3586, Validation Loss: 0.3564\n",
      "Epoch 318/1000 - Train Loss: 0.3580, Validation Loss: 0.3558\n",
      "Epoch 319/1000 - Train Loss: 0.3575, Validation Loss: 0.3553\n",
      "Epoch 320/1000 - Train Loss: 0.3569, Validation Loss: 0.3547\n",
      "Epoch 321/1000 - Train Loss: 0.3564, Validation Loss: 0.3541\n",
      "Epoch 322/1000 - Train Loss: 0.3558, Validation Loss: 0.3536\n",
      "Epoch 323/1000 - Train Loss: 0.3552, Validation Loss: 0.3530\n",
      "Epoch 324/1000 - Train Loss: 0.3547, Validation Loss: 0.3525\n",
      "Epoch 325/1000 - Train Loss: 0.3541, Validation Loss: 0.3519\n",
      "Epoch 326/1000 - Train Loss: 0.3536, Validation Loss: 0.3514\n",
      "Epoch 327/1000 - Train Loss: 0.3530, Validation Loss: 0.3508\n",
      "Epoch 328/1000 - Train Loss: 0.3525, Validation Loss: 0.3503\n",
      "Epoch 329/1000 - Train Loss: 0.3520, Validation Loss: 0.3498\n",
      "Epoch 330/1000 - Train Loss: 0.3514, Validation Loss: 0.3492\n",
      "Epoch 331/1000 - Train Loss: 0.3509, Validation Loss: 0.3487\n",
      "Epoch 332/1000 - Train Loss: 0.3503, Validation Loss: 0.3481\n",
      "Epoch 333/1000 - Train Loss: 0.3498, Validation Loss: 0.3476\n",
      "Epoch 334/1000 - Train Loss: 0.3493, Validation Loss: 0.3471\n",
      "Epoch 335/1000 - Train Loss: 0.3487, Validation Loss: 0.3465\n",
      "Epoch 336/1000 - Train Loss: 0.3482, Validation Loss: 0.3460\n",
      "Epoch 337/1000 - Train Loss: 0.3477, Validation Loss: 0.3455\n",
      "Epoch 338/1000 - Train Loss: 0.3471, Validation Loss: 0.3449\n",
      "Epoch 339/1000 - Train Loss: 0.3466, Validation Loss: 0.3444\n",
      "Epoch 340/1000 - Train Loss: 0.3461, Validation Loss: 0.3439\n",
      "Epoch 341/1000 - Train Loss: 0.3455, Validation Loss: 0.3434\n",
      "Epoch 342/1000 - Train Loss: 0.3450, Validation Loss: 0.3429\n",
      "Epoch 343/1000 - Train Loss: 0.3445, Validation Loss: 0.3423\n",
      "Epoch 344/1000 - Train Loss: 0.3440, Validation Loss: 0.3418\n",
      "Epoch 345/1000 - Train Loss: 0.3435, Validation Loss: 0.3413\n",
      "Epoch 346/1000 - Train Loss: 0.3429, Validation Loss: 0.3408\n",
      "Epoch 347/1000 - Train Loss: 0.3424, Validation Loss: 0.3403\n",
      "Epoch 348/1000 - Train Loss: 0.3419, Validation Loss: 0.3398\n",
      "Epoch 349/1000 - Train Loss: 0.3414, Validation Loss: 0.3392\n",
      "Epoch 350/1000 - Train Loss: 0.3409, Validation Loss: 0.3387\n",
      "Epoch 351/1000 - Train Loss: 0.3404, Validation Loss: 0.3382\n",
      "Epoch 352/1000 - Train Loss: 0.3399, Validation Loss: 0.3377\n",
      "Epoch 353/1000 - Train Loss: 0.3394, Validation Loss: 0.3372\n",
      "Epoch 354/1000 - Train Loss: 0.3389, Validation Loss: 0.3367\n",
      "Epoch 355/1000 - Train Loss: 0.3384, Validation Loss: 0.3362\n",
      "Epoch 356/1000 - Train Loss: 0.3378, Validation Loss: 0.3357\n",
      "Epoch 357/1000 - Train Loss: 0.3373, Validation Loss: 0.3352\n",
      "Epoch 358/1000 - Train Loss: 0.3368, Validation Loss: 0.3347\n",
      "Epoch 359/1000 - Train Loss: 0.3364, Validation Loss: 0.3342\n",
      "Epoch 360/1000 - Train Loss: 0.3359, Validation Loss: 0.3337\n",
      "Epoch 361/1000 - Train Loss: 0.3354, Validation Loss: 0.3332\n",
      "Epoch 362/1000 - Train Loss: 0.3349, Validation Loss: 0.3327\n",
      "Epoch 363/1000 - Train Loss: 0.3344, Validation Loss: 0.3323\n",
      "Epoch 364/1000 - Train Loss: 0.3339, Validation Loss: 0.3318\n",
      "Epoch 365/1000 - Train Loss: 0.3334, Validation Loss: 0.3313\n",
      "Epoch 366/1000 - Train Loss: 0.3329, Validation Loss: 0.3308\n",
      "Epoch 367/1000 - Train Loss: 0.3324, Validation Loss: 0.3303\n",
      "Epoch 368/1000 - Train Loss: 0.3319, Validation Loss: 0.3298\n",
      "Epoch 369/1000 - Train Loss: 0.3315, Validation Loss: 0.3293\n",
      "Epoch 370/1000 - Train Loss: 0.3310, Validation Loss: 0.3289\n",
      "Epoch 371/1000 - Train Loss: 0.3305, Validation Loss: 0.3284\n",
      "Epoch 372/1000 - Train Loss: 0.3300, Validation Loss: 0.3279\n",
      "Epoch 373/1000 - Train Loss: 0.3295, Validation Loss: 0.3274\n",
      "Epoch 374/1000 - Train Loss: 0.3291, Validation Loss: 0.3270\n",
      "Epoch 375/1000 - Train Loss: 0.3286, Validation Loss: 0.3265\n",
      "Epoch 376/1000 - Train Loss: 0.3281, Validation Loss: 0.3260\n",
      "Epoch 377/1000 - Train Loss: 0.3276, Validation Loss: 0.3255\n",
      "Epoch 378/1000 - Train Loss: 0.3272, Validation Loss: 0.3251\n",
      "Epoch 379/1000 - Train Loss: 0.3267, Validation Loss: 0.3246\n",
      "Epoch 380/1000 - Train Loss: 0.3262, Validation Loss: 0.3241\n",
      "Epoch 381/1000 - Train Loss: 0.3258, Validation Loss: 0.3237\n",
      "Epoch 382/1000 - Train Loss: 0.3253, Validation Loss: 0.3232\n",
      "Epoch 383/1000 - Train Loss: 0.3248, Validation Loss: 0.3227\n",
      "Epoch 384/1000 - Train Loss: 0.3244, Validation Loss: 0.3223\n",
      "Epoch 385/1000 - Train Loss: 0.3239, Validation Loss: 0.3218\n",
      "Epoch 386/1000 - Train Loss: 0.3234, Validation Loss: 0.3214\n",
      "Epoch 387/1000 - Train Loss: 0.3230, Validation Loss: 0.3209\n",
      "Epoch 388/1000 - Train Loss: 0.3225, Validation Loss: 0.3205\n",
      "Epoch 389/1000 - Train Loss: 0.3221, Validation Loss: 0.3200\n",
      "Epoch 390/1000 - Train Loss: 0.3216, Validation Loss: 0.3195\n",
      "Epoch 391/1000 - Train Loss: 0.3212, Validation Loss: 0.3191\n",
      "Epoch 392/1000 - Train Loss: 0.3207, Validation Loss: 0.3186\n",
      "Epoch 393/1000 - Train Loss: 0.3203, Validation Loss: 0.3182\n",
      "Epoch 394/1000 - Train Loss: 0.3198, Validation Loss: 0.3177\n",
      "Epoch 395/1000 - Train Loss: 0.3194, Validation Loss: 0.3173\n",
      "Epoch 396/1000 - Train Loss: 0.3189, Validation Loss: 0.3169\n",
      "Epoch 397/1000 - Train Loss: 0.3185, Validation Loss: 0.3164\n",
      "Epoch 398/1000 - Train Loss: 0.3180, Validation Loss: 0.3160\n",
      "Epoch 399/1000 - Train Loss: 0.3176, Validation Loss: 0.3155\n",
      "Epoch 400/1000 - Train Loss: 0.3171, Validation Loss: 0.3151\n",
      "Epoch 401/1000 - Train Loss: 0.3167, Validation Loss: 0.3146\n",
      "Epoch 402/1000 - Train Loss: 0.3163, Validation Loss: 0.3142\n",
      "Epoch 403/1000 - Train Loss: 0.3158, Validation Loss: 0.3138\n",
      "Epoch 404/1000 - Train Loss: 0.3154, Validation Loss: 0.3133\n",
      "Epoch 405/1000 - Train Loss: 0.3149, Validation Loss: 0.3129\n",
      "Epoch 406/1000 - Train Loss: 0.3145, Validation Loss: 0.3125\n",
      "Epoch 407/1000 - Train Loss: 0.3141, Validation Loss: 0.3120\n",
      "Epoch 408/1000 - Train Loss: 0.3136, Validation Loss: 0.3116\n",
      "Epoch 409/1000 - Train Loss: 0.3132, Validation Loss: 0.3112\n",
      "Epoch 410/1000 - Train Loss: 0.3128, Validation Loss: 0.3107\n",
      "Epoch 411/1000 - Train Loss: 0.3124, Validation Loss: 0.3103\n",
      "Epoch 412/1000 - Train Loss: 0.3119, Validation Loss: 0.3099\n",
      "Epoch 413/1000 - Train Loss: 0.3115, Validation Loss: 0.3095\n",
      "Epoch 414/1000 - Train Loss: 0.3111, Validation Loss: 0.3090\n",
      "Epoch 415/1000 - Train Loss: 0.3107, Validation Loss: 0.3086\n",
      "Epoch 416/1000 - Train Loss: 0.3102, Validation Loss: 0.3082\n",
      "Epoch 417/1000 - Train Loss: 0.3098, Validation Loss: 0.3078\n",
      "Epoch 418/1000 - Train Loss: 0.3094, Validation Loss: 0.3074\n",
      "Epoch 419/1000 - Train Loss: 0.3090, Validation Loss: 0.3069\n",
      "Epoch 420/1000 - Train Loss: 0.3085, Validation Loss: 0.3065\n",
      "Epoch 421/1000 - Train Loss: 0.3081, Validation Loss: 0.3061\n",
      "Epoch 422/1000 - Train Loss: 0.3077, Validation Loss: 0.3057\n",
      "Epoch 423/1000 - Train Loss: 0.3073, Validation Loss: 0.3053\n",
      "Epoch 424/1000 - Train Loss: 0.3069, Validation Loss: 0.3049\n",
      "Epoch 425/1000 - Train Loss: 0.3065, Validation Loss: 0.3045\n",
      "Epoch 426/1000 - Train Loss: 0.3061, Validation Loss: 0.3041\n",
      "Epoch 427/1000 - Train Loss: 0.3057, Validation Loss: 0.3036\n",
      "Epoch 428/1000 - Train Loss: 0.3052, Validation Loss: 0.3032\n",
      "Epoch 429/1000 - Train Loss: 0.3048, Validation Loss: 0.3028\n",
      "Epoch 430/1000 - Train Loss: 0.3044, Validation Loss: 0.3024\n",
      "Epoch 431/1000 - Train Loss: 0.3040, Validation Loss: 0.3020\n",
      "Epoch 432/1000 - Train Loss: 0.3036, Validation Loss: 0.3016\n",
      "Epoch 433/1000 - Train Loss: 0.3032, Validation Loss: 0.3012\n",
      "Epoch 434/1000 - Train Loss: 0.3028, Validation Loss: 0.3008\n",
      "Epoch 435/1000 - Train Loss: 0.3024, Validation Loss: 0.3004\n",
      "Epoch 436/1000 - Train Loss: 0.3020, Validation Loss: 0.3000\n",
      "Epoch 437/1000 - Train Loss: 0.3016, Validation Loss: 0.2996\n",
      "Epoch 438/1000 - Train Loss: 0.3012, Validation Loss: 0.2992\n",
      "Epoch 439/1000 - Train Loss: 0.3008, Validation Loss: 0.2988\n",
      "Epoch 440/1000 - Train Loss: 0.3004, Validation Loss: 0.2984\n",
      "Epoch 441/1000 - Train Loss: 0.3000, Validation Loss: 0.2980\n",
      "Epoch 442/1000 - Train Loss: 0.2996, Validation Loss: 0.2976\n",
      "Epoch 443/1000 - Train Loss: 0.2992, Validation Loss: 0.2973\n",
      "Epoch 444/1000 - Train Loss: 0.2988, Validation Loss: 0.2969\n",
      "Epoch 445/1000 - Train Loss: 0.2985, Validation Loss: 0.2965\n",
      "Epoch 446/1000 - Train Loss: 0.2981, Validation Loss: 0.2961\n",
      "Epoch 447/1000 - Train Loss: 0.2977, Validation Loss: 0.2957\n",
      "Epoch 448/1000 - Train Loss: 0.2973, Validation Loss: 0.2953\n",
      "Epoch 449/1000 - Train Loss: 0.2969, Validation Loss: 0.2949\n",
      "Epoch 450/1000 - Train Loss: 0.2965, Validation Loss: 0.2945\n",
      "Epoch 451/1000 - Train Loss: 0.2961, Validation Loss: 0.2942\n",
      "Epoch 452/1000 - Train Loss: 0.2957, Validation Loss: 0.2938\n",
      "Epoch 453/1000 - Train Loss: 0.2954, Validation Loss: 0.2934\n",
      "Epoch 454/1000 - Train Loss: 0.2950, Validation Loss: 0.2930\n",
      "Epoch 455/1000 - Train Loss: 0.2946, Validation Loss: 0.2926\n",
      "Epoch 456/1000 - Train Loss: 0.2942, Validation Loss: 0.2923\n",
      "Epoch 457/1000 - Train Loss: 0.2938, Validation Loss: 0.2919\n",
      "Epoch 458/1000 - Train Loss: 0.2935, Validation Loss: 0.2915\n",
      "Epoch 459/1000 - Train Loss: 0.2931, Validation Loss: 0.2911\n",
      "Epoch 460/1000 - Train Loss: 0.2927, Validation Loss: 0.2908\n",
      "Epoch 461/1000 - Train Loss: 0.2923, Validation Loss: 0.2904\n",
      "Epoch 462/1000 - Train Loss: 0.2920, Validation Loss: 0.2900\n",
      "Epoch 463/1000 - Train Loss: 0.2916, Validation Loss: 0.2896\n",
      "Epoch 464/1000 - Train Loss: 0.2912, Validation Loss: 0.2893\n",
      "Epoch 465/1000 - Train Loss: 0.2909, Validation Loss: 0.2889\n",
      "Epoch 466/1000 - Train Loss: 0.2905, Validation Loss: 0.2885\n",
      "Epoch 467/1000 - Train Loss: 0.2901, Validation Loss: 0.2882\n",
      "Epoch 468/1000 - Train Loss: 0.2897, Validation Loss: 0.2878\n",
      "Epoch 469/1000 - Train Loss: 0.2894, Validation Loss: 0.2874\n",
      "Epoch 470/1000 - Train Loss: 0.2890, Validation Loss: 0.2871\n",
      "Epoch 471/1000 - Train Loss: 0.2887, Validation Loss: 0.2867\n",
      "Epoch 472/1000 - Train Loss: 0.2883, Validation Loss: 0.2863\n",
      "Epoch 473/1000 - Train Loss: 0.2879, Validation Loss: 0.2860\n",
      "Epoch 474/1000 - Train Loss: 0.2876, Validation Loss: 0.2856\n",
      "Epoch 475/1000 - Train Loss: 0.2872, Validation Loss: 0.2853\n",
      "Epoch 476/1000 - Train Loss: 0.2868, Validation Loss: 0.2849\n",
      "Epoch 477/1000 - Train Loss: 0.2865, Validation Loss: 0.2846\n",
      "Epoch 478/1000 - Train Loss: 0.2861, Validation Loss: 0.2842\n",
      "Epoch 479/1000 - Train Loss: 0.2858, Validation Loss: 0.2838\n",
      "Epoch 480/1000 - Train Loss: 0.2854, Validation Loss: 0.2835\n",
      "Epoch 481/1000 - Train Loss: 0.2851, Validation Loss: 0.2831\n",
      "Epoch 482/1000 - Train Loss: 0.2847, Validation Loss: 0.2828\n",
      "Epoch 483/1000 - Train Loss: 0.2843, Validation Loss: 0.2824\n",
      "Epoch 484/1000 - Train Loss: 0.2840, Validation Loss: 0.2821\n",
      "Epoch 485/1000 - Train Loss: 0.2836, Validation Loss: 0.2817\n",
      "Epoch 486/1000 - Train Loss: 0.2833, Validation Loss: 0.2814\n",
      "Epoch 487/1000 - Train Loss: 0.2829, Validation Loss: 0.2810\n",
      "Epoch 488/1000 - Train Loss: 0.2826, Validation Loss: 0.2807\n",
      "Epoch 489/1000 - Train Loss: 0.2822, Validation Loss: 0.2803\n",
      "Epoch 490/1000 - Train Loss: 0.2819, Validation Loss: 0.2800\n",
      "Epoch 491/1000 - Train Loss: 0.2815, Validation Loss: 0.2796\n",
      "Epoch 492/1000 - Train Loss: 0.2812, Validation Loss: 0.2793\n",
      "Epoch 493/1000 - Train Loss: 0.2809, Validation Loss: 0.2789\n",
      "Epoch 494/1000 - Train Loss: 0.2805, Validation Loss: 0.2786\n",
      "Epoch 495/1000 - Train Loss: 0.2802, Validation Loss: 0.2783\n",
      "Epoch 496/1000 - Train Loss: 0.2798, Validation Loss: 0.2779\n",
      "Epoch 497/1000 - Train Loss: 0.2795, Validation Loss: 0.2776\n",
      "Epoch 498/1000 - Train Loss: 0.2791, Validation Loss: 0.2772\n",
      "Epoch 499/1000 - Train Loss: 0.2788, Validation Loss: 0.2769\n",
      "Epoch 500/1000 - Train Loss: 0.2785, Validation Loss: 0.2766\n",
      "Epoch 501/1000 - Train Loss: 0.2781, Validation Loss: 0.2762\n",
      "Epoch 502/1000 - Train Loss: 0.2778, Validation Loss: 0.2759\n",
      "Epoch 503/1000 - Train Loss: 0.2775, Validation Loss: 0.2756\n",
      "Epoch 504/1000 - Train Loss: 0.2771, Validation Loss: 0.2752\n",
      "Epoch 505/1000 - Train Loss: 0.2768, Validation Loss: 0.2749\n",
      "Epoch 506/1000 - Train Loss: 0.2765, Validation Loss: 0.2746\n",
      "Epoch 507/1000 - Train Loss: 0.2761, Validation Loss: 0.2742\n",
      "Epoch 508/1000 - Train Loss: 0.2758, Validation Loss: 0.2739\n",
      "Epoch 509/1000 - Train Loss: 0.2755, Validation Loss: 0.2736\n",
      "Epoch 510/1000 - Train Loss: 0.2751, Validation Loss: 0.2732\n",
      "Epoch 511/1000 - Train Loss: 0.2748, Validation Loss: 0.2729\n",
      "Epoch 512/1000 - Train Loss: 0.2745, Validation Loss: 0.2726\n",
      "Epoch 513/1000 - Train Loss: 0.2741, Validation Loss: 0.2723\n",
      "Epoch 514/1000 - Train Loss: 0.2738, Validation Loss: 0.2719\n",
      "Epoch 515/1000 - Train Loss: 0.2735, Validation Loss: 0.2716\n",
      "Epoch 516/1000 - Train Loss: 0.2732, Validation Loss: 0.2713\n",
      "Epoch 517/1000 - Train Loss: 0.2728, Validation Loss: 0.2710\n",
      "Epoch 518/1000 - Train Loss: 0.2725, Validation Loss: 0.2706\n",
      "Epoch 519/1000 - Train Loss: 0.2722, Validation Loss: 0.2703\n",
      "Epoch 520/1000 - Train Loss: 0.2719, Validation Loss: 0.2700\n",
      "Epoch 521/1000 - Train Loss: 0.2715, Validation Loss: 0.2697\n",
      "Epoch 522/1000 - Train Loss: 0.2712, Validation Loss: 0.2694\n",
      "Epoch 523/1000 - Train Loss: 0.2709, Validation Loss: 0.2690\n",
      "Epoch 524/1000 - Train Loss: 0.2706, Validation Loss: 0.2687\n",
      "Epoch 525/1000 - Train Loss: 0.2703, Validation Loss: 0.2684\n",
      "Epoch 526/1000 - Train Loss: 0.2700, Validation Loss: 0.2681\n",
      "Epoch 527/1000 - Train Loss: 0.2696, Validation Loss: 0.2678\n",
      "Epoch 528/1000 - Train Loss: 0.2693, Validation Loss: 0.2675\n",
      "Epoch 529/1000 - Train Loss: 0.2690, Validation Loss: 0.2671\n",
      "Epoch 530/1000 - Train Loss: 0.2687, Validation Loss: 0.2668\n",
      "Epoch 531/1000 - Train Loss: 0.2684, Validation Loss: 0.2665\n",
      "Epoch 532/1000 - Train Loss: 0.2681, Validation Loss: 0.2662\n",
      "Epoch 533/1000 - Train Loss: 0.2678, Validation Loss: 0.2659\n",
      "Epoch 534/1000 - Train Loss: 0.2674, Validation Loss: 0.2656\n",
      "Epoch 535/1000 - Train Loss: 0.2671, Validation Loss: 0.2653\n",
      "Epoch 536/1000 - Train Loss: 0.2668, Validation Loss: 0.2650\n",
      "Epoch 537/1000 - Train Loss: 0.2665, Validation Loss: 0.2647\n",
      "Epoch 538/1000 - Train Loss: 0.2662, Validation Loss: 0.2643\n",
      "Epoch 539/1000 - Train Loss: 0.2659, Validation Loss: 0.2640\n",
      "Epoch 540/1000 - Train Loss: 0.2656, Validation Loss: 0.2637\n",
      "Epoch 541/1000 - Train Loss: 0.2653, Validation Loss: 0.2634\n",
      "Epoch 542/1000 - Train Loss: 0.2650, Validation Loss: 0.2631\n",
      "Epoch 543/1000 - Train Loss: 0.2647, Validation Loss: 0.2628\n",
      "Epoch 544/1000 - Train Loss: 0.2644, Validation Loss: 0.2625\n",
      "Epoch 545/1000 - Train Loss: 0.2641, Validation Loss: 0.2622\n",
      "Epoch 546/1000 - Train Loss: 0.2638, Validation Loss: 0.2619\n",
      "Epoch 547/1000 - Train Loss: 0.2635, Validation Loss: 0.2616\n",
      "Epoch 548/1000 - Train Loss: 0.2632, Validation Loss: 0.2613\n",
      "Epoch 549/1000 - Train Loss: 0.2629, Validation Loss: 0.2610\n",
      "Epoch 550/1000 - Train Loss: 0.2626, Validation Loss: 0.2607\n",
      "Epoch 551/1000 - Train Loss: 0.2623, Validation Loss: 0.2604\n",
      "Epoch 552/1000 - Train Loss: 0.2620, Validation Loss: 0.2601\n",
      "Epoch 553/1000 - Train Loss: 0.2617, Validation Loss: 0.2598\n",
      "Epoch 554/1000 - Train Loss: 0.2614, Validation Loss: 0.2595\n",
      "Epoch 555/1000 - Train Loss: 0.2611, Validation Loss: 0.2592\n",
      "Epoch 556/1000 - Train Loss: 0.2608, Validation Loss: 0.2589\n",
      "Epoch 557/1000 - Train Loss: 0.2605, Validation Loss: 0.2586\n",
      "Epoch 558/1000 - Train Loss: 0.2602, Validation Loss: 0.2584\n",
      "Epoch 559/1000 - Train Loss: 0.2599, Validation Loss: 0.2581\n",
      "Epoch 560/1000 - Train Loss: 0.2596, Validation Loss: 0.2578\n",
      "Epoch 561/1000 - Train Loss: 0.2593, Validation Loss: 0.2575\n",
      "Epoch 562/1000 - Train Loss: 0.2590, Validation Loss: 0.2572\n",
      "Epoch 563/1000 - Train Loss: 0.2587, Validation Loss: 0.2569\n",
      "Epoch 564/1000 - Train Loss: 0.2584, Validation Loss: 0.2566\n",
      "Epoch 565/1000 - Train Loss: 0.2581, Validation Loss: 0.2563\n",
      "Epoch 566/1000 - Train Loss: 0.2579, Validation Loss: 0.2560\n",
      "Epoch 567/1000 - Train Loss: 0.2576, Validation Loss: 0.2557\n",
      "Epoch 568/1000 - Train Loss: 0.2573, Validation Loss: 0.2555\n",
      "Epoch 569/1000 - Train Loss: 0.2570, Validation Loss: 0.2552\n",
      "Epoch 570/1000 - Train Loss: 0.2567, Validation Loss: 0.2549\n",
      "Epoch 571/1000 - Train Loss: 0.2564, Validation Loss: 0.2546\n",
      "Epoch 572/1000 - Train Loss: 0.2561, Validation Loss: 0.2543\n",
      "Epoch 573/1000 - Train Loss: 0.2559, Validation Loss: 0.2540\n",
      "Epoch 574/1000 - Train Loss: 0.2556, Validation Loss: 0.2538\n",
      "Epoch 575/1000 - Train Loss: 0.2553, Validation Loss: 0.2535\n",
      "Epoch 576/1000 - Train Loss: 0.2550, Validation Loss: 0.2532\n",
      "Epoch 577/1000 - Train Loss: 0.2547, Validation Loss: 0.2529\n",
      "Epoch 578/1000 - Train Loss: 0.2544, Validation Loss: 0.2526\n",
      "Epoch 579/1000 - Train Loss: 0.2542, Validation Loss: 0.2524\n",
      "Epoch 580/1000 - Train Loss: 0.2539, Validation Loss: 0.2521\n",
      "Epoch 581/1000 - Train Loss: 0.2536, Validation Loss: 0.2518\n",
      "Epoch 582/1000 - Train Loss: 0.2533, Validation Loss: 0.2515\n",
      "Epoch 583/1000 - Train Loss: 0.2531, Validation Loss: 0.2513\n",
      "Epoch 584/1000 - Train Loss: 0.2528, Validation Loss: 0.2510\n",
      "Epoch 585/1000 - Train Loss: 0.2525, Validation Loss: 0.2507\n",
      "Epoch 586/1000 - Train Loss: 0.2522, Validation Loss: 0.2504\n",
      "Epoch 587/1000 - Train Loss: 0.2520, Validation Loss: 0.2502\n",
      "Epoch 588/1000 - Train Loss: 0.2517, Validation Loss: 0.2499\n",
      "Epoch 589/1000 - Train Loss: 0.2514, Validation Loss: 0.2496\n",
      "Epoch 590/1000 - Train Loss: 0.2511, Validation Loss: 0.2493\n",
      "Epoch 591/1000 - Train Loss: 0.2509, Validation Loss: 0.2491\n",
      "Epoch 592/1000 - Train Loss: 0.2506, Validation Loss: 0.2488\n",
      "Epoch 593/1000 - Train Loss: 0.2503, Validation Loss: 0.2485\n",
      "Epoch 594/1000 - Train Loss: 0.2500, Validation Loss: 0.2483\n",
      "Epoch 595/1000 - Train Loss: 0.2498, Validation Loss: 0.2480\n",
      "Epoch 596/1000 - Train Loss: 0.2495, Validation Loss: 0.2477\n",
      "Epoch 597/1000 - Train Loss: 0.2492, Validation Loss: 0.2474\n",
      "Epoch 598/1000 - Train Loss: 0.2490, Validation Loss: 0.2472\n",
      "Epoch 599/1000 - Train Loss: 0.2487, Validation Loss: 0.2469\n",
      "Epoch 600/1000 - Train Loss: 0.2484, Validation Loss: 0.2466\n",
      "Epoch 601/1000 - Train Loss: 0.2482, Validation Loss: 0.2464\n",
      "Epoch 602/1000 - Train Loss: 0.2479, Validation Loss: 0.2461\n",
      "Epoch 603/1000 - Train Loss: 0.2476, Validation Loss: 0.2459\n",
      "Epoch 604/1000 - Train Loss: 0.2474, Validation Loss: 0.2456\n",
      "Epoch 605/1000 - Train Loss: 0.2471, Validation Loss: 0.2453\n",
      "Epoch 606/1000 - Train Loss: 0.2468, Validation Loss: 0.2451\n",
      "Epoch 607/1000 - Train Loss: 0.2466, Validation Loss: 0.2448\n",
      "Epoch 608/1000 - Train Loss: 0.2463, Validation Loss: 0.2445\n",
      "Epoch 609/1000 - Train Loss: 0.2461, Validation Loss: 0.2443\n",
      "Epoch 610/1000 - Train Loss: 0.2458, Validation Loss: 0.2440\n",
      "Epoch 611/1000 - Train Loss: 0.2455, Validation Loss: 0.2438\n",
      "Epoch 612/1000 - Train Loss: 0.2453, Validation Loss: 0.2435\n",
      "Epoch 613/1000 - Train Loss: 0.2450, Validation Loss: 0.2432\n",
      "Epoch 614/1000 - Train Loss: 0.2448, Validation Loss: 0.2430\n",
      "Epoch 615/1000 - Train Loss: 0.2445, Validation Loss: 0.2427\n",
      "Epoch 616/1000 - Train Loss: 0.2442, Validation Loss: 0.2425\n",
      "Epoch 617/1000 - Train Loss: 0.2440, Validation Loss: 0.2422\n",
      "Epoch 618/1000 - Train Loss: 0.2437, Validation Loss: 0.2420\n",
      "Epoch 619/1000 - Train Loss: 0.2435, Validation Loss: 0.2417\n",
      "Epoch 620/1000 - Train Loss: 0.2432, Validation Loss: 0.2415\n",
      "Epoch 621/1000 - Train Loss: 0.2430, Validation Loss: 0.2412\n",
      "Epoch 622/1000 - Train Loss: 0.2427, Validation Loss: 0.2410\n",
      "Epoch 623/1000 - Train Loss: 0.2425, Validation Loss: 0.2407\n",
      "Epoch 624/1000 - Train Loss: 0.2422, Validation Loss: 0.2404\n",
      "Epoch 625/1000 - Train Loss: 0.2420, Validation Loss: 0.2402\n",
      "Epoch 626/1000 - Train Loss: 0.2417, Validation Loss: 0.2399\n",
      "Epoch 627/1000 - Train Loss: 0.2415, Validation Loss: 0.2397\n",
      "Epoch 628/1000 - Train Loss: 0.2412, Validation Loss: 0.2394\n",
      "Epoch 629/1000 - Train Loss: 0.2410, Validation Loss: 0.2392\n",
      "Epoch 630/1000 - Train Loss: 0.2407, Validation Loss: 0.2389\n",
      "Epoch 631/1000 - Train Loss: 0.2405, Validation Loss: 0.2387\n",
      "Epoch 632/1000 - Train Loss: 0.2402, Validation Loss: 0.2385\n",
      "Epoch 633/1000 - Train Loss: 0.2400, Validation Loss: 0.2382\n",
      "Epoch 634/1000 - Train Loss: 0.2397, Validation Loss: 0.2380\n",
      "Epoch 635/1000 - Train Loss: 0.2395, Validation Loss: 0.2377\n",
      "Epoch 636/1000 - Train Loss: 0.2392, Validation Loss: 0.2375\n",
      "Epoch 637/1000 - Train Loss: 0.2390, Validation Loss: 0.2372\n",
      "Epoch 638/1000 - Train Loss: 0.2387, Validation Loss: 0.2370\n",
      "Epoch 639/1000 - Train Loss: 0.2385, Validation Loss: 0.2367\n",
      "Epoch 640/1000 - Train Loss: 0.2382, Validation Loss: 0.2365\n",
      "Epoch 641/1000 - Train Loss: 0.2380, Validation Loss: 0.2362\n",
      "Epoch 642/1000 - Train Loss: 0.2378, Validation Loss: 0.2360\n",
      "Epoch 643/1000 - Train Loss: 0.2375, Validation Loss: 0.2358\n",
      "Epoch 644/1000 - Train Loss: 0.2373, Validation Loss: 0.2355\n",
      "Epoch 645/1000 - Train Loss: 0.2370, Validation Loss: 0.2353\n",
      "Epoch 646/1000 - Train Loss: 0.2368, Validation Loss: 0.2350\n",
      "Epoch 647/1000 - Train Loss: 0.2365, Validation Loss: 0.2348\n",
      "Epoch 648/1000 - Train Loss: 0.2363, Validation Loss: 0.2346\n",
      "Epoch 649/1000 - Train Loss: 0.2361, Validation Loss: 0.2343\n",
      "Epoch 650/1000 - Train Loss: 0.2358, Validation Loss: 0.2341\n",
      "Epoch 651/1000 - Train Loss: 0.2356, Validation Loss: 0.2339\n",
      "Epoch 652/1000 - Train Loss: 0.2354, Validation Loss: 0.2336\n",
      "Epoch 653/1000 - Train Loss: 0.2351, Validation Loss: 0.2334\n",
      "Epoch 654/1000 - Train Loss: 0.2349, Validation Loss: 0.2331\n",
      "Epoch 655/1000 - Train Loss: 0.2346, Validation Loss: 0.2329\n",
      "Epoch 656/1000 - Train Loss: 0.2344, Validation Loss: 0.2327\n",
      "Epoch 657/1000 - Train Loss: 0.2342, Validation Loss: 0.2324\n",
      "Epoch 658/1000 - Train Loss: 0.2339, Validation Loss: 0.2322\n",
      "Epoch 659/1000 - Train Loss: 0.2337, Validation Loss: 0.2320\n",
      "Epoch 660/1000 - Train Loss: 0.2335, Validation Loss: 0.2317\n",
      "Epoch 661/1000 - Train Loss: 0.2332, Validation Loss: 0.2315\n",
      "Epoch 662/1000 - Train Loss: 0.2330, Validation Loss: 0.2313\n",
      "Epoch 663/1000 - Train Loss: 0.2328, Validation Loss: 0.2310\n",
      "Epoch 664/1000 - Train Loss: 0.2325, Validation Loss: 0.2308\n",
      "Epoch 665/1000 - Train Loss: 0.2323, Validation Loss: 0.2306\n",
      "Epoch 666/1000 - Train Loss: 0.2321, Validation Loss: 0.2303\n",
      "Epoch 667/1000 - Train Loss: 0.2318, Validation Loss: 0.2301\n",
      "Epoch 668/1000 - Train Loss: 0.2316, Validation Loss: 0.2299\n",
      "Epoch 669/1000 - Train Loss: 0.2314, Validation Loss: 0.2297\n",
      "Epoch 670/1000 - Train Loss: 0.2312, Validation Loss: 0.2294\n",
      "Epoch 671/1000 - Train Loss: 0.2309, Validation Loss: 0.2292\n",
      "Epoch 672/1000 - Train Loss: 0.2307, Validation Loss: 0.2290\n",
      "Epoch 673/1000 - Train Loss: 0.2305, Validation Loss: 0.2288\n",
      "Epoch 674/1000 - Train Loss: 0.2302, Validation Loss: 0.2285\n",
      "Epoch 675/1000 - Train Loss: 0.2300, Validation Loss: 0.2283\n",
      "Epoch 676/1000 - Train Loss: 0.2298, Validation Loss: 0.2281\n",
      "Epoch 677/1000 - Train Loss: 0.2296, Validation Loss: 0.2279\n",
      "Epoch 678/1000 - Train Loss: 0.2293, Validation Loss: 0.2276\n",
      "Epoch 679/1000 - Train Loss: 0.2291, Validation Loss: 0.2274\n",
      "Epoch 680/1000 - Train Loss: 0.2289, Validation Loss: 0.2272\n",
      "Epoch 681/1000 - Train Loss: 0.2287, Validation Loss: 0.2270\n",
      "Epoch 682/1000 - Train Loss: 0.2284, Validation Loss: 0.2267\n",
      "Epoch 683/1000 - Train Loss: 0.2282, Validation Loss: 0.2265\n",
      "Epoch 684/1000 - Train Loss: 0.2280, Validation Loss: 0.2263\n",
      "Epoch 685/1000 - Train Loss: 0.2278, Validation Loss: 0.2261\n",
      "Epoch 686/1000 - Train Loss: 0.2276, Validation Loss: 0.2259\n",
      "Epoch 687/1000 - Train Loss: 0.2273, Validation Loss: 0.2256\n",
      "Epoch 688/1000 - Train Loss: 0.2271, Validation Loss: 0.2254\n",
      "Epoch 689/1000 - Train Loss: 0.2269, Validation Loss: 0.2252\n",
      "Epoch 690/1000 - Train Loss: 0.2267, Validation Loss: 0.2250\n",
      "Epoch 691/1000 - Train Loss: 0.2265, Validation Loss: 0.2248\n",
      "Epoch 692/1000 - Train Loss: 0.2262, Validation Loss: 0.2245\n",
      "Epoch 693/1000 - Train Loss: 0.2260, Validation Loss: 0.2243\n",
      "Epoch 694/1000 - Train Loss: 0.2258, Validation Loss: 0.2241\n",
      "Epoch 695/1000 - Train Loss: 0.2256, Validation Loss: 0.2239\n",
      "Epoch 696/1000 - Train Loss: 0.2254, Validation Loss: 0.2237\n",
      "Epoch 697/1000 - Train Loss: 0.2252, Validation Loss: 0.2235\n",
      "Epoch 698/1000 - Train Loss: 0.2249, Validation Loss: 0.2232\n",
      "Epoch 699/1000 - Train Loss: 0.2247, Validation Loss: 0.2230\n",
      "Epoch 700/1000 - Train Loss: 0.2245, Validation Loss: 0.2228\n",
      "Epoch 701/1000 - Train Loss: 0.2243, Validation Loss: 0.2226\n",
      "Epoch 702/1000 - Train Loss: 0.2241, Validation Loss: 0.2224\n",
      "Epoch 703/1000 - Train Loss: 0.2239, Validation Loss: 0.2222\n",
      "Epoch 704/1000 - Train Loss: 0.2237, Validation Loss: 0.2220\n",
      "Epoch 705/1000 - Train Loss: 0.2234, Validation Loss: 0.2217\n",
      "Epoch 706/1000 - Train Loss: 0.2232, Validation Loss: 0.2215\n",
      "Epoch 707/1000 - Train Loss: 0.2230, Validation Loss: 0.2213\n",
      "Epoch 708/1000 - Train Loss: 0.2228, Validation Loss: 0.2211\n",
      "Epoch 709/1000 - Train Loss: 0.2226, Validation Loss: 0.2209\n",
      "Epoch 710/1000 - Train Loss: 0.2224, Validation Loss: 0.2207\n",
      "Epoch 711/1000 - Train Loss: 0.2222, Validation Loss: 0.2205\n",
      "Epoch 712/1000 - Train Loss: 0.2220, Validation Loss: 0.2203\n",
      "Epoch 713/1000 - Train Loss: 0.2218, Validation Loss: 0.2201\n",
      "Epoch 714/1000 - Train Loss: 0.2215, Validation Loss: 0.2199\n",
      "Epoch 715/1000 - Train Loss: 0.2213, Validation Loss: 0.2196\n",
      "Epoch 716/1000 - Train Loss: 0.2211, Validation Loss: 0.2194\n",
      "Epoch 717/1000 - Train Loss: 0.2209, Validation Loss: 0.2192\n",
      "Epoch 718/1000 - Train Loss: 0.2207, Validation Loss: 0.2190\n",
      "Epoch 719/1000 - Train Loss: 0.2205, Validation Loss: 0.2188\n",
      "Epoch 720/1000 - Train Loss: 0.2203, Validation Loss: 0.2186\n",
      "Epoch 721/1000 - Train Loss: 0.2201, Validation Loss: 0.2184\n",
      "Epoch 722/1000 - Train Loss: 0.2199, Validation Loss: 0.2182\n",
      "Epoch 723/1000 - Train Loss: 0.2197, Validation Loss: 0.2180\n",
      "Epoch 724/1000 - Train Loss: 0.2195, Validation Loss: 0.2178\n",
      "Epoch 725/1000 - Train Loss: 0.2193, Validation Loss: 0.2176\n",
      "Epoch 726/1000 - Train Loss: 0.2191, Validation Loss: 0.2174\n",
      "Epoch 727/1000 - Train Loss: 0.2189, Validation Loss: 0.2172\n",
      "Epoch 728/1000 - Train Loss: 0.2187, Validation Loss: 0.2170\n",
      "Epoch 729/1000 - Train Loss: 0.2185, Validation Loss: 0.2168\n",
      "Epoch 730/1000 - Train Loss: 0.2183, Validation Loss: 0.2166\n",
      "Epoch 731/1000 - Train Loss: 0.2181, Validation Loss: 0.2164\n",
      "Epoch 732/1000 - Train Loss: 0.2179, Validation Loss: 0.2162\n",
      "Epoch 733/1000 - Train Loss: 0.2176, Validation Loss: 0.2160\n",
      "Epoch 734/1000 - Train Loss: 0.2174, Validation Loss: 0.2158\n",
      "Epoch 735/1000 - Train Loss: 0.2172, Validation Loss: 0.2156\n",
      "Epoch 736/1000 - Train Loss: 0.2170, Validation Loss: 0.2154\n",
      "Epoch 737/1000 - Train Loss: 0.2168, Validation Loss: 0.2152\n",
      "Epoch 738/1000 - Train Loss: 0.2166, Validation Loss: 0.2150\n",
      "Epoch 739/1000 - Train Loss: 0.2165, Validation Loss: 0.2148\n",
      "Epoch 740/1000 - Train Loss: 0.2163, Validation Loss: 0.2146\n",
      "Epoch 741/1000 - Train Loss: 0.2161, Validation Loss: 0.2144\n",
      "Epoch 742/1000 - Train Loss: 0.2159, Validation Loss: 0.2142\n",
      "Epoch 743/1000 - Train Loss: 0.2157, Validation Loss: 0.2140\n",
      "Epoch 744/1000 - Train Loss: 0.2155, Validation Loss: 0.2138\n",
      "Epoch 745/1000 - Train Loss: 0.2153, Validation Loss: 0.2136\n",
      "Epoch 746/1000 - Train Loss: 0.2151, Validation Loss: 0.2134\n",
      "Epoch 747/1000 - Train Loss: 0.2149, Validation Loss: 0.2132\n",
      "Epoch 748/1000 - Train Loss: 0.2147, Validation Loss: 0.2130\n",
      "Epoch 749/1000 - Train Loss: 0.2145, Validation Loss: 0.2128\n",
      "Epoch 750/1000 - Train Loss: 0.2143, Validation Loss: 0.2126\n",
      "Epoch 751/1000 - Train Loss: 0.2141, Validation Loss: 0.2124\n",
      "Epoch 752/1000 - Train Loss: 0.2139, Validation Loss: 0.2122\n",
      "Epoch 753/1000 - Train Loss: 0.2137, Validation Loss: 0.2121\n",
      "Epoch 754/1000 - Train Loss: 0.2135, Validation Loss: 0.2119\n",
      "Epoch 755/1000 - Train Loss: 0.2133, Validation Loss: 0.2117\n",
      "Epoch 756/1000 - Train Loss: 0.2131, Validation Loss: 0.2115\n",
      "Epoch 757/1000 - Train Loss: 0.2129, Validation Loss: 0.2113\n",
      "Epoch 758/1000 - Train Loss: 0.2127, Validation Loss: 0.2111\n",
      "Epoch 759/1000 - Train Loss: 0.2126, Validation Loss: 0.2109\n",
      "Epoch 760/1000 - Train Loss: 0.2124, Validation Loss: 0.2107\n",
      "Epoch 761/1000 - Train Loss: 0.2122, Validation Loss: 0.2105\n",
      "Epoch 762/1000 - Train Loss: 0.2120, Validation Loss: 0.2103\n",
      "Epoch 763/1000 - Train Loss: 0.2118, Validation Loss: 0.2101\n",
      "Epoch 764/1000 - Train Loss: 0.2116, Validation Loss: 0.2100\n",
      "Epoch 765/1000 - Train Loss: 0.2114, Validation Loss: 0.2098\n",
      "Epoch 766/1000 - Train Loss: 0.2112, Validation Loss: 0.2096\n",
      "Epoch 767/1000 - Train Loss: 0.2110, Validation Loss: 0.2094\n",
      "Epoch 768/1000 - Train Loss: 0.2108, Validation Loss: 0.2092\n",
      "Epoch 769/1000 - Train Loss: 0.2107, Validation Loss: 0.2090\n",
      "Epoch 770/1000 - Train Loss: 0.2105, Validation Loss: 0.2088\n",
      "Epoch 771/1000 - Train Loss: 0.2103, Validation Loss: 0.2086\n",
      "Epoch 772/1000 - Train Loss: 0.2101, Validation Loss: 0.2085\n",
      "Epoch 773/1000 - Train Loss: 0.2099, Validation Loss: 0.2083\n",
      "Epoch 774/1000 - Train Loss: 0.2097, Validation Loss: 0.2081\n",
      "Epoch 775/1000 - Train Loss: 0.2095, Validation Loss: 0.2079\n",
      "Epoch 776/1000 - Train Loss: 0.2094, Validation Loss: 0.2077\n",
      "Epoch 777/1000 - Train Loss: 0.2092, Validation Loss: 0.2075\n",
      "Epoch 778/1000 - Train Loss: 0.2090, Validation Loss: 0.2074\n",
      "Epoch 779/1000 - Train Loss: 0.2088, Validation Loss: 0.2072\n",
      "Epoch 780/1000 - Train Loss: 0.2086, Validation Loss: 0.2070\n",
      "Epoch 781/1000 - Train Loss: 0.2084, Validation Loss: 0.2068\n",
      "Epoch 782/1000 - Train Loss: 0.2083, Validation Loss: 0.2066\n",
      "Epoch 783/1000 - Train Loss: 0.2081, Validation Loss: 0.2064\n",
      "Epoch 784/1000 - Train Loss: 0.2079, Validation Loss: 0.2063\n",
      "Epoch 785/1000 - Train Loss: 0.2077, Validation Loss: 0.2061\n",
      "Epoch 786/1000 - Train Loss: 0.2075, Validation Loss: 0.2059\n",
      "Epoch 787/1000 - Train Loss: 0.2073, Validation Loss: 0.2057\n",
      "Epoch 788/1000 - Train Loss: 0.2072, Validation Loss: 0.2055\n",
      "Epoch 789/1000 - Train Loss: 0.2070, Validation Loss: 0.2054\n",
      "Epoch 790/1000 - Train Loss: 0.2068, Validation Loss: 0.2052\n",
      "Epoch 791/1000 - Train Loss: 0.2066, Validation Loss: 0.2050\n",
      "Epoch 792/1000 - Train Loss: 0.2064, Validation Loss: 0.2048\n",
      "Epoch 793/1000 - Train Loss: 0.2063, Validation Loss: 0.2046\n",
      "Epoch 794/1000 - Train Loss: 0.2061, Validation Loss: 0.2045\n",
      "Epoch 795/1000 - Train Loss: 0.2059, Validation Loss: 0.2043\n",
      "Epoch 796/1000 - Train Loss: 0.2057, Validation Loss: 0.2041\n",
      "Epoch 797/1000 - Train Loss: 0.2056, Validation Loss: 0.2039\n",
      "Epoch 798/1000 - Train Loss: 0.2054, Validation Loss: 0.2038\n",
      "Epoch 799/1000 - Train Loss: 0.2052, Validation Loss: 0.2036\n",
      "Epoch 800/1000 - Train Loss: 0.2050, Validation Loss: 0.2034\n",
      "Epoch 801/1000 - Train Loss: 0.2048, Validation Loss: 0.2032\n",
      "Epoch 802/1000 - Train Loss: 0.2047, Validation Loss: 0.2030\n",
      "Epoch 803/1000 - Train Loss: 0.2045, Validation Loss: 0.2029\n",
      "Epoch 804/1000 - Train Loss: 0.2043, Validation Loss: 0.2027\n",
      "Epoch 805/1000 - Train Loss: 0.2041, Validation Loss: 0.2025\n",
      "Epoch 806/1000 - Train Loss: 0.2040, Validation Loss: 0.2023\n",
      "Epoch 807/1000 - Train Loss: 0.2038, Validation Loss: 0.2022\n",
      "Epoch 808/1000 - Train Loss: 0.2036, Validation Loss: 0.2020\n",
      "Epoch 809/1000 - Train Loss: 0.2034, Validation Loss: 0.2018\n",
      "Epoch 810/1000 - Train Loss: 0.2033, Validation Loss: 0.2017\n",
      "Epoch 811/1000 - Train Loss: 0.2031, Validation Loss: 0.2015\n",
      "Epoch 812/1000 - Train Loss: 0.2029, Validation Loss: 0.2013\n",
      "Epoch 813/1000 - Train Loss: 0.2028, Validation Loss: 0.2011\n",
      "Epoch 814/1000 - Train Loss: 0.2026, Validation Loss: 0.2010\n",
      "Epoch 815/1000 - Train Loss: 0.2024, Validation Loss: 0.2008\n",
      "Epoch 816/1000 - Train Loss: 0.2022, Validation Loss: 0.2006\n",
      "Epoch 817/1000 - Train Loss: 0.2021, Validation Loss: 0.2005\n",
      "Epoch 818/1000 - Train Loss: 0.2019, Validation Loss: 0.2003\n",
      "Epoch 819/1000 - Train Loss: 0.2017, Validation Loss: 0.2001\n",
      "Epoch 820/1000 - Train Loss: 0.2016, Validation Loss: 0.1999\n",
      "Epoch 821/1000 - Train Loss: 0.2014, Validation Loss: 0.1998\n",
      "Epoch 822/1000 - Train Loss: 0.2012, Validation Loss: 0.1996\n",
      "Epoch 823/1000 - Train Loss: 0.2010, Validation Loss: 0.1994\n",
      "Epoch 824/1000 - Train Loss: 0.2009, Validation Loss: 0.1993\n",
      "Epoch 825/1000 - Train Loss: 0.2007, Validation Loss: 0.1991\n",
      "Epoch 826/1000 - Train Loss: 0.2005, Validation Loss: 0.1989\n",
      "Epoch 827/1000 - Train Loss: 0.2004, Validation Loss: 0.1988\n",
      "Epoch 828/1000 - Train Loss: 0.2002, Validation Loss: 0.1986\n",
      "Epoch 829/1000 - Train Loss: 0.2000, Validation Loss: 0.1984\n",
      "Epoch 830/1000 - Train Loss: 0.1999, Validation Loss: 0.1983\n",
      "Epoch 831/1000 - Train Loss: 0.1997, Validation Loss: 0.1981\n",
      "Epoch 832/1000 - Train Loss: 0.1995, Validation Loss: 0.1979\n",
      "Epoch 833/1000 - Train Loss: 0.1994, Validation Loss: 0.1978\n",
      "Epoch 834/1000 - Train Loss: 0.1992, Validation Loss: 0.1976\n",
      "Epoch 835/1000 - Train Loss: 0.1990, Validation Loss: 0.1974\n",
      "Epoch 836/1000 - Train Loss: 0.1989, Validation Loss: 0.1973\n",
      "Epoch 837/1000 - Train Loss: 0.1987, Validation Loss: 0.1971\n",
      "Epoch 838/1000 - Train Loss: 0.1985, Validation Loss: 0.1969\n",
      "Epoch 839/1000 - Train Loss: 0.1984, Validation Loss: 0.1968\n",
      "Epoch 840/1000 - Train Loss: 0.1982, Validation Loss: 0.1966\n",
      "Epoch 841/1000 - Train Loss: 0.1980, Validation Loss: 0.1964\n",
      "Epoch 842/1000 - Train Loss: 0.1979, Validation Loss: 0.1963\n",
      "Epoch 843/1000 - Train Loss: 0.1977, Validation Loss: 0.1961\n",
      "Epoch 844/1000 - Train Loss: 0.1976, Validation Loss: 0.1960\n",
      "Epoch 845/1000 - Train Loss: 0.1974, Validation Loss: 0.1958\n",
      "Epoch 846/1000 - Train Loss: 0.1972, Validation Loss: 0.1956\n",
      "Epoch 847/1000 - Train Loss: 0.1971, Validation Loss: 0.1955\n",
      "Epoch 848/1000 - Train Loss: 0.1969, Validation Loss: 0.1953\n",
      "Epoch 849/1000 - Train Loss: 0.1967, Validation Loss: 0.1952\n",
      "Epoch 850/1000 - Train Loss: 0.1966, Validation Loss: 0.1950\n",
      "Epoch 851/1000 - Train Loss: 0.1964, Validation Loss: 0.1948\n",
      "Epoch 852/1000 - Train Loss: 0.1963, Validation Loss: 0.1947\n",
      "Epoch 853/1000 - Train Loss: 0.1961, Validation Loss: 0.1945\n",
      "Epoch 854/1000 - Train Loss: 0.1959, Validation Loss: 0.1944\n",
      "Epoch 855/1000 - Train Loss: 0.1958, Validation Loss: 0.1942\n",
      "Epoch 856/1000 - Train Loss: 0.1956, Validation Loss: 0.1940\n",
      "Epoch 857/1000 - Train Loss: 0.1955, Validation Loss: 0.1939\n",
      "Epoch 858/1000 - Train Loss: 0.1953, Validation Loss: 0.1937\n",
      "Epoch 859/1000 - Train Loss: 0.1951, Validation Loss: 0.1936\n",
      "Epoch 860/1000 - Train Loss: 0.1950, Validation Loss: 0.1934\n",
      "Epoch 861/1000 - Train Loss: 0.1948, Validation Loss: 0.1932\n",
      "Epoch 862/1000 - Train Loss: 0.1947, Validation Loss: 0.1931\n",
      "Epoch 863/1000 - Train Loss: 0.1945, Validation Loss: 0.1929\n",
      "Epoch 864/1000 - Train Loss: 0.1944, Validation Loss: 0.1928\n",
      "Epoch 865/1000 - Train Loss: 0.1942, Validation Loss: 0.1926\n",
      "Epoch 866/1000 - Train Loss: 0.1940, Validation Loss: 0.1925\n",
      "Epoch 867/1000 - Train Loss: 0.1939, Validation Loss: 0.1923\n",
      "Epoch 868/1000 - Train Loss: 0.1937, Validation Loss: 0.1921\n",
      "Epoch 869/1000 - Train Loss: 0.1936, Validation Loss: 0.1920\n",
      "Epoch 870/1000 - Train Loss: 0.1934, Validation Loss: 0.1918\n",
      "Epoch 871/1000 - Train Loss: 0.1933, Validation Loss: 0.1917\n",
      "Epoch 872/1000 - Train Loss: 0.1931, Validation Loss: 0.1915\n",
      "Epoch 873/1000 - Train Loss: 0.1929, Validation Loss: 0.1914\n",
      "Epoch 874/1000 - Train Loss: 0.1928, Validation Loss: 0.1912\n",
      "Epoch 875/1000 - Train Loss: 0.1926, Validation Loss: 0.1911\n",
      "Epoch 876/1000 - Train Loss: 0.1925, Validation Loss: 0.1909\n",
      "Epoch 877/1000 - Train Loss: 0.1923, Validation Loss: 0.1908\n",
      "Epoch 878/1000 - Train Loss: 0.1922, Validation Loss: 0.1906\n",
      "Epoch 879/1000 - Train Loss: 0.1920, Validation Loss: 0.1905\n",
      "Epoch 880/1000 - Train Loss: 0.1919, Validation Loss: 0.1903\n",
      "Epoch 881/1000 - Train Loss: 0.1917, Validation Loss: 0.1901\n",
      "Epoch 882/1000 - Train Loss: 0.1916, Validation Loss: 0.1900\n",
      "Epoch 883/1000 - Train Loss: 0.1914, Validation Loss: 0.1898\n",
      "Epoch 884/1000 - Train Loss: 0.1913, Validation Loss: 0.1897\n",
      "Epoch 885/1000 - Train Loss: 0.1911, Validation Loss: 0.1895\n",
      "Epoch 886/1000 - Train Loss: 0.1910, Validation Loss: 0.1894\n",
      "Epoch 887/1000 - Train Loss: 0.1908, Validation Loss: 0.1892\n",
      "Epoch 888/1000 - Train Loss: 0.1907, Validation Loss: 0.1891\n",
      "Epoch 889/1000 - Train Loss: 0.1905, Validation Loss: 0.1889\n",
      "Epoch 890/1000 - Train Loss: 0.1904, Validation Loss: 0.1888\n",
      "Epoch 891/1000 - Train Loss: 0.1902, Validation Loss: 0.1886\n",
      "Epoch 892/1000 - Train Loss: 0.1901, Validation Loss: 0.1885\n",
      "Epoch 893/1000 - Train Loss: 0.1899, Validation Loss: 0.1883\n",
      "Epoch 894/1000 - Train Loss: 0.1898, Validation Loss: 0.1882\n",
      "Epoch 895/1000 - Train Loss: 0.1896, Validation Loss: 0.1880\n",
      "Epoch 896/1000 - Train Loss: 0.1895, Validation Loss: 0.1879\n",
      "Epoch 897/1000 - Train Loss: 0.1893, Validation Loss: 0.1877\n",
      "Epoch 898/1000 - Train Loss: 0.1892, Validation Loss: 0.1876\n",
      "Epoch 899/1000 - Train Loss: 0.1890, Validation Loss: 0.1875\n",
      "Epoch 900/1000 - Train Loss: 0.1889, Validation Loss: 0.1873\n",
      "Epoch 901/1000 - Train Loss: 0.1887, Validation Loss: 0.1872\n",
      "Epoch 902/1000 - Train Loss: 0.1886, Validation Loss: 0.1870\n",
      "Epoch 903/1000 - Train Loss: 0.1884, Validation Loss: 0.1869\n",
      "Epoch 904/1000 - Train Loss: 0.1883, Validation Loss: 0.1867\n",
      "Epoch 905/1000 - Train Loss: 0.1881, Validation Loss: 0.1866\n",
      "Epoch 906/1000 - Train Loss: 0.1880, Validation Loss: 0.1864\n",
      "Epoch 907/1000 - Train Loss: 0.1878, Validation Loss: 0.1863\n",
      "Epoch 908/1000 - Train Loss: 0.1877, Validation Loss: 0.1861\n",
      "Epoch 909/1000 - Train Loss: 0.1875, Validation Loss: 0.1860\n",
      "Epoch 910/1000 - Train Loss: 0.1874, Validation Loss: 0.1858\n",
      "Epoch 911/1000 - Train Loss: 0.1873, Validation Loss: 0.1857\n",
      "Epoch 912/1000 - Train Loss: 0.1871, Validation Loss: 0.1856\n",
      "Epoch 913/1000 - Train Loss: 0.1870, Validation Loss: 0.1854\n",
      "Epoch 914/1000 - Train Loss: 0.1868, Validation Loss: 0.1853\n",
      "Epoch 915/1000 - Train Loss: 0.1867, Validation Loss: 0.1851\n",
      "Epoch 916/1000 - Train Loss: 0.1865, Validation Loss: 0.1850\n",
      "Epoch 917/1000 - Train Loss: 0.1864, Validation Loss: 0.1848\n",
      "Epoch 918/1000 - Train Loss: 0.1862, Validation Loss: 0.1847\n",
      "Epoch 919/1000 - Train Loss: 0.1861, Validation Loss: 0.1846\n",
      "Epoch 920/1000 - Train Loss: 0.1860, Validation Loss: 0.1844\n",
      "Epoch 921/1000 - Train Loss: 0.1858, Validation Loss: 0.1843\n",
      "Epoch 922/1000 - Train Loss: 0.1857, Validation Loss: 0.1841\n",
      "Epoch 923/1000 - Train Loss: 0.1855, Validation Loss: 0.1840\n",
      "Epoch 924/1000 - Train Loss: 0.1854, Validation Loss: 0.1838\n",
      "Epoch 925/1000 - Train Loss: 0.1852, Validation Loss: 0.1837\n",
      "Epoch 926/1000 - Train Loss: 0.1851, Validation Loss: 0.1836\n",
      "Epoch 927/1000 - Train Loss: 0.1850, Validation Loss: 0.1834\n",
      "Epoch 928/1000 - Train Loss: 0.1848, Validation Loss: 0.1833\n",
      "Epoch 929/1000 - Train Loss: 0.1847, Validation Loss: 0.1831\n",
      "Epoch 930/1000 - Train Loss: 0.1845, Validation Loss: 0.1830\n",
      "Epoch 931/1000 - Train Loss: 0.1844, Validation Loss: 0.1829\n",
      "Epoch 932/1000 - Train Loss: 0.1843, Validation Loss: 0.1827\n",
      "Epoch 933/1000 - Train Loss: 0.1841, Validation Loss: 0.1826\n",
      "Epoch 934/1000 - Train Loss: 0.1840, Validation Loss: 0.1824\n",
      "Epoch 935/1000 - Train Loss: 0.1838, Validation Loss: 0.1823\n",
      "Epoch 936/1000 - Train Loss: 0.1837, Validation Loss: 0.1822\n",
      "Epoch 937/1000 - Train Loss: 0.1836, Validation Loss: 0.1820\n",
      "Epoch 938/1000 - Train Loss: 0.1834, Validation Loss: 0.1819\n",
      "Epoch 939/1000 - Train Loss: 0.1833, Validation Loss: 0.1817\n",
      "Epoch 940/1000 - Train Loss: 0.1831, Validation Loss: 0.1816\n",
      "Epoch 941/1000 - Train Loss: 0.1830, Validation Loss: 0.1815\n",
      "Epoch 942/1000 - Train Loss: 0.1829, Validation Loss: 0.1813\n",
      "Epoch 943/1000 - Train Loss: 0.1827, Validation Loss: 0.1812\n",
      "Epoch 944/1000 - Train Loss: 0.1826, Validation Loss: 0.1811\n",
      "Epoch 945/1000 - Train Loss: 0.1825, Validation Loss: 0.1809\n",
      "Epoch 946/1000 - Train Loss: 0.1823, Validation Loss: 0.1808\n",
      "Epoch 947/1000 - Train Loss: 0.1822, Validation Loss: 0.1807\n",
      "Epoch 948/1000 - Train Loss: 0.1820, Validation Loss: 0.1805\n",
      "Epoch 949/1000 - Train Loss: 0.1819, Validation Loss: 0.1804\n",
      "Epoch 950/1000 - Train Loss: 0.1818, Validation Loss: 0.1802\n",
      "Epoch 951/1000 - Train Loss: 0.1816, Validation Loss: 0.1801\n",
      "Epoch 952/1000 - Train Loss: 0.1815, Validation Loss: 0.1800\n",
      "Epoch 953/1000 - Train Loss: 0.1814, Validation Loss: 0.1798\n",
      "Epoch 954/1000 - Train Loss: 0.1812, Validation Loss: 0.1797\n",
      "Epoch 955/1000 - Train Loss: 0.1811, Validation Loss: 0.1796\n",
      "Epoch 956/1000 - Train Loss: 0.1810, Validation Loss: 0.1794\n",
      "Epoch 957/1000 - Train Loss: 0.1808, Validation Loss: 0.1793\n",
      "Epoch 958/1000 - Train Loss: 0.1807, Validation Loss: 0.1792\n",
      "Epoch 959/1000 - Train Loss: 0.1806, Validation Loss: 0.1790\n",
      "Epoch 960/1000 - Train Loss: 0.1804, Validation Loss: 0.1789\n",
      "Epoch 961/1000 - Train Loss: 0.1803, Validation Loss: 0.1788\n",
      "Epoch 962/1000 - Train Loss: 0.1802, Validation Loss: 0.1786\n",
      "Epoch 963/1000 - Train Loss: 0.1800, Validation Loss: 0.1785\n",
      "Epoch 964/1000 - Train Loss: 0.1799, Validation Loss: 0.1784\n",
      "Epoch 965/1000 - Train Loss: 0.1798, Validation Loss: 0.1782\n",
      "Epoch 966/1000 - Train Loss: 0.1796, Validation Loss: 0.1781\n",
      "Epoch 967/1000 - Train Loss: 0.1795, Validation Loss: 0.1780\n",
      "Epoch 968/1000 - Train Loss: 0.1794, Validation Loss: 0.1778\n",
      "Epoch 969/1000 - Train Loss: 0.1792, Validation Loss: 0.1777\n",
      "Epoch 970/1000 - Train Loss: 0.1791, Validation Loss: 0.1776\n",
      "Epoch 971/1000 - Train Loss: 0.1790, Validation Loss: 0.1775\n",
      "Epoch 972/1000 - Train Loss: 0.1788, Validation Loss: 0.1773\n",
      "Epoch 973/1000 - Train Loss: 0.1787, Validation Loss: 0.1772\n",
      "Epoch 974/1000 - Train Loss: 0.1786, Validation Loss: 0.1771\n",
      "Epoch 975/1000 - Train Loss: 0.1784, Validation Loss: 0.1769\n",
      "Epoch 976/1000 - Train Loss: 0.1783, Validation Loss: 0.1768\n",
      "Epoch 977/1000 - Train Loss: 0.1782, Validation Loss: 0.1767\n",
      "Epoch 978/1000 - Train Loss: 0.1781, Validation Loss: 0.1765\n",
      "Epoch 979/1000 - Train Loss: 0.1779, Validation Loss: 0.1764\n",
      "Epoch 980/1000 - Train Loss: 0.1778, Validation Loss: 0.1763\n",
      "Epoch 981/1000 - Train Loss: 0.1777, Validation Loss: 0.1762\n",
      "Epoch 982/1000 - Train Loss: 0.1775, Validation Loss: 0.1760\n",
      "Epoch 983/1000 - Train Loss: 0.1774, Validation Loss: 0.1759\n",
      "Epoch 984/1000 - Train Loss: 0.1773, Validation Loss: 0.1758\n",
      "Epoch 985/1000 - Train Loss: 0.1772, Validation Loss: 0.1756\n",
      "Epoch 986/1000 - Train Loss: 0.1770, Validation Loss: 0.1755\n",
      "Epoch 987/1000 - Train Loss: 0.1769, Validation Loss: 0.1754\n",
      "Epoch 988/1000 - Train Loss: 0.1768, Validation Loss: 0.1753\n",
      "Epoch 989/1000 - Train Loss: 0.1766, Validation Loss: 0.1751\n",
      "Epoch 990/1000 - Train Loss: 0.1765, Validation Loss: 0.1750\n",
      "Epoch 991/1000 - Train Loss: 0.1764, Validation Loss: 0.1749\n",
      "Epoch 992/1000 - Train Loss: 0.1763, Validation Loss: 0.1748\n",
      "Epoch 993/1000 - Train Loss: 0.1761, Validation Loss: 0.1746\n",
      "Epoch 994/1000 - Train Loss: 0.1760, Validation Loss: 0.1745\n",
      "Epoch 995/1000 - Train Loss: 0.1759, Validation Loss: 0.1744\n",
      "Epoch 996/1000 - Train Loss: 0.1758, Validation Loss: 0.1742\n",
      "Epoch 997/1000 - Train Loss: 0.1756, Validation Loss: 0.1741\n",
      "Epoch 998/1000 - Train Loss: 0.1755, Validation Loss: 0.1740\n",
      "Epoch 999/1000 - Train Loss: 0.1754, Validation Loss: 0.1739\n",
      "Epoch 1000/1000 - Train Loss: 0.1752, Validation Loss: 0.1737\n",
      "Epoch 1/1000 - Train Loss: 0.6931, Validation Loss: 0.6865\n",
      "Epoch 2/1000 - Train Loss: 0.6867, Validation Loss: 0.6801\n",
      "Epoch 3/1000 - Train Loss: 0.6804, Validation Loss: 0.6739\n",
      "Epoch 4/1000 - Train Loss: 0.6744, Validation Loss: 0.6680\n",
      "Epoch 5/1000 - Train Loss: 0.6686, Validation Loss: 0.6622\n",
      "Epoch 6/1000 - Train Loss: 0.6630, Validation Loss: 0.6566\n",
      "Epoch 7/1000 - Train Loss: 0.6575, Validation Loss: 0.6511\n",
      "Epoch 8/1000 - Train Loss: 0.6521, Validation Loss: 0.6458\n",
      "Epoch 9/1000 - Train Loss: 0.6469, Validation Loss: 0.6406\n",
      "Epoch 10/1000 - Train Loss: 0.6418, Validation Loss: 0.6355\n",
      "Epoch 11/1000 - Train Loss: 0.6368, Validation Loss: 0.6305\n",
      "Epoch 12/1000 - Train Loss: 0.6318, Validation Loss: 0.6256\n",
      "Epoch 13/1000 - Train Loss: 0.6270, Validation Loss: 0.6208\n",
      "Epoch 14/1000 - Train Loss: 0.6222, Validation Loss: 0.6160\n",
      "Epoch 15/1000 - Train Loss: 0.6175, Validation Loss: 0.6114\n",
      "Epoch 16/1000 - Train Loss: 0.6129, Validation Loss: 0.6068\n",
      "Epoch 17/1000 - Train Loss: 0.6084, Validation Loss: 0.6023\n",
      "Epoch 18/1000 - Train Loss: 0.6039, Validation Loss: 0.5978\n",
      "Epoch 19/1000 - Train Loss: 0.5995, Validation Loss: 0.5934\n",
      "Epoch 20/1000 - Train Loss: 0.5951, Validation Loss: 0.5891\n",
      "Epoch 21/1000 - Train Loss: 0.5908, Validation Loss: 0.5848\n",
      "Epoch 22/1000 - Train Loss: 0.5866, Validation Loss: 0.5806\n",
      "Epoch 23/1000 - Train Loss: 0.5824, Validation Loss: 0.5765\n",
      "Epoch 24/1000 - Train Loss: 0.5782, Validation Loss: 0.5724\n",
      "Epoch 25/1000 - Train Loss: 0.5741, Validation Loss: 0.5683\n",
      "Epoch 26/1000 - Train Loss: 0.5701, Validation Loss: 0.5643\n",
      "Epoch 27/1000 - Train Loss: 0.5661, Validation Loss: 0.5604\n",
      "Epoch 28/1000 - Train Loss: 0.5622, Validation Loss: 0.5565\n",
      "Epoch 29/1000 - Train Loss: 0.5583, Validation Loss: 0.5526\n",
      "Epoch 30/1000 - Train Loss: 0.5544, Validation Loss: 0.5488\n",
      "Epoch 31/1000 - Train Loss: 0.5507, Validation Loss: 0.5451\n",
      "Epoch 32/1000 - Train Loss: 0.5469, Validation Loss: 0.5414\n",
      "Epoch 33/1000 - Train Loss: 0.5432, Validation Loss: 0.5377\n",
      "Epoch 34/1000 - Train Loss: 0.5395, Validation Loss: 0.5341\n",
      "Epoch 35/1000 - Train Loss: 0.5359, Validation Loss: 0.5305\n",
      "Epoch 36/1000 - Train Loss: 0.5323, Validation Loss: 0.5270\n",
      "Epoch 37/1000 - Train Loss: 0.5288, Validation Loss: 0.5235\n",
      "Epoch 38/1000 - Train Loss: 0.5253, Validation Loss: 0.5200\n",
      "Epoch 39/1000 - Train Loss: 0.5219, Validation Loss: 0.5166\n",
      "Epoch 40/1000 - Train Loss: 0.5184, Validation Loss: 0.5133\n",
      "Epoch 41/1000 - Train Loss: 0.5151, Validation Loss: 0.5099\n",
      "Epoch 42/1000 - Train Loss: 0.5117, Validation Loss: 0.5066\n",
      "Epoch 43/1000 - Train Loss: 0.5084, Validation Loss: 0.5034\n",
      "Epoch 44/1000 - Train Loss: 0.5052, Validation Loss: 0.5001\n",
      "Epoch 45/1000 - Train Loss: 0.5020, Validation Loss: 0.4970\n",
      "Epoch 46/1000 - Train Loss: 0.4988, Validation Loss: 0.4938\n",
      "Epoch 47/1000 - Train Loss: 0.4956, Validation Loss: 0.4907\n",
      "Epoch 48/1000 - Train Loss: 0.4925, Validation Loss: 0.4876\n",
      "Epoch 49/1000 - Train Loss: 0.4894, Validation Loss: 0.4846\n",
      "Epoch 50/1000 - Train Loss: 0.4864, Validation Loss: 0.4816\n",
      "Epoch 51/1000 - Train Loss: 0.4834, Validation Loss: 0.4786\n",
      "Epoch 52/1000 - Train Loss: 0.4804, Validation Loss: 0.4757\n",
      "Epoch 53/1000 - Train Loss: 0.4775, Validation Loss: 0.4728\n",
      "Epoch 54/1000 - Train Loss: 0.4746, Validation Loss: 0.4699\n",
      "Epoch 55/1000 - Train Loss: 0.4717, Validation Loss: 0.4671\n",
      "Epoch 56/1000 - Train Loss: 0.4688, Validation Loss: 0.4642\n",
      "Epoch 57/1000 - Train Loss: 0.4660, Validation Loss: 0.4615\n",
      "Epoch 58/1000 - Train Loss: 0.4633, Validation Loss: 0.4587\n",
      "Epoch 59/1000 - Train Loss: 0.4605, Validation Loss: 0.4560\n",
      "Epoch 60/1000 - Train Loss: 0.4578, Validation Loss: 0.4533\n",
      "Epoch 61/1000 - Train Loss: 0.4551, Validation Loss: 0.4506\n",
      "Epoch 62/1000 - Train Loss: 0.4524, Validation Loss: 0.4480\n",
      "Epoch 63/1000 - Train Loss: 0.4498, Validation Loss: 0.4454\n",
      "Epoch 64/1000 - Train Loss: 0.4472, Validation Loss: 0.4428\n",
      "Epoch 65/1000 - Train Loss: 0.4446, Validation Loss: 0.4403\n",
      "Epoch 66/1000 - Train Loss: 0.4421, Validation Loss: 0.4378\n",
      "Epoch 67/1000 - Train Loss: 0.4395, Validation Loss: 0.4353\n",
      "Epoch 68/1000 - Train Loss: 0.4370, Validation Loss: 0.4328\n",
      "Epoch 69/1000 - Train Loss: 0.4346, Validation Loss: 0.4304\n",
      "Epoch 70/1000 - Train Loss: 0.4321, Validation Loss: 0.4280\n",
      "Epoch 71/1000 - Train Loss: 0.4297, Validation Loss: 0.4256\n",
      "Epoch 72/1000 - Train Loss: 0.4273, Validation Loss: 0.4232\n",
      "Epoch 73/1000 - Train Loss: 0.4249, Validation Loss: 0.4209\n",
      "Epoch 74/1000 - Train Loss: 0.4226, Validation Loss: 0.4185\n",
      "Epoch 75/1000 - Train Loss: 0.4203, Validation Loss: 0.4162\n",
      "Epoch 76/1000 - Train Loss: 0.4180, Validation Loss: 0.4140\n",
      "Epoch 77/1000 - Train Loss: 0.4157, Validation Loss: 0.4117\n",
      "Epoch 78/1000 - Train Loss: 0.4135, Validation Loss: 0.4095\n",
      "Epoch 79/1000 - Train Loss: 0.4112, Validation Loss: 0.4073\n",
      "Epoch 80/1000 - Train Loss: 0.4090, Validation Loss: 0.4051\n",
      "Epoch 81/1000 - Train Loss: 0.4069, Validation Loss: 0.4030\n",
      "Epoch 82/1000 - Train Loss: 0.4047, Validation Loss: 0.4008\n",
      "Epoch 83/1000 - Train Loss: 0.4026, Validation Loss: 0.3987\n",
      "Epoch 84/1000 - Train Loss: 0.4004, Validation Loss: 0.3966\n",
      "Epoch 85/1000 - Train Loss: 0.3984, Validation Loss: 0.3946\n",
      "Epoch 86/1000 - Train Loss: 0.3963, Validation Loss: 0.3925\n",
      "Epoch 87/1000 - Train Loss: 0.3942, Validation Loss: 0.3905\n",
      "Epoch 88/1000 - Train Loss: 0.3922, Validation Loss: 0.3885\n",
      "Epoch 89/1000 - Train Loss: 0.3902, Validation Loss: 0.3865\n",
      "Epoch 90/1000 - Train Loss: 0.3882, Validation Loss: 0.3845\n",
      "Epoch 91/1000 - Train Loss: 0.3862, Validation Loss: 0.3826\n",
      "Epoch 92/1000 - Train Loss: 0.3843, Validation Loss: 0.3807\n",
      "Epoch 93/1000 - Train Loss: 0.3823, Validation Loss: 0.3787\n",
      "Epoch 94/1000 - Train Loss: 0.3804, Validation Loss: 0.3768\n",
      "Epoch 95/1000 - Train Loss: 0.3785, Validation Loss: 0.3750\n",
      "Epoch 96/1000 - Train Loss: 0.3767, Validation Loss: 0.3731\n",
      "Epoch 97/1000 - Train Loss: 0.3748, Validation Loss: 0.3713\n",
      "Epoch 98/1000 - Train Loss: 0.3730, Validation Loss: 0.3695\n",
      "Epoch 99/1000 - Train Loss: 0.3711, Validation Loss: 0.3677\n",
      "Epoch 100/1000 - Train Loss: 0.3693, Validation Loss: 0.3659\n",
      "Epoch 101/1000 - Train Loss: 0.3675, Validation Loss: 0.3641\n",
      "Epoch 102/1000 - Train Loss: 0.3658, Validation Loss: 0.3623\n",
      "Epoch 103/1000 - Train Loss: 0.3640, Validation Loss: 0.3606\n",
      "Epoch 104/1000 - Train Loss: 0.3623, Validation Loss: 0.3589\n",
      "Epoch 105/1000 - Train Loss: 0.3605, Validation Loss: 0.3572\n",
      "Epoch 106/1000 - Train Loss: 0.3588, Validation Loss: 0.3555\n",
      "Epoch 107/1000 - Train Loss: 0.3572, Validation Loss: 0.3538\n",
      "Epoch 108/1000 - Train Loss: 0.3555, Validation Loss: 0.3522\n",
      "Epoch 109/1000 - Train Loss: 0.3538, Validation Loss: 0.3505\n",
      "Epoch 110/1000 - Train Loss: 0.3522, Validation Loss: 0.3489\n",
      "Epoch 111/1000 - Train Loss: 0.3505, Validation Loss: 0.3473\n",
      "Epoch 112/1000 - Train Loss: 0.3489, Validation Loss: 0.3457\n",
      "Epoch 113/1000 - Train Loss: 0.3473, Validation Loss: 0.3441\n",
      "Epoch 114/1000 - Train Loss: 0.3457, Validation Loss: 0.3425\n",
      "Epoch 115/1000 - Train Loss: 0.3442, Validation Loss: 0.3410\n",
      "Epoch 116/1000 - Train Loss: 0.3426, Validation Loss: 0.3394\n",
      "Epoch 117/1000 - Train Loss: 0.3411, Validation Loss: 0.3379\n",
      "Epoch 118/1000 - Train Loss: 0.3395, Validation Loss: 0.3364\n",
      "Epoch 119/1000 - Train Loss: 0.3380, Validation Loss: 0.3349\n",
      "Epoch 120/1000 - Train Loss: 0.3365, Validation Loss: 0.3334\n",
      "Epoch 121/1000 - Train Loss: 0.3350, Validation Loss: 0.3319\n",
      "Epoch 122/1000 - Train Loss: 0.3336, Validation Loss: 0.3305\n",
      "Epoch 123/1000 - Train Loss: 0.3321, Validation Loss: 0.3290\n",
      "Epoch 124/1000 - Train Loss: 0.3306, Validation Loss: 0.3276\n",
      "Epoch 125/1000 - Train Loss: 0.3292, Validation Loss: 0.3262\n",
      "Epoch 126/1000 - Train Loss: 0.3278, Validation Loss: 0.3248\n",
      "Epoch 127/1000 - Train Loss: 0.3264, Validation Loss: 0.3234\n",
      "Epoch 128/1000 - Train Loss: 0.3250, Validation Loss: 0.3220\n",
      "Epoch 129/1000 - Train Loss: 0.3236, Validation Loss: 0.3206\n",
      "Epoch 130/1000 - Train Loss: 0.3222, Validation Loss: 0.3192\n",
      "Epoch 131/1000 - Train Loss: 0.3208, Validation Loss: 0.3179\n",
      "Epoch 132/1000 - Train Loss: 0.3195, Validation Loss: 0.3165\n",
      "Epoch 133/1000 - Train Loss: 0.3182, Validation Loss: 0.3152\n",
      "Epoch 134/1000 - Train Loss: 0.3168, Validation Loss: 0.3139\n",
      "Epoch 135/1000 - Train Loss: 0.3155, Validation Loss: 0.3126\n",
      "Epoch 136/1000 - Train Loss: 0.3142, Validation Loss: 0.3113\n",
      "Epoch 137/1000 - Train Loss: 0.3129, Validation Loss: 0.3100\n",
      "Epoch 138/1000 - Train Loss: 0.3116, Validation Loss: 0.3087\n",
      "Epoch 139/1000 - Train Loss: 0.3103, Validation Loss: 0.3075\n",
      "Epoch 140/1000 - Train Loss: 0.3091, Validation Loss: 0.3062\n",
      "Epoch 141/1000 - Train Loss: 0.3078, Validation Loss: 0.3050\n",
      "Epoch 142/1000 - Train Loss: 0.3066, Validation Loss: 0.3038\n",
      "Epoch 143/1000 - Train Loss: 0.3053, Validation Loss: 0.3025\n",
      "Epoch 144/1000 - Train Loss: 0.3041, Validation Loss: 0.3013\n",
      "Epoch 145/1000 - Train Loss: 0.3029, Validation Loss: 0.3001\n",
      "Epoch 146/1000 - Train Loss: 0.3017, Validation Loss: 0.2989\n",
      "Epoch 147/1000 - Train Loss: 0.3005, Validation Loss: 0.2977\n",
      "Epoch 148/1000 - Train Loss: 0.2993, Validation Loss: 0.2966\n",
      "Epoch 149/1000 - Train Loss: 0.2982, Validation Loss: 0.2954\n",
      "Epoch 150/1000 - Train Loss: 0.2970, Validation Loss: 0.2942\n",
      "Epoch 151/1000 - Train Loss: 0.2958, Validation Loss: 0.2931\n",
      "Epoch 152/1000 - Train Loss: 0.2947, Validation Loss: 0.2920\n",
      "Epoch 153/1000 - Train Loss: 0.2935, Validation Loss: 0.2908\n",
      "Epoch 154/1000 - Train Loss: 0.2924, Validation Loss: 0.2897\n",
      "Epoch 155/1000 - Train Loss: 0.2913, Validation Loss: 0.2886\n",
      "Epoch 156/1000 - Train Loss: 0.2902, Validation Loss: 0.2875\n",
      "Epoch 157/1000 - Train Loss: 0.2891, Validation Loss: 0.2864\n",
      "Epoch 158/1000 - Train Loss: 0.2880, Validation Loss: 0.2853\n",
      "Epoch 159/1000 - Train Loss: 0.2869, Validation Loss: 0.2843\n",
      "Epoch 160/1000 - Train Loss: 0.2858, Validation Loss: 0.2832\n",
      "Epoch 161/1000 - Train Loss: 0.2848, Validation Loss: 0.2821\n",
      "Epoch 162/1000 - Train Loss: 0.2837, Validation Loss: 0.2811\n",
      "Epoch 163/1000 - Train Loss: 0.2827, Validation Loss: 0.2800\n",
      "Epoch 164/1000 - Train Loss: 0.2816, Validation Loss: 0.2790\n",
      "Epoch 165/1000 - Train Loss: 0.2806, Validation Loss: 0.2780\n",
      "Epoch 166/1000 - Train Loss: 0.2795, Validation Loss: 0.2770\n",
      "Epoch 167/1000 - Train Loss: 0.2785, Validation Loss: 0.2759\n",
      "Epoch 168/1000 - Train Loss: 0.2775, Validation Loss: 0.2749\n",
      "Epoch 169/1000 - Train Loss: 0.2765, Validation Loss: 0.2739\n",
      "Epoch 170/1000 - Train Loss: 0.2755, Validation Loss: 0.2730\n",
      "Epoch 171/1000 - Train Loss: 0.2745, Validation Loss: 0.2720\n",
      "Epoch 172/1000 - Train Loss: 0.2735, Validation Loss: 0.2710\n",
      "Epoch 173/1000 - Train Loss: 0.2726, Validation Loss: 0.2700\n",
      "Epoch 174/1000 - Train Loss: 0.2716, Validation Loss: 0.2691\n",
      "Epoch 175/1000 - Train Loss: 0.2706, Validation Loss: 0.2681\n",
      "Epoch 176/1000 - Train Loss: 0.2697, Validation Loss: 0.2672\n",
      "Epoch 177/1000 - Train Loss: 0.2687, Validation Loss: 0.2662\n",
      "Epoch 178/1000 - Train Loss: 0.2678, Validation Loss: 0.2653\n",
      "Epoch 179/1000 - Train Loss: 0.2669, Validation Loss: 0.2644\n",
      "Epoch 180/1000 - Train Loss: 0.2659, Validation Loss: 0.2635\n",
      "Epoch 181/1000 - Train Loss: 0.2650, Validation Loss: 0.2626\n",
      "Epoch 182/1000 - Train Loss: 0.2641, Validation Loss: 0.2616\n",
      "Epoch 183/1000 - Train Loss: 0.2632, Validation Loss: 0.2607\n",
      "Epoch 184/1000 - Train Loss: 0.2623, Validation Loss: 0.2599\n",
      "Epoch 185/1000 - Train Loss: 0.2614, Validation Loss: 0.2590\n",
      "Epoch 186/1000 - Train Loss: 0.2605, Validation Loss: 0.2581\n",
      "Epoch 187/1000 - Train Loss: 0.2596, Validation Loss: 0.2572\n",
      "Epoch 188/1000 - Train Loss: 0.2587, Validation Loss: 0.2563\n",
      "Epoch 189/1000 - Train Loss: 0.2579, Validation Loss: 0.2555\n",
      "Epoch 190/1000 - Train Loss: 0.2570, Validation Loss: 0.2546\n",
      "Epoch 191/1000 - Train Loss: 0.2562, Validation Loss: 0.2538\n",
      "Epoch 192/1000 - Train Loss: 0.2553, Validation Loss: 0.2529\n",
      "Epoch 193/1000 - Train Loss: 0.2545, Validation Loss: 0.2521\n",
      "Epoch 194/1000 - Train Loss: 0.2536, Validation Loss: 0.2513\n",
      "Epoch 195/1000 - Train Loss: 0.2528, Validation Loss: 0.2504\n",
      "Epoch 196/1000 - Train Loss: 0.2520, Validation Loss: 0.2496\n",
      "Epoch 197/1000 - Train Loss: 0.2511, Validation Loss: 0.2488\n",
      "Epoch 198/1000 - Train Loss: 0.2503, Validation Loss: 0.2480\n",
      "Epoch 199/1000 - Train Loss: 0.2495, Validation Loss: 0.2472\n",
      "Epoch 200/1000 - Train Loss: 0.2487, Validation Loss: 0.2464\n",
      "Epoch 201/1000 - Train Loss: 0.2479, Validation Loss: 0.2456\n",
      "Epoch 202/1000 - Train Loss: 0.2471, Validation Loss: 0.2448\n",
      "Epoch 203/1000 - Train Loss: 0.2463, Validation Loss: 0.2440\n",
      "Epoch 204/1000 - Train Loss: 0.2455, Validation Loss: 0.2433\n",
      "Epoch 205/1000 - Train Loss: 0.2448, Validation Loss: 0.2425\n",
      "Epoch 206/1000 - Train Loss: 0.2440, Validation Loss: 0.2417\n",
      "Epoch 207/1000 - Train Loss: 0.2432, Validation Loss: 0.2410\n",
      "Epoch 208/1000 - Train Loss: 0.2425, Validation Loss: 0.2402\n",
      "Epoch 209/1000 - Train Loss: 0.2417, Validation Loss: 0.2394\n",
      "Epoch 210/1000 - Train Loss: 0.2410, Validation Loss: 0.2387\n",
      "Epoch 211/1000 - Train Loss: 0.2402, Validation Loss: 0.2380\n",
      "Epoch 212/1000 - Train Loss: 0.2395, Validation Loss: 0.2372\n",
      "Epoch 213/1000 - Train Loss: 0.2387, Validation Loss: 0.2365\n",
      "Epoch 214/1000 - Train Loss: 0.2380, Validation Loss: 0.2358\n",
      "Epoch 215/1000 - Train Loss: 0.2373, Validation Loss: 0.2350\n",
      "Epoch 216/1000 - Train Loss: 0.2365, Validation Loss: 0.2343\n",
      "Epoch 217/1000 - Train Loss: 0.2358, Validation Loss: 0.2336\n",
      "Epoch 218/1000 - Train Loss: 0.2351, Validation Loss: 0.2329\n",
      "Epoch 219/1000 - Train Loss: 0.2344, Validation Loss: 0.2322\n",
      "Epoch 220/1000 - Train Loss: 0.2337, Validation Loss: 0.2315\n",
      "Epoch 221/1000 - Train Loss: 0.2330, Validation Loss: 0.2308\n",
      "Epoch 222/1000 - Train Loss: 0.2323, Validation Loss: 0.2301\n",
      "Epoch 223/1000 - Train Loss: 0.2316, Validation Loss: 0.2294\n",
      "Epoch 224/1000 - Train Loss: 0.2309, Validation Loss: 0.2287\n",
      "Epoch 225/1000 - Train Loss: 0.2302, Validation Loss: 0.2281\n",
      "Epoch 226/1000 - Train Loss: 0.2296, Validation Loss: 0.2274\n",
      "Epoch 227/1000 - Train Loss: 0.2289, Validation Loss: 0.2267\n",
      "Epoch 228/1000 - Train Loss: 0.2282, Validation Loss: 0.2261\n",
      "Epoch 229/1000 - Train Loss: 0.2275, Validation Loss: 0.2254\n",
      "Epoch 230/1000 - Train Loss: 0.2269, Validation Loss: 0.2247\n",
      "Epoch 231/1000 - Train Loss: 0.2262, Validation Loss: 0.2241\n",
      "Epoch 232/1000 - Train Loss: 0.2256, Validation Loss: 0.2234\n",
      "Epoch 233/1000 - Train Loss: 0.2249, Validation Loss: 0.2228\n",
      "Epoch 234/1000 - Train Loss: 0.2243, Validation Loss: 0.2222\n",
      "Epoch 235/1000 - Train Loss: 0.2236, Validation Loss: 0.2215\n",
      "Epoch 236/1000 - Train Loss: 0.2230, Validation Loss: 0.2209\n",
      "Epoch 237/1000 - Train Loss: 0.2224, Validation Loss: 0.2203\n",
      "Epoch 238/1000 - Train Loss: 0.2217, Validation Loss: 0.2196\n",
      "Epoch 239/1000 - Train Loss: 0.2211, Validation Loss: 0.2190\n",
      "Epoch 240/1000 - Train Loss: 0.2205, Validation Loss: 0.2184\n",
      "Epoch 241/1000 - Train Loss: 0.2199, Validation Loss: 0.2178\n",
      "Epoch 242/1000 - Train Loss: 0.2193, Validation Loss: 0.2172\n",
      "Epoch 243/1000 - Train Loss: 0.2186, Validation Loss: 0.2166\n",
      "Epoch 244/1000 - Train Loss: 0.2180, Validation Loss: 0.2160\n",
      "Epoch 245/1000 - Train Loss: 0.2174, Validation Loss: 0.2154\n",
      "Epoch 246/1000 - Train Loss: 0.2168, Validation Loss: 0.2148\n",
      "Epoch 247/1000 - Train Loss: 0.2162, Validation Loss: 0.2142\n",
      "Epoch 248/1000 - Train Loss: 0.2156, Validation Loss: 0.2136\n",
      "Epoch 249/1000 - Train Loss: 0.2150, Validation Loss: 0.2130\n",
      "Epoch 250/1000 - Train Loss: 0.2145, Validation Loss: 0.2124\n",
      "Epoch 251/1000 - Train Loss: 0.2139, Validation Loss: 0.2118\n",
      "Epoch 252/1000 - Train Loss: 0.2133, Validation Loss: 0.2113\n",
      "Epoch 253/1000 - Train Loss: 0.2127, Validation Loss: 0.2107\n",
      "Epoch 254/1000 - Train Loss: 0.2121, Validation Loss: 0.2101\n",
      "Epoch 255/1000 - Train Loss: 0.2116, Validation Loss: 0.2096\n",
      "Epoch 256/1000 - Train Loss: 0.2110, Validation Loss: 0.2090\n",
      "Epoch 257/1000 - Train Loss: 0.2104, Validation Loss: 0.2084\n",
      "Epoch 258/1000 - Train Loss: 0.2099, Validation Loss: 0.2079\n",
      "Epoch 259/1000 - Train Loss: 0.2093, Validation Loss: 0.2073\n",
      "Epoch 260/1000 - Train Loss: 0.2088, Validation Loss: 0.2068\n",
      "Epoch 261/1000 - Train Loss: 0.2082, Validation Loss: 0.2062\n",
      "Epoch 262/1000 - Train Loss: 0.2077, Validation Loss: 0.2057\n",
      "Epoch 263/1000 - Train Loss: 0.2071, Validation Loss: 0.2051\n",
      "Epoch 264/1000 - Train Loss: 0.2066, Validation Loss: 0.2046\n",
      "Epoch 265/1000 - Train Loss: 0.2061, Validation Loss: 0.2041\n",
      "Epoch 266/1000 - Train Loss: 0.2055, Validation Loss: 0.2035\n",
      "Epoch 267/1000 - Train Loss: 0.2050, Validation Loss: 0.2030\n",
      "Epoch 268/1000 - Train Loss: 0.2045, Validation Loss: 0.2025\n",
      "Epoch 269/1000 - Train Loss: 0.2039, Validation Loss: 0.2020\n",
      "Epoch 270/1000 - Train Loss: 0.2034, Validation Loss: 0.2015\n",
      "Epoch 271/1000 - Train Loss: 0.2029, Validation Loss: 0.2009\n",
      "Epoch 272/1000 - Train Loss: 0.2024, Validation Loss: 0.2004\n",
      "Epoch 273/1000 - Train Loss: 0.2019, Validation Loss: 0.1999\n",
      "Epoch 274/1000 - Train Loss: 0.2014, Validation Loss: 0.1994\n",
      "Epoch 275/1000 - Train Loss: 0.2008, Validation Loss: 0.1989\n",
      "Epoch 276/1000 - Train Loss: 0.2003, Validation Loss: 0.1984\n",
      "Epoch 277/1000 - Train Loss: 0.1998, Validation Loss: 0.1979\n",
      "Epoch 278/1000 - Train Loss: 0.1993, Validation Loss: 0.1974\n",
      "Epoch 279/1000 - Train Loss: 0.1988, Validation Loss: 0.1969\n",
      "Epoch 280/1000 - Train Loss: 0.1983, Validation Loss: 0.1964\n",
      "Epoch 281/1000 - Train Loss: 0.1978, Validation Loss: 0.1959\n",
      "Epoch 282/1000 - Train Loss: 0.1974, Validation Loss: 0.1954\n",
      "Epoch 283/1000 - Train Loss: 0.1969, Validation Loss: 0.1950\n",
      "Epoch 284/1000 - Train Loss: 0.1964, Validation Loss: 0.1945\n",
      "Epoch 285/1000 - Train Loss: 0.1959, Validation Loss: 0.1940\n",
      "Epoch 286/1000 - Train Loss: 0.1954, Validation Loss: 0.1935\n",
      "Epoch 287/1000 - Train Loss: 0.1949, Validation Loss: 0.1930\n",
      "Epoch 288/1000 - Train Loss: 0.1945, Validation Loss: 0.1926\n",
      "Epoch 289/1000 - Train Loss: 0.1940, Validation Loss: 0.1921\n",
      "Epoch 290/1000 - Train Loss: 0.1935, Validation Loss: 0.1916\n",
      "Epoch 291/1000 - Train Loss: 0.1931, Validation Loss: 0.1912\n",
      "Epoch 292/1000 - Train Loss: 0.1926, Validation Loss: 0.1907\n",
      "Epoch 293/1000 - Train Loss: 0.1921, Validation Loss: 0.1903\n",
      "Epoch 294/1000 - Train Loss: 0.1917, Validation Loss: 0.1898\n",
      "Epoch 295/1000 - Train Loss: 0.1912, Validation Loss: 0.1894\n",
      "Epoch 296/1000 - Train Loss: 0.1908, Validation Loss: 0.1889\n",
      "Epoch 297/1000 - Train Loss: 0.1903, Validation Loss: 0.1885\n",
      "Epoch 298/1000 - Train Loss: 0.1899, Validation Loss: 0.1880\n",
      "Epoch 299/1000 - Train Loss: 0.1894, Validation Loss: 0.1876\n",
      "Epoch 300/1000 - Train Loss: 0.1890, Validation Loss: 0.1871\n",
      "Epoch 301/1000 - Train Loss: 0.1885, Validation Loss: 0.1867\n",
      "Epoch 302/1000 - Train Loss: 0.1881, Validation Loss: 0.1862\n",
      "Epoch 303/1000 - Train Loss: 0.1876, Validation Loss: 0.1858\n",
      "Epoch 304/1000 - Train Loss: 0.1872, Validation Loss: 0.1854\n",
      "Epoch 305/1000 - Train Loss: 0.1868, Validation Loss: 0.1849\n",
      "Epoch 306/1000 - Train Loss: 0.1863, Validation Loss: 0.1845\n",
      "Epoch 307/1000 - Train Loss: 0.1859, Validation Loss: 0.1841\n",
      "Epoch 308/1000 - Train Loss: 0.1855, Validation Loss: 0.1837\n",
      "Epoch 309/1000 - Train Loss: 0.1851, Validation Loss: 0.1832\n",
      "Epoch 310/1000 - Train Loss: 0.1846, Validation Loss: 0.1828\n",
      "Epoch 311/1000 - Train Loss: 0.1842, Validation Loss: 0.1824\n",
      "Epoch 312/1000 - Train Loss: 0.1838, Validation Loss: 0.1820\n",
      "Epoch 313/1000 - Train Loss: 0.1834, Validation Loss: 0.1816\n",
      "Epoch 314/1000 - Train Loss: 0.1830, Validation Loss: 0.1812\n",
      "Epoch 315/1000 - Train Loss: 0.1826, Validation Loss: 0.1807\n",
      "Epoch 316/1000 - Train Loss: 0.1821, Validation Loss: 0.1803\n",
      "Epoch 317/1000 - Train Loss: 0.1817, Validation Loss: 0.1799\n",
      "Epoch 318/1000 - Train Loss: 0.1813, Validation Loss: 0.1795\n",
      "Epoch 319/1000 - Train Loss: 0.1809, Validation Loss: 0.1791\n",
      "Epoch 320/1000 - Train Loss: 0.1805, Validation Loss: 0.1787\n",
      "Epoch 321/1000 - Train Loss: 0.1801, Validation Loss: 0.1783\n",
      "Epoch 322/1000 - Train Loss: 0.1797, Validation Loss: 0.1779\n",
      "Epoch 323/1000 - Train Loss: 0.1793, Validation Loss: 0.1775\n",
      "Epoch 324/1000 - Train Loss: 0.1789, Validation Loss: 0.1772\n",
      "Epoch 325/1000 - Train Loss: 0.1785, Validation Loss: 0.1768\n",
      "Epoch 326/1000 - Train Loss: 0.1781, Validation Loss: 0.1764\n",
      "Epoch 327/1000 - Train Loss: 0.1778, Validation Loss: 0.1760\n",
      "Epoch 328/1000 - Train Loss: 0.1774, Validation Loss: 0.1756\n",
      "Epoch 329/1000 - Train Loss: 0.1770, Validation Loss: 0.1752\n",
      "Epoch 330/1000 - Train Loss: 0.1766, Validation Loss: 0.1748\n",
      "Epoch 331/1000 - Train Loss: 0.1762, Validation Loss: 0.1745\n",
      "Epoch 332/1000 - Train Loss: 0.1758, Validation Loss: 0.1741\n",
      "Epoch 333/1000 - Train Loss: 0.1755, Validation Loss: 0.1737\n",
      "Epoch 334/1000 - Train Loss: 0.1751, Validation Loss: 0.1733\n",
      "Epoch 335/1000 - Train Loss: 0.1747, Validation Loss: 0.1730\n",
      "Epoch 336/1000 - Train Loss: 0.1743, Validation Loss: 0.1726\n",
      "Epoch 337/1000 - Train Loss: 0.1740, Validation Loss: 0.1722\n",
      "Epoch 338/1000 - Train Loss: 0.1736, Validation Loss: 0.1719\n",
      "Epoch 339/1000 - Train Loss: 0.1732, Validation Loss: 0.1715\n",
      "Epoch 340/1000 - Train Loss: 0.1729, Validation Loss: 0.1711\n",
      "Epoch 341/1000 - Train Loss: 0.1725, Validation Loss: 0.1708\n",
      "Epoch 342/1000 - Train Loss: 0.1721, Validation Loss: 0.1704\n",
      "Epoch 343/1000 - Train Loss: 0.1718, Validation Loss: 0.1700\n",
      "Epoch 344/1000 - Train Loss: 0.1714, Validation Loss: 0.1697\n",
      "Epoch 345/1000 - Train Loss: 0.1711, Validation Loss: 0.1693\n",
      "Epoch 346/1000 - Train Loss: 0.1707, Validation Loss: 0.1690\n",
      "Epoch 347/1000 - Train Loss: 0.1703, Validation Loss: 0.1686\n",
      "Epoch 348/1000 - Train Loss: 0.1700, Validation Loss: 0.1683\n",
      "Epoch 349/1000 - Train Loss: 0.1696, Validation Loss: 0.1679\n",
      "Epoch 350/1000 - Train Loss: 0.1693, Validation Loss: 0.1676\n",
      "Epoch 351/1000 - Train Loss: 0.1689, Validation Loss: 0.1672\n",
      "Epoch 352/1000 - Train Loss: 0.1686, Validation Loss: 0.1669\n",
      "Epoch 353/1000 - Train Loss: 0.1682, Validation Loss: 0.1666\n",
      "Epoch 354/1000 - Train Loss: 0.1679, Validation Loss: 0.1662\n",
      "Epoch 355/1000 - Train Loss: 0.1676, Validation Loss: 0.1659\n",
      "Epoch 356/1000 - Train Loss: 0.1672, Validation Loss: 0.1655\n",
      "Epoch 357/1000 - Train Loss: 0.1669, Validation Loss: 0.1652\n",
      "Epoch 358/1000 - Train Loss: 0.1665, Validation Loss: 0.1649\n",
      "Epoch 359/1000 - Train Loss: 0.1662, Validation Loss: 0.1645\n",
      "Epoch 360/1000 - Train Loss: 0.1659, Validation Loss: 0.1642\n",
      "Epoch 361/1000 - Train Loss: 0.1655, Validation Loss: 0.1639\n",
      "Epoch 362/1000 - Train Loss: 0.1652, Validation Loss: 0.1635\n",
      "Epoch 363/1000 - Train Loss: 0.1649, Validation Loss: 0.1632\n",
      "Epoch 364/1000 - Train Loss: 0.1646, Validation Loss: 0.1629\n",
      "Epoch 365/1000 - Train Loss: 0.1642, Validation Loss: 0.1626\n",
      "Epoch 366/1000 - Train Loss: 0.1639, Validation Loss: 0.1622\n",
      "Epoch 367/1000 - Train Loss: 0.1636, Validation Loss: 0.1619\n",
      "Epoch 368/1000 - Train Loss: 0.1633, Validation Loss: 0.1616\n",
      "Epoch 369/1000 - Train Loss: 0.1629, Validation Loss: 0.1613\n",
      "Epoch 370/1000 - Train Loss: 0.1626, Validation Loss: 0.1610\n",
      "Epoch 371/1000 - Train Loss: 0.1623, Validation Loss: 0.1606\n",
      "Epoch 372/1000 - Train Loss: 0.1620, Validation Loss: 0.1603\n",
      "Epoch 373/1000 - Train Loss: 0.1617, Validation Loss: 0.1600\n",
      "Epoch 374/1000 - Train Loss: 0.1614, Validation Loss: 0.1597\n",
      "Epoch 375/1000 - Train Loss: 0.1610, Validation Loss: 0.1594\n",
      "Epoch 376/1000 - Train Loss: 0.1607, Validation Loss: 0.1591\n",
      "Epoch 377/1000 - Train Loss: 0.1604, Validation Loss: 0.1588\n",
      "Epoch 378/1000 - Train Loss: 0.1601, Validation Loss: 0.1585\n",
      "Epoch 379/1000 - Train Loss: 0.1598, Validation Loss: 0.1582\n",
      "Epoch 380/1000 - Train Loss: 0.1595, Validation Loss: 0.1579\n",
      "Epoch 381/1000 - Train Loss: 0.1592, Validation Loss: 0.1576\n",
      "Epoch 382/1000 - Train Loss: 0.1589, Validation Loss: 0.1573\n",
      "Epoch 383/1000 - Train Loss: 0.1586, Validation Loss: 0.1570\n",
      "Epoch 384/1000 - Train Loss: 0.1583, Validation Loss: 0.1567\n",
      "Epoch 385/1000 - Train Loss: 0.1580, Validation Loss: 0.1564\n",
      "Epoch 386/1000 - Train Loss: 0.1577, Validation Loss: 0.1561\n",
      "Epoch 387/1000 - Train Loss: 0.1574, Validation Loss: 0.1558\n",
      "Epoch 388/1000 - Train Loss: 0.1571, Validation Loss: 0.1555\n",
      "Epoch 389/1000 - Train Loss: 0.1568, Validation Loss: 0.1552\n",
      "Epoch 390/1000 - Train Loss: 0.1565, Validation Loss: 0.1549\n",
      "Epoch 391/1000 - Train Loss: 0.1562, Validation Loss: 0.1546\n",
      "Epoch 392/1000 - Train Loss: 0.1559, Validation Loss: 0.1543\n",
      "Epoch 393/1000 - Train Loss: 0.1556, Validation Loss: 0.1540\n",
      "Epoch 394/1000 - Train Loss: 0.1553, Validation Loss: 0.1537\n",
      "Epoch 395/1000 - Train Loss: 0.1551, Validation Loss: 0.1535\n",
      "Epoch 396/1000 - Train Loss: 0.1548, Validation Loss: 0.1532\n",
      "Epoch 397/1000 - Train Loss: 0.1545, Validation Loss: 0.1529\n",
      "Epoch 398/1000 - Train Loss: 0.1542, Validation Loss: 0.1526\n",
      "Epoch 399/1000 - Train Loss: 0.1539, Validation Loss: 0.1523\n",
      "Epoch 400/1000 - Train Loss: 0.1536, Validation Loss: 0.1520\n",
      "Epoch 401/1000 - Train Loss: 0.1534, Validation Loss: 0.1518\n",
      "Epoch 402/1000 - Train Loss: 0.1531, Validation Loss: 0.1515\n",
      "Epoch 403/1000 - Train Loss: 0.1528, Validation Loss: 0.1512\n",
      "Epoch 404/1000 - Train Loss: 0.1525, Validation Loss: 0.1509\n",
      "Epoch 405/1000 - Train Loss: 0.1522, Validation Loss: 0.1507\n",
      "Epoch 406/1000 - Train Loss: 0.1520, Validation Loss: 0.1504\n",
      "Epoch 407/1000 - Train Loss: 0.1517, Validation Loss: 0.1501\n",
      "Epoch 408/1000 - Train Loss: 0.1514, Validation Loss: 0.1498\n",
      "Epoch 409/1000 - Train Loss: 0.1511, Validation Loss: 0.1496\n",
      "Epoch 410/1000 - Train Loss: 0.1509, Validation Loss: 0.1493\n",
      "Epoch 411/1000 - Train Loss: 0.1506, Validation Loss: 0.1490\n",
      "Epoch 412/1000 - Train Loss: 0.1503, Validation Loss: 0.1488\n",
      "Epoch 413/1000 - Train Loss: 0.1501, Validation Loss: 0.1485\n",
      "Epoch 414/1000 - Train Loss: 0.1498, Validation Loss: 0.1482\n",
      "Epoch 415/1000 - Train Loss: 0.1495, Validation Loss: 0.1480\n",
      "Epoch 416/1000 - Train Loss: 0.1493, Validation Loss: 0.1477\n",
      "Epoch 417/1000 - Train Loss: 0.1490, Validation Loss: 0.1475\n",
      "Epoch 418/1000 - Train Loss: 0.1488, Validation Loss: 0.1472\n",
      "Epoch 419/1000 - Train Loss: 0.1485, Validation Loss: 0.1469\n",
      "Epoch 420/1000 - Train Loss: 0.1482, Validation Loss: 0.1467\n",
      "Epoch 421/1000 - Train Loss: 0.1480, Validation Loss: 0.1464\n",
      "Epoch 422/1000 - Train Loss: 0.1477, Validation Loss: 0.1462\n",
      "Epoch 423/1000 - Train Loss: 0.1475, Validation Loss: 0.1459\n",
      "Epoch 424/1000 - Train Loss: 0.1472, Validation Loss: 0.1457\n",
      "Epoch 425/1000 - Train Loss: 0.1469, Validation Loss: 0.1454\n",
      "Epoch 426/1000 - Train Loss: 0.1467, Validation Loss: 0.1452\n",
      "Epoch 427/1000 - Train Loss: 0.1464, Validation Loss: 0.1449\n",
      "Epoch 428/1000 - Train Loss: 0.1462, Validation Loss: 0.1447\n",
      "Epoch 429/1000 - Train Loss: 0.1459, Validation Loss: 0.1444\n",
      "Epoch 430/1000 - Train Loss: 0.1457, Validation Loss: 0.1442\n",
      "Epoch 431/1000 - Train Loss: 0.1454, Validation Loss: 0.1439\n",
      "Epoch 432/1000 - Train Loss: 0.1452, Validation Loss: 0.1437\n",
      "Epoch 433/1000 - Train Loss: 0.1449, Validation Loss: 0.1434\n",
      "Epoch 434/1000 - Train Loss: 0.1447, Validation Loss: 0.1432\n",
      "Epoch 435/1000 - Train Loss: 0.1445, Validation Loss: 0.1429\n",
      "Epoch 436/1000 - Train Loss: 0.1442, Validation Loss: 0.1427\n",
      "Epoch 437/1000 - Train Loss: 0.1440, Validation Loss: 0.1424\n",
      "Epoch 438/1000 - Train Loss: 0.1437, Validation Loss: 0.1422\n",
      "Epoch 439/1000 - Train Loss: 0.1435, Validation Loss: 0.1420\n",
      "Epoch 440/1000 - Train Loss: 0.1432, Validation Loss: 0.1417\n",
      "Epoch 441/1000 - Train Loss: 0.1430, Validation Loss: 0.1415\n",
      "Epoch 442/1000 - Train Loss: 0.1428, Validation Loss: 0.1413\n",
      "Epoch 443/1000 - Train Loss: 0.1425, Validation Loss: 0.1410\n",
      "Epoch 444/1000 - Train Loss: 0.1423, Validation Loss: 0.1408\n",
      "Epoch 445/1000 - Train Loss: 0.1420, Validation Loss: 0.1405\n",
      "Epoch 446/1000 - Train Loss: 0.1418, Validation Loss: 0.1403\n",
      "Epoch 447/1000 - Train Loss: 0.1416, Validation Loss: 0.1401\n",
      "Epoch 448/1000 - Train Loss: 0.1413, Validation Loss: 0.1399\n",
      "Epoch 449/1000 - Train Loss: 0.1411, Validation Loss: 0.1396\n",
      "Epoch 450/1000 - Train Loss: 0.1409, Validation Loss: 0.1394\n",
      "Epoch 451/1000 - Train Loss: 0.1406, Validation Loss: 0.1392\n",
      "Epoch 452/1000 - Train Loss: 0.1404, Validation Loss: 0.1389\n",
      "Epoch 453/1000 - Train Loss: 0.1402, Validation Loss: 0.1387\n",
      "Epoch 454/1000 - Train Loss: 0.1400, Validation Loss: 0.1385\n",
      "Epoch 455/1000 - Train Loss: 0.1397, Validation Loss: 0.1383\n",
      "Epoch 456/1000 - Train Loss: 0.1395, Validation Loss: 0.1380\n",
      "Epoch 457/1000 - Train Loss: 0.1393, Validation Loss: 0.1378\n",
      "Epoch 458/1000 - Train Loss: 0.1391, Validation Loss: 0.1376\n",
      "Epoch 459/1000 - Train Loss: 0.1388, Validation Loss: 0.1374\n",
      "Epoch 460/1000 - Train Loss: 0.1386, Validation Loss: 0.1371\n",
      "Epoch 461/1000 - Train Loss: 0.1384, Validation Loss: 0.1369\n",
      "Epoch 462/1000 - Train Loss: 0.1382, Validation Loss: 0.1367\n",
      "Epoch 463/1000 - Train Loss: 0.1379, Validation Loss: 0.1365\n",
      "Epoch 464/1000 - Train Loss: 0.1377, Validation Loss: 0.1363\n",
      "Epoch 465/1000 - Train Loss: 0.1375, Validation Loss: 0.1360\n",
      "Epoch 466/1000 - Train Loss: 0.1373, Validation Loss: 0.1358\n",
      "Epoch 467/1000 - Train Loss: 0.1371, Validation Loss: 0.1356\n",
      "Epoch 468/1000 - Train Loss: 0.1368, Validation Loss: 0.1354\n",
      "Epoch 469/1000 - Train Loss: 0.1366, Validation Loss: 0.1352\n",
      "Epoch 470/1000 - Train Loss: 0.1364, Validation Loss: 0.1350\n",
      "Epoch 471/1000 - Train Loss: 0.1362, Validation Loss: 0.1347\n",
      "Epoch 472/1000 - Train Loss: 0.1360, Validation Loss: 0.1345\n",
      "Epoch 473/1000 - Train Loss: 0.1358, Validation Loss: 0.1343\n",
      "Epoch 474/1000 - Train Loss: 0.1356, Validation Loss: 0.1341\n",
      "Epoch 475/1000 - Train Loss: 0.1354, Validation Loss: 0.1339\n",
      "Epoch 476/1000 - Train Loss: 0.1351, Validation Loss: 0.1337\n",
      "Epoch 477/1000 - Train Loss: 0.1349, Validation Loss: 0.1335\n",
      "Epoch 478/1000 - Train Loss: 0.1347, Validation Loss: 0.1333\n",
      "Epoch 479/1000 - Train Loss: 0.1345, Validation Loss: 0.1331\n",
      "Epoch 480/1000 - Train Loss: 0.1343, Validation Loss: 0.1329\n",
      "Epoch 481/1000 - Train Loss: 0.1341, Validation Loss: 0.1327\n",
      "Epoch 482/1000 - Train Loss: 0.1339, Validation Loss: 0.1325\n",
      "Epoch 483/1000 - Train Loss: 0.1337, Validation Loss: 0.1322\n",
      "Epoch 484/1000 - Train Loss: 0.1335, Validation Loss: 0.1320\n",
      "Epoch 485/1000 - Train Loss: 0.1333, Validation Loss: 0.1318\n",
      "Epoch 486/1000 - Train Loss: 0.1331, Validation Loss: 0.1316\n",
      "Epoch 487/1000 - Train Loss: 0.1329, Validation Loss: 0.1314\n",
      "Epoch 488/1000 - Train Loss: 0.1327, Validation Loss: 0.1312\n",
      "Epoch 489/1000 - Train Loss: 0.1325, Validation Loss: 0.1310\n",
      "Epoch 490/1000 - Train Loss: 0.1323, Validation Loss: 0.1308\n",
      "Epoch 491/1000 - Train Loss: 0.1321, Validation Loss: 0.1306\n",
      "Epoch 492/1000 - Train Loss: 0.1319, Validation Loss: 0.1304\n",
      "Epoch 493/1000 - Train Loss: 0.1317, Validation Loss: 0.1302\n",
      "Epoch 494/1000 - Train Loss: 0.1315, Validation Loss: 0.1300\n",
      "Epoch 495/1000 - Train Loss: 0.1313, Validation Loss: 0.1299\n",
      "Epoch 496/1000 - Train Loss: 0.1311, Validation Loss: 0.1297\n",
      "Epoch 497/1000 - Train Loss: 0.1309, Validation Loss: 0.1295\n",
      "Epoch 498/1000 - Train Loss: 0.1307, Validation Loss: 0.1293\n",
      "Epoch 499/1000 - Train Loss: 0.1305, Validation Loss: 0.1291\n",
      "Epoch 500/1000 - Train Loss: 0.1303, Validation Loss: 0.1289\n",
      "Epoch 501/1000 - Train Loss: 0.1301, Validation Loss: 0.1287\n",
      "Epoch 502/1000 - Train Loss: 0.1299, Validation Loss: 0.1285\n",
      "Epoch 503/1000 - Train Loss: 0.1297, Validation Loss: 0.1283\n",
      "Epoch 504/1000 - Train Loss: 0.1295, Validation Loss: 0.1281\n",
      "Epoch 505/1000 - Train Loss: 0.1293, Validation Loss: 0.1279\n",
      "Epoch 506/1000 - Train Loss: 0.1291, Validation Loss: 0.1277\n",
      "Epoch 507/1000 - Train Loss: 0.1289, Validation Loss: 0.1276\n",
      "Epoch 508/1000 - Train Loss: 0.1288, Validation Loss: 0.1274\n",
      "Epoch 509/1000 - Train Loss: 0.1286, Validation Loss: 0.1272\n",
      "Epoch 510/1000 - Train Loss: 0.1284, Validation Loss: 0.1270\n",
      "Epoch 511/1000 - Train Loss: 0.1282, Validation Loss: 0.1268\n",
      "Epoch 512/1000 - Train Loss: 0.1280, Validation Loss: 0.1266\n",
      "Epoch 513/1000 - Train Loss: 0.1278, Validation Loss: 0.1264\n",
      "Epoch 514/1000 - Train Loss: 0.1276, Validation Loss: 0.1263\n",
      "Epoch 515/1000 - Train Loss: 0.1275, Validation Loss: 0.1261\n",
      "Epoch 516/1000 - Train Loss: 0.1273, Validation Loss: 0.1259\n",
      "Epoch 517/1000 - Train Loss: 0.1271, Validation Loss: 0.1257\n",
      "Epoch 518/1000 - Train Loss: 0.1269, Validation Loss: 0.1255\n",
      "Epoch 519/1000 - Train Loss: 0.1267, Validation Loss: 0.1253\n",
      "Epoch 520/1000 - Train Loss: 0.1265, Validation Loss: 0.1252\n",
      "Epoch 521/1000 - Train Loss: 0.1264, Validation Loss: 0.1250\n",
      "Epoch 522/1000 - Train Loss: 0.1262, Validation Loss: 0.1248\n",
      "Epoch 523/1000 - Train Loss: 0.1260, Validation Loss: 0.1246\n",
      "Epoch 524/1000 - Train Loss: 0.1258, Validation Loss: 0.1244\n",
      "Epoch 525/1000 - Train Loss: 0.1256, Validation Loss: 0.1243\n",
      "Epoch 526/1000 - Train Loss: 0.1255, Validation Loss: 0.1241\n",
      "Epoch 527/1000 - Train Loss: 0.1253, Validation Loss: 0.1239\n",
      "Epoch 528/1000 - Train Loss: 0.1251, Validation Loss: 0.1237\n",
      "Epoch 529/1000 - Train Loss: 0.1249, Validation Loss: 0.1236\n",
      "Epoch 530/1000 - Train Loss: 0.1247, Validation Loss: 0.1234\n",
      "Epoch 531/1000 - Train Loss: 0.1246, Validation Loss: 0.1232\n",
      "Epoch 532/1000 - Train Loss: 0.1244, Validation Loss: 0.1230\n",
      "Epoch 533/1000 - Train Loss: 0.1242, Validation Loss: 0.1229\n",
      "Epoch 534/1000 - Train Loss: 0.1241, Validation Loss: 0.1227\n",
      "Epoch 535/1000 - Train Loss: 0.1239, Validation Loss: 0.1225\n",
      "Epoch 536/1000 - Train Loss: 0.1237, Validation Loss: 0.1224\n",
      "Epoch 537/1000 - Train Loss: 0.1235, Validation Loss: 0.1222\n",
      "Epoch 538/1000 - Train Loss: 0.1234, Validation Loss: 0.1220\n",
      "Epoch 539/1000 - Train Loss: 0.1232, Validation Loss: 0.1218\n",
      "Epoch 540/1000 - Train Loss: 0.1230, Validation Loss: 0.1217\n",
      "Epoch 541/1000 - Train Loss: 0.1229, Validation Loss: 0.1215\n",
      "Epoch 542/1000 - Train Loss: 0.1227, Validation Loss: 0.1213\n",
      "Epoch 543/1000 - Train Loss: 0.1225, Validation Loss: 0.1212\n",
      "Epoch 544/1000 - Train Loss: 0.1223, Validation Loss: 0.1210\n",
      "Epoch 545/1000 - Train Loss: 0.1222, Validation Loss: 0.1208\n",
      "Epoch 546/1000 - Train Loss: 0.1220, Validation Loss: 0.1207\n",
      "Epoch 547/1000 - Train Loss: 0.1218, Validation Loss: 0.1205\n",
      "Epoch 548/1000 - Train Loss: 0.1217, Validation Loss: 0.1203\n",
      "Epoch 549/1000 - Train Loss: 0.1215, Validation Loss: 0.1202\n",
      "Epoch 550/1000 - Train Loss: 0.1213, Validation Loss: 0.1200\n",
      "Epoch 551/1000 - Train Loss: 0.1212, Validation Loss: 0.1198\n",
      "Epoch 552/1000 - Train Loss: 0.1210, Validation Loss: 0.1197\n",
      "Epoch 553/1000 - Train Loss: 0.1209, Validation Loss: 0.1195\n",
      "Epoch 554/1000 - Train Loss: 0.1207, Validation Loss: 0.1194\n",
      "Epoch 555/1000 - Train Loss: 0.1205, Validation Loss: 0.1192\n",
      "Epoch 556/1000 - Train Loss: 0.1204, Validation Loss: 0.1190\n",
      "Epoch 557/1000 - Train Loss: 0.1202, Validation Loss: 0.1189\n",
      "Epoch 558/1000 - Train Loss: 0.1200, Validation Loss: 0.1187\n",
      "Epoch 559/1000 - Train Loss: 0.1199, Validation Loss: 0.1186\n",
      "Epoch 560/1000 - Train Loss: 0.1197, Validation Loss: 0.1184\n",
      "Epoch 561/1000 - Train Loss: 0.1196, Validation Loss: 0.1182\n",
      "Epoch 562/1000 - Train Loss: 0.1194, Validation Loss: 0.1181\n",
      "Epoch 563/1000 - Train Loss: 0.1192, Validation Loss: 0.1179\n",
      "Epoch 564/1000 - Train Loss: 0.1191, Validation Loss: 0.1178\n",
      "Epoch 565/1000 - Train Loss: 0.1189, Validation Loss: 0.1176\n",
      "Epoch 566/1000 - Train Loss: 0.1188, Validation Loss: 0.1175\n",
      "Epoch 567/1000 - Train Loss: 0.1186, Validation Loss: 0.1173\n",
      "Epoch 568/1000 - Train Loss: 0.1185, Validation Loss: 0.1171\n",
      "Epoch 569/1000 - Train Loss: 0.1183, Validation Loss: 0.1170\n",
      "Epoch 570/1000 - Train Loss: 0.1181, Validation Loss: 0.1168\n",
      "Epoch 571/1000 - Train Loss: 0.1180, Validation Loss: 0.1167\n",
      "Epoch 572/1000 - Train Loss: 0.1178, Validation Loss: 0.1165\n",
      "Epoch 573/1000 - Train Loss: 0.1177, Validation Loss: 0.1164\n",
      "Epoch 574/1000 - Train Loss: 0.1175, Validation Loss: 0.1162\n",
      "Epoch 575/1000 - Train Loss: 0.1174, Validation Loss: 0.1161\n",
      "Epoch 576/1000 - Train Loss: 0.1172, Validation Loss: 0.1159\n",
      "Epoch 577/1000 - Train Loss: 0.1171, Validation Loss: 0.1158\n",
      "Epoch 578/1000 - Train Loss: 0.1169, Validation Loss: 0.1156\n",
      "Epoch 579/1000 - Train Loss: 0.1168, Validation Loss: 0.1155\n",
      "Epoch 580/1000 - Train Loss: 0.1166, Validation Loss: 0.1153\n",
      "Epoch 581/1000 - Train Loss: 0.1165, Validation Loss: 0.1152\n",
      "Epoch 582/1000 - Train Loss: 0.1163, Validation Loss: 0.1150\n",
      "Epoch 583/1000 - Train Loss: 0.1162, Validation Loss: 0.1149\n",
      "Epoch 584/1000 - Train Loss: 0.1160, Validation Loss: 0.1147\n",
      "Epoch 585/1000 - Train Loss: 0.1159, Validation Loss: 0.1146\n",
      "Epoch 586/1000 - Train Loss: 0.1157, Validation Loss: 0.1144\n",
      "Epoch 587/1000 - Train Loss: 0.1156, Validation Loss: 0.1143\n",
      "Epoch 588/1000 - Train Loss: 0.1154, Validation Loss: 0.1141\n",
      "Epoch 589/1000 - Train Loss: 0.1153, Validation Loss: 0.1140\n",
      "Epoch 590/1000 - Train Loss: 0.1151, Validation Loss: 0.1139\n",
      "Epoch 591/1000 - Train Loss: 0.1150, Validation Loss: 0.1137\n",
      "Epoch 592/1000 - Train Loss: 0.1148, Validation Loss: 0.1136\n",
      "Epoch 593/1000 - Train Loss: 0.1147, Validation Loss: 0.1134\n",
      "Epoch 594/1000 - Train Loss: 0.1145, Validation Loss: 0.1133\n",
      "Epoch 595/1000 - Train Loss: 0.1144, Validation Loss: 0.1131\n",
      "Epoch 596/1000 - Train Loss: 0.1143, Validation Loss: 0.1130\n",
      "Epoch 597/1000 - Train Loss: 0.1141, Validation Loss: 0.1128\n",
      "Epoch 598/1000 - Train Loss: 0.1140, Validation Loss: 0.1127\n",
      "Epoch 599/1000 - Train Loss: 0.1138, Validation Loss: 0.1126\n",
      "Epoch 600/1000 - Train Loss: 0.1137, Validation Loss: 0.1124\n",
      "Epoch 601/1000 - Train Loss: 0.1135, Validation Loss: 0.1123\n",
      "Epoch 602/1000 - Train Loss: 0.1134, Validation Loss: 0.1121\n",
      "Epoch 603/1000 - Train Loss: 0.1133, Validation Loss: 0.1120\n",
      "Epoch 604/1000 - Train Loss: 0.1131, Validation Loss: 0.1119\n",
      "Epoch 605/1000 - Train Loss: 0.1130, Validation Loss: 0.1117\n",
      "Epoch 606/1000 - Train Loss: 0.1128, Validation Loss: 0.1116\n",
      "Epoch 607/1000 - Train Loss: 0.1127, Validation Loss: 0.1114\n",
      "Epoch 608/1000 - Train Loss: 0.1126, Validation Loss: 0.1113\n",
      "Epoch 609/1000 - Train Loss: 0.1124, Validation Loss: 0.1112\n",
      "Epoch 610/1000 - Train Loss: 0.1123, Validation Loss: 0.1110\n",
      "Epoch 611/1000 - Train Loss: 0.1121, Validation Loss: 0.1109\n",
      "Epoch 612/1000 - Train Loss: 0.1120, Validation Loss: 0.1108\n",
      "Epoch 613/1000 - Train Loss: 0.1119, Validation Loss: 0.1106\n",
      "Epoch 614/1000 - Train Loss: 0.1117, Validation Loss: 0.1105\n",
      "Epoch 615/1000 - Train Loss: 0.1116, Validation Loss: 0.1104\n",
      "Epoch 616/1000 - Train Loss: 0.1115, Validation Loss: 0.1102\n",
      "Epoch 617/1000 - Train Loss: 0.1113, Validation Loss: 0.1101\n",
      "Epoch 618/1000 - Train Loss: 0.1112, Validation Loss: 0.1100\n",
      "Epoch 619/1000 - Train Loss: 0.1111, Validation Loss: 0.1098\n",
      "Epoch 620/1000 - Train Loss: 0.1109, Validation Loss: 0.1097\n",
      "Epoch 621/1000 - Train Loss: 0.1108, Validation Loss: 0.1096\n",
      "Epoch 622/1000 - Train Loss: 0.1107, Validation Loss: 0.1094\n",
      "Epoch 623/1000 - Train Loss: 0.1105, Validation Loss: 0.1093\n",
      "Epoch 624/1000 - Train Loss: 0.1104, Validation Loss: 0.1092\n",
      "Epoch 625/1000 - Train Loss: 0.1103, Validation Loss: 0.1090\n",
      "Epoch 626/1000 - Train Loss: 0.1101, Validation Loss: 0.1089\n",
      "Epoch 627/1000 - Train Loss: 0.1100, Validation Loss: 0.1088\n",
      "Epoch 628/1000 - Train Loss: 0.1099, Validation Loss: 0.1086\n",
      "Epoch 629/1000 - Train Loss: 0.1097, Validation Loss: 0.1085\n",
      "Epoch 630/1000 - Train Loss: 0.1096, Validation Loss: 0.1084\n",
      "Epoch 631/1000 - Train Loss: 0.1095, Validation Loss: 0.1082\n",
      "Epoch 632/1000 - Train Loss: 0.1093, Validation Loss: 0.1081\n",
      "Epoch 633/1000 - Train Loss: 0.1092, Validation Loss: 0.1080\n",
      "Epoch 634/1000 - Train Loss: 0.1091, Validation Loss: 0.1079\n",
      "Epoch 635/1000 - Train Loss: 0.1090, Validation Loss: 0.1077\n",
      "Epoch 636/1000 - Train Loss: 0.1088, Validation Loss: 0.1076\n",
      "Epoch 637/1000 - Train Loss: 0.1087, Validation Loss: 0.1075\n",
      "Epoch 638/1000 - Train Loss: 0.1086, Validation Loss: 0.1073\n",
      "Epoch 639/1000 - Train Loss: 0.1084, Validation Loss: 0.1072\n",
      "Epoch 640/1000 - Train Loss: 0.1083, Validation Loss: 0.1071\n",
      "Epoch 641/1000 - Train Loss: 0.1082, Validation Loss: 0.1070\n",
      "Epoch 642/1000 - Train Loss: 0.1081, Validation Loss: 0.1068\n",
      "Epoch 643/1000 - Train Loss: 0.1079, Validation Loss: 0.1067\n",
      "Epoch 644/1000 - Train Loss: 0.1078, Validation Loss: 0.1066\n",
      "Epoch 645/1000 - Train Loss: 0.1077, Validation Loss: 0.1065\n",
      "Epoch 646/1000 - Train Loss: 0.1076, Validation Loss: 0.1063\n",
      "Epoch 647/1000 - Train Loss: 0.1074, Validation Loss: 0.1062\n",
      "Epoch 648/1000 - Train Loss: 0.1073, Validation Loss: 0.1061\n",
      "Epoch 649/1000 - Train Loss: 0.1072, Validation Loss: 0.1060\n",
      "Epoch 650/1000 - Train Loss: 0.1071, Validation Loss: 0.1059\n",
      "Epoch 651/1000 - Train Loss: 0.1069, Validation Loss: 0.1057\n",
      "Epoch 652/1000 - Train Loss: 0.1068, Validation Loss: 0.1056\n",
      "Epoch 653/1000 - Train Loss: 0.1067, Validation Loss: 0.1055\n",
      "Epoch 654/1000 - Train Loss: 0.1066, Validation Loss: 0.1054\n",
      "Epoch 655/1000 - Train Loss: 0.1064, Validation Loss: 0.1052\n",
      "Epoch 656/1000 - Train Loss: 0.1063, Validation Loss: 0.1051\n",
      "Epoch 657/1000 - Train Loss: 0.1062, Validation Loss: 0.1050\n",
      "Epoch 658/1000 - Train Loss: 0.1061, Validation Loss: 0.1049\n",
      "Epoch 659/1000 - Train Loss: 0.1060, Validation Loss: 0.1048\n",
      "Epoch 660/1000 - Train Loss: 0.1058, Validation Loss: 0.1046\n",
      "Epoch 661/1000 - Train Loss: 0.1057, Validation Loss: 0.1045\n",
      "Epoch 662/1000 - Train Loss: 0.1056, Validation Loss: 0.1044\n",
      "Epoch 663/1000 - Train Loss: 0.1055, Validation Loss: 0.1043\n",
      "Epoch 664/1000 - Train Loss: 0.1054, Validation Loss: 0.1042\n",
      "Epoch 665/1000 - Train Loss: 0.1052, Validation Loss: 0.1040\n",
      "Epoch 666/1000 - Train Loss: 0.1051, Validation Loss: 0.1039\n",
      "Epoch 667/1000 - Train Loss: 0.1050, Validation Loss: 0.1038\n",
      "Epoch 668/1000 - Train Loss: 0.1049, Validation Loss: 0.1037\n",
      "Epoch 669/1000 - Train Loss: 0.1048, Validation Loss: 0.1036\n",
      "Epoch 670/1000 - Train Loss: 0.1046, Validation Loss: 0.1035\n",
      "Epoch 671/1000 - Train Loss: 0.1045, Validation Loss: 0.1033\n",
      "Epoch 672/1000 - Train Loss: 0.1044, Validation Loss: 0.1032\n",
      "Epoch 673/1000 - Train Loss: 0.1043, Validation Loss: 0.1031\n",
      "Epoch 674/1000 - Train Loss: 0.1042, Validation Loss: 0.1030\n",
      "Epoch 675/1000 - Train Loss: 0.1041, Validation Loss: 0.1029\n",
      "Epoch 676/1000 - Train Loss: 0.1039, Validation Loss: 0.1028\n",
      "Epoch 677/1000 - Train Loss: 0.1038, Validation Loss: 0.1027\n",
      "Epoch 678/1000 - Train Loss: 0.1037, Validation Loss: 0.1025\n",
      "Epoch 679/1000 - Train Loss: 0.1036, Validation Loss: 0.1024\n",
      "Epoch 680/1000 - Train Loss: 0.1035, Validation Loss: 0.1023\n",
      "Epoch 681/1000 - Train Loss: 0.1034, Validation Loss: 0.1022\n",
      "Epoch 682/1000 - Train Loss: 0.1033, Validation Loss: 0.1021\n",
      "Epoch 683/1000 - Train Loss: 0.1031, Validation Loss: 0.1020\n",
      "Epoch 684/1000 - Train Loss: 0.1030, Validation Loss: 0.1019\n",
      "Epoch 685/1000 - Train Loss: 0.1029, Validation Loss: 0.1018\n",
      "Epoch 686/1000 - Train Loss: 0.1028, Validation Loss: 0.1016\n",
      "Epoch 687/1000 - Train Loss: 0.1027, Validation Loss: 0.1015\n",
      "Epoch 688/1000 - Train Loss: 0.1026, Validation Loss: 0.1014\n",
      "Epoch 689/1000 - Train Loss: 0.1025, Validation Loss: 0.1013\n",
      "Epoch 690/1000 - Train Loss: 0.1024, Validation Loss: 0.1012\n",
      "Epoch 691/1000 - Train Loss: 0.1022, Validation Loss: 0.1011\n",
      "Epoch 692/1000 - Train Loss: 0.1021, Validation Loss: 0.1010\n",
      "Epoch 693/1000 - Train Loss: 0.1020, Validation Loss: 0.1009\n",
      "Epoch 694/1000 - Train Loss: 0.1019, Validation Loss: 0.1008\n",
      "Epoch 695/1000 - Train Loss: 0.1018, Validation Loss: 0.1006\n",
      "Epoch 696/1000 - Train Loss: 0.1017, Validation Loss: 0.1005\n",
      "Epoch 697/1000 - Train Loss: 0.1016, Validation Loss: 0.1004\n",
      "Epoch 698/1000 - Train Loss: 0.1015, Validation Loss: 0.1003\n",
      "Epoch 699/1000 - Train Loss: 0.1014, Validation Loss: 0.1002\n",
      "Epoch 700/1000 - Train Loss: 0.1013, Validation Loss: 0.1001\n",
      "Epoch 701/1000 - Train Loss: 0.1011, Validation Loss: 0.1000\n",
      "Epoch 702/1000 - Train Loss: 0.1010, Validation Loss: 0.0999\n",
      "Epoch 703/1000 - Train Loss: 0.1009, Validation Loss: 0.0998\n",
      "Epoch 704/1000 - Train Loss: 0.1008, Validation Loss: 0.0997\n",
      "Epoch 705/1000 - Train Loss: 0.1007, Validation Loss: 0.0996\n",
      "Epoch 706/1000 - Train Loss: 0.1006, Validation Loss: 0.0995\n",
      "Epoch 707/1000 - Train Loss: 0.1005, Validation Loss: 0.0994\n",
      "Epoch 708/1000 - Train Loss: 0.1004, Validation Loss: 0.0992\n",
      "Epoch 709/1000 - Train Loss: 0.1003, Validation Loss: 0.0991\n",
      "Epoch 710/1000 - Train Loss: 0.1002, Validation Loss: 0.0990\n",
      "Epoch 711/1000 - Train Loss: 0.1001, Validation Loss: 0.0989\n",
      "Epoch 712/1000 - Train Loss: 0.1000, Validation Loss: 0.0988\n",
      "Epoch 713/1000 - Train Loss: 0.0999, Validation Loss: 0.0987\n",
      "Epoch 714/1000 - Train Loss: 0.0998, Validation Loss: 0.0986\n",
      "Epoch 715/1000 - Train Loss: 0.0997, Validation Loss: 0.0985\n",
      "Epoch 716/1000 - Train Loss: 0.0995, Validation Loss: 0.0984\n",
      "Epoch 717/1000 - Train Loss: 0.0994, Validation Loss: 0.0983\n",
      "Epoch 718/1000 - Train Loss: 0.0993, Validation Loss: 0.0982\n",
      "Epoch 719/1000 - Train Loss: 0.0992, Validation Loss: 0.0981\n",
      "Epoch 720/1000 - Train Loss: 0.0991, Validation Loss: 0.0980\n",
      "Epoch 721/1000 - Train Loss: 0.0990, Validation Loss: 0.0979\n",
      "Epoch 722/1000 - Train Loss: 0.0989, Validation Loss: 0.0978\n",
      "Epoch 723/1000 - Train Loss: 0.0988, Validation Loss: 0.0977\n",
      "Epoch 724/1000 - Train Loss: 0.0987, Validation Loss: 0.0976\n",
      "Epoch 725/1000 - Train Loss: 0.0986, Validation Loss: 0.0975\n",
      "Epoch 726/1000 - Train Loss: 0.0985, Validation Loss: 0.0974\n",
      "Epoch 727/1000 - Train Loss: 0.0984, Validation Loss: 0.0973\n",
      "Epoch 728/1000 - Train Loss: 0.0983, Validation Loss: 0.0972\n",
      "Epoch 729/1000 - Train Loss: 0.0982, Validation Loss: 0.0971\n",
      "Epoch 730/1000 - Train Loss: 0.0981, Validation Loss: 0.0970\n",
      "Epoch 731/1000 - Train Loss: 0.0980, Validation Loss: 0.0969\n",
      "Epoch 732/1000 - Train Loss: 0.0979, Validation Loss: 0.0968\n",
      "Epoch 733/1000 - Train Loss: 0.0978, Validation Loss: 0.0967\n",
      "Epoch 734/1000 - Train Loss: 0.0977, Validation Loss: 0.0966\n",
      "Epoch 735/1000 - Train Loss: 0.0976, Validation Loss: 0.0965\n",
      "Epoch 736/1000 - Train Loss: 0.0975, Validation Loss: 0.0964\n",
      "Epoch 737/1000 - Train Loss: 0.0974, Validation Loss: 0.0963\n",
      "Epoch 738/1000 - Train Loss: 0.0973, Validation Loss: 0.0962\n",
      "Epoch 739/1000 - Train Loss: 0.0972, Validation Loss: 0.0961\n",
      "Epoch 740/1000 - Train Loss: 0.0971, Validation Loss: 0.0960\n",
      "Epoch 741/1000 - Train Loss: 0.0970, Validation Loss: 0.0959\n",
      "Epoch 742/1000 - Train Loss: 0.0969, Validation Loss: 0.0958\n",
      "Epoch 743/1000 - Train Loss: 0.0968, Validation Loss: 0.0957\n",
      "Epoch 744/1000 - Train Loss: 0.0967, Validation Loss: 0.0956\n",
      "Epoch 745/1000 - Train Loss: 0.0966, Validation Loss: 0.0955\n",
      "Epoch 746/1000 - Train Loss: 0.0965, Validation Loss: 0.0954\n",
      "Epoch 747/1000 - Train Loss: 0.0964, Validation Loss: 0.0953\n",
      "Epoch 748/1000 - Train Loss: 0.0963, Validation Loss: 0.0952\n",
      "Epoch 749/1000 - Train Loss: 0.0962, Validation Loss: 0.0951\n",
      "Epoch 750/1000 - Train Loss: 0.0961, Validation Loss: 0.0950\n",
      "Epoch 751/1000 - Train Loss: 0.0960, Validation Loss: 0.0949\n",
      "Epoch 752/1000 - Train Loss: 0.0959, Validation Loss: 0.0948\n",
      "Epoch 753/1000 - Train Loss: 0.0958, Validation Loss: 0.0947\n",
      "Epoch 754/1000 - Train Loss: 0.0957, Validation Loss: 0.0947\n",
      "Epoch 755/1000 - Train Loss: 0.0957, Validation Loss: 0.0946\n",
      "Epoch 756/1000 - Train Loss: 0.0956, Validation Loss: 0.0945\n",
      "Epoch 757/1000 - Train Loss: 0.0955, Validation Loss: 0.0944\n",
      "Epoch 758/1000 - Train Loss: 0.0954, Validation Loss: 0.0943\n",
      "Epoch 759/1000 - Train Loss: 0.0953, Validation Loss: 0.0942\n",
      "Epoch 760/1000 - Train Loss: 0.0952, Validation Loss: 0.0941\n",
      "Epoch 761/1000 - Train Loss: 0.0951, Validation Loss: 0.0940\n",
      "Epoch 762/1000 - Train Loss: 0.0950, Validation Loss: 0.0939\n",
      "Epoch 763/1000 - Train Loss: 0.0949, Validation Loss: 0.0938\n",
      "Epoch 764/1000 - Train Loss: 0.0948, Validation Loss: 0.0937\n",
      "Epoch 765/1000 - Train Loss: 0.0947, Validation Loss: 0.0936\n",
      "Epoch 766/1000 - Train Loss: 0.0946, Validation Loss: 0.0935\n",
      "Epoch 767/1000 - Train Loss: 0.0945, Validation Loss: 0.0934\n",
      "Epoch 768/1000 - Train Loss: 0.0944, Validation Loss: 0.0933\n",
      "Epoch 769/1000 - Train Loss: 0.0943, Validation Loss: 0.0933\n",
      "Epoch 770/1000 - Train Loss: 0.0942, Validation Loss: 0.0932\n",
      "Epoch 771/1000 - Train Loss: 0.0942, Validation Loss: 0.0931\n",
      "Epoch 772/1000 - Train Loss: 0.0941, Validation Loss: 0.0930\n",
      "Epoch 773/1000 - Train Loss: 0.0940, Validation Loss: 0.0929\n",
      "Epoch 774/1000 - Train Loss: 0.0939, Validation Loss: 0.0928\n",
      "Epoch 775/1000 - Train Loss: 0.0938, Validation Loss: 0.0927\n",
      "Epoch 776/1000 - Train Loss: 0.0937, Validation Loss: 0.0926\n",
      "Epoch 777/1000 - Train Loss: 0.0936, Validation Loss: 0.0925\n",
      "Epoch 778/1000 - Train Loss: 0.0935, Validation Loss: 0.0924\n",
      "Epoch 779/1000 - Train Loss: 0.0934, Validation Loss: 0.0924\n",
      "Epoch 780/1000 - Train Loss: 0.0933, Validation Loss: 0.0923\n",
      "Epoch 781/1000 - Train Loss: 0.0932, Validation Loss: 0.0922\n",
      "Epoch 782/1000 - Train Loss: 0.0932, Validation Loss: 0.0921\n",
      "Epoch 783/1000 - Train Loss: 0.0931, Validation Loss: 0.0920\n",
      "Epoch 784/1000 - Train Loss: 0.0930, Validation Loss: 0.0919\n",
      "Epoch 785/1000 - Train Loss: 0.0929, Validation Loss: 0.0918\n",
      "Epoch 786/1000 - Train Loss: 0.0928, Validation Loss: 0.0917\n",
      "Epoch 787/1000 - Train Loss: 0.0927, Validation Loss: 0.0916\n",
      "Epoch 788/1000 - Train Loss: 0.0926, Validation Loss: 0.0916\n",
      "Epoch 789/1000 - Train Loss: 0.0925, Validation Loss: 0.0915\n",
      "Epoch 790/1000 - Train Loss: 0.0924, Validation Loss: 0.0914\n",
      "Epoch 791/1000 - Train Loss: 0.0924, Validation Loss: 0.0913\n",
      "Epoch 792/1000 - Train Loss: 0.0923, Validation Loss: 0.0912\n",
      "Epoch 793/1000 - Train Loss: 0.0922, Validation Loss: 0.0911\n",
      "Epoch 794/1000 - Train Loss: 0.0921, Validation Loss: 0.0910\n",
      "Epoch 795/1000 - Train Loss: 0.0920, Validation Loss: 0.0909\n",
      "Epoch 796/1000 - Train Loss: 0.0919, Validation Loss: 0.0909\n",
      "Epoch 797/1000 - Train Loss: 0.0918, Validation Loss: 0.0908\n",
      "Epoch 798/1000 - Train Loss: 0.0917, Validation Loss: 0.0907\n",
      "Epoch 799/1000 - Train Loss: 0.0917, Validation Loss: 0.0906\n",
      "Epoch 800/1000 - Train Loss: 0.0916, Validation Loss: 0.0905\n",
      "Epoch 801/1000 - Train Loss: 0.0915, Validation Loss: 0.0904\n",
      "Epoch 802/1000 - Train Loss: 0.0914, Validation Loss: 0.0903\n",
      "Epoch 803/1000 - Train Loss: 0.0913, Validation Loss: 0.0903\n",
      "Epoch 804/1000 - Train Loss: 0.0912, Validation Loss: 0.0902\n",
      "Epoch 805/1000 - Train Loss: 0.0911, Validation Loss: 0.0901\n",
      "Epoch 806/1000 - Train Loss: 0.0911, Validation Loss: 0.0900\n",
      "Epoch 807/1000 - Train Loss: 0.0910, Validation Loss: 0.0899\n",
      "Epoch 808/1000 - Train Loss: 0.0909, Validation Loss: 0.0898\n",
      "Epoch 809/1000 - Train Loss: 0.0908, Validation Loss: 0.0898\n",
      "Epoch 810/1000 - Train Loss: 0.0907, Validation Loss: 0.0897\n",
      "Epoch 811/1000 - Train Loss: 0.0906, Validation Loss: 0.0896\n",
      "Epoch 812/1000 - Train Loss: 0.0906, Validation Loss: 0.0895\n",
      "Epoch 813/1000 - Train Loss: 0.0905, Validation Loss: 0.0894\n",
      "Epoch 814/1000 - Train Loss: 0.0904, Validation Loss: 0.0893\n",
      "Epoch 815/1000 - Train Loss: 0.0903, Validation Loss: 0.0893\n",
      "Epoch 816/1000 - Train Loss: 0.0902, Validation Loss: 0.0892\n",
      "Epoch 817/1000 - Train Loss: 0.0901, Validation Loss: 0.0891\n",
      "Epoch 818/1000 - Train Loss: 0.0901, Validation Loss: 0.0890\n",
      "Epoch 819/1000 - Train Loss: 0.0900, Validation Loss: 0.0889\n",
      "Epoch 820/1000 - Train Loss: 0.0899, Validation Loss: 0.0888\n",
      "Epoch 821/1000 - Train Loss: 0.0898, Validation Loss: 0.0888\n",
      "Epoch 822/1000 - Train Loss: 0.0897, Validation Loss: 0.0887\n",
      "Epoch 823/1000 - Train Loss: 0.0896, Validation Loss: 0.0886\n",
      "Epoch 824/1000 - Train Loss: 0.0896, Validation Loss: 0.0885\n",
      "Epoch 825/1000 - Train Loss: 0.0895, Validation Loss: 0.0884\n",
      "Epoch 826/1000 - Train Loss: 0.0894, Validation Loss: 0.0884\n",
      "Epoch 827/1000 - Train Loss: 0.0893, Validation Loss: 0.0883\n",
      "Epoch 828/1000 - Train Loss: 0.0892, Validation Loss: 0.0882\n",
      "Epoch 829/1000 - Train Loss: 0.0892, Validation Loss: 0.0881\n",
      "Epoch 830/1000 - Train Loss: 0.0891, Validation Loss: 0.0880\n",
      "Epoch 831/1000 - Train Loss: 0.0890, Validation Loss: 0.0880\n",
      "Epoch 832/1000 - Train Loss: 0.0889, Validation Loss: 0.0879\n",
      "Epoch 833/1000 - Train Loss: 0.0888, Validation Loss: 0.0878\n",
      "Epoch 834/1000 - Train Loss: 0.0887, Validation Loss: 0.0877\n",
      "Epoch 835/1000 - Train Loss: 0.0887, Validation Loss: 0.0876\n",
      "Epoch 836/1000 - Train Loss: 0.0886, Validation Loss: 0.0876\n",
      "Epoch 837/1000 - Train Loss: 0.0885, Validation Loss: 0.0875\n",
      "Epoch 838/1000 - Train Loss: 0.0884, Validation Loss: 0.0874\n",
      "Epoch 839/1000 - Train Loss: 0.0884, Validation Loss: 0.0873\n",
      "Epoch 840/1000 - Train Loss: 0.0883, Validation Loss: 0.0873\n",
      "Epoch 841/1000 - Train Loss: 0.0882, Validation Loss: 0.0872\n",
      "Epoch 842/1000 - Train Loss: 0.0881, Validation Loss: 0.0871\n",
      "Epoch 843/1000 - Train Loss: 0.0880, Validation Loss: 0.0870\n",
      "Epoch 844/1000 - Train Loss: 0.0880, Validation Loss: 0.0869\n",
      "Epoch 845/1000 - Train Loss: 0.0879, Validation Loss: 0.0869\n",
      "Epoch 846/1000 - Train Loss: 0.0878, Validation Loss: 0.0868\n",
      "Epoch 847/1000 - Train Loss: 0.0877, Validation Loss: 0.0867\n",
      "Epoch 848/1000 - Train Loss: 0.0876, Validation Loss: 0.0866\n",
      "Epoch 849/1000 - Train Loss: 0.0876, Validation Loss: 0.0866\n",
      "Epoch 850/1000 - Train Loss: 0.0875, Validation Loss: 0.0865\n",
      "Epoch 851/1000 - Train Loss: 0.0874, Validation Loss: 0.0864\n",
      "Epoch 852/1000 - Train Loss: 0.0873, Validation Loss: 0.0863\n",
      "Epoch 853/1000 - Train Loss: 0.0873, Validation Loss: 0.0862\n",
      "Epoch 854/1000 - Train Loss: 0.0872, Validation Loss: 0.0862\n",
      "Epoch 855/1000 - Train Loss: 0.0871, Validation Loss: 0.0861\n",
      "Epoch 856/1000 - Train Loss: 0.0870, Validation Loss: 0.0860\n",
      "Epoch 857/1000 - Train Loss: 0.0870, Validation Loss: 0.0859\n",
      "Epoch 858/1000 - Train Loss: 0.0869, Validation Loss: 0.0859\n",
      "Epoch 859/1000 - Train Loss: 0.0868, Validation Loss: 0.0858\n",
      "Epoch 860/1000 - Train Loss: 0.0867, Validation Loss: 0.0857\n",
      "Epoch 861/1000 - Train Loss: 0.0866, Validation Loss: 0.0856\n",
      "Epoch 862/1000 - Train Loss: 0.0866, Validation Loss: 0.0856\n",
      "Epoch 863/1000 - Train Loss: 0.0865, Validation Loss: 0.0855\n",
      "Epoch 864/1000 - Train Loss: 0.0864, Validation Loss: 0.0854\n",
      "Epoch 865/1000 - Train Loss: 0.0863, Validation Loss: 0.0853\n",
      "Epoch 866/1000 - Train Loss: 0.0863, Validation Loss: 0.0853\n",
      "Epoch 867/1000 - Train Loss: 0.0862, Validation Loss: 0.0852\n",
      "Epoch 868/1000 - Train Loss: 0.0861, Validation Loss: 0.0851\n",
      "Epoch 869/1000 - Train Loss: 0.0860, Validation Loss: 0.0851\n",
      "Epoch 870/1000 - Train Loss: 0.0860, Validation Loss: 0.0850\n",
      "Epoch 871/1000 - Train Loss: 0.0859, Validation Loss: 0.0849\n",
      "Epoch 872/1000 - Train Loss: 0.0858, Validation Loss: 0.0848\n",
      "Epoch 873/1000 - Train Loss: 0.0858, Validation Loss: 0.0848\n",
      "Epoch 874/1000 - Train Loss: 0.0857, Validation Loss: 0.0847\n",
      "Epoch 875/1000 - Train Loss: 0.0856, Validation Loss: 0.0846\n",
      "Epoch 876/1000 - Train Loss: 0.0855, Validation Loss: 0.0845\n",
      "Epoch 877/1000 - Train Loss: 0.0855, Validation Loss: 0.0845\n",
      "Epoch 878/1000 - Train Loss: 0.0854, Validation Loss: 0.0844\n",
      "Epoch 879/1000 - Train Loss: 0.0853, Validation Loss: 0.0843\n",
      "Epoch 880/1000 - Train Loss: 0.0852, Validation Loss: 0.0842\n",
      "Epoch 881/1000 - Train Loss: 0.0852, Validation Loss: 0.0842\n",
      "Epoch 882/1000 - Train Loss: 0.0851, Validation Loss: 0.0841\n",
      "Epoch 883/1000 - Train Loss: 0.0850, Validation Loss: 0.0840\n",
      "Epoch 884/1000 - Train Loss: 0.0849, Validation Loss: 0.0840\n",
      "Epoch 885/1000 - Train Loss: 0.0849, Validation Loss: 0.0839\n",
      "Epoch 886/1000 - Train Loss: 0.0848, Validation Loss: 0.0838\n",
      "Epoch 887/1000 - Train Loss: 0.0847, Validation Loss: 0.0837\n",
      "Epoch 888/1000 - Train Loss: 0.0847, Validation Loss: 0.0837\n",
      "Epoch 889/1000 - Train Loss: 0.0846, Validation Loss: 0.0836\n",
      "Epoch 890/1000 - Train Loss: 0.0845, Validation Loss: 0.0835\n",
      "Epoch 891/1000 - Train Loss: 0.0844, Validation Loss: 0.0835\n",
      "Epoch 892/1000 - Train Loss: 0.0844, Validation Loss: 0.0834\n",
      "Epoch 893/1000 - Train Loss: 0.0843, Validation Loss: 0.0833\n",
      "Epoch 894/1000 - Train Loss: 0.0842, Validation Loss: 0.0833\n",
      "Epoch 895/1000 - Train Loss: 0.0842, Validation Loss: 0.0832\n",
      "Epoch 896/1000 - Train Loss: 0.0841, Validation Loss: 0.0831\n",
      "Epoch 897/1000 - Train Loss: 0.0840, Validation Loss: 0.0830\n",
      "Epoch 898/1000 - Train Loss: 0.0839, Validation Loss: 0.0830\n",
      "Epoch 899/1000 - Train Loss: 0.0839, Validation Loss: 0.0829\n",
      "Epoch 900/1000 - Train Loss: 0.0838, Validation Loss: 0.0828\n",
      "Epoch 901/1000 - Train Loss: 0.0837, Validation Loss: 0.0828\n",
      "Epoch 902/1000 - Train Loss: 0.0837, Validation Loss: 0.0827\n",
      "Epoch 903/1000 - Train Loss: 0.0836, Validation Loss: 0.0826\n",
      "Epoch 904/1000 - Train Loss: 0.0835, Validation Loss: 0.0826\n",
      "Epoch 905/1000 - Train Loss: 0.0835, Validation Loss: 0.0825\n",
      "Epoch 906/1000 - Train Loss: 0.0834, Validation Loss: 0.0824\n",
      "Epoch 907/1000 - Train Loss: 0.0833, Validation Loss: 0.0824\n",
      "Epoch 908/1000 - Train Loss: 0.0833, Validation Loss: 0.0823\n",
      "Epoch 909/1000 - Train Loss: 0.0832, Validation Loss: 0.0822\n",
      "Epoch 910/1000 - Train Loss: 0.0831, Validation Loss: 0.0822\n",
      "Epoch 911/1000 - Train Loss: 0.0830, Validation Loss: 0.0821\n",
      "Epoch 912/1000 - Train Loss: 0.0830, Validation Loss: 0.0820\n",
      "Epoch 913/1000 - Train Loss: 0.0829, Validation Loss: 0.0819\n",
      "Epoch 914/1000 - Train Loss: 0.0828, Validation Loss: 0.0819\n",
      "Epoch 915/1000 - Train Loss: 0.0828, Validation Loss: 0.0818\n",
      "Epoch 916/1000 - Train Loss: 0.0827, Validation Loss: 0.0817\n",
      "Epoch 917/1000 - Train Loss: 0.0826, Validation Loss: 0.0817\n",
      "Epoch 918/1000 - Train Loss: 0.0826, Validation Loss: 0.0816\n",
      "Epoch 919/1000 - Train Loss: 0.0825, Validation Loss: 0.0815\n",
      "Epoch 920/1000 - Train Loss: 0.0824, Validation Loss: 0.0815\n",
      "Epoch 921/1000 - Train Loss: 0.0824, Validation Loss: 0.0814\n",
      "Epoch 922/1000 - Train Loss: 0.0823, Validation Loss: 0.0813\n",
      "Epoch 923/1000 - Train Loss: 0.0822, Validation Loss: 0.0813\n",
      "Epoch 924/1000 - Train Loss: 0.0822, Validation Loss: 0.0812\n",
      "Epoch 925/1000 - Train Loss: 0.0821, Validation Loss: 0.0811\n",
      "Epoch 926/1000 - Train Loss: 0.0820, Validation Loss: 0.0811\n",
      "Epoch 927/1000 - Train Loss: 0.0820, Validation Loss: 0.0810\n",
      "Epoch 928/1000 - Train Loss: 0.0819, Validation Loss: 0.0809\n",
      "Epoch 929/1000 - Train Loss: 0.0818, Validation Loss: 0.0809\n",
      "Epoch 930/1000 - Train Loss: 0.0818, Validation Loss: 0.0808\n",
      "Epoch 931/1000 - Train Loss: 0.0817, Validation Loss: 0.0808\n",
      "Epoch 932/1000 - Train Loss: 0.0816, Validation Loss: 0.0807\n",
      "Epoch 933/1000 - Train Loss: 0.0816, Validation Loss: 0.0806\n",
      "Epoch 934/1000 - Train Loss: 0.0815, Validation Loss: 0.0806\n",
      "Epoch 935/1000 - Train Loss: 0.0814, Validation Loss: 0.0805\n",
      "Epoch 936/1000 - Train Loss: 0.0814, Validation Loss: 0.0804\n",
      "Epoch 937/1000 - Train Loss: 0.0813, Validation Loss: 0.0804\n",
      "Epoch 938/1000 - Train Loss: 0.0812, Validation Loss: 0.0803\n",
      "Epoch 939/1000 - Train Loss: 0.0812, Validation Loss: 0.0802\n",
      "Epoch 940/1000 - Train Loss: 0.0811, Validation Loss: 0.0802\n",
      "Epoch 941/1000 - Train Loss: 0.0810, Validation Loss: 0.0801\n",
      "Epoch 942/1000 - Train Loss: 0.0810, Validation Loss: 0.0800\n",
      "Epoch 943/1000 - Train Loss: 0.0809, Validation Loss: 0.0800\n",
      "Epoch 944/1000 - Train Loss: 0.0809, Validation Loss: 0.0799\n",
      "Epoch 945/1000 - Train Loss: 0.0808, Validation Loss: 0.0799\n",
      "Epoch 946/1000 - Train Loss: 0.0807, Validation Loss: 0.0798\n",
      "Epoch 947/1000 - Train Loss: 0.0807, Validation Loss: 0.0797\n",
      "Epoch 948/1000 - Train Loss: 0.0806, Validation Loss: 0.0797\n",
      "Epoch 949/1000 - Train Loss: 0.0805, Validation Loss: 0.0796\n",
      "Epoch 950/1000 - Train Loss: 0.0805, Validation Loss: 0.0795\n",
      "Epoch 951/1000 - Train Loss: 0.0804, Validation Loss: 0.0795\n",
      "Epoch 952/1000 - Train Loss: 0.0803, Validation Loss: 0.0794\n",
      "Epoch 953/1000 - Train Loss: 0.0803, Validation Loss: 0.0793\n",
      "Epoch 954/1000 - Train Loss: 0.0802, Validation Loss: 0.0793\n",
      "Epoch 955/1000 - Train Loss: 0.0802, Validation Loss: 0.0792\n",
      "Epoch 956/1000 - Train Loss: 0.0801, Validation Loss: 0.0792\n",
      "Epoch 957/1000 - Train Loss: 0.0800, Validation Loss: 0.0791\n",
      "Epoch 958/1000 - Train Loss: 0.0800, Validation Loss: 0.0790\n",
      "Epoch 959/1000 - Train Loss: 0.0799, Validation Loss: 0.0790\n",
      "Epoch 960/1000 - Train Loss: 0.0798, Validation Loss: 0.0789\n",
      "Epoch 961/1000 - Train Loss: 0.0798, Validation Loss: 0.0789\n",
      "Epoch 962/1000 - Train Loss: 0.0797, Validation Loss: 0.0788\n",
      "Epoch 963/1000 - Train Loss: 0.0797, Validation Loss: 0.0787\n",
      "Epoch 964/1000 - Train Loss: 0.0796, Validation Loss: 0.0787\n",
      "Epoch 965/1000 - Train Loss: 0.0795, Validation Loss: 0.0786\n",
      "Epoch 966/1000 - Train Loss: 0.0795, Validation Loss: 0.0785\n",
      "Epoch 967/1000 - Train Loss: 0.0794, Validation Loss: 0.0785\n",
      "Epoch 968/1000 - Train Loss: 0.0793, Validation Loss: 0.0784\n",
      "Epoch 969/1000 - Train Loss: 0.0793, Validation Loss: 0.0784\n",
      "Epoch 970/1000 - Train Loss: 0.0792, Validation Loss: 0.0783\n",
      "Epoch 971/1000 - Train Loss: 0.0792, Validation Loss: 0.0782\n",
      "Epoch 972/1000 - Train Loss: 0.0791, Validation Loss: 0.0782\n",
      "Epoch 973/1000 - Train Loss: 0.0790, Validation Loss: 0.0781\n",
      "Epoch 974/1000 - Train Loss: 0.0790, Validation Loss: 0.0781\n",
      "Epoch 975/1000 - Train Loss: 0.0789, Validation Loss: 0.0780\n",
      "Epoch 976/1000 - Train Loss: 0.0789, Validation Loss: 0.0779\n",
      "Epoch 977/1000 - Train Loss: 0.0788, Validation Loss: 0.0779\n",
      "Epoch 978/1000 - Train Loss: 0.0787, Validation Loss: 0.0778\n",
      "Epoch 979/1000 - Train Loss: 0.0787, Validation Loss: 0.0778\n",
      "Epoch 980/1000 - Train Loss: 0.0786, Validation Loss: 0.0777\n",
      "Epoch 981/1000 - Train Loss: 0.0786, Validation Loss: 0.0776\n",
      "Epoch 982/1000 - Train Loss: 0.0785, Validation Loss: 0.0776\n",
      "Epoch 983/1000 - Train Loss: 0.0784, Validation Loss: 0.0775\n",
      "Epoch 984/1000 - Train Loss: 0.0784, Validation Loss: 0.0775\n",
      "Epoch 985/1000 - Train Loss: 0.0783, Validation Loss: 0.0774\n",
      "Epoch 986/1000 - Train Loss: 0.0783, Validation Loss: 0.0773\n",
      "Epoch 987/1000 - Train Loss: 0.0782, Validation Loss: 0.0773\n",
      "Epoch 988/1000 - Train Loss: 0.0781, Validation Loss: 0.0772\n",
      "Epoch 989/1000 - Train Loss: 0.0781, Validation Loss: 0.0772\n",
      "Epoch 990/1000 - Train Loss: 0.0780, Validation Loss: 0.0771\n",
      "Epoch 991/1000 - Train Loss: 0.0780, Validation Loss: 0.0771\n",
      "Epoch 992/1000 - Train Loss: 0.0779, Validation Loss: 0.0770\n",
      "Epoch 993/1000 - Train Loss: 0.0778, Validation Loss: 0.0769\n",
      "Epoch 994/1000 - Train Loss: 0.0778, Validation Loss: 0.0769\n",
      "Epoch 995/1000 - Train Loss: 0.0777, Validation Loss: 0.0768\n",
      "Epoch 996/1000 - Train Loss: 0.0777, Validation Loss: 0.0768\n",
      "Epoch 997/1000 - Train Loss: 0.0776, Validation Loss: 0.0767\n",
      "Epoch 998/1000 - Train Loss: 0.0775, Validation Loss: 0.0766\n",
      "Epoch 999/1000 - Train Loss: 0.0775, Validation Loss: 0.0766\n",
      "Epoch 1000/1000 - Train Loss: 0.0774, Validation Loss: 0.0765\n"
     ]
    }
   ],
   "source": [
    "learning_rate = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3]\n",
    "MAX_EPOCHS = 1000\n",
    "MAX_PATIENCE = 10\n",
    "\n",
    "starting_theta = np.zeros(X_train.shape[1])\n",
    "\n",
    "learning_rate_dict = {lr: () for lr in learning_rate }\n",
    "\n",
    "for rate in learning_rate:\n",
    "    best_theta, best_loss = my_gradient_descent_with_early_stopping(X_train, y_train, X_val, y_val, starting_theta, rate, MAX_EPOCHS, MAX_PATIENCE)\n",
    "\n",
    "    learning_rate_dict[rate] = (best_theta, best_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07653236104146711\n",
      "[ 3.94611427e+00  1.24886109e-02  1.62984763e-03 -7.21022837e+00\n",
      " -2.55793785e-02 -7.17737793e+00]\n",
      "0.3\n"
     ]
    }
   ],
   "source": [
    "min_loss = float('inf')\n",
    "best_theta = np.zeros(X_train.shape[1])\n",
    "best_lr = 0\n",
    "for lr, (theta, loss) in learning_rate_dict.items():\n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        best_theta = theta\n",
    "        best_lr = lr\n",
    "\n",
    "\n",
    "print(min_loss)\n",
    "print(best_theta)\n",
    "print(best_lr)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07684582611502522"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = my_sigmoid_func(np.dot(X_test, np.transpose(best_theta)))\n",
    "\n",
    "loss = my_loss_function(y_test, y_pred)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Plotting the Results<h2>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1oAAAIiCAYAAADRpLmGAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAEAAElEQVR4nOydd3wUZf7HP7ub3c2mbzoJCUGkd+lFEEJTQKzgYZeze+pZUDzPcnqnZ7mf/dQ7FQX7YUMsoYgCgoICUgWUECCkbtomm2yb3x9fnp3Z3dnNbrIhCXzfr1deSWanPPPM7Mzzeb5NI0mSBIZhGIZhGIZhGCZiaNu7AQzDMAzDMAzDMCcbLLQYhmEYhmEYhmEiDAsthmEYhmEYhmGYCMNCi2EYhmEYhmEYJsKw0GIYhmEYhmEYhokwLLQYhmEYhmEYhmEiDAsthmEYhmEYhmGYCMNCi2EYhmEYhmEYJsKw0GIYhmEYhmEYhokwLLQYpo1ZvHgxNBoNtmzZckKPe9ZZZ+Gss84Ka5vdu3fjoYceQmFhod9nV111FfLy8iLStoceeggajcbzo9frkZubi2uvvRYlJSUROUZnIJJ9Gi7K/tfpdDCbzRg8eDCuv/56bNq0qc2P35L7c+3atdBoNFi7dm2btCkYV111lV+fde3aFXPnzsXOnTtPeHvCpT37LtL43jsNDQ146KGHVM9NPGsqKipadczly5dj9uzZyMjIgMFgQHJyMvLz8/H222/D4XB41tNoNHjooYdadayWUFhYCI1Gg8WLF5+Q41VWVmLRokXo168fYmNjkZiYiD59+uDyyy/HL7/84lkvUv3PMJ2VqPZuAMMwbcNLL70U9ja7d+/Gww8/jLPOOstPAPz1r3/FbbfdFqHWEV999RUSExNhtVpRUFCAp59+Gt9//z22bdsGvV4f0WN1RNqiT8Phoosuwp133glJklBbW4udO3firbfewquvvopbb70Vzz77bJsduyX35xlnnIGNGzeiX79+bdCi5jGZTFizZg0AwOl04sCBA3j00UcxduxY7NmzB9nZ2e3SrlMN33unoaEBDz/8MACELd6bQ5IkXHPNNVi8eDHOOecc/Otf/0JOTg5qamrwzTff4KabbkJFRYXne7xx40Z07do1om3oaFitVowePRpWqxV33303Bg8eDJvNhn379uGjjz7Ctm3bMGjQoPZuJsN0CFhoMcxJSqQHoz169Ijo/gBg2LBhSE1NBQBMmTIFFRUVeOONN7B+/XpMmjQp4scLhCRJaGxshMlkOmHHBNqmT8MhIyMDo0eP9vw/ffp03H777bjuuuvw3HPPoU+fPrjxxhvb5NgtuT8TEhK82nui0Wq1XscfP348cnNzkZ+fjxUrVuC6665rt7adaBoaGhATE9Muxz6RQvvJJ5/E4sWL8fDDD+OBBx7w+mz27NlYuHAhDhw44FkWyv1ps9kQHR0NjUYT8fZGCofDAY1Gg6go/2Hihx9+iAMHDmDNmjV+z+k77rgDbrf7RDWTYTo87DrIMB2E9evXIz8/H/Hx8YiJicHYsWOxYsUK1fXGjBmD6OhoZGdn469//Sv++9//QqPReLn8qblm/fvf/8bgwYMRFxeH+Ph49OnTB/fddx8AcnG8+OKLAQCTJk3yuEgJVxQ1Nze3243nn38eQ4YMgclkQlJSEkaPHo3PPvusRX0wfPhwAEBpaanX8lWrViE/Px8JCQmIiYnBuHHjsHr1ar/tP/30UwwaNAhGoxGnnXYann32WY/rihKNRoNbbrkFL7/8Mvr27Quj0Yg333wTALB//37Mnz8f6enpMBqN6Nu3L1588UW/83700UfRu3dvz3kPGjTIywJUXl6O6667Djk5OTAajUhLS8O4ceOwatUqzzpqfdrY2IhFixahe/fuMBgMyM7Oxs0334zq6mqv9fLy8jBr1ix89dVXOOOMM2AymdCnTx+8/vrroXV2AHQ6HV544QWkpqbiySef9PqstrYWd911l1fbbr/9dtTX1/v1T3P3Rbj3JxDY/e2zzz7DmDFjEBMTg/j4eEydOhUbN270WkfcB7t27cIf/vAHJCYmIiMjA9dccw1qampa3F+JiYkA4GeB3blzJ+bMmQOz2Yzo6GgMGTLEc48JhFuxr6uu2nmeddZZGDBgADZv3owzzzwTMTExOO200/D444/7DWz37t2LGTNmICYmBqmpqbjhhhtQV1fn1/aVK1dizpw56Nq1K6Kjo3H66afj+uuv93PzEn33888/46KLLoLZbEaPHj2wZMkSaDQav74GgL/97W/Q6/UoLi5W7bddu3ZBo9Hgww8/9Cz76aefoNFo0L9/f691zz33XAwbNsyrL8S9U1hYiLS0NADAww8/7HluXXXVVV77KC0tDfu6OxwO/POf/0SfPn3w17/+VXWdzMxMjB8/3vO/r+uguMYFBQW45pprkJaWhpiYGDQ1NQEA3nnnHYwZMwZxcXGIi4vDkCFD8Nprr3m2z8vL8zsX3z4IxIEDB3D11VejZ8+eiImJQXZ2NmbPno0dO3Z4rSfutyVLluDOO+9EdnY2jEajl4BUUllZCQDo0qWL6udarf/QMpT+f/HFFzFhwgSkp6cjNjYWAwcOxBNPPOHlminOfcCAAVi3bh1Gjx4Nk8nkeRe6XC6vde12Ox599FH06dPH8xy++uqrUV5eHrTvGCZSsEWLYToA3377LaZOnYpBgwbhtddeg9FoxEsvvYTZs2fj3Xffxbx58wAAv/zyC6ZOnYpevXrhzTffRExMDF5++WUsXbq02WO89957uOmmm/CnP/0JTz31FLRaLQ4cOIDdu3cDAGbOnIl//OMfuO+++/Diiy/ijDPOABDc6nLVVVdh6dKlWLBgAf72t7/BYDDg559/Vo3xCoWDBw8CAHr16uVZtnTpUlxxxRWYM2cO3nzzTej1erzyyiuYPn06vv76a+Tn5wMgN8QLLrgAEyZMwPvvvw+n04mnnnrKT7QJPvnkE6xbtw4PPPAAMjMzkZ6ejt27d2Ps2LHIzc3F008/jczMTHz99de49dZbUVFRgQcffBAA8MQTT+Chhx7C/fffjwkTJsDhcGDv3r1eYujyyy/Hzz//jL///e/o1asXqqur8fPPP3sGKWpIkoTzzjsPq1evxqJFi3DmmWfil19+wYMPPoiNGzdi48aNMBqNnvW3b9+OO++8E/feey8yMjLw3//+FwsWLMDpp5+OCRMmtOgaAOQiN2XKFLz33ns4cuQIunbtioaGBkycOBFHjhzBfffdh0GDBmHXrl144IEHsGPHDqxatcojaFtyXzR3fwbinXfewaWXXopp06bh3XffRVNTE5544gmcddZZWL16tdcgGAAuvPBCzJs3DwsWLMCOHTuwaNEiAAhZoDqdTs/vAwcO4O6774bZbMbMmTM96/z6668YO3Ys0tPT8dxzzyElJQVLly7FVVddhdLSUixcuDCkY/lSUlKCSy+9FHfeeScefPBBfPzxx1i0aBGysrJwxRVXAKAB7cSJE6HX6/HSSy8hIyMDb7/9Nm655Ra//f32228YM2YM/vjHPyIxMRGFhYX417/+hfHjx2PHjh1+4vGCCy7AJZdcghtuuAH19fU4++yzsXDhQrz44osYM2aMVx+98sorOP/885GVlaV6Lv3790eXLl2watUqzwTPqlWrYDKZsHv3bhQXFyMrKwtOpxPffvstbrjhBtX9dOnSBV999RVmzJiBBQsW4I9//CMAeMSXoCXXfcuWLbBYLLj22mtbbX265pprMHPmTCxZsgT19fXQ6/V44IEH8Mgjj+CCCy7AnXfeicTEROzcuROHDh1q1bEExcXFSElJweOPP460tDRYLBa8+eabGDVqFLZu3YrevXt7rb9o0SKMGTMGL7/8MrRaLdLT01X3K671FVdcgfvuuw9nnnkmUlJSgrYllP7/7bffMH/+fM9Ezvbt2/H3v/8de/fu9btOJSUluOSSS3Dvvffib3/7G1asWIFHH30UVVVVeOGFFwDQhM+cOXOwbt06LFy4EGPHjsWhQ4fw4IMP4qyzzsKWLVtOuBcDcwoiMQzTprzxxhsSAGnz5s0B1xk9erSUnp4u1dXVeZY5nU5pwIABUteuXSW32y1JkiRdfPHFUmxsrFReXu5Zz+VySf369ZMASAcPHvQsnzhxojRx4kTP/7fccouUlJQUtK0ffvihBED65ptv/D678sorpW7dunn+/+677yQA0l/+8peg+1TjwQcflABIJSUlksPhkKqqqqQPPvhAio2Nlf7whz941quvr5eSk5Ol2bNne23vcrmkwYMHSyNHjvQsGzFihJSTkyM1NTV5ltXV1UkpKSmS76MOgJSYmChZLBav5dOnT5e6du0q1dTUeC2/5ZZbpOjoaM/6s2bNkoYMGRL0HOPi4qTbb7896Dq+ffrVV19JAKQnnnjCa733339fAiC9+uqrnmXdunWToqOjpUOHDnmW2Ww2KTk5Wbr++uuDHleSqA9uvvnmgJ/fc889EgDphx9+kCRJkh577DFJq9X63cf/+9//JADSF198IUlS6PdFS+7Pb775xuv+dLlcUlZWljRw4EDJ5XJ51qurq5PS09OlsWPHepaJe863b2+66SYpOjra8x0LxJVXXikB8Pvp0qWLtH79eq91L7nkEsloNEpFRUVey88++2wpJiZGqq6uliRJfjYov7dq5ylJ1F/K6yHo16+fNH36dM//99xzj6TRaKRt27Z5rTd16tSA321JkiS32y05HA7p0KFDEgDp008/9Xwm+u6BBx7w2+7BBx+UDAaDVFpa6lkm7tdvv/1W9ViCyy67TDrttNM8/0+ZMkW69tprJbPZLL355puSJEnShg0bJABSQUGBV18o753y8nIJgPTggw+qtq+l1/29996TAEgvv/xy0PNQ4tsOcY2vuOIKr/V+//13SafTSZdeemnQ/XXr1k268sor/Zb79sHBgwclANIbb7wRcF9Op1Oy2+1Sz549pT//+c+e5eJ+mzBhQtC2KPnb3/4mGQwGz/ege/fu0g033CBt377da72W9r/L5ZIcDof01ltvSTqdzutZLb4LyntUkiTp2muvlbRareeZ+O6770oApGXLlnmtt3nzZgmA9NJLL4V8vgzTUth1kGHamfr6evzwww+46KKLEBcX51mu0+lw+eWX48iRI/j1118BkOVr8uTJnrgmgNw05s6d2+xxRo4cierqavzhD3/Ap59+2uosUF9++SUA4Oabb27xPjIzM6HX62E2mzF37lwMGzbMy73q+++/h8ViwZVXXgmn0+n5cbvdmDFjBjZv3oz6+nrU19djy5YtOO+882AwGDzbx8XFYfbs2arHnjx5Msxms+f/xsZGrF69Gueffz5iYmK8jnfOOeegsbHRk41v5MiR2L59O2666SZ8/fXXqK2t9dv/yJEjsXjxYjz66KPYtGmTn/uLGiLRgq+r0MUXX4zY2Fg/d8khQ4YgNzfX8390dDR69eoVkRlxSZK8/v/8888xYMAADBkyxKtvpk+f7uXm1tL7oiX356+//ori4mJcfvnlXu5KcXFxuPDCC7Fp0yY0NDR4bXPuued6/T9o0CA0NjairKys2eOZTCZs3rwZmzdvxg8//ICPPvoIvXr1wjnnnOPlPrdmzRrk5+cjJyfHa/urrroKDQ0Nqq52oZCZmYmRI0f6tV95vb/55hv0798fgwcP9lpv/vz5fvsrKyvDDTfcgJycHERFRUGv16Nbt24AgD179vitf+GFF/otEzF8//nPfzzLXnjhBQwcOLBZq2p+fj5+//13HDx4EI2NjVi/fj1mzJiBSZMmYeXKlQDIymU0Gv0sk+HSmuseCXz7buXKlXC5XK16fjaH0+nEP/7xD/Tr1w8GgwFRUVEwGAzYv39/yNc3EH/9619RVFSE119/Hddffz3i4uLw8ssvY9iwYXj33Xf91g+l/7du3Ypzzz0XKSkp0Ol00Ov1uOKKK+ByubBv3z6v7ePj4/32OX/+fLjdbnz33XcA6JmVlJSE2bNnez2zhgwZgszMzJMiAyfT8WGhxTDtTFVVFSRJUvV3F243wt2ssrISGRkZfuupLfPl8ssvx+uvv45Dhw7hwgsvRHp6OkaNGuUZ0IRLeXk5dDodMjMzW7Q9QIOozZs34+uvv8aFF16I7777Dn/60588nwu3v4suugh6vd7r55///CckSYLFYvH0YTh949vflZWVcDqdeP755/2Odc455wCAZ/C/aNEiPPXUU9i0aRPOPvtspKSkID8/3yuF//vvv48rr7wS//3vfzFmzBgkJyfjiiuuCJq+vrKyElFRUX5uTxqNBpmZmX5uh2ruOkajETabLeAxQkUM3sU9WFpail9++cWvb+Lj4yFJkqdvWnpftOT+DBYrkpWVBbfbjaqqKq/lvn0mXDFD6TOtVovhw4dj+PDhGDlyJM4//3x88cUXiIqKwh133OHVrlC+z+ESyvWurKxU7XvfZW63G9OmTcNHH32EhQsXYvXq1fjxxx89kwlq/aF2ThkZGZg3bx5eeeUVuFwu/PLLL1i3bp2qq6IvU6ZMAUDPgfXr18PhcGDy5MmYMmWKZ1Jh1apVGDduXKtdvFpy3cUkhnBpbg2+fSdihNoyQ+Edd9yBv/71rzjvvPOwfPly/PDDD9i8ebMnS2BzbWyOjIwMXH311Xj55Zfxyy+/4Ntvv4XBYFDNpNpc/xcVFeHMM8/E0aNH8eyzz2LdunXYvHmzJz7Wt71qz3Vxj4vvV2lpKaqrq2EwGPyeWyUlJZxynjkhcIwWw7QzZrMZWq0Wx44d8/tMBJILC1ZKSopqzFGotaeuvvpqXH311aivr8d3332HBx98ELNmzcK+ffs8M9mhkpaWBpfLhZKSkrBf0ILBgwd7zm3q1KmYPn06Xn31VSxYsAAjRozwfPb8888HzOaVkZHhyZAVTt/4xlyYzWaPFTHQLHP37t0BwDOwvuOOO1BdXY1Vq1bhvvvuw/Tp03H48GFPEoJnnnkGzzzzDIqKivDZZ5/h3nvvRVlZGb766ivV/aekpMDpdKK8vNxLbEmShJKSEowYMUJ1u0hjs9mwatUq9OjRwzMQTE1NhclkChjTIq5Va+6LcO9PMXgL9N3RarVeVsu2ICYmBj169MD27du92hXK9zk6OhoAPIkRBK0ZAKakpKje877Ldu7cie3bt2Px4sW48sorPcsDJUAA/L8zgttuuw1LlizBp59+iq+++gpJSUm49NJLm21r165d0atXL6xatQp5eXkYPnw4kpKSkJ+fj5tuugk//PADNm3a5EndfqIZPnw4kpOT8emnn+Kxxx5rVZyW77bi+33kyBE/y6eS6Ohov/sDoHtE6dmghohv/cc//uG3bVJSUrNtDJcJEyZg2rRp+OSTT1BWVhYwxkuNTz75BPX19fjoo4+8vuvbtm1TXT/Ys148F1JTU5GSkhLweRsfHx9y+ximpbBFi2HamdjYWIwaNQofffSR16yd2+3G0qVLPYMRAJg4cSLWrFnjNRBzu91embtCPebZZ5+Nv/zlL7Db7di1axeA8Gb3zz77bACUKS4SaDQavPjii9DpdLj//vsBAOPGjUNSUhJ2797tsST4/hgMBsTGxmL48OH45JNPYLfbPfu0Wq34/PPPQzp+TEwMJk2ahK1bt2LQoEGqx1KzKCQlJeGiiy7CzTffDIvFoprwITc3F7fccgumTp2Kn3/+OWAbRGIP3+Qmy5YtQ319vefztsTlcuGWW25BZWUl7rnnHs/yWbNm4bfffkNKSopq34jsiZG4LwLdn7707t0b2dnZeOedd7xcHevr67Fs2TJPJsK2xGq14sCBA16Dyvz8fKxZs8Yv495bb72FmJgYz6SB6DNlgVcALc7aCVDG0F27dnkJP4CShigRg2plchUAeOWVV8I+5rBhwzB27Fj885//xNtvv42rrroKsbGxIW07ZcoUrFmzBitXrsTUqVMBUDKc3NxcPPDAA3A4HB7LVyDCeW6Fg16vxz333IO9e/fikUceUV2nrKwMGzZsCHvf06ZNg06na/Z7kpeX53d/7Nu3z+NOHgyNRuN3fVesWIGjR4+G3V4lpaWlqincXS4X9u/fj5iYGFUhFwy1+1GSJC+XVCV1dXV+35N33nkHWq3W47I6a9YsVFZWwuVyqT6zfJOBMExbwBYthjlBrFmzRnUQfs455+Cxxx7D1KlTMWnSJNx1110wGAx46aWXsHPnTrz77ruel9Bf/vIXLF++HPn5+fjLX/4Ck8mEl19+2ZNeWy2truDaa6+FyWTCuHHj0KVLF5SUlOCxxx5DYmKix1IyYMAAAMCrr76K+Ph4REdHo3v37qoC48wzz8Tll1+ORx99FKWlpZg1axaMRiO2bt2KmJgYLxfAUOnZsyeuu+46vPTSS1i/fj3Gjx+P559/HldeeSUsFgsuuugipKeno7y8HNu3b0d5eblnoPK3v/0NM2fOxPTp03HbbbfB5XLhySefRFxcHCwWS0jHf/bZZzF+/HiceeaZuPHGG5GXl4e6ujocOHAAy5cv98RQzZ49GwMGDMDw4cORlpaGQ4cO4ZlnnkG3bt3Qs2dP1NTUYNKkSZg/fz769OmD+Ph4bN682ZMZMRDCqnfPPfegtrYW48aN82QdHDp0KC6//PKw+zQYpaWl2LRpEyRJQl1dnadg8fbt2/HnP/8Z1157rWfd22+/HcuWLcOECRPw5z//GYMGDYLb7UZRUREKCgpw5513YtSoUS2+L0K5P33RarV44okncOmll2LWrFm4/vrr0dTUhCeffBLV1dV4/PHHI9pfbrfb41rndrtx9OhRPPfcc6iqqvJK6f3ggw/i888/x6RJk/DAAw8gOTkZb7/9NlasWIEnnnjCkxJ+xIgR6N27N+666y44nU6YzWZ8/PHHWL9+fYvbePvtt+P111/HzJkz8eijj3qyDu7du9drvT59+qBHjx649957IUkSkpOTsXz58ha7Et92222YN28eNBoNbrrpppC3y8/Px0svvYSKigo888wzXsvfeOMNmM1mr9TuasTHx6Nbt2749NNPkZ+fj+TkZKSmpvqVTmgJd999N/bs2YMHH3wQP/74I+bPn+8pWPzdd9/h1VdfxcMPP4xx48aFtd+8vDzcd999eOSRR2Cz2Typz3fv3o2KigqPFe/yyy/HZZddhptuugkXXnghDh06hCeeeMLPvViNWbNmYfHixejTpw8GDRqEn376CU8++WSr3RWXLFmCV155BfPnz8eIESOQmJiII0eO4L///a8nE6kyVjYUpk6dCoPBgD/84Q9YuHAhGhsb8e9//9vP9VeQkpKCG2+8EUVFRejVqxe++OIL/Oc//8GNN97ocfm85JJL8Pbbb+Occ87BbbfdhpEjR0Kv1+PIkSP45ptvMGfOHJx//vmt6guGaZb2ysLBMKcKIutUoB+RcWzdunXS5MmTpdjYWMlkMkmjR4+Wli9f7re/devWSaNGjZKMRqOUmZkp3X333dI///lPCYAnm5kk+WelevPNN6VJkyZJGRkZksFgkLKysqS5c+dKv/zyi9f+n3nmGal79+6STqfzymLlmyFPkigz1P/93/9JAwYMkAwGg5SYmCiNGTNGtd1KRCYqZfZEQWlpqRQXFydNmjTJs+zbb7+VZs6cKSUnJ0t6vV7Kzs6WZs6cKX344Yde23788cfSwIEDJYPBIOXm5kqPP/64dOutt0pms9lrPQTJuHfw4EHpmmuukbKzsyW9Xi+lpaVJY8eOlR599FHPOk8//bQ0duxYKTU11XOsBQsWSIWFhZIkSVJjY6N0ww03SIMGDZISEhIkk8kk9e7dW3rwwQel+vp6z37U+tRms0n33HOP1K1bN0mv10tdunSRbrzxRqmqqsprvW7dukkzZ870a7/vdQ+E8h7UarVSQkKCNHDgQOm6666TNm7cqLqN1WqV7r//fql3796e6z1w4EDpz3/+s1RSUuJZL5T7oiX3p1o2PkmSpE8++UQaNWqUFB0dLcXGxkr5+fnShg0bvNYJdM8Fyvzni1rWwfT0dGnixInSxx9/7Lf+jh07pNmzZ0uJiYmSwWCQBg8erJoRbt++fdK0adOkhIQEKS0tTfrTn/4krVixQjXrYP/+/VXb5XsP7d69W5o6daoUHR0tJScnSwsWLJA+/fRTv32K9eLj4yWz2SxdfPHFUlFRkV/mvGDfV0FTU5NkNBqlGTNmBFxHjaqqKkmr1UqxsbGS3W73LH/77bclANIFF1zgt43aPb5q1Spp6NChktFolAB4MvW19roLPv30U2nmzJlSWlqaFBUVJZnNZmnSpEnSyy+/7JXp1Lfvmss6+9Zbb0kjRoyQoqOjpbi4OGno0KFe94nb7ZaeeOIJ6bTTTpOio6Ol4cOHS2vWrAkp62BVVZW0YMECKT09XYqJiZHGjx8vrVu3zm9b8b3yfZ4GYvfu3dKdd94pDR8+3Ks/Jk6cKC1ZssRr3XD6f/ny5dLgwYOl6OhoKTs7W7r77rulL7/8MuB3Ye3atdLw4cMlo9EodenSRbrvvvskh8PhdRyHwyE99dRTnv3GxcVJffr0ka6//npp//79IZ0vw7QGjST5pJZiGKbTMW3aNBQWFvplZjrVcTgcGDJkCLKzs1FQUNDezWGYk5bly5fj3HPPxYoVKzzJYximLTjrrLNQUVGBnTt3tndTGKZZ2HWQYToZd9xxB4YOHYqcnBxYLBa8/fbbWLlyJV577bX2blq7s2DBAkydOtXjevbyyy9jz549ePbZZ9u7aQxzUrJ7924cOnQId955J4YMGeKJ0WMYhmFYaDFMp8PlcuGBBx5ASUkJNBoN+vXrhyVLluCyyy5r76a1O3V1dbjrrrtQXl4OvV6PM844A1988UWzwfQMw7SMm266CRs2bMAZZ5yBN998s9WZ6xiGYU4m2HWQYRiGYRiGYRgmwnB6d4ZhGIZhGIZhmAjDQothGIZhGIZhGCbCsNBiGIZhGIZhGIaJMJwMoxncbjeKi4sRHx/PQb4MwzAMwzAMcwojSRLq6uqQlZUFrTa4zYqFVjMUFxcjJyenvZvBMAzDMAzDMEwH4fDhw+jatWvQdVhoNUN8fDwA4PXXDyMmJqGdW9M+SJIDklQAjWYaNBp9ezeHCQO+dp0Tvm6dF752nRO+bp0Tvm6dl8587RoaanHNNTkejRAMFlrNINwFY2ISTnGhFQONJqHTfRlOdfjadU74unVe+Np1Tvi6dU74unVeToZrF0pIESfDYBiGYRiGYRiGiTAstBiGYRiGYRiGYSIMCy2GYRiGYRiGYZgIwzFaDMMwDMMwDNOB0Ghc0GodOFkrC1GMVhQ0mkZoNK72bo4XkgS4XAZEwh7FQothGIZhGIZhOgQS4uJKEBdXjWZKNHVyJACZAA4D6Hhq0unUoqKiO9xuQ6v2w0KLYRiGYRiGYToAcXElSEqqRmpqOgyGmJAy23VO3ACsAOLQ0SKZJMmNiopi2O3HUF2di9YIQRZaDMMwDMMwDNPOaDQuxMWRyIqPT2nv5rQxbgB2ANHoaEILAMzmNNhsxaitdcLtbnn6+Y53ZgzDMAzDMAxziqHVOqDVAgZDTHs35ZQnKsoAjQatjh9jocUwDMMwDMMw7YzwEjx53QU7E3QNWnspWGgxDMMwDMMwDMNEGBZaDMMwDMMwDMO0KWazBitWfNLezTihsNBiGIZhGIZhGKbFlJaWYOHCP2HIkNOQkWFE//45uOSS2fj229Xt3TQAgCRJePzxh9C3bxa6dDFh1qyzsGfPrjY/LgsthmEYhmEYhmFaRFFRISZNGoZ169bg4YefwIYNO/C//32FM8+chLvvvrm9mwcAePbZJ/DSS//CE0+8gNWrNyM9PRMXXDAVdXV1bXpcFloMwzAMwzAMw7SIO++8CRqNBqtW/Yg5cy7C6af3Qt++/XHzzXdg5cpNAbd78MEHMXx4H2RlxWDIkNPw97//FQ6Hw/P5jh3bMXv2JOTkxCM3NwFnnTUMW7duAQAUFR3CJZfMRl6eGdnZsRgzpj8KCr5QPY4kSXj55Wdwxx1/wezZF6BfvwH497/fRENDA/73v3ci2xk+cB0thmEYhmEYhjmJcDoBqxWIiwOi2nC0X1VlwerVX+H++/+O2NhYv88TE5MCbhsfH48XX3wdXbp0xa5dO3D77dciLi4et922EABw3XWXYtCgoXj66X9Dp9Nhx45tiIqimlZ3330zHA47Vqz4DrGxsdi7dzdiY+NUj3Po0EGUlpZg8uRpnmVGoxHjxk3Ejz9+j6uvvr4VPRAcFloMwzAMwzAMc5JQWAgsXQqUlQHp6cBllwF5eW1zrN9/PwBJktCrV5+wt73rrrsAJADQIjc3D/v334mPP37fI7SOHi3Crbfe7dl3jx49PdseOVKEc8+9EP37DwQA5OWdFvA4paUlAIC0tAyv5enpGTh8+FDY7Q4Hdh1kGIZhGIZhmJMAp5NE1v79gMlEv5cupeVtgSRJAFpW++vTTz/FjBkT0Lt3Jrp2jcM//vFXHDlS5Pn8ppvuwK23/hHnnTcF//d/j+Pgwd88n11//a146qlHMX36ODz22IPYufOXZo/n20ZJktq8ZhkLLYZhGIZhGIY5CbBayZKVmQmYzfS7rIyWtwU9evSERqPBr7/uCWu7zZs3YcGCBZgyZQbee+9zfPvtVtx5519gt9s969x770PYuHEXpk2biXXr1mD06H74/POPAQBXXPFHbN36O+bNuxy7d+/A5MnD8eqrz6seKyMjEwBQVlbitby8vMzPyhVpWGgxDMMwDMMwzElAXBy5C5aUAFVVwLFj9H+cevhSqzGbkzF58nS89tqLqK+v9/u8pqZadbsffvgeOTk5uOuu+zB06HD06NFT1Y3v9NN74aab/oyPPirArFkX4O233/B81rVrDq655gYsWfIRbr75Trz55n9Uj9WtW3dkZGTim29WepbZ7XZs2PAtRo4cG+YZhwcLLYZhGIZhGIY5CYiKopisnj0Bmw3o1Yv+b8uEGE8//RJcLhemTBmJzz5bht9+249ff92DV155DtOmjVHd5rTTeuDIkSNYtuw9HDz4G1555TmPtQoAbDYb7r77FqxfvxZFRYewadMGbN26Gb169QUALFp0O1av/hqHDh3E9u0/Y926Nejdu6/qsTQaDW644Xb861//wOeff4zdu3fippuuQkxMDC66aH7kO0QBJ8NgGIZhGIZhmJOEvDzg3ntPTNZBgCxGa9f+jKef/jvuv/9OlJYeQ2pqGgYPHoann/636jbnnDMHN954IxYuvBV2exOmTp2Ju+/+Kx5//CEAgE6ng8VSiRtuuALl5aVISUnFrFkXYNGihwEALpcLd999M4qLjyA+PgH5+TPwj3/8X8A23nbbQjQ22nDXXTehuroKw4aNwrJlBYiPj494fyjRSCKKjVGltrYWiYmJeO+9GsTEJLR3c9oFSXJAkr6ARnMONBp9ezeHCQO+dp0Tvm6dF752nRO+bp2Tk+26RUU1Ij39IHJyusNgiG7v5rQxbgC1EFkHOxp2eyMOHz6IsrLucDq9r0VDQy0uuSQRNTU1SEgIrg063pkxDMMwDMMwDMN0clhoMQzDMAzDMAzDRBgWWgzDMAzDMAzDMBGGhRbDMAzDMAzDMEyEYaHFMAzDMAzDMAwTYVhoMQzDMAzDMAzDRJhOJbS+++47zJ49G1lZWdBoNPjkk0+Crr927VpoNBq/n717956YBjMMwzAMwzAMc0rSqQoW19fXY/Dgwbj66qtx4YUXhrzdr7/+6pXnPi0trS2axzAMwzAMwzAMA6CTCa2zzz4bZ599dtjbpaenIykpKfINYhiGYRiGYRiGUaFTCa2WMnToUDQ2NqJfv364//77MWnSpIDrNjU1oampyfN/bW0tAFF93NHmbe2IiPM+Vc+/M8PXrnPC163zwteuc8LXrXNysl03Og8JgPv4z8mF2azD0qXLMHPmeaDzBOTz7Wi4AUjHx/86r0/Cud9OaqHVpUsXvPrqqxg2bBiampqwZMkS5OfnY+3atZgwYYLqNo899hgefvhhv+WSVABJimnrJndwVkKSml+L6Yjwteuc8HXrvPC165zwdeucnBzXTZKiAGQCsAKwt3NrwqO0tBRPP/00CgoKcOzYMaSmpmLgwIG48cYbMXHiRMWaNgC1iv/rTkj7li9fjsWLF2Pbtm2wWCz47rvvMHDgwCBb2AHYIEnfQZKcXp9IUkPIxz2phVbv3r3Ru3dvz/9jxozB4cOH8dRTTwUUWosWLcIdd9zh+b+2thY5OTnQaKZBo0lQ3eZkh5T7SgBTodHo27s5TBjwteuc8HXrvPC165zwdeucnGzXTaNpBHAYQByA6HZuTegUFRVixozJSExMwsMPP4H+/QfB4XBgzZoC3H33Pfjxx92KtU0AEkCWrDoA8QA0bd7G+no3Ro2agDlz5uG2264HEHu8HYFoBGCCRjMBGo33tdBoatU3UeGkFlpqjB49GkuXLg34udFohNFo9Fuu0ehPii9xS5Ek7oPOCl+7zglft84LX7vOCV+3zsnJdN00GhdIdGjRmRKD33nnLdBoNFi16kfExsZ6lvftOxCXXbYA3ucizs2NBx98ECtWfIni4iNIT8/ExRdfioULH4BeT9dyx47tuO++27Ft2xZoNBqcdlpP/N//vYKhQ4ejqOgQFi68BZs2rYfDYUdubh4efvhJTJt2jmobL7nkSgAkCr3bEQgtAI3qvRXOvXbKCa2tW7eiS5cu7d0MhmEYhmEYhmkb3E5oXHWQdPGAtu2G+1VVFqxe/RXuv//vXiJLkJiYFHDb+Ph4vPji6+jSpSt27dqB22+/FnFx8bjttoUAgOuuuxSDBg3F00//GzqdDjt2bENUFImcu+++GQ6HHStWfIfY2Fjs3bsbsbFxbXKOraFTCS2r1YoDBw54/j948CC2bduG5ORk5ObmYtGiRTh69CjeeustAMAzzzyDvLw89O/fH3a7HUuXLsWyZcuwbNmy9joFhmEYhmEYhmkztA2/Q3/4dWibSuA2ZsKRcw3cMae1ybF+//0AJElCr159wt72rrvuArnvaZGbm4f9++/Exx+/7xFaR48W4dZb7/bsu0ePnp5tjxwpwrnnXoj+/SnOKi+vbc6vtXQqobVlyxavjIEilurKK6/E4sWLcezYMRQVFXk+t9vtuOuuu3D06FGYTCb0798fK1aswDnnqJsVGYZhGIZhGKbT4nZCf/h16Or3QjJmQVe/Fzj8Opp6PtQmli3peBYSjSb8OKtPP/0U//73f3Dw4AHU11vhdDoRHy/HTd100x249dY/4v33l2DixCk477yL0b17DwDA9dffijvvvBFr1hTgrLOmYPbsCzFgwKDInFQE6TwOoADOOussSJLk97N48WIAwOLFi7F27VrP+gsXLsSBAwdgs9lgsViwbt06FlkMwzAMwzDMSYnGVQdtUwkkYxYkfTIkYxa0TSXQuNomu1+PHj2h0Wjw6697wtpu8+ZNWLBgAaZMmYH33vsc3367FXfe+RfY7XK2xXvvfQgbN+7CtGkzsW7dGowe3Q+ff/4xAOCKK/6IrVt/x7x5l2P37h2YPHk4Xn31+YieWyToVEKLYRiGYRiGYRh1JF083MZMaJqKoXFYoGk6Crcxk2K12gCzORmTJ0/Ha6+9iPr6er/Pa2qqVbf74YfvkZOTg7vuug9Dhw5Hjx49cfjwIb/1Tj+9F2666c/46KMCzJp1Ad5++w3PZ1275uCaa27AkiUf4eab78Sbb/4nYucVKVhoMQzDMAzDMMzJgDYKjpxr4IrtA7ga4IrtC0fONW2aEOPpp1+Cy+XClCkj8dlny/Dbb/vx66978Morz2HatDGq25x2Wg8cOXIEy5a9h4MHf8MrrzznsVYBgM1mw91334L169eiqOgQNm3agK1bN6NXr74AgEWLbsfq1V/j0KGD2L79Z6xbtwa9e/cN2MaqKgt27NiGvXsp1fz+/b9ix45tKC0tiWBP+NOpYrQYhmEYhmEYhgmMO+Y0NPV86IRkHQSAbt26Y+3an/H003/H/fffidLSY0hNTcPgwcPw9NP/Vt3mnHPm4MYbb8TChbfCbm/C1Kkzcffdf8Xjjz8EANDpdLBYKnHDDVegvLwUKSmpmDXrAixa9DAAwOVy4e67b0Zx8RHExycgP38G/vGP/wvYxi+//Aw333y15/8FCy4BANxzz4O4996HItMRKmgk6WSopd121NbWIjExEe+9V4OYmFO3YLEkfQGN5pyTok7FqQRfu84JX7fOC1+7zglft87JyXbdoqIakZ5+EDk53WEwdJ6CxS3DDaAWIutgR8Nub8ThwwdRVtYdTqf3tWhoqMUllySipqYGCQnBtUHHOzOGYRiGYRiGYZhODgsthmEYhmEYhmGYCMNCi2EYhmEYhmEYJsKw0GIYhmEYhmEYhokwLLQYhmEYhmEYhmEiDAsthmEYhmEYhmlnRB5wSXK3b0MYiKTsrc3NznW0GIZhGIZhGKadcbkMcDq1qKgohtmchqgoAwBNezerjXADsANoREez+0iShNracrhcGrjdrSsbwEKLYRiGYRiGYdodLSoqusNuPwabrRiak1VjAQAkADYAJnREMelyaWCxdIUk6Vq1HxZaDMMwDMMwDNMBcLsNqK7ORW2tExqN66QVW1Rs+jtoNBM6XLFpSQLcbn2rRRbAQothGIZhGIZhOhDCZa1jCZBIIkk6SJITGk10hxNakaRjOUUyDMMwDMMwDMOcBLDQYhiGYRiGYRiGiTAstBiGYRiGYRiGYSIMCy2GYRiGYRiGYZgIw0KLYRiGYRiGYRgmwrDQYhiGYZhOgssFWK30m2EYhunYcHp3hmEYhukElJQAK1cC1dVAUhIwdSqQmdnerWIYhmECwRYthmEYhunguFwkso4cAYxG+r1yJVu2GIZhOjJs0WIYhmGYDo7NRpaslBQgLo6WVVfTcvE/wzAM07FgixbDMAzDdHBMJnIXrKykGK3KSvrfZGrvljEMwzCBYKHFMAzDMB0cnY5isrp2BZqa6PfUqbScYRiG6Ziw6yDDMAzDdAIyM4H588ld0GRikcUwDNPRYYsWwzAMwwShI6VU1+koJotFFsMwTMeHLVoMwzAMEwDflOqTJwOJif4WJZdLtjRpNO3VWoZhGKYjwUKLYRiGYVRQplRPSQEOHAB27gSysoDkZLmOlVKMpaYC8+a1d8sZhmGYjgC7DjIMwzCMCsqU6rGxQF0dUFFBlixRx8pu965vVVxM27rd7dp0hmEYpgPAFi2GYRiGUUGkVD9yhARVTQ25DZrNgMFAIqyqyru+lV5P27Z1fSulqyLHazEMw3RMWGgxDMMwHZL2FhMipfrKlYDFQm6B0dFAfT3VseralUSXEGMAWb2A0OpbiSQbQHgJLnzjxoQL46lIe98jDMMwwWChxTAMw3Q4OoqYUKZUr6kB1qyhNok6VgaDLMaqqyl+CwC0zTjml5QAn3wC7N5N//frB5x3XvPn6Bs3JlwY588/9YRGR7lHGIZhAsFCi2EYhulQdDQxIVKqx8Wp17HyrW/VHC4XUFAAbN8up4zfvh2IiQEuvTT4OSrjxoRrYnV127sqdjQ62j3CMAyjBifDYBiG6eR0pDpPkcBXTKSkyGKiNUSinwLVsRLLBcGSYdhslFRDqwXi4+lHq6VlzZ2jiBurrKRzqayk/0MReOHSke+rtrpHGIZhIglbtBiGYToxJ6P7lDIJBSDHQ7VGTJyIfiopAb75htK7f/ABMGmS+jFMJor32r9fjunS6WiZyRQ87kgZN6Z0YYy0Faet+itSMVVtcY8wDMNEGrZoMQzDdFKU7lNGo+w+1ZEsEC2xiggx0bUr0NTUejERTj+11IojjiHSuxcXBz6GTgdMmwYMHkzJNaKj6e9p04DycuCdd4A33qDfJSX+2wtXxauvpt9qAijU81Bbr63uq5KS5s8tVCJ9jzAMw7QFbNFiGIbppHT0eJ3WWEV8455aM4AOtZ9a015xjORk+j85Ofi1yMwErr3WO+sgQAIklLgjX1dFJaGeR6D1WntfqVmt2iKmKpL3CMMwTFvAFi2GYZhOyomM1wmXSFhFAsVDhUso/dTa9opjWCz0v8XS/LXQ6aguV2Ii/R2JuKNQzyPYeq25r9SsVi4XxZ9ZLJGPqYrUPcIwDNMWsNBiGIbppHRk96m2SFYg3Nzs9vDc+3z7KTsbGDu29e1Vut2JY4j07llZ4V+LUAVOMLfAUM8j2Hotva/UxNsnnwBvvw289x65Ux492vEmBRiGYdoKdh1kGIbpxARzn2qPYq7imAZDZJMVCDe34mLZMtKlS+jufaKfCguBDRuAL77wdpcLN7lCILe7uXPp87lzw+/zUBJdNOcWGOp5NLdeS9zyfMWb2011wtLSgIwMikVrbKT1OtKkAMMwTFvBQothGKaToxavE068USiCLJR1fI85ZAgtb212PGEpOXxYdkFzOOTlweJ8lO0GgO+/J6uKWpyQUuSoWb1826MWb6TVApLkXbA4HMHbnHBuLs4p1KyEoawXLA5MDYOBaoGVltL/5eX0Oy2N9pOdTed1ySWUYZFFFsMwJzsstBiGYU4ywkk8EIogC2Ud5THNZrIcSRINqu321lnVhKUkIQEoK6PfbjfVnwqWpMG33WPHBk/y0JzVy7c9avuJjQ2/73wJJHCaS1IhBF1aGp2Hb6INXyKZTEKcZ2UlUFND++rWjdpSVUXCU1jNfEVWe1heGYZhTgQco8UwDHOSEWqcTiiJE0JNriCOGR1NQqWkBNiyhaxQIlmB3U7WDrs9cNtdLhqo19TIxxCWkpoaGrDX1sq/A8X5qLV7wwZKPNFcDJSwegU631Biqdxuam9BQeTSpAc7rm8Sit27gc8+A956K3gq9Ugkk1D2dVIS/aSmksg+77zgsV6RTPku2tJRiywzDHPqwRYthmGYk4xQ43RCSeMdaqpvk4lEzMaNNMiVJCAqisRNXh4N/JcuJfGRmAhcdhkwcKB3e0pKKHnC7t30f79+wLhxwLZtdA61tWTN0uu9Y7TURIJau2tqgHPOISEVyF0ulPMN5nYnSbTOBx8Ax46R6Oze3XtfViutKyw4oVp0Ah0X8LZgHj4M7NxJ90Awi2akLElqfdbQQIK6ta6Q4dCWRanZ6sYwTEtgocUwDHOCOFGDtVDjdIQ4OnSILDBVVf6CLFTRptORKNqyhaxN8fGUAEFYp5YuJWtWQgL9XroUeOQRslYB1DcFBcD27bI1Yvt24PffZQuJywWkp9NAXKQhD9SPgdqdl0c/ga5DqOcbSEA4HCQwi4vJjdDhAPbto3UqK6lfPvlEtsYNGkR9ZrVS7a3mxIHaca1Wb6FjtwNFRUBOTmCxGClR4nLRT2IiWQHV+kxYzYS1SbQ7knXg2qJOl6AtBRzDMCc3LLQYhmFOACd6sBZK/E15OVkeysvpp18/9YQIgawoykEzQAJm+HASbiI2p2tXyjRXU0MiS8Qw1dRQYouEBNqHzUb/a7XkJggA9fV0zNxcb0uJy9X8QLw5sRlo+1BFqppoLikhsXjZZXQu8fFAr17AwYNy7NLRo2T16tUL2L8fWLOGzjkxUa7B1Zw48I3h8hWHwmpYV0dC1lf4REqUKO9pvZ5i84K5CPre/2lpoWd6bG6SIhTR1pKJjrYUcAzDnPyw0GIYhmljhLVGCJATNVgLljVODCCrqoCePWlQGhND7fPFV7SVl1M8jZpoHDeOftfUyAPu5GQa+ItsdLW1NChfuVK27EyeTFar/ftJIAjXw6QkWkdNMDRHWhpw7rn0dzhxSM2J1ECiYeVKStYBUL82NdE5DRtGli23m8Sj00n7sNlIrKankxgFSGyFa9HxFYe5uZTxcds2dbEYriVJTaD4CpDKSsoqOGeOd18LK1ZBgXq2x1BEbSiTFM1ZIls60RFJqxvDMKceLLQYhmHamMJCcg9zuWignZHR/oM1q5XcyyoqSABptZSwIVCbhGiz24EVK0hQKAfNkyeTdUZkB5w0CejRQy7me9llcoxWejoNcouL5X2sWQPk55PFSi1GK9wU8a2xIAazfKhlVywoIIEhBuQAfVZVRdd6/HjKYJiWRtffYiHx2NhI4tbtJotQTQ31scFA18dgaD5jo2+mQWW7+/VTP49waoYF6sdAMXA6nbeFb+VKur8KC4HTTvMXK82J2lAtSsEskeFMdLjd3m0Jt74awzCMEhZaDMMwbYjLRQkhRN0ni4UGpGPGtHyw1tpYr5IS4Ouvgb17yeqSkkL70+vlmKlA261YAWzeTAIhJYV+LBbgq69IfEVHA5s2AT/8IGc8zMqiQe8jj5D40OuBt9+mz5UD78RE4NprvdOSBxMMwfqnpe5ezQk03+yKdXVk4RszhtYXFq3kZOD004HLL6djisG6iFvT68m1UKslMVVTQ9av4cOB99+nRBqVlbQf0X/hpt0PZtEcO5buS6XlMRyR05wAEdseOECisqKCrv2wYbJ7oW8MlxqhprQ3mQKLtnAmOj74gNqq7M9QrG4MwzBqsNBiGIZpQ2w2Gsz26kUz+3V1cuKI9sisJgbARUUklpxOGnympNCg3m5XF1tiu9JS2s5iIaGWmkoDV6tVtvA4nWSZslrpb2Vh4YwM+j/QIF2nI8GlJNzCuS1x92rOxU1cq0DZFTduJIvcd9/Rel27klVP9KVysD5mDF3/6Ghg9WoSZ/36AdOmAd9+S8ctLw9emLmlYlJ5/yQmUhbGvLyWxT0FEyA2G7W/ro6ElbDw/f47MHJk6GIlmKAL9F1QXuNQJzrcbkCjIStrfLx3f4ZTb4yzEzIMo4SFFsMwTBuiHCjm5dEAuls3+jtcIhGYLwbPwo3N7ZZjobKy/K1sYuDoctF2qan0s3cviamMDGDGDHL9ExYeSZIFk9tNroRigC4SXyhdDcOxEigHsuJ8fAe1ou6WsC6JwblwyfNdXwzYy8vV07Er220yBc6umJgIzJ1L282d630MtcG6qBml1VLbHA46Xny8nKHRt//CTbvv23dKF7qjRynVvbgXfUVCc1Yr5TkJN0fhKmoyUTtqa+laOByUjr9rV3Kz9BXTgQg1pX2g70KoEx02G7UzOZlcaH37MxSxz9kJGYbxpVMJre+++w5PPvkkfvrpJxw7dgwff/wxzjvvvKDbfPvtt7jjjjuwa9cuZGVlYeHChbjhhhtOTIMZhjnl8R0o5uW13PUoEoH5ysFzSorsxpaXR+5kysF2ebm39UOvlzMFJicD/fuTa5zBQOdUUEDb6PW0fV0drVdTQwkaamqAjz+WB6KTJ9N+Q539981yB9AAXjmoFetUVNB6Oh0NzocMIZc830Gwb8yVMh27yJqo1m7f7IrZ2bLQEC6BvigH6+K4wnp29CjwzTfUt8XFtH11tdx/OTlyKvWWxg4Fc6GzWtVFQnNucyK9vNq2M2ZQX1ZU0HWOj6f4vHDjEtWSmvimtAcC13cLZaJDWB4rK+kahBuLxdkJGYZRQ+VV0HGpr6/H4MGD8cILL4S0/sGDB3HOOefgzDPPxNatW3Hffffh1ltvxbJly9q4pQzDMDJi5v/qq2VXpJYgBo2VlTTQrKyk/8OJ9dLpSHRUVwO//UaD35kzyW1q2TLgr38FXnyRYqg++YQGjEYjCQGRbn3nTrJUiILDVisNhi+9FLjtNnLLysmhgXxGBoksYcES+xMJMAwG2WIWCJeLxEZBAW2n11ONre3b6W8xqLXbvUVTYiINei+6iBJqKI+9cqUsKsWAPSGBMjCKgXzXroHbnZ9Pg3WHg45VUQE89BDw6KPUZmFNC4TyuAAJgC1b6DzNZrpHRP+lpJD18K23KNvj0aOyVbBr18Ap1X37b/16aq/DQS50+/ZRHxkMcr/p9XKCD5er+XtXKTB8+zY7G7j1VhLw3bpRzFq4kwwlJXTOb70FfPYZ9RMQ+ndBTHR07UrnnZdHLpq+Fk0xLKitlQV2OG31nQRJSZGFH8Mwpy6dyqJ19tln4+yzzw55/Zdffhm5ubl45plnAAB9+/bFli1b8NRTT+HCCy9so1YyDHOy05I4jHDjjALtoyWB+b7udtu20QA7J4cG4GvWyLP4Ii6oqYnEQ79+VPuqqYkG5snJ5Dp48CCweLF/wosePeSCwMqseWrWuGPHgCVLSET4Wpl8rWpKt77oaNliFB0tD2orKmg9s9m77lZtbWDrh9LiUV9P6eX1em+Lm9q2iYkkPKxWEqTKQssA9amv+6AS4d5YUiL3e3KyLPD+8Ae53z79lNqXkEDt27mT+js5uXmroK9bZE4O9YfShc5uV0/wMW4cXU9hQVO755uzsmZnA1ddFfz7Euj71JyVKNTvQqAYK2VcnhBwiYl07efNC54YxhfOTsgwjBqdSmiFy8aNGzFt2jSvZdOnT8drr70Gh8MBvfA9YRiGCZH2jsPwHTQC6nFHgdo7dqwcayUGxocP037Ly+W4IGGlOXKExEplJQmRxkZZUDQ1qSe8UIpKMVj1HYhWVJDIczqpLWpp4hMT6dhVVd5ufYMHUxsBao/4fOVKEgoOB8XkNDbSQF+vp30dPUrblJfT+RoM8oC9oIAsSgCJufJyase8eXK73W6yVGVl0XbCWlFZKRdaFvE9lZWBXTqV7o1VVSR8kpOBPn3oc5EmXQjVY8fkNPzV1WR9zMmRrWuB3NPU3CIPHwYGDaL9KV3o1BJ8bNggu9sFuufVBEZ2trebY7BJhmDfp+ZEXDhJKkQbhLgSEwxCgJ52Gq0XF0efB0sKo3a8lk6CMAxzcnNSC62SkhJkZGR4LcvIyIDT6URFRQW6dOnit01TUxOampo8/9fW1gIAJMkBSXK0bYM7KOK8T9Xz78zwtYssbjfF0ZSV0cC4rIz+nztXPSanpTR33bRasjKVldFgUSRimDyZYmCCtffHH0nYFBeTALHZaBunU45LMptJpAwcSNkJm5pIQLjdNFiXJBrsi0G2TkeD4fp62l9srHcbxMB02jS5vWK2PymJ1tfryZKyejUNfpOTZYHRpw+5OA4YIGc1HD6c9t/URMLHbqd1e/emlOLFxSS2HA5K2a3X03nW1tI2dXXkLjZ5MrnnzZlDn5lMdKz6elqnuprcBL/8kixJdXXUj/v300A/M5PWF8kstFq6ZhkZDphM1FfKvrBaqQ+Ki+k6iEQYIvaoulpOSiJJ9Fl9PQnOuDjah8lEgthkUu9zgc1Gn2dm0uei/5qayI1v8mT5vh0/Htixg/YfF0d9JTJHKu+h0lISpZdcQn2q1Xpf1/R06od331W/J5U0930ymbzv1bo6775Rfhfo+xLgC3Uc8X2pqiKBZzRSG+vrgT176Lrt2eNAQgLdC7592tz3LSPDW/hptc23iWkd/I7rvHTmaxdOmzWS1DkfAxqNptlkGL169cLVV1+NRYsWeZZt2LAB48ePx7Fjx5CpMg390EMP4eGHH/Zb/s477yAmJiYibWcYhmEYhmEYpvPR0NCA+fPno6amBgkJCUHXPaktWpmZmSgR+XOPU1ZWhqioKKSICGQfFi1ahDvuuMPzf21tLXJycqDRTINGE7wzT1ZIua8EMBUaDbtbdib42nmjtK60xALldpN1pLiYZuAtFpphnzuXrCnBZrvDwfe6qbW7vh5YupRm5WNj6f+mJuCyy+SZ+GDtBeR9iraLArmjR5NbGUDbHz1Kn1VV0bmJ2kjiuAkJVBtJec7i2EePksWnro5cypTWv7Iy4PPPKVW8JJEFSlh1kpKoXcnJZGFR9mtqKllavviCzi0piaxNAFltRPp64VIZG0uWub17yRpmNJL7ocnk3WdqFo+sLFpeUkJWDmHVc7loG2FZ+8MfxNVzID7e+zunvA7l5WSp0+lo+4YG6r8BA+h8c3O9+0i5bWwssGsXbZOYSH02YADFQPnez+KeOXgQ+PBD6j+bjVwCTSb63HdbNYtNaqr/PZCURFZP37aGck/6tjHQ/ak8n9Z+b33bFhMDbN1K94nRKFw1HfjPf1bi5punIj5ej7w84Ior5HaHe27MiYHfcZ2XznztNJrakNc9qYXWmDFjsHz5cq9lBQUFGD58eMD4LKPRCKNwsleg0eg73Y0QSchV6NTug84KXzsiErFVOh0VoRX7SU+n/wE5I15Kipy1bd48ORkEEF4CDXHdSkv1qu0WAkIcUxl8r9EEb684vohZUbb90CFa1q2b9/Yul1zTyWYj17PkZPrbZqPCt8raSDYbiZvSUtpOq/WOb7HZaLDe1EQCRqejwW/PnvT59u20n8REYMIEOeFDeTlloVMmxzCZaNB/8KDsvqbMFmg2Az//TALJYKDj/fADCbvcXLnPUlPpPOrrSZyYTLRNSQn9NDaSC5vTSddHqyVxIupu6XS0XFw7t1vvyahYUUGD9MZGGuiLgXpDA7k7mkxyXJwytkt5DcrLqZ39+1PfNzbS9r6xYOJet1hIxERH0/X84QfZJa++nvrYaqW+FcLxwgv979kJE4CvviKXTL2ePi8qIvE1fDjVxzKZ/O/Jigpyp9Pp6HhqcU2TJtH9V1FB4lh5fyrXE/eqcj/hJKVRti06Wo6hq6ujaxwfT+s5HHpUVOg910R8lwKdm8EgrxMqXNQ4svA7rvPSWa9dOO3tVELLarXiwIEDnv8PHjyIbdu2ITk5Gbm5uVi0aBGOHj2Kt956CwBwww034IUXXsAdd9yBa6+9Fhs3bsRrr72Gd999t71OgWGYdiCSNW7UAvDVavooM+oFqvnUHG536FnXsrOBESNI2KSmyoH8wYrKCgFgsXi33WKh5amp/ttbrcBHH9GgX2Sr69rVP9mBwUD7sVjkgrt6Pf3/7bf0v8lElihJkutuFRZSbFhamlyjSiR8AALXvGpspEH/nDmy6BH9c+wYnau4DlotnU9KCgkyUdRWmYTDaKTBeHk5tUEMru12OeFFQkLgumhlZSQglDXIqqrkYyckkNDS6Ugg6vV0DmqZ6sQ1sFopA+HRo7SuqAmlXF95r8fHyzWscnPJmiWsccqgAbVJCLXaWJIE/PQTHVuI5//8h+695GRaR/T50aN0rZuaKO19SgoJspYmj/Ft45AhlD0z2MSJr6BRJj2JigLOOIOu8dGj8vWLiqL+mjHD/5qOHUsJQkpK5IQl778f3jm1dzIdhmFOLJ1KaG3ZsgWTxPQx4HHxu/LKK7F48WIcO3YMRUVFns+7d++OL774An/+85/x4osvIisrC8899xyndmeYUwybjQZ98fGym0+4hX59B23KdNfBMuolJ8vWmcGDaZ0VK+RCv2r7F+5RyqxrsbE0yLdY/LOuFRZSQd2//52OmZkJXHMNpWYX+/QdOIuBamUltSkmhgb5YhD/3nvy4Dkzk44nBomVld7FgNWEht1O7XY4aFCenCxnBiwro8+Ki0lcRUfL27nd1HcZGXRMUbhXZPhTCtpevUikWK1kxcrP97aqif6xWIDdu+lYIqlHXJycxEFp+cnOpj4wm0noHTokZwS0Wqn2WE4OiYbx40loKdOF22zUl8KaJooRm820b52OBvN1dfS7Xz/KBHjwIAnFYJnqdDo6x+XL6XwAaqPIoqh2zyQmkgWvvp7OT5Lo2ohjm0xUn0op5gsKaF+imPKRIySOJ04kodXQICd6cDhIxCknAc46C3j2WerX8nJvd0vlRIFa0Wa1CRC1iZKdO+nclBkrldsFEjRz5tD3MyaGxK74vooQ7CFDgNmz6VoJlPtKSKB+TEykaxrOpA0XNWaYU49OJbTOOussBMvdsXjxYr9lEydOxM8//9yGrWIYpqNTU0MD6cpKGijFx5PrW6g1bkKZTVdal4S7lNksW1E0GhpolZfT4B2gWfPERNmaYrGQADj7bNk9MCmJXLbq6mi91FT6rRSI69eT253dTgPgo0eB114Dhg6lQbYyTbpyoGo0kniwWOQsgo2NNJA0mbxFoU7nPUh0ueh3oHpDJhOJEZeL+ru2Vo6bEkIpPZ2sTW43HVeno8F/XJycit23HpFS0DY2kgASlrY1a/wtBEIUd+8O/P677CaWlydnvIuLo+uSmEjiDSBLzNy51C+lpfKyUaO8rWa+90hdHXDDDXReSithUxNtp9PRdVq8mAb38fH0Iz5XCkW1+y8xkfpLafFTDtZ9RX98PAmiAwfoesfH03Y5OSQ0hXhXTkJUVNBv37TqKSlyRsb4eOoXIeYMBlpH1KWqqqK2VFaSqBP3gXKCo7n07QLf9ZqaSJgqLanK7YIJmrg4On9RtmDLFlo/KYn2k5joff/47quoiO4VcZ+qHTuQW2Co58swzMlDpxJaDMMw4eJy0QA8OppEVk0NiZ/Jk0ObRfYdaB0+TCIlKcl/EKd0sXv/fRrc1tbSQFanA/bsoYFocjKJreeeIzFy7BgJpKYmat+hQ+RupdVSO3fulBMUREd7106y2Wgg7nLRZzod7ae0lAajWVm0P+Xg0G4nK5jRSH/Hx8vpw2NiZFGjFIVnneU9SBSWJ3G+vvi6NubkeMdNATQYF0kpKitJRIrSh4HqEfm6SzY0UDuDWQhMJqqTFBVF59fQQINpq5X67MgR6rNjx0jguVx03MREYOZM/7b4iiFxjxw4QP0JUPr3tDTaRohFIc5cLvrswAFyfRQCWsRLBbv/lNdSWGTKy+Vtffu9Rw/6rLKSjllaShMAF19M/XL0qP8kRI8etF9fsavTUTtF3bTYWBKiNTUkMLt2pfVFW0TyjcZGWl5bS/eBuL9CLfLrW1T6119p37t2UXybr8tlIEFjtdI5TJ5MZQR+/JHOIzmZBLi4J5XCx3dfbjf1tyhwrHTfbM4tkIsaM8ypBwsthmFOasRAKTubBoZVVTS4UrMcBNteDLREIoCcHPVZabFMCKTaWtq2sZEGVpmZNDj89VcaoGZmkgXB6SQREB0tD+LcbmpnVhYdz2ymgabyeCYT7UOno2NotbRddLTs8qccHGq11CajkQbdWi39JCfLVoeyMlrXYpFrJ23YIBf9ra8ngaDXU8zQtGl0LN/Z/MxMsniJ2lwGg79QGjeOzk0kYBACKVAhWmXMmMsFvPVW8xYCX/GRmysPtkWRXqORxNaRI94ufGoxeb7nKVxT6+rkY0qSnKhCzb1y9GiqWxVIQAe6/5TXsqGB7iOj0fs6qPVRXBxds9JSyr7ocgEXXKA+CZGfL1swlQIzLs7bSllWRn3mctE9OnQoXePkZLrXXS4SWvHxtF12tnc/hFrk1ze+SqMB+vYN7HKpJmjMZuqjmhr6bMwYar9eL8fKAfJ3SuC7r6oqErlut7f7ZkmJt7uomujnosYMc+rBQothmJMa34GSmHkPdRbZd3sxMK6ro0GlMvuYksRE2k7M5hsMNKgTSRzEflJS5Nlwu11Omw6Q9aJbNxq4HjlC+1CbBR8/ngbe27eTYOvShcSESL4gBocxMXKxYLEvMZPf2EjHyc+nDHPK2CRx3uecQ4JryxYaaOblyXE1wlqlnM0H1Gf4588nN75vv6X07iIWzFccBXKnUmahC8VC4HLR+soskDodibwtW2ShKVLT+7rwKduiZrVIS5NT0Ccn03pmM90Xl1xCViDf2KHyctn1MTOTtlXG3wkCDfRdLmDTJrp+qakUO6Yc2Cv7KDGRBGV1Nd0fUVEkEkT2QbVJiLg4dYEpEkLU1FCGyMmT6R743//oGImJtE5TE51faiqlvu/aVRbbStSErBpq8VXJySQ21a6XEGYVFSQCbTbvmLONG+l619XRT0MDbTtpkndb1MSREOlpaXR+5eVU0Lq+vnnRH+r5MgxzcsBCi2GYk5rWziKrWUNEjNaxY4Gzj4mYlZoa2VpgNpNwqq6mAZpGQ/uxWmkQ63TKSQYAGkh36xa4/co03klJwMKFZJ3o2pWO57tNWpq3lWPYMDqH+noafI8bR4Puyy+n44vYJCFg8vJIYP34Ix2/rIwGq2VlNNBUuvAVFNB5FBXRuYqU95deSu3+739ldzWLhY4TblKAUK6tmjASA9+8PLKGHDokxzupZVAUBIv9mTGDLEb19bRuXBytoxRZdjvFvJWVeWdNLC4mK6Na/F2ggf6XX5JwT0qidtXVqQs1ISh//JGuR0yMnM69upraUVZG6/pOQgQSmImJJLrz8mg/zz1H+0hIoHvmk0/IVTMnh5Z/8AGJHWVyFd/rGEqMkjK+SkwgBLteAjGxobQKVlRQ0guNhvrNbKZ116+nz5QTA77iSGSpjIuje6euju7900+nexoI7hYY6vkyDNP5YaHFMMxJT2tnkZXptQEaJPXuTenbnU717GPKrHvCSpCRAZx3Hn1usQAvvCBnMnM6qX3R0bJFSwycA7mvibggMcjesIHaJVy01LYBvK0kPXrIcSZ5efS5waAemwTIrnYuFw2ii4poAK3VyvWkAHLrOnaMzv/gQRJypaVU2HjDBhrMxsbKFj81kdDSayNoLsubTkfudqGK8GDJDDIzgT/+Efj+e1p+2mneNaFKSkhkbd5MYiclhSxCW7fKlrlA7oNqA32rlVzy7HYSXGLgrzawz8uj1P/ff08io76errHI1CgskcrzV7pHAiSShSA9epT2lZdHYkdMJsTG0vUWSV3MZrJc1tSQ6PLt/3DrSYU6aeKbzbC0lNrpdHq7vW7cKGeqFJa24mJyxVS7V8Q1N5lkK6FIlR8VRT/Z2bLVmN0CGYZhocUwzClBqLPILpf3oF0MlMrLvS0jY8eSu1FqqrqrkMi6J2KqrFYa7FmtNBgrLSWRYTDIwsfhoEGeGPQJt0K19ttscpp1u50GkY2NJG4kyTvLGqCeOVG0Wa0WVKB6YcJl7NgxGpS6XHKxYFHTqrJSTm9fWyuneNfrqe5ScrIc79acSAgF32sjLBGhZHkLR4QHSmZQU0Pp9YWlEqCMhcq07wUFNPA3mUiI7N1L+zKbqT+Tk/3j75Qor39NjWxNdbvJKpORoV77SWw7fTqJ223b6LokJFBMVXa2//n73iu9e8vZ+UTWSCGMzWYSHcXFtExkj6yslK+tSIUurLxCKLaknpTv9RL9AcjfV+V1F9epro6+F+Lade9O10MIW5G4QxSM1mrlfaldC6XbaXw89b/LJWeWjLRbIBc5ZpjOCQsthmE6LK0dXIS7fUkJuT2JIPd+/cgClZwsu3wJy4gyOQTg7yokspvt3ClnYRMWi3nzaHshQKqqaBDYpQv9LwriBsuMWFND7SgupgGs0ynXo/JNo61m2QH8Y5Z88RV3JhMNnnfvpvY6nWThyM6m5aKmVUqKnKFu506K1wFoQF1ZKbtXSZIsEqZObdm1Dma1CjXLW6gi3Df2JztbjtcR1p7iYv/tCgtloSJSrDc00P2Vnk7XXxRIbi5+UJlFUySk0OvJIhms30Q8Uffu1E/19SS6+vXzPn+1LJs7dtC92tREYqqwkI5XU0N9cMklVDervp6sWsKS63TSMY1GOkeRddBg8D+GWm25YNdB1HVT+76mpcnXXZnURRSJ7tmT2qUUtuK4VVWyINTr/dsjnik5OYHdToNdh2DPpECfcZFjhum8sNBiGKZD4hsTMm6cd3HYcLYPZXAirA7bt8sudtu3k/AxGGigbDLRYM1slpNDfP+9d+yMcqAUKGOgcLfq1YssW3V1tP7NN9PAWxxfWEfU2rpmDbmgxcTQfjUa+kyn80+jHciyY7cHj0cKJny0WrIANDVR+5U1rerrZfGQlET/i0LMQlwlJpIoM5tpoP7tty271s1Zrdo6y9vRo7KIqq+nfgdINAmLihDVLhf91mppkH7FFSQCwmmfON8uXajP4+Opz8V+AsW5FRZSsWHhotqli3fKc2UGRbUsm3l5crZCIUBWr6bsfT/9RNc6Lg4YMIDOz2aj61pSArzzjlxgePZs2qfS4lRRQceQJHK3DOXaK7+vTidtu307fR8uvZT6ccUK/4LTBw6QwDSb5VT2wlKXlCQnsBEFtquq5Dg732fK0KF0Lwe6dr7foWDPpECfCeF7+DA9ew4f5iLHDNOZYKHFMEyHQzmrHh1NsRBbttDgVKSwDnV7XysHoC4gbDYa8Gm1NFgTy3bvJvGj19OgWgT9DxxIAzBhFRJFh32z0allDDSb5Rn3vDw5Ruq00+jvb76h/X7wAQ08fc9XDIa7diWLwu7dNMhPSqK2dunSfLrrYJaTQIM+m42EwuDBdF2EdaOhwb+mVXQ0DVi7dJHdtgwG2kdyMg1Sa2roWv38M/VrS651c+cWySxvvrE/ovCzEFEWi5wM43//o4H82LHqonrSJOqPcNsnzrewkMSBRkP3Y1paYLdDl4vEnnDZq6ykczjjDO+U5+Ke9c2yaTKRtVKUD0hPp2u4ZYtci8pgoHPbt4++F2JyoaCABFZODk0AbNtGrohJSSQaKiqo32JiaH+//BLatRffV7dbdp212WifImZOmdTF7abaZtHR1D+1tXRPWq3Ayy/T74cfpnPMypJdfd97j85VWQMuFKuw73dIub3Z7J0cBgj8vLLZyEpaUUHfkWAujQzDdDy07d0AhmEYX4SQMJtpkCSSLxw6RAMQYfFpbnsxK5+SQv8XFtLs+htv0O+SEnkbk4kGiG63nPLZ5aKBTVoaCS0RwG+306Bt8WLKNihE1pEj3oH0AA1eu3Yly4+Y9Rb1pMTyrCwKygdoO+F+VlxMs/KiCK6yrcINT7jejRkDPPIIcNNNNEBTDlKFy5tvO9Rcl2pqgK+/pr6KipIHhC6XnARApCZvaqJB8YIFFJvicMh9np1N53XNNTSAPfNMclvLyCABYrNRH8fFyZatllzrUM5NuJq11gLge18lJNCAvXt3GozrdHKacJPJ28W0sZFEdWYm9ZlIPBJu+8T5ClfBqCjq06oquifUxLPNRp9HR8t101wusiIdPkz3kLCUAN79mZNDf4sBvttN5/Lrr/S52y1bucxmOn+lK2h5OfVNcjJ9v4QldepUWq+2Vi5+XVND+wzl2ptMdB2sVhK3TqecXVC4+4mkLjk51C69ntwLhw+nyQKXiwRMSYmcYVOjoevW2Ej9Ja7jV1+RIPR9pgirsK8lSwgn8TwQ20dHk2gVltDCwsDPK+HSaLHQj9st/x2KiyXDMO0PW7QYhulwKGftRRHY+Pjgs/Zq2yutHNnZNOhVWiPUMtA1NMgxH3360ACzvJwGgHFxctKK2lraRgyiRGySsqis1RrYYpGZSbPcYts1a8j6UV0t12KqqCBBB9CAUYgnZfY1i0VOhBAstqc5y4mYgS8qIhcxvZ5qMxkMdC7jxlH8jbBalZfToHXaNDlduJplSbhdXXWVnBZbmeVOzPSLay1J4V3rUM4tUgSqqeZykZWnslJOzQ/Q/eDrYqqWeCRcMjPJEjJunFzTKpjboclEfSisiQ4HXdeGBrk4tdJSolbwePBguj47dtA9FxVF119kvGxqovtwwACyJFksZC0rLKTj9epF4kVYG0Wdrj17qA1uN61nt8uCLNi11+moftwPP8glFkRdOrtdFiLiXGpqgI8+omMJF16AhE9lJZ0PQALWbqf+SEiQj2+10t8iFX4wq7DVSn1qNntvHxtL7bVa6XyjomhS4+qryaKntm+bTY55c7vVXRoZhum4sNBiGKbDoUw6UF5OAwwxax9KsWG1NNBjxwJffKEeyyMGNGlpwLXXemcdLC+X2xEVRev8+qt3JjXlIEyZPvrTT2UXKDV3rjVr1BNslJfTOlVVNAATqcFFsgBRgPess6htQqg1F4cWKOmDcgZeZF0TAlerpfatX0+z/aJgbnk5tS0tLXCf+8asxcWpF8KdOpUGnKWl3haacApLn6jaRMqCvaKm2tatZJ2IipIL5+7bR+3JzSVxlZcXWSGo01F8USj71enkOl8VFXJB4ro6OS7ON/mD6E+lgC4vly2oTU20rGdPWejk5dH9rtPJLpbdu9NxDx4kS5JSDLpcdP80NtI97nLR30ePknthc9c+Lw8YPZrEnNlMkx9ZWf7biayUFovc1m7d6L4WiT4Ehw7RNdVo/BPdKItyBxK2JSV0L//+O1nZeveWBeaIERSL6HaTwNPpyPX07bflDKI6nfe+RfZSl0tOfqJ0aeTEGAzTsWGhxTBMhyTcWXu17X3TQIu4EBFTlZvrnZpbLWmGsh3r18sxSCYTiSrlIGz1ahpwA3L6aGVsmFLAqSVxENaPDRvof7OZBrXCxQugOlTbttGgsbiYBmzZ2f4WunAQbYmPp4GiXk+DT7EfvV62eoj2arXU3kCp0tVi1pQWOV9RpNHQgLKmhq5PR6tDFKhgr05H91FFBQlPkTHSZqMCtspzaAshGKrAzM4Gbr1VtqAKdzeRIj452d8aJPavTCyRkiInlvj9d9p2zBjvBCZWq/e9bTKR9WzOHFmIArKIKCyU3UlFzFWwjJuAnGhCWQcsN1c9IYUy/snlIkvQxReTxXbvXrJciW2ioshSFhvrn6SkOcupy0VZEEUSHauVLNKjR8suwwkJJLySkkgY1tXR91gkvkhOJuu16Cdf63VTk7dLY1smxuCU8gzTelhoMQzTYQln1j7Q9spB6JAhNINcVEQDmUGD/APc1QYuOh0NvDQaEhh5efRbGROUmUkDSTHgTkiQB5yFhbRfZRrq2bPVXe3y8uTMdQkJNLitqqIBWEkJsHQpbSesbYmJ5JYFhO5q54uvS5zDQeJKoyHhIAaGBkPgdPbKvjKZSLwq+zVQ+m5lgom0NOpXkWSko8Sh+A7WlQV7AervtDT6XIjJM86grHstOYe2GuBmZ8sunAYDxRceOUIip7aWRI+aFck3sUR9PQkIvZ7ui/x82rfI3mcweN9PytTnSnzrUaWnU/8ajd6CzBe1RBOJier9pTahUVFBMZpWK4mWhAT5Wp5xhiwY1URVMGFrtdJ3XFif3G46r1mzSDx+/jm5ljY20rqiBld6Ou2zvp6SgdTW0v0knitC4FVUkCVLuF4CLf/ONwenlGeYyMBCi2GYDk8k3MJcLrIEJSWRkKmrowGeMrYKUB+4+GabEzFfc+Z4B8IrB9wACaHcXLKEibTxkkSuZiYTMGUKWcFETSYxG19RQfuprKQBT2oqWRHsdrJspabSMZqa5MLBTmd4rnZKlLPmGg0N9Fwu+lujobacfbbsEtZcKnLfgrHl5SQYAe9YM991RZ83NPhbVtqT5lLIK/tPZB2cPr1l7W/rAa7yu6R09czJCW5BFIklCgq8rbbl5TRZoXSr8y2IHexeycvzr0eVnBz4PlbLKCqKDgeKT1OKvvJyOQGHsEw3NsoJZ5SWNDFpIISpyC4IhCaExcQMID8/evYkV0qdDhg2jL7DVVW0zr59cpuVWQlFDGlqqpzFFAit7lpLCJa1lS1bDBMeLLQYhukQhDKL35qZft/Bsm9sFRB44BLIzU8MgARiwK0soipchLRasgCIzGqbNwN9+6qfoyhq3KcPCUJRLLamhmbff/9dLn7b1ETia/hw/5iocBCz5lYribf160k0xMVRfE92Nq0XStIJ5eBWWTC2tNR/wBZu6vn2IJQ2Kt3KALJShEuoA9xIWbzCTSISyGprsZBLojLeEGi+IDYgJ6ERrnHp6cHdBn2/i2433a81NXISGd/9KwVlZqZsiRPZMW024KKLaH3ldROit7hYzjiYkECfORz+QthkInfRPXtIvOl0ZL0G5OQYCQmyK+UFF9CxV66kz/V62tehQ/S9F0loevRQP5dgAjaSz0qg7SxnDHOyw0KLYZh2J5RZ/NbO9AcaLIcS4K7c1m73LwisJC1NThIhZuhrasjiZLHIbnkOB7luJSfTeiKe69xzaX1x3NxciiPZsYMGavn55Ian1dK2YmA4ZkzgmCggtIGXSBog4pDUiseGYl30jesRBWMB/wFbOIPHQLR1LEmobRQupsrMg+EQygA30havcK3FSqutVkvfo/R0dcuwb0HsQNdJLQNnoPNSfhcrKsgVGAAef5zcGwcO9N9GKSiVLpOA/BwQ1ldlW0WhYFHrq6mJ4ro0GrLYKYWw+O7YbOQOKGqHDR5M2Q7Vsi/GxdF6YoLjk0+ATZtky3dUFMVrKr+DygkRcT18211YKMe1RvJZ2ZEmPxims8B1tBiGaVfUas741tBRDnqUNX+aq7GkJFC9pexsGrhcfbV//SnltkOG0OBx504awAwZEthtrqaGklgkJNAALjWVBlgi5kmkZT5yRLamido5YpAFAD/9BOzaRXEkAwfS4KekhFJoZ2bSAKypifa3cWPgPiwpCVw/LNB1EHFILUXE9YwYQe0DaMAmYr2sVrl9YvAY7BoEIpRziwStaWOoKOujicLCytpYoXxX2hq179GMGSSmA7UbCH6dlBk4lUke1M5LHD8riyxHTieJlbIyil/0rTmn3E5YstWeA1qf0ZAQvQkJZDUzmUhwVVfLNfbMZhJYNTXydRHFyDMzgQkT6Fw3baLvtNNJ2ReVbsKibYmJlIRDr6eflBR6ZtTUUJ8qvy/l5cBnn1Ha/bffJvHnclGfvv028Oyz9DxwOlt2jwR6VrLbIMOED1u0GIZpV0KZxbfZyH2nooIGVMqaP+HMxgdylWpuVt9uB378kQZdOTlk0dq2jdyCglm/AHk2+KKLaBB09Kg8WIuOpr/37qXzT0kBli+Xa2eJ2jlGIw1knU4SXxkZNPAyGkNLXe/rjlZQ4B9f1hbuQiKuR2kJGjKELAq+FpmWxOGd6FiSUNrodpOgdrvDb0NzlrOO4tKl9j0S5Rh84w2B5q9TuOeVmUn737BBdgEUbrlVVfT9CLf9vlZIg0EWfQB9j3U6urZ2uyzyDAayWCmLGQP0/fzqK+qP2FhaV7gqiuyLvhY+tXg1s5nKRAjrlLDAHzlCz4+NGylmbtgwuUC0KPpdWkr7bMk9cqJq0zHMyQ4LLYZh2pVQ3FQMBhrIWCwkdnxr/oSD72C5ObczUcNq82bZJTBYQdVAg2WTibKPrVhBMSXJyeQWWFRE8Rr9+tFg7NAhedCXkEDuQ7W1dO4iWD4lhQZ8KSkUB6PTBe5Dm422jY+nAV99PQ3MRMINIXTayl0okNtWJIRRRxEegpIS4Jtv6Jp88AG5XoZr+Qo2wO1ILl3hCOPmrlNLzis1lURIaamcwCUjg5YFwve7Hqj9JSXkxvfLLzQhYjTS8yY6mr6jIglNUhLVySorIyEkrEZKd8rERHIVFN/jAQPouIFcQKdNozpcJSVyoWIhvJTF0c1mchF0uWji6eBB+p737UvfcYtFjvPKywueXCTQ8y8SSYgY5lSHhRbDMB7ao25KKPEvdrs86AhW8yfc82gu3kXMxJeVkciyWGTrU25u4MFLoMGyb5rsmBgaMGZkAOefD/znPzSLLTLXWa0kkETGM72eMr0lJNDgSmTni4sLXCxY1NuqqJCTF0RF0bF9rVvNXYeW3h9iwOZbXwkInOUxlON0JOGhvFcA6vOWishAA9xIxLO1Bb5ZOZX140TmvmDXqSXnZTAAl11G7oLCVfeyywJPvoQa2+Z203dCZAmNjqbvWpcuJFy0Wvr+iO9mejp9X0VWwIYG79hPi4X2W1NDn8+YQf8HsvCVl1NW0pISEpAAfW/r62VLdlwc3V91dTQpEx9P52Kx0Pc8I8O7MHOgvmyLDJdce4thvGGhxTAMgPatm9Kcm4oobCrq0wSq+RNOIHgobmfKmfiUFBJZDQ1A//6hD3BF8gyzmQaBvu50Iq12XBwNlIS7EEDHOuMMSgMfF0cuREePynEwysGqWrFgIbI0GppZr64msTp0KA3ebDZ/61ag6xCJ+yMUYRTOcTqS8BD3ish8l5zcNta1SLt0RWJgHE76+0DXqSXnNXAg8Mgj8ncmkMgKx8XUZqPvg1ZLkxEAWaTi4+m3JNE5xcTQ97CqigRP167+WRanTqXtLRbv7J2BJhxqaoAlS+TvrDieJJEArKmhpDf5+VQWorycRF9GBrWjXz9qV00NFUkeNozivAJNRjXXJ+HeG1x7i2H8YaHFMExEY11aa/UI9FlzNX9KSuQaPyK7V6B4JIAGOyLlsnKwY7XKs/BKYSCSWmRkqBfeVSIGHL//TsJPp6PtL7uMBodqg0qRtU1kJQToHM47Ty7eKtJgBxqsinaLYsHx8TRoTEwkcVVdTfFf9fUk/oQrorBuiWuulsksEvdHcwPulhyntcLD5XKhpqYGDQ0NaGhoQH19PWw2G8aMGQONRoMvv/wahYWHYbfbYLPVo6GhAeeddx7OOOMMbNq0CR999BHcbjfcbjcqKtxITOyFK6/MRkWFHbt23YtDh7TQ6bTQaDTQarW49957kZCQgBUrVqCoqAgxMTGIiYlBbGwM+vbth+7du8NqtaKsrMzzWUxMDKKi5Nd1pFy6IjUwDjf9faDr1JLzMhiaj8kKx8XUZKLv+f79ssUoKorc7/LyyNU3LY1cBxsb6Z4V97GYSGnunAP1V2MjtUuno2eA0ynH+kVF0bJx40isXXop/S0mlbKz6f+cHEoWtGEDubFu3ap+XZvrk3DvDa69xTDqsNBimFOIQCIoUrEubTmjGWygJl7yhw55B4Knp3tbbCZPJtFRU0MzwiLl8mmnyXVxPvyQhEhyMrVfTeAFE1miLUVFJLSsVmpvaSm5OT3yCG2vHFSKNmdm0m9hFREpoEPpA4HyWsbG0vnW1srZy8Ssd0WFvytioGseyVioYOfQkuNkOJfTH9EAJABOwO1yoc5qRXR0NIxGIw4dOoTdu3ejtrYWtbW1aGxsRPe8PMyaPRs1NTV47bnn/PY7a+i9sFr1sB34H2LqypBkiIY5zYiYGAP6JmxAhvMoBqcWQjPaAq1GC2g0cDg0aHKUAMjGzKEFGJNbB4MBkNxuuCUJkiShq+YrmJwmdItaDaf0G5osTWg81oSapib0S8hHRs5oVP6+C6uWfeTVnqysLCxYsAAA8M4778BkMiEhIQGJiQlITExEbm43GI1Gv/MojZqt2m/NDYzDmTAJJ/39iYj58W27EDaHD5PFqaYmsOuvVksTGg0Nci28fv2oADUgn+Ppp8vPk+bqhIUax5mcTO2sqpKfCaJgeHKyLPbEPnr0oP+FFf+LL6g9DQ20j2CCJ5DYMxiofwoKZFfQI0cotjTYBFNHi5dkmI4CCy2GOUUIJoIiEetyImY0Aw3UxEs+LU0OBK+tpcGGcAE6cIBSs3fpQrPR0dF0/rt2AT//TLPixcW0r8REObZi/vzwLCaiLTExJN6MRmpDXJx6VjTlddHrycImkmGoFW5tbrDqey3j42m/ypn3tDQSXcFcEYPts7WxUIHOIZTjSJKE2tpaxNe+j9raWsy6rBc00ODNN9/Ezl07UVFRAYvFArdbwh13/Blnjp+EuroDKC9fgdTUVHTvnor4+AScdloSRo4AHI4YJCbOQGysbD2KjYlFtCkK774L9Op1EVKSgUoLtWX+fEB3PBX4yBF5mHtxntc5NDokfP2LhNtu1yFary5yaNt8APnyeUGC2+2GTgv069cNY8deApuNLGwNDTZERxsxcgTgdDmxbt0xlJeX47ffKlBRUQGXy43XX3sNaWlpeP6F57Fnzx6kpqYC0ggkJH6HnqefDm3u9bDb7ZAkCUajMejA2GoNf8Kko2SpC/ScGzKEvv9FRfT9DlSeQaRynzuX/hf3qlg3Uufo218A/X322ZQCX8RSpqRQKvsuXfytvyLBzPff0/fYbKZU78KNMJjgURN7IiNoeTmJt+7dad3ycprEAsjtubn6ZgDX3mIYAQsthjkFcLuDi6BIxLq054ym8iUvAsFF0Hr37iQ29u0j8ZWZKSeGMBhIEOl0sjtdejq58AA0WKioIFeiUM9BtKWoiASO1UptqasjgZOQIK9rt9NMcWkpHaOyUk7/DMjFiAWhWBl8r2WgmffExOZdEQPts61ioXyPk55eh0GD6qDTZaG2thaPPPIIBpg3oqlJFEvajPPPfwdxsXHQaDXIysrCoEGDkJaWhrS0NPTo0QMAkD85H/mT81WPqdfrMXLECL/lVitQXQWkJANx8bSsugqwNQS/F4QIE79DRQMNdFrq0LjYOPTq2VN1vShdFO68407P/y63C9XV1UhKSgIADBkyFNHR0aioqEB5+Tc4WFiBmJhbMTxrOT7YmICnn34KaWnp6NatG6zWPAB9cPrpI70sGi2dMBGixOWSLbknUnAFmuyZN4/KMSQlkVW6ri5weYbFiykRBkCfK113gcha5cS+hDgUMZV5edRWq5WSWZx3nnfaeBGDKSZ0Kitp4qiwkJ5htbX0d14eia5AgidQRlCzmSaJ9u2j/VZVkUWttDTwvXCi4yWVz0KRNIRhOiIstBjmFCAUEdTaGWnfGU2R/aolKdjDxfclP2YM/WzcSDO9VVU0OElMJEEjEkMIT6v4eHkG2eGQ08lrtcB778luhKG4QSrb4nTSgEcQFwf8739ykLwybXxqKl2fmhp5fWUtpnDcMkO9luFc8xNhsSgqKsKqVatQWFiIwsJDqK62YM+e3hg8+CnExcXhotFVSEkdj1GjNEhLS0Nq6p8QGxsLALji8isi2hZTDJBkVszQH7domWIiephWo9PqkJKc4vn/zPHjceb48V7rSJCgAVBdXYTeD47El790xaFDh1BSsgYm0yE0NY1EZmYDvv/+Hhw50g3l5d1gNneDRpOH5OQ0VFdrQp4waYn7sHLQDLT8Hgv0nKuq8l5uMPg//0T9s5075YmW7dvpu3nppZG7330nS5TiMD6eRFNCAqWNj4sj0aTTkVVJKcaio2lSprTUu4iy00m/jxyRy0YEEzyBMoL26kXWMeFG3aeP3J/B6pupPSMinYlQeY+lppKQZpiOCgsthjkFCNWtozWztUqBceyYnF74/fdPTPYptZd8fLw8OElNpcGJzUbLo6LkAVWXLhT8HhND29bU0KBL/N/crL7vQELZFoBisyor5Vo4BQW0XJk2fs8emklOTaVYC2UtprS08K0MoV7LcK55JGbzq6ursXfvXhw8eBCFhYU4dOgQ8vPzcfHFF6OqqgobN36Pbt3yMHXqFOTl5aF79+6eOKxHH53TuoOHgU6rEO9Vihn6MC1VHQENaMp/2tQk/Lh5CAYPBoBUlEY9hKYmBxwOoKnJDputLwoLD6GwcDMOHGiARhOFkSM/RG5uFL7++iMYjQacfvrp6NGjB/QiY4uClrgP+7rOAnK8ZLjPjUDPObPZf3l2thwHpdPRdzUmhiZX4o9bMBsbacIoUlZ5NREaF+cdU5mQILsYi2yGSiujUoyZTPTb5SJRpdGQ0DKZ6FlnNsu1/8Ltu8ZGYMQIuhaiZEGg90ag+mThZIENFd97rLiYlgcrEM4p55n2hIUWw5wCaLUnxq0jM5MEwpIl9MI3m09s9ilfIaCW8lzpTtfYKA8CaPBJxUiNRjlVd3NukIFm8JUzxQ4HDXbEthUV9Fukjf/lF9qP3U4DrNRU+lzUYjr33Ja5Zbb3AEOSJBgrlqCoqAjdu3dHQkICtq7/Cr9s3gyTyYRhmRmYMTANvXsfQ4ZzOab1B6b9WymmqgFsBQCM9Pfua3MyM47fPw1kyeqMIssX0Y8/bj6eSEQH+okGHr4uB0AOLJZx+PHHWlRVVSMz80sMGQIsX/4ujhw+jOLNbmyMikKXrGzk558Nbc410GolaDSasN2HlYNms1l22Rs8uGXPjUDuawaD93KzmYTJW2+RdVtk6wNowC7q2Ol09F2MRJxRMLfG5mIq7XZ/MWaxUKIfka20b1+yepWV0bM3IYEmkGpqQhOKyr6zWMhtecoUWh7svRHo+RcoC2xr3wW+95gQ54HOkVPOM+0NCy2GOUU4UcHqdjsNYpRxTaKQZmpqeMeNhFAQgicuzv/8XS5Z1Ii2+sYrAMFncpubwVebZc/Opr9FALvLRQOjXr1IdEVH0+eiFhMQmkVS2V/C1ag9Bhhr165FVOliHD58GHV1awAA99yzECNHjEf37sNw443DkJqa6rG0dGR02pMza1pw4arB1KmJsDUkegTm9GlXwOly4vfff8emTbvw/fe7sXmzCUn7l8NSuRwf/RiHvn37wWrtj+rqfgASm02IoBw0Gww0IQTQ/Z+S0rIYz2DFwufP904CEx1N7sVbtpCr8bx5wIAB3jFa06ZF5lkZSITa7c3HVLpc3t//uDiakLFavdfr3p2etZIk19YS/R/KszQzk4791Ve07zVrgtfWCyYe1bLA5uW1Pm7X93laVycv94VTzjMdARZaDHMKEalA7mAvbd8X4dGjZDkKN9Yp2EykCLYH/Otjhdrmo0flAYWyXaJ/QrEAhjKDH2iWHaBl5eVymnURPyYGD2JmOS4ucHvEeSktdqGmeG4tDocDv/32G3bt2oXdu3fhz3++Az2iv4Gx4hNU1dZi6tRE9O9/P/r27Yv44xkl0lJD8GNi2h01gRmli0KPHr3www+90K3b+Z5sjG73abhozD7898vvUVHxKQCgf/870K/fJAwbVoHKSjfSfTO7wPtZYTaTNQmg50WwJA7Ntj3Ac04k/qmpoeMVFtL3R6ul5DUApTC/6CL6O9RnSygEc99WmwTybbfy+9+tG7kExsXRedTXkyX+D38Axo+XrfTiOVFeTtYlMdk1bVrgIu5r1pBVzPe5ESzba6CYOGUW2Lo6akdennxNWzKR5tsXWVm0XKtibeaU80xHgIUWwzBh0Zwrhq8LSmMjzRyLWKdA9Vh8A+IDzUSWlwOffCLXuDn9dODCC2UrUShtHjAAePttGhD4pnL3nQEPNhAINfYt0L58Z9jr68l1SKR3z8qiGC3fuC+xD99sZSJA/tAh6qfmUjy3FEmS8Oijj2D79l9gtzfBaIzGdTO1MNf/D4hOwd//PqdTWKuY8LE1+GdjjIvtj6uv7o/zzwdqamrwxfau6N69H3JzgbfeWo6PP/4IqalpOOOMMzBq1CgMHjwYBoPBb9As3HcdjuDuza2xdIvvbGGhXJA4Pl62bNvt3lkGwyFYu5rLytfcJFigDIEGg/zcEZZ7Xyv9f/5DVjqNBvj1Vzrvyy7zF5JCmJjNtF+zOfhzI5SYOJEFVqcjgSjOuTUufWqp8dXglPNMR4CFFsMwIROqK4Z4EVZUkCVLvNgC1WPxfemOHes/E2mxyOmFt2+nGVybjZYdOQLcdpu62PJt8/79VKy4vp5isYRlzGJRrzUTNJW3yuzq0KFygL3vumqFS33TrJ9+OpCfT5/Pneu9H99Ac2WAfEUF7Ss2lmaSy8vpR6tt3QBDkiRIR/6Dffv2obCwEJdeeimioqJw4ehqXHpWL3TrlouMjEzodDqFOxqLrJOVYNkYR44AftyciD9MqAPwAyABt14Yg/NHTMChoiLs3/85tn7+FmKrx2PSpEmw2WyIj5EwcG4MmuyA8fjkS5MdqIqZrSqiWhtzI76zBQX0/YiKIjEgXHRbOggPpV2tdd9Wfv/VRJuvu/DkySSudu+m56VImvHNNzTJJISPaKeY/Nq+nZ4bbjeJ30B9EmpM3JgxFAeXl+efabGlFnfRF5IkT0yF2j52G2ROJCy0GIbxI9DMbDiuGCKQPDmZXqTl5SRmfOuxAN4B8YWF9IJPTCQrj9tNn9ntwDvvyO4+Lhdtq9XSvr/6CrjqKv+XqNVKn5vNJEJqakhkGQw0c97QQMHj/fu3bJAlEoBs3Ah8/jn9Tkgg96Nhw0J7qfsOwLRaGjyoucMIlNciNpb6SxRprqsja1ZMjLcLUXjxcS5s/+JP2LdvH2praxEbuwvDhw1Hv35WJCUmYeSISaHvjDlpaC4bo3/sVwyAPgD6QMJUHDlyBCaTCakpwP+WrcCSJUvQt29fjBo1CqNGjUJWF/IF+3HzcsAJlEbJRZ8jFXOTmUkp28eNk93shBUo2HcuEOG0K1Lu28qYM4CeG8LKlZIiF2hPS6PnrsNB5+Z00rOlrExOdCE8BQoKSJTV1lIbQ+kLNfHoctH28+bRc7s175FI9RNnHWTaCxZaDMN4oXRHi4sDZsyQLUXhumKIGcUVK8iSpVaPRfwtCm4KX/7LLiMRtHs3iYfoaHppulxyzRiNhmakRXFPq5WOqXStKyig/TocFAdVV0cCxGCg4zc10Yz2hAkt76+vvwZWraJ9JSbS8Z5/nrJ2TZ/eNkkofK+FWraytLTQBxhWqxU//fQT9uzZjeuvvwFZ0hdYV1uLiRNMGDX6LPTvvwhROn5lhIyzHtCaAM3JN7JraTZGDTTI6Zrj+T8/fwoSEhKwadMPWLp0KV5//Q3MnXsxLr/scgwd6sBPP+k8qf1Lo2ZHdICu0wE9epCVpTkXtOZor1ggpQUrJoas2mLipa5OnmQxGulZqtfTM1MU+Y2Pp22tVjl5hVZL+0pIAE47jZ6bzZ2HUjwGSmGv5ES79EVK3DJMS+C3JsMwHsTM7IED9KKurQX27QNuvZXEVktcMTIzKSYLIEsW4P9iTUwkS5CwUrndVFfKZCJLlNNJP2VlQM+e5P5XV0eDgORkGhQYjRTrJOq1TJxI7SwrI4G1bx+92FNTaTBht9PxkpNpQPHVV+G7Ion+OniQ2qLRUJ9pNPT/77+HNuPuOziZNq352je+10ItWxkQfIDhcDhQUFCAjRs3YufOnXC7Xbj2HC0S6pIxcmIMRo7gSqBh01gGIA04uBSIjgUypwLRJ18+6UhkYzQnJWHa1GmYNnUaGpsasW3rNqSl042/du1avPXWEowcOQLp6bPQrduncJnmRHyAHooLWiCE5d9gaHvhEKzQcUoKPeeqq2m53S4XaE9OJmv91q20ndFI56nT0bNKpLUXySusVmp/fT0JN2XyilDaGIplj136mFMJFloMw3iw2eQMUY2N8iyp0i1PLRDZag1uNTEYKCYr0It13DhKsSyKhaankyjTaqkWTFOT3K7YWPL5HzkSWL+eBgSiLs7Ro7LbzPbttH50NLnRDR5M68yeDWzaRPvr108elDTn8qPmTilmsjMzKWtZbS2JRK2WxF9mZvMz22qDkzVryO2mOYK5xQRy/3S73fjttwPo2bMXtFotPvnkE2RlZeH5ewejV69eSEhIaJeaVScFkgsoXQNgHqA1Ag1HgJKVQLf5J6VlK5JEG6MxevRoz/+9evXCpEmT8MOmTSg+thIZGekYM2YXFswYiNe+mh2xAbrye6IJI7TQd3JkyBBaHkq7wk3m0VyhY2WG05QUeh6LAu0iI+GYMfQcrqiQs5F26SLvKymJnpsNDfTcNBgoaVA4/atm2QtU2qM5l762qAHY3nUFmVMTFloMw3gQqYZra0lkORw0K2q1+qcsj4sLLzA92Is1Lw8YPpxcV2JjyWKl19NAoa7OO3NVbq4cWN2zJ+3P5QIWLyaRZjLRNhYLLa+slFMi9+xJ1qvTTpO3e+ut5l1+Ap2n0gXm9NMpJqKpiQYpp58uD7qCzQirDU5qakK/ZmpuMb7tXTBjOTSaKmzbth3bt29HbW0tBt56KxITE/HR8+cgKopeBSywWonLBtiPX7yoWECTAjRV0/KoVpp/JBftR3dyuiP60i23G665+mpcffVV2Lt3L1atXIU+fWqh1wOXnPkKysstMA+4EyaTofmdBUD5PUlNDW1yA6DJmRUrvNOgA4FjkgIds7lnpihjUVAgTyIFKnQsrGjz5tEzpayMvASUMZrCldhgkNsJ0LKJE+n51dBASX1iY+m50pxlXUm4pT0CufS1RZFhLlzMtBcstBiG8aDTUUzWvn1yFrv4eHpJtqRYr+8MYrD6NtOm0YBiyxZa1r07vRQbG8lCNGYMxXft3Qt88YX3y/LwYfqpqpJnegESapJEbWhoINc6pUudbyFQNZcf3/M8fNg7Rb3SBWb6dBKAhYUkVkUbg82eqsUr5OWFcrXUUbZ3xsDlqKuT8M47H8BieRsmkwkTJpyJKVMuRu/eCcdzA/JrIGJoDUBUDP3trAeclUBMVxJHraGxhCxjTdWAMemkdUdUQwMN+vbpi759+nqWHTiwFp9//huiV30JW/KlmDJlCnr06BHWfn2/18XFtNztbt7Nd8UKYPNmmoxKSfEurhwsHb3BEHrSDCEMysvpedK9e/BCx0JMlZZS+5qayNJ/zjlytj9A3ofB4C0+YmJo/ZwcuTZXTY3/pFMoKewLCkjoifVEaY9gbtQt6aNQ4cLFTHvCb1iGYbzIzqaYLGUx38mTA7vNqdVcMZlocCAyeoUyg5iZCcyZQwJPBGPHxtL+LrmE9v/++/4zuxMnAi++SNtJEh1PxFoYjfQ7OZkGEL71cUKJFVBanAA6jihuKlLU+1rqxo8P3UVFrQ2TJzdzkYLQ0CAhV/cqEhJ/gV4/CT1PN8Ll0mPevNsxefJYRBujW77zjkRHs/B4xNDxomyOaiC2K4mi1rRPctF+G44A+hR2RwQw/w/zMWHCEaxetRpfffUeVr/1GvaP+RtmzJgR8j58Lcl6vby8OTff0lJ6RlksNPEjsqsqY0TF885XzJSV0eRVbCztU82CrhQGZjN5FuzbR88TZSFn30LHO3cC//d/JJJMJnqWazTqEze+4qO0VH52KmtzKSedwrXGNTaSe2JzCUJ8+0gk9YhUYhEuXMy0Jyy0GIbxIzubYrJsNnqxK0WX0m1Or/evuVJTA3z0EVmmHA6gV6/QZxCFq8qRI971n1JTA/v/f/EFrZeQIFuunE6a8a2upuNFRwcO6m4uVkBYnA4fpgGASFFfVuZ9TuHU32quDSK9ezg0NDRg9erVcBW9irKyUhgMv0GnOx2VltMxdOgFmD499OxwHZ6OZuHxEkOZQCMAYwqQO4+sXK3BZaPz1KcA+uM3VaTcESPJCRa+XbO74sorr8Rll7vw7ru/ISuzEnGNH+Bfy+woLj6G6dOnY+DAgdAECLzytSTX1cnLAyGeQamp9LN3Lz1v0tPpmaPm3qcUTL//TuuI+nnx8eRi7HtM32ddz560bX2992SQ0rrkcgGvvUbbabV0PocP07PFNxur2jEAuSRHQ4P/pFOoHgwrV9I5ilIdagJRictFFrBDh+jZr0zqAUQmsQgXLmbaExZaDMOootORaHrhBRIYCQnkxiJJVIPGF0kidxXx0nQ66WVZUkIvNYvF+4UP+IubYBYmtZdlejoNKITIstloMKLVyi9qgATf4cPqhYTFcQMJI2WK+qIi9RT1wURVqAHYyjaEK7IAYOP/FqDs4EGMGq3FvHlno6RkKGqqdUgye9c56tRILsBpBY4VALajkbHwREIgKMWQ7ripwmkF7FWAMbV1wkNnIjHZcPzGd0TIHTGStKPw1Wl1uOzCBKDkU/y4NQmTMqx4dH087r//O/Ts2RMXXXQxRo0aBa1PUSi1YuNA8NpRymeQcBns3x84/3zg7bf9LSZVVXLpioMHaTunk9arqaGJKqU7s9px6utJrOh0JMwmT/a3lCUlAYMGyQXKNRp6htTX07NPzdIWSHy0pvaVSKYUH08/vXrRedfX07Na7VwLC2lSzuWi9TIy5L5VE3wtgbMcMu0JCy2GOUVpTgC4XGTJqqwkV5LSUjl9+bhx9EJ0OMiK5XLJmf6amsgtRgitI0doljIpiQYjLpfspuNw+LugiALAVVWyWyIQ2MVuzRpaV7iqAFRby+mkvyWJXAjr6mi9jIzw+0qZor6sjH6HMivalgHYZWVl+Pjjj3HlFAe6deuGKVOmYMxoHVKO+zi63OHXOerQiMG8rRxoKARiu7fewhMpgaAUQ9Lxm7uhBDj0HmBMDm+/vsJPo6PtRTtjIuCOGEna27VRcfyRA2wY2bsSQ/qMxu/WSfj7m+V47LF/4Omn/4WePXv6baqWQTUYvs+g3Fz6PzFRXbSYzXLpCoeDnkkis2rfvnJh9kDHKSigbevqSMxs3UrbXHONv3VJxIcJoShJ9ByMivK3tAkrlJr4MBjkZ66SUKxCNTUU6yY8DOLjaVLKYKBJtjVrvJ+BLhe5lzsc9LfFQvsYM4bcxZtLLBIOXLiYaS9YaDHMKYgo5CvS7k6bJhcDFi8im41ejtHRtL4oEFxfTy/HSy7xdqmrqqJBgMNBAwMhbvR6uT7Ljh0kzLZvp3YMHuz/8g8mTtRE2NSp9Fl5OR1f1OoSiGQYBgO9/FtKcynqfWmrAOyioiIsW7YM3377LS4cXYW6uhnHswWme60XiTpHHQavwbwZcDuAun0kRhxVLbPwRFIgKMVQ43EftCgjFSwOZ7+BhF90Jm3fkWLSBO3t2qhy/FG9dkJjGY3XH+mJ0tIeQHZPSJKEf/zjHxg0aBCmTp2K6GiKVQy3jlagAXsg0SJKV2g0FH8kSfRcrK4OXqMqMxOYNQv48UfaLi6Ottu9m55x5eX0DFRakwYOBH75hQSdXk9WLo0msBUqHPHRnFXI5SIhFR1Nz9maGhJ5ALVV7Rlos9F6vXrROdXV0fJx4wILvtbAhYuZ9oCFFsOcYrhcwCefyLFV+/fL9aXWrJEFzuTJcn0qYR0SLnxVVXLWK+FSl5hI68XEkNWrqYm2MZuBHj0ongGgY4pZ1+ho74xdJlNwcRJIhE2eTNa3rCw5U5aIcxIv17w8b3fClhDqwMTlkuO5IhmAvW7dOjz55BOYP9GGZ+4ahWuvG3LyJLcIhu9gOr4XUH8QcDW03MITaYEgxFBDJbAXQHQWoDeGvt/mhJ9G17FisgTt7doY4PgjRxsADfDj5gzAuRyHnFNhMpnw2muv4b333sPs2bMxa9YsxLXgy6g2YA/0bBClK/bto+9/eTk9H0SNKkCuQwj4Z2kVroAAPc8cDuCzz8jlTsTANjbKFv5Vq+g5mZkJTJlCz/RgVijluYh08gCtY7d7p4JPSwPOPZc+F9uItgvXwuxs8mioqqJ3QGNj4Geg0kqWl0d9061b67KuMkxHg4UWw5xiWK00K+pykSgSs6RRUd4zj2vW0Eu8oEB+2ZvN8kvSYJCzXgH0cj92jF7mkkTrm0z0ov39d9ki5nbTD0CfiSBpUUwzkDgJJMLmzaO2ipo23bvTOTU10TFzc6k9ubmRCX5ublZUiEGLhdxooqNp8NGSAGxJkrBt21ZUVlZiypQpmDnkGE7/6wgMGDgQY8ecAo9v4UanNXgPpt2NQPJwoOscEh8tsfDoTIAhEag/BMAd2DKmFsMVKK5Lo6MkGADgsACa+NCFRySEX3tkYmxv18Zmju+pDbd5Jf55a0/8cul8fPzxx/jwww/xzTff4N///rdf/FZLUXs26HRAfj6waxc9x5Q1qlwu4J136Bmn5k6dlkZF1bdvl92i6+uBn3+mZ7fTSTFQw4fLk06XXSZb8G02YPRo/3paahNEJSU0Abd7N+3XaKTJM5uNnqvCG0C0b8gQYNs2antiIrn7JSaSmyJAz+DsbPpbLPN9BvpayfLyOHaKOfk4Bd7UDHPyEE5le7FuTEzz+3W71TP67dxJ/0dFkXCpraUZx+HDKdW6sCyNHEnxA0eP0rpuN4mz5GT632ajmASRfn3AAGp/UxMFSQ8YACxZQiIwkDgJFIwtAs7F8uxsWjc/H/jpJ9pHaqq/m0tb+Or7ugtGR9MAyWYLLwBbOu7DdN9992H37l8xaNBgzJ/YAI3JhOuuGxq5BndkfN3okobQcuVgWq8S4BIqTeWAs4F+N5UDCf38BUJjCSXeaKwAolOBLtNoebC4Lo0WgASYsgBHRejCo7WWofbMxNjero0hHH/kCODHzcCglM0Y9MeuuOuSi1BRWYku7hWora7Fho0bMeTsqUh3fYnyqHODHi7c50diIgksZY2qqipg+XI5i2kgd+rzzqNneHm5HP8kYmDF827OHDnWS6ej56gQTQDFSfnW0/I9n4ICaoPTSds7nXQsrZae07/9Rn+L9u3cScc0mUjIbdlCxzGbaX3xvAOCu1u3JnYqnHccw7QXLLQYppMQTmIFsW59PXDddWTtEUkg4uK8Z0l1Ovo/Ls575jE9nV64vXuT/3xtLb1or7mGinUqLUsAxRNUVNBMaGEhtdPtphdvXh65IO7cScsyMmhw8Pvv1LbnniMRlpxM26uJk0DB2GZz4OXCgma3y26DbZmgwlcMCtF3ySUk9kIZRNhsNvzzn3/HAw+MQEyMCe8+NQXdu3fHqJHqaapPStTc6ABKl+62t34wL/bvqCKB1VROhYaNafLnTitw+COgegcALWDdT8ui4qg9UQlA/eHA8Ve5cwGEITxaYxlq74QUQPu7NoZwfI91CwAQd/wH2P7LQRQW/g9DMBX7972HvG52GI1GlEbN9ttHS54fJhM9244cIUvT0aP0bK6rI9GUmBjYnTozk7K8VlQA775Lz8nGRprAqqmh57NvgXUhmsQzb8cOOk5qKj2XfCechKuzVkvrNTTQOg4HWbIqKujvqChaNz6eMst27Urn4nLJ5Thyc8m9MDVVjrFqTki1JHYq2DuOYToSLLQYphMQTmIF5bpiALBmDTB3ruz3L2ZJlckwAPWMfr7+8126qFuWdDq5BlZWlpzKPSWF4sCKikj0iIHGm29SfZiyMhpwREfTyxig44gixUIkBco6aLfLbfVt+2+/0b737KE23Hwz8O23kU9QIQgkBkMRWRaLBWazGSaTCd26dQMAPH/fCGih8RkgtjNK9zSgbawYgdzo3PbIDOb99q8F7DW03Gk9nt2wDKjaBmj1gMEMOOuA6t2AKRNoqgSkY4Amis47FPe+UNz6WmoZau+EFJ2cwYMG49lnnsM3vwIrVqyAPuoL3Hbbbcg4HpsqBFdLE9won10WCwml2Fh6HlosJJ6Ea7XSnVrpYpeaSsesqqJlFgutX11N3gVC8NlssmgSlh6rlSbHKivpGe1raUpMpOev203Cxe2m9phMdBwRK+ZwAL/+SpNwiYnUFlF/TBRhFl4E4jiZmS0TUsGshs294ximI8FCi2E6AeFUtleuGxtLy6qqZFGl08mzpL4vMt+ZRzX/+bg4dTERF+e9/pgx9LN2Lb2shTshQL9FHIFIvy5SH9fU0L6cTm/3RPHSFm2sqfFP3iFcWUQ9l7o6eVBTWUnFjZua/PtRiEJl4HewRBeBBgAtqdfS0NCADz/8EJ9++inuvfdejBw5Egsvz0ApJAw7A9B3pIGD0j1NezyoxO2IvKtaa9zoQhE0gfavNciWIV0cIDkAlxOQzAAkABqgqQywldC+peMmA7WixEUfkOugcHus3haaW19LLEPtnZDiJMBkigYg4Zlnn8F77yxFWloauuUCa79tQLrpM2g0GvzWODvk57Av4tlVUQG8954sokTR43796PnjcKg/N8SzBaBnm7A+CUuZEHwmEz3n9++n55+op5WYSMLryBGyeAFy2ndRYHjgQGqPXk/7b2ykbaOi6BlbV0feDQYDJU86dIjOx+0m8bV/v+hL8mr4+mua1FNa0UKhOauh2jtOJEHirIJMR4OFFsN0EIIN4MOpbK9cVwRYl5TQyz052XuWUYgSZZYr5YsqUE2rQGLC19++sJDSE9fWykkw3G56ccfF0fKaGnqha7Vywcpp02RrmtrMsckEfPyx9+dr1nh/HhdH+xbxDAkJdJz4eO9aWGYzFfQsKaH/k5PJIqfmEhSK21CoMQeSJGHt2rV4443X0dBgw4UXXohp/YtgdJZi6BnAF9uC3CztgW+K9erjQSVJgyPjquYrkFriRhdqnFKg/bvtCstQLBUbbqyg7IaaKCDhdKB27/EsgMdnDdxNcsIOAJDcADSArRgwxAP1R4CqnZR4w5Dq3VdAZCyCofZXeyTLaCnt1NaU5BTcftvtAACX24X3378TmZmZGDXyFnRPWo6kpNkhPYfVEJYpIY5SUuj/jAyq0ydSngd6bqiJNTXBN20aibfdu+Xnbc+eZLUym2l7wFswNjUBV1xBf7tcFD9WVESfWyxyIfjMTNpHURF5HYwbR+U+KirofZOZSQKsqooyLR45ItcbC8VFOxSrodo7TkyyMUxHg4UWw3QAmhvAh2MpUa4r3DqMRnoJKV9a5eXNi4ZA9baCiQkh1lwu4Lvv6IWrrE/jdlPs0nnnUUp2UV9GDEJuvple5MFmjpuz8Ol0wIwZ9KJXFs9MSfF2M8zOpgHJ0aPUHxaLXDzT9+UejttQKK4yq1atwvPPP4fx48fjgQXZSEyktF4jRwCOVqahjziSC2iqABorAV08oDUCOC40dNEAUlrnqhZIIIXjRhdunJLa/iWXt2XImALoYoDodPpJGQNYf6NzjIoFnPWA1uc16rIBiAH0yZTeXbJTZsOYHG+3vvpCoOL7yCWvaK6/2jNZRrh0kLZqtVpcccUV+O9//4vt267F+RecjyunOLBzpx6r984OK8GNwPdZnpMj19wKpfyEr1gD/AVfZiZw7bVkqXe5SJTt2EFCye0my5VvTK7wShDJNGprSQBmZFDGRJEyvl8/ekZaLGT979GDvB1EAo5Nm+SEGiL2S6MJ3UU7FO8NtXfcxInsNsh0TFhoMUw7E+oAPpzsTGLdykr6PyuLxBYgu8o1d8xA9bauvVbd+uWLzUaWI61WnnV0u2mbu+4iMfXDD2RlEungxQDCYCDxJYoP+w4kQrHwZWcDt95KYs5q9bbmiX50uYC33iIRVlpKgsztpt++L/dw3DcDYbVasWvXLowaNQoTJ05Ely5dkN/nIADfQP0OhBj0NhwFan+li2Uwk/VHGwW4GlteNBhoXiCFKtxaEqfku39fy1D86UDGZMpuKM4toR9Z89wOOv+Eft77EOt50rvX0vbOWlq/qRyIyQXKNwC2o61LXhFqvFykkmWEk+q+pXSExB7H0UCDMaPH4IyhZ+B/y/6HZcuW4fTTd+D88/+J0aOXw2gAyo3+CTOaQ+1ZHk6SjVAm3nQ6svKIRBVKtFrKyqqMa1Vur3y+pqSQW6BeT8t//ZU8BVJTZTdvcazx4ylGS5Jo/aQk+lvteRrIgyNU7w1RP3H1avr/22+BSZMil9iIYSJFpxNaL730Ep588kkcO3YM/fv3xzPPPIMzzzxTdd21a9di0qRJfsv37NmDPn36tHVTGSYkwhnAhxNULBJRADT7GB8vv7TEMYIdU9TbcjrJ/a6+nv63WuVUwsGoqaHZTKeTxIteL7sXiuxQVVW0XkIC/Y6OpmVr11Jba2poG9+BQKgWvuxs4Kqr/F/oSqubeKlrtbSv5GQ6rm/drXDcN9X4/vvv8dJLL0GSJPz3v/9Fnn4Vcvp0YIEFyIPe+iMkENxOcplz1JB4SOhJgqM1tZNCEUitibsKN66rOctQznmUoVCZ8t2rlpZPevfYHCB7Ngmr2uP5tvVJ5I7YmuQVocbLCWtkkyVyxxPHACJveeqAiT2MRiMunX8pJk+ejMrKSgzor0FVdTV++kmLDN1y1eyEzeFbKDjcJBuhTrxZrTRBNmiQXNfQ4aBneDCvBOXzNTeXssq+8w5ZukTyDKW7NiAXZz50iN45VVW0b9/nqbLWYFwceR+ImluhPttdLjp+eTn9X1wc2cRGDBMpOpXQev/993H77bfjpZdewrhx4/DKK6/g7LPPxu7du5Gbmxtwu19//RUJotoegLS0tBPRXIYJidYO4IOh1dKMYlYWiR7x0gqU0ML3mMIFpKFBFkuhIF6CMTE0G1pWRtvn5FAsgsEgW5kcDjkNfFwcBVCLwskuF82czpsnx4cJQh1oBBOnype6Tkfnp4zRCjb4CNVtyGZrwKuv/gerV6/C6NFj8OiNeYjXrwLQwUUWoBj0xgONpWTJ0miA2DwSFHmXksjQGsjCJbnCF1vNCSS1Ab4xzV8IRTquSzmoVxZOjooDul1y3EUQgQf/yvTuAFC1ldptTAPsVYC9Wk6mEUgUBhKYocbLNZUfPzcL0FAMREUDyFY/XjAxK7monlj9IWp/wxH6H2i9Vc6XDpzYo0tmF3TJ7AIAWLz4DWzevBm33HILRFbxlgguIPhkm28crZJQiqcXFFCsrMNBBegbG+VnfbDtfZ+votiyshaYmkvftGn0jDQa6Znt+zwVovLAAXL7q60lF+9bb5XFlji21Ur/K9uoTEkvJsYA+h2uhwHDnAg6ldD617/+hQULFuCPf/wjAOCZZ57B119/jX//+9947LHHAm6Xnp6OpKSkE9RKhgmPlg7gw2HuXP+XdXPHNJnoZSniBlwuOdarOcTAITubXu6VlfRivv56+cVoMtEL2OWiYO3ffyf3vfJyoHt3b8taVZV/ivRIFR1WDiiayzrYkuKab7yxGBs2bMCtt95GRYc1bZyuPZKuXGLQW3+EhJW9GjAkkzUmNpdEhmcwX61uTXEeHy1Fxam3J5hAUnMjO/wJWZTsNf7Hi2RcF0D7cdQApWtIqDRZKG5LnwDATW6ThhQgdSxgSj8uuo77aWm0lLkQoD6w1wDGDDmdvEZH+3I2+ItCyUUxXOUb1M9TafXRGaAaL+e0eoujqGjA2Qi4bYApm9osaC4mqr4QsGwB3C6KS4vOICuZhMhbnlpTT+wEsuCaBbDZbHjssccxZUo+zjjjBmRgOYDwBVegybaaGkr605Kaf0LQHD1Kz9N9+4CDB8niFOr7RSnEfGuBBXPpEyJJlOVQZh30zQgryox89RV5H4j11GKIAe+U9Ho97Qug3+npnBCD6Xh0GqFlt9vx008/4d577/VaPm3aNHz//fdBtx06dCgaGxvRr18/3H///aruhAzTnrRkAB8OWq3/LF9zx7Tb5Ze600liKDOTlvtal3zxHTjU19NLWelyKARmQQGwZQsZSk47jWLB9u2jfRw7Ri/jd98l10fhYhLposPKAUVz5xaK+6bT6cSxY8eQk5OD+fPn47aLYpGcbMPIEW1cdDjSSQSUg16NDtDoAWMyEJPl7TqmJlSaykkUCXe5hH7kdqfWnkACyc+NzE37M6aRaFGzorQ4riuWElc0WWSR01hOljxdNOCwAnYLWe7q9pPY1MVQDFZJAQmuxH5A1vkAfLwmAllp1Aow244CxV8CVb9Qevn4Xv7nqdyflARIx106lfFytjKgcgvt32Gl+l8GLZCRD1T9DBz9gvaRMfm4kAwQEyW5qC/cDvrbbiHxmTKavrS2o97nFAnLU0vriZ1AEhISsGjRIqxevRqvvvoq9u7di+eeew5bt+qR4QzPnTBQjcBgmVebw9dKZjKRZ8KcOaG5fofSxkCCLViiJZOJXNEtFnI/bGwk13GrVbZGqblSBkpJn5VFy7OyKEaL3QaZjkanEVoVFRVwuVzI8Cn9nZGRgZKSEtVtunTpgldffRXDhg1DU1MTlixZgvz8fKxduxYTJkxQ3aapqQlNTU2e/2trawEAkuSAJDkidDadC3Hep+r5nyhEXRTAO0tfa2ju2gU6pihYmZtLL674eHLx6NqVhJYIgvYNslbuV6Ror6kh3/3Jk2VXRkFGBr34a2vpBRwfT1azwkI6jiTRy7i0lFxNDh0CrrsOWLeO3BGTk+n3N9+Q1S5Qe04kx44dwwsvPA+LpQrvPzMTaXE6AGYMPUMKOZugwyV5/Q4JyQ0Uf0MDbH0yUF9G/+fOlVORtwR9BtB1vuw65xEGWsBeDzTWA1GZgC4WkPT0f5OVjl39K1k9APpbF6w9WkATC7gBeSMToE+lVOmSHmiqAWAEDFmU/VB5PCFANFrqC88gPdi5H9+/9Xeg9iCJJoMZKPzkuIhxk6gwJFEclD4NcEuUFtKtBdyN1F63E9DYgao9cGiSAVzkc+20QNo0EjT2GiA6D0idCDiO96X7eFyX7Riw7xXAXkFp47VGwFZN1sPGesBuo2yHYn9HPwfq9gKaGFrX3giY8oDkM4Hiz4CmehJHDjvgaKCsiZYdgK1cvkeOribrl+81FMdy2oCmBiBuAN1bLit90VLOpM+V55Q2WT6XVqN2P7QdLfrOAZh4Vj769BuIA/v3A5ooDBzsBAC4t38GACjTnR3SfjIy/F316utJoMTGkvWmvp6Wi2c2QM9qsQ0g/y3qaRUXy9tmZdFzu7n3i3Kfymeqbxt9n+di22++oeOmptKzu6CAUsHr9WS9slgonbzNRlpdo5HFoCSpn/vxoZjXsqYm4Jxz6N02d65DtT1Mx6Uzjy3DabNGkjrHbVlcXIzs7Gx8//33GDNmjGf53//+dyxZsgR79+4NaT+zZ8+GRqPBZ599pvr5Qw89hIcffthv+TvvvIMYUWadYRiGYRiGYZhTjoaGBsyfPx81NTVeOSDU6DQWrdTUVOh0Oj/rVVlZmZ+VKxijR4/G0qVLA36+aNEi3HHHHZ7/a2trkZOTA41mGjSa4J15skLKfSWAqdBoQsyGwHQIwr12bjfwwQc0G5mcTL/r68n3vaKCrFOa495vOh0wYgQwc6Zs3Sork61YInGGyHA1eTLtRw3ldmLd1FTg1VcpBbxWS8c1m8m9MC6O3FOSk2l2NCur/S1ab775Jr788gvcc0UWJp11FsaMacYHMQgOl4SVO4CpAwG9LkR3Q8kNFH1A1h99MqUXN2W13qIlaCyTrReGRHI5i05XX25MpbZU/ng84YNEBX9TRlJ7mirU9xXoePoEIGkgxRa5G4Gyb+VtnQ2Ao5rO2W45vjyBXPlC6QNnPXDwLQBaisOyV1KyCkjwsqRo9Mfjrkzk0uesB6DBcZMLba81wqFPx8qoxzF1gAS9U+U8Rd/Yiin7oK0YcNnp/G1F5KLnqKN4KLeDXDWTBpIlseEQHSq+D5AxiWKwtEa5ppf7eHyU7RhQt+94CvpoSiuvMwJJg4DqX6g9UbF0PkkDgKyZ3n3qez0CXXs1AlkTw9lHS9ZvJS36zqlw4LcDeOH5F2CxWHDFlVcgKSkf5VHntGhfas9F8QxVPquTkoCdO2l5jx7Ab7+Rq/cZZ1B9qYQEf+uUGr7Pf7Vna6A2ud3k/rdiBbB5M7mb19eTZ0SXLkBaGv2UlwM//0yfi7peUVHAsGHkrSCsdWrHAfyXpaXx+KSz0pnHlhpNbcjrdhqhZTAYMGzYMKxcuRLnn3++Z/nKlSsxZ86ckPezdetWdOnSJeDnRqMRRlFwSIFGo+90N0IkoTpHp3YftAfhJHwQ6yoTOghXCnHtmtufzUaCKj6e9rFvHy2rraWXqMNB7iNuN71Ev/+e4qXS0rxjCsxmirsCgMGDyRWwoIDcTsRxlG3IyPBP2OFyUdsdDvrR6eRYM2UNmPT09vXNd7vdVNh0sgvnjRiL3r17RyjZhQS9ThPGoE8HZE2SY7Ri04HMSUBUCzvGt0ZTeQHQeDyOp7GQ/u82H4jNAPIuJHFiMJN7IUBtcdUcj9HSUCr49JGA1hV4X8pkEGIdbTRQ8RNQ+iVgNFOsV9fZlF5ecgG/vwUY4qk4MIxAQxmdu8F4vI5VBSj7X5z6+ekNQHQ8YC0EXJW0rtZOwkb0a1QMxWlJABJ7kXCp3HK8YLGBBI5GS+6FGnI919sOQl+90f88s8+lNum0QP0+wHaEXA+NsYDbejwboQTABRJxdqBhP4lJCfRZ9WbqR4MJaCwGNCmAsxIwpgPOKiA6EXAkkuBy24GoBGpzw2+Aowxw1QMuC7W9TgvozgG6zw0cExWbEfxzQaAYQXE9bYeBqHg6nzKHnLVS7d5r7h5pE8L9zvnTt1dPPP3UP/Haa6/hpReeR69eFoy9+GwYmgv+VEHtuShQPqt1OtnV+tAhejbr9eRu7XSGF9cl9mk00u+KCu/YqYICOXZKPNfFs7+8nJZlZlICo/JyOm5ODrWnqopcwW02apcgKkp2HRQTeRkZwIUX0jZmsxw7O3eud6INUYMx3PFJpJIpMa2js44tw2lvpxFaAHDHHXfg8ssvx/DhwzFmzBi8+uqrKCoqwg033ACArFFHjx7FW2+9BYCyEubl5aF///6w2+1YunQpli1bhmXLlrXnaTBMSIST8EGse+wYZYMSKXWnTSMRFOr+RBKLw4fJt95qpRejqIXlcFAQsiTRiyo5mbJGHTkiFwZOSaGXohB5Wi29KKur6SX8/fehnZNI4TtsGJ1XfT29kMeNo4QYbZk8JFRWr16NgoIC/OehUdBnZWFOe6drj1QSAd8Bc+rYwLWNnFb1wXV0JnD6tfR5YxlQsZESMETFkEUrWLY6T5IKM2A9SPuQXGS9qt5O+8i7lNb1SjKhLA5sAOzl1A6tzyDX9/yShtDN2lhOMUlQTv27AFcTfQGMyYB1P32ujaJ2aKMBt7B26eGxcFVsAFwqfQaQhaZiIx3L2UDL6n6lQsZNVSRGJDuJZI2W2uWykfVKOj7zULEJMA+hPnI3USIKZWKLmBzaRnJTG+11QFPl8eMJK5yO+qz4K+C0q4InEfFNMuIrxEWWQ7V07y4bWQsbjgGOvdSnthIgbRwQ18P/WB2wllY4RBujcfNNN2P48OH4+usq6EOti6FCoOQ7yoRDZjPdnmICDCCRlJYWXsrz5kqNqKWht1jo2V9WRsscDnp/DBhAE3RaLZ2D2NfEicCePfQecbvp86ws8oxQPscDva/Ky4FPPqGajgBN5F19dXh9KtLeV1SQ58S0aVzomGk7OpXQmjdvHiorK/G3v/0Nx44dw4ABA/DFF1+gW7duACgIvaioyLO+3W7HXXfdhaNHj8JkMqF///5YsWIFzjmnZWZ8hjlRhFPA0m4HPv+c3D2qqujH4ZBrWc2bRy80sT+zWZ6JvPRS9VpRK1ZQunWtVq6lpdHQLKfdToJHoyERFh9P61mt9KItK6Nj2O2U5WrbNjp+377A+vXUTt9zUmapSkwkMZWTI7/0e/Sgdbp1o8Qaoq3tVS9FkiS88847qN/3LC4aMxSjRmlabDiKOGpZ98JJ+e4pUnyYLCH1hwFpA4kD3wxzWkPgrIMandyWys/kAXhjWfM1pHQmOp71N0pGIblomT6RMus1VsiDbr9U4FOA2r1kzbHXkIA6+BaQdTa5HqqldAeoNlbSYGDPU+S2F5Vw3D3QRW6D+jgAGhIukKgdUbHkjtdYSmnUEQ1Emcny5KynTIa2YsCVRJam2O7U5rRxZBGTao73k5bcBWuPixBnDQAtpWTXGgFnHVnN3E3UBkhkBXPUUUHkrnPk9PnK/kgcQALOUadwd3TL/exuAqLSSCS1tliyq4GyNcZ29xdHWgOJvKbS433oAlADlK0nQeibebG5WlqRLGHQhowaOQoaDVCq0WDz5h+RnJyCHj1UhGUL8M0COHgwPWf37qVbPiOD3gXh1GRsLrOgmhBLT6dnc3k5Tc7pdNSOpiZg6FBaz+GQ95WZCSxaRO+Yykp6F8ycKdfQAuT33+HD5PZ4+DD9P28evbe2b6d9ajSyy2RtrXca+UC4XCTUtm+n99b+/fSeuvZatmwxbUOnEloAcNNNN+Gmm25S/Wzx4sVe/y9cuBALFy48Aa1imMgSrIClUlyUlJBP/caNcvamhAR60SUkkC+7cn/R0SSy6uroxThuHIkYJSLt+5499LKUJErBGxdHNbHi4+mF+8svNHtaVUX7U6YktljkdrpcJMJ27yahpqyRVV1NnwkRGB1N57JlC9V7ES/q6moSWJGuL9YSHA4HNn9yPer37cTkyZNx++1joUEbp20HWj64DDflu7A+NFYAKIOn5lPuRUDF97KgyZhM7oJNFnXLg8503KLi8rdOBKshBVBqeKeV2uCok0Wb8/jf0anyoFtY8URK9oofKKZL+n/2/jxOruo8E8efu9XeVb13S62lhZAQAoMAYQMCYwsjMEvASwxmsZ3FicfjOIknk0zizEycOJP5TjbHdpz8YjtOwMY4NrYxNmaxwRA2g9hBSCAhtXrfqrqqa7/b74/nnL63q6u6qzdJQL2fT3+6u+rec89dqs55zvO8z+tycp8fBKZeAqZeBrb/AcGaZMu0AIAW/u+UgVgv5Y9WniDJKQMIAV0X8+/Uc0KCaIOAR2UxZ8fk8e0ioAnJoRrk9UkfYF6ZFvLqjkV7gZYzgPHHCOjKU2Sw3DKAAKC6BFblIq3ZXQcey+YCapjHNRIEk/LaWVla32+8gX8f/S7318KivxWhKDzPYGv9tuzzFUt2TOaGaWHPZl4+B4EEUBCgTAnxeuQHgMO38nr7n835ammtdAmDYxCd5o/w/e8/joMHD+IP//APce65K0N9V5boAPj9/uij/O5fbE1G2+Z383XXVa8nWA2IvetdwJe/zO98adPe2cmaWNJGvlJ50NMD/MZv1FYkFApckJuY4MKdZMVSKYIu6UCo6+wnANx6K4+3UKkPORbZNtUY09P8P5tdmu19IxqxULzhgFYjGvFWiIUkHICnl3/lFf5fLnvyvp4eDrQnneS1l0gQxMjcJ13ngNzbO3egs20vwVkWLO7u5mtHj3JwkoPd1BRt4OUAd9117PePfkRg9frrbEfTCNxkjSy52irbkEybbXNg7RN5/1ddNbfo5fGKLusuvPraq9i/fz/+8A/fjYsu3HVsDrzUyeV8BXlrgjWNUrXSJCfH5hRZi9Ba5hcBnMSPPiCAzADrSWGdxzyYaWDgB+xvIMH9zUnuW55gwduNNwCwPeAogaQaYP2tqRcBKJyQS2MFBUB8Gxmhyph4TLBmLUB6H9kw1xYrEDpQHKZ0cf0HAFXzAAJcslKSNUtsB5JPU97oWNy2NAnkj1KSaGVZtNk1+b+Zo5xQCxNImVnAENc+exBkkAQTNn2Q8rreG8mwZV7jcVSNtvEAr4mrYsZowy0D0Cn/gwvKFg3BdKVp/e6/3vL50GOiqLDN/qvyftO0A06JTF14HdBxcf3gfb5iyU1bgdzhuQBaC5O5yg8QjEERLJ5w1wm0z302q8lgl/Q8H99gvqaCf/6fO/HDHw7g85//PH77t38LV1xx5Yq0X8nsb97M7/TFyqqrSfVkXpa/rY4O4FfE10AsRoASj3s5Yq2tnnxcHrua8mA+RUIgQOAmwdvUFHO8olGOa5LNKpW88SkcXnytsUY04lhEA2g1ohEnYNRTHFImLqsqB790msyTrlN3vmED9fAydu0iU6SqZKW6urhPNf1+OEynKNueXUPr4ouBf/xHr45WqcQBev167icH62SSeVWGQVkGwAGzs5NgKp/3zikW48AumTbX5TGjUfZ3YoLnt9yixMuNpsx3gEgEN924FZdd9pvoaO84NgdezuRysbkuxRFg8CdiAiyOHWxlLlLfbZxAS6e/4jDZplKSsx49MjdPyGjzwE+4h3k5koEZ+J4HCPxAUg/TGc+1Ra6SxUn5qf+dzJDM9fIDTnmeaog5XbmjAqCogKsAsAAlCKSe5/FzRzzTCUUBpvYBB78GhDrojDj9Go8bbmHbmVdYY0pPUCJnTRPsODaQeRmAQoAW6gSKWSAHuhe6rudUKCV7UvYY7gG2fRoYuBMY/U8AGsiU2UJap4BDtABgepQMmSrywQJxgqxaBYd73sdjuTbzyewCAafRBjgikcc1CSpzR4FNN9HdcKGYJetr8c5L5uu1nMPC1FLKCPD3mj18bjL7CDqbtpABNFpqP5uVMli7ABQnyYjpYQBtb5jcrQt3BaBrH0Bz88/xy19+Dj8olWcZe61kLFZWXUuqLhUKEnzt2EEpuFQs7NxJCd7oKMHPpk38vXZt/XLFalEusx+myUU6Cd5yOf4uFDgGWZbnbtvUxPOQKglNmw00/YBx+3b2u1jk+9u3Hz8ZeiPe/NEAWo1oxAkalbKQyhU6WZDytdc4IAUClN6ddx7w/vdzsHnoITJM3/oWJR47d5Ip6uiYX79fCfTWr/dA0dq13G9gwHOP6usjuwYwybmtzXOX0jSCv64uDmw7d7JIsZ+huvRS7j8+zm07O3leAAfSo0ep6b/5Zs996lhFl3UX+vv78ZXvfAef+MTZAHYfO5AFLM8YYKFcF39IQFccoyytlOQEPdBKw4TCIF3tcn1kvBSNrIgR5wRbiwDrPgigilTQKQFrryLr4lqcXEtAsOG62UCyIACcFpIdE5gjCgz/wgNu2SPA0L2c1Gth9mPiMTImrgkCFxeAxV+26IdmkOmBwvMpjTCPyikzRyq5F7BKPB/VYFt2HohtIjgrT9K1T9GBcCeLGVs53g8zx7YAIP2al4PlOiKXyaVk0hVgKtwDbLieQK846uWtAeyfHiEYAQS4C1KiBxsId/PaOWXf9Y4SYOYHgSPfFIBZ47ULttJG3rXIGkpTDKfEa374VuDMz881Dql8RuyCB+5KSSB+Ks1Cpl4S17RNuDlW6LBC3XSLHNJFf5sBteAxnfM9mzKmD5GJtHLcLrwGaD6t9j4nWC7XeedpOO+8Pfinf27D5s1ZlOQbjq+f6rHv50ImFxJ8vfQSVQrZLIHOI49wbNi0iUqFgQHgjDMI0JbDKIXDHP9KJQK86Wku/LW0cPyxbWDLFvZNRi5H5UdLC3DnneyfZOaA2Wzdrl2UDfrNMBoMWCNWKxpAqxGNOIFjvpVJTeMAkc97DkzbtwPvfS/3+dGPCFAA4MkngZdfJnBTlNosmT+qAT3pNHjgANsulciQ6bq3gigH654e7nvJJayb4s8ZqNTCd3fTmGPXLsoZJybYT1Vlcnc2S8YLYOL0sWC2uqy7AAD79u3Dj370p9i6dSt27ty5+geujMWApcqYL9fFH06Z7ZeSzFGSOU52gYCjMMjJrZUnOHFHCb70JrJMrs0cqL7bgLWXV++vqglGrN0HGJPecWeAmQMYw2KSXCSgiW8XEr4psla5I2R3Mq9y/2Ab+1NOC5AFgkTHAqVtwiVQDXlMi1tmnS1HABkzw+tgakBwDQHYDKOiEmDGt4h9XCDcCiROJYgqT5LNMrNAaYzSwUACKGX4vhbiNW3azGv6+i0eIxfsYLuFIczkfUlrd8eivE+PiDyvKKWcoU6eq5yc6xH2bzpLMAiXUr0ZwGzw+EgDRZG4CZegyi7xGuf7eT2bT6/+LBVHCGyLIwRNLTsISgtjwPQrgjELAMlneQ4nf3z2c+baApyNC1OUIY/pLKdrP5v+Z/TIbULOGSDYLY4CHZ+svk89cttZzokLFJlawfgvnzgHAPDQw/+Be++5C6dufSeag0Wvn+FjS93XMrmQLrKxGFmmI0e4gGaa3GdsjN/rp5zCseH11zm2PPDA8hQIIyNsR5psbN/O9gIB/va7Dm7Zwt+lEsecfN5b7BsYmL0AKOXprgtcf331PLRGNGKlowG0GtGIN3B0d9MtKZvl/5IlymY5WEozjHCY4GXvXrJC9Q4wlUBP07ha+cILHNhkscmxMba3bh2TmAEvr+zUU/mzUM6Apnn5Bek08H//L9u1LE/eKKWJfg3+atZDmZq6D3fc8WVcfPE78buf/t1l2TQvOeoFS5UhJ5HSHKHWyv7Ui8Dhb3KC7gh5mZS6JU4V8j2HTEhpkoyXlPSVxgRTI0wVZJHZGcbD1189NhuAFQcBq0jpXGGQIMLt5gS86RQCAzPFAr9r9nB/aYvuWJ7le3Gc9ZkAMQEvE1DZJZ6DGuE1gENmqpwm8DFLYhsRThmARXZBMmKuS8YquokTd3Oa8kEotGYvjrMOlipznXYBmcNsT0+wppZVBE79A06eh35c3f587RXA5FNkl2ZytRQyWIE2ILZOyBltXvP8UV6XI98CoBJ85fvZXyPB3C0ry+uIA2TaVIMsEjS2AVeATJE/pgVpzhHfymdE5ss5Zf4+8i1g8hmR96ayv+E1BDtmhv3QHB43vY+/Javl2mQRK41TnBIdE2Ue13zPdDlFhi7QQoZOOilqwerP/kJy20og1rEHwDFkqgH0bhzB4dcPo7/vdXzsqtOQz2/y+nkMma1qUnV/XUSA38mRiCcbl2Arm+U2zz8vKiAEyUABS8uVGhwEvvhFjh9SQh6JeGVKOjq8/zs6PDv7D3+Yv2+5ZTYzNzHB3/UYQTWiEasRDaDViEa8wUPT5jJE6TQHv/Fx/l8qcZtsliBrOXr0RIIywKmp2cnIzc3AhRd6dbIqGbN6j6lpXLlsa2P74+Mc0GMxHtvvvriYWmOLDcdx8OCDD+K9770c/+W//JfVdxacb3V9sfWx/JPIQIIAINpbnck6/E1OlvUmMjOAN3m1C5RryW1t6YynUjKWO0IWJ9xNkwoXQhaWmN1f2VbHxeyXOU0AoqgECKUk4A4DmQNi8hwCWs4C1r9vdr87dpFFAQgI9Ti3l9jEiIIGEoJFsksEK3YBzH1ymG+lRwG4BEtuGZ62EPy7PEHAFWgGoieR3dKCBJJ2mZNgMwVMTZKVadrqyQ/1JjZX6GcBZFUHxh4k01dOV5eAxk4C2s9nbSwnwz4oAe5rTQPZ18lQldMEdq5DYDf1ItuJb+c9CcSYI5V6zmP3gu3sn1OiW2HYBSaSgtWbeRDY5tiDZOyMOIFNOU22MNACJJ8B3JJnpFEc5r2RBh0A76djCZfEymcxSTdLPQSgx2M6/blc80Wghc9VcZT/W1maqgRa5m67kNy2GhAbfQDAdQv3YwVjY08HvvB7Cv7oK3vxrXsD+OgVCjKlmAC5xzZpqJqCQYKv4WHm6crv30yGyoZEgt//0sSotZXf2dPTBEpSmrcY18N77uF+0SjbUhTK3GXelW1zfOvq4hgQFF9VUlFRycz19HD94YknvLHKcWobQTWiESsdDaDViEa8yULWz4pEuIoHeFr31tblJSkD3L+zEzh0yDueYRBY9fYuzfGq2jHWriWbBXBwDwY5wK9fz/cXU2tssWHbNlRVxZ/92Z/BMIzVB1n1rK5Xq48FzM1D8U8i1RAZoOReoHUnmSG/fEqyBEacwEQ1OElOnA5ApSTMKfE1uwRAyLZUhWCpZQeQfoX5Py44eZa1qoDZRhf5YTJiwRYyK4FmysjsIrcrDIJytiCPlXqWbM6Gdm8yHu3leWQOAOWMqMukCbamidbrSp5AqjgB1qSawoxTn2zHkblKBqBEAVtQwlJmCJ3nqMd4/laRQMvMcVtHJQApjdGUQYsQMOb6gPAWoAwB7lT2Kf2Sx8gVBgE4wuZ9I+9bcUQA2QJm0I9bZsFlNcbzyPURUJXGgWCCxh35I9xej7DtcprX2IiJe2kRjHRfCoz9gm0YzSK/rIe/C8IJUBpwJJ8jYILL1yxhcmEVRL9KHpCy0mxDVUXFXIvXt3m7sHhPzy5irId4LZ1C/cysDDVAw47DIvcs1MX//TllfufK+eS21YBYOY1jHloYXd1r8Oe/dir+x//vUfzkP/fi/Zf+JlT3ZxjFtce+OxUKBukie+ut/C5ub+dtlmZGoRDHFpm7Zdt8LZnkI3H77Rxz6l0AKxQ8m3Vp7JQWxpQy7yqR4HgzKdaEJHtWCQ79i325HPD00/UZQTWiESsdDaDViEa8yUImNkvgA3Dw27hxZepQ+XPDpHOTNL4YH+eAutzByz9g6jrbb2tjQrQ8h2y2vlpji40DBw7g7//+7/H1z52HYKBteSdSTyxndb1aHooeI3ugxdiWaxMY5Prmyqf8LIErJtaKcLUrCc1NZANla06Jrweltfk0UE4yp0ePCLamhZPyg19nravuS3guuQEChFKSk3rH5N9mWoAZkScl5XJwCTyST/EYgWYyQuEeoOOdgl0xBSBQhOthlOAHLlAYBSBytaBixvQBMSEbnCYzFerkOZu6MIewCRwUAIFO1tXqfg+vm6LTJEOyfo5NhsjMAukX+VuP0d7cAI8TaKMFul0kAFp/DTB8P533AEoap15i7lFxFF69LH9R4TzraQEA9vF+BQTjZE6xH1Mv8RrAAab3E0ytvZxMmJUFhu5mTlNpnM6PWkCAOog8NhAsGjEaY8h7AZDhip7Ea+0KYxE4vN7RkzwZol3gs9O8Hei4CDj6HUorZxUx7iHI2ng9mbbFGlQ0vw048y947oGW2SCr8rPQvIOv++u+yQUJWRA718dzMVNAqJdukccyhCx4A4A/+40Ajk66OG/Pdjz5ojaTIzqqX73q3ZhPfi0d/lpb+b26bh1f+9VfBX72M4KqpiaOA8UiJYUAF/qCQbJd994LXHvt/CU6bJs/LS1sE+Bx29o4Bsi8K5lrJUuYrF3LbVVBqtbKLa7HCGo1ZeiNeOtGA2g1ohFvsvDLJ+Qq4jnnMPl3KY591Qaf7m7g13+devjhYQ5eyeTKOgP6B8xAYG5eWT21xhYbR4/24XOf+xzWrVuHWFPTss+hrljq6nqtPJSOiynRKo0LuViQ4CjYMdetsJIlCPcA0XWcfEc3ErhMvUh2RAsKICANGxSCsLWXsW0ry3ZSL3DSP/2aZ8xgNHnyRLsAFC3P9c7KCAc6kQ/klAgeFJeALD/AnJ/MqwQPgz/h+bk2jTn0ENtyLIIhaKIulWBleKLiWFlh3uFwm4Bg1wqDBASukBc6AW5bGAYG72IRXtcVjJgqGL6C16aVFbXCUoCtiTpaJiWIRoz9CrYRiKpBOjmGugkYjtxK0KnHCF79sjuAx4DD83JMoPlkbpt6mnltRkjkSDmUF0qjjKF7yFQacTr1ORYAXZh5mLzeAcFkurZgEouYqfulaMJxsQRYQiLpFATANICmk4AN7ycgH3uEvwMJoOs9wOjPCeiMOGCbc4sYB1o80OPa1YGT/zn3M7ZqgGzWQp8FwHNlNNNezqAEYVZegP9xMoVdu4FUjc/ZajoXClnw1nUFbJ05xpM455xz8PTTBFzLAVsLgQd/SY5YDLj8coIY+d599xEsmSYL1heL/J6VNa3a2z2ZdzJJgKUoXk5UMklDo8OHWddxz57Z7JaUHsoiy4bBBTUJ7N75TsoJ/QtqpRKda6VcsDKq5Rbv2TN/uZTVlKE34q0dDaDViEa8ycLPBslE4csuWxr4mW/wKZc5gHeJOc/EhOdyuFLOgP4Bs7L/tWQiANmuxa5Kjo6O4n/9r/+N6y6cxs0370TgWPnIV3MVrGd1vWoeSpITTj0EOAkCBbdEG3I5ya10K6xkCaQRghYm+MjsB6BwQuhYnIwHEgQLik9SmTsCjD8qmA2NP+mXgdZzyGw4ZU5qXYdgJdQtrNGFjCy6Hpg+TAZL18mwaCIfSI9y39f/Xeyv8bxKY4ArJu2BhDBJeBWASnDjCrZGVQFXFUBK/DZEPbD8kJAXCuMMp0iAYWbYT7soQJzK44S62AcrC7gKcaeiCOBoAZAzvABm6nc1beK+r/0Tr6e0bQ+0AeVpnitsgpmyz7O6MqwCj9O9h/liWojXsDhBJivUKYopi/vhFAgiJZM4AzxdAkctCsS2ALnXxcsG+yLvkSOutdEKGBnAtAEjwue1aTOfkYnHhINgG+WTr36Zz5JTJsBWdF4HWcS4eQfZrtIU5ZG5Ac8OvrKWV72FumvlZDll9nHgBx4Iy/UDqZd43aQUU4+QYauMpRYKX2z4ZMFH+4/iL//yL7Fnzx588pOfxFNPLV22vBB4kPLrgwe9IvSvvgp8+tPc7v77ySBJ+/bDh8kM+esfHjzI/WRNx82b+ZqUE8p6Vy++yLbyeRo4aZoH5Pbu9YBcNkug9+EPewWTIxHPyl0uqEl2zBWP8kIxX7mU5crQG0xYI+aLBtBqRCPehOEfVADmVFWL+QaIhQYfySj193OQTSa5Cjk2xu2uu666u+FKDkqVg+f4OHDbbYtflXQcB3/5l3+JK3cM44YbPoaL37nMRLbFRDVXwY4aq+v+qAbQgp3CJKAHiJ3MSaWUgs2XE1PJEkjGK9pL57rkc14muRHhZD7YwUl8/w/Zl8knKU+DIgBNGSiaBFmlcTIejtAVyZlRuIdAasOvEiQpAQJCxQAG7wTGH+frrkVQUBgWhZQdQNbIsrLCOn0rmbtAs7Cpb+UxFQUIrWU7M6BJo129OcV2HBNkwmSOlsXzsPOiVlgr34v0gqYa4r7ljohcqjRmmWkA/L/jQmDDh4Dhn/JeFEfZnikMI0qTQoZZ8HZVo5z4WwXA8eeOCZfAwjDQ/z2yRHAJzvQwgYo5La5hWtTHShEswaq44QqBamHIy9ELdfGaWdNA9iBBJBw+A8Vh5sS5LoAsYEeA1vN8AKeFLFc5I0BdjtdUAvbwGuCkjxEEHf0On1m9meYfrsljF0fJiJ75F3weF1Ooe74SCJUgzCmzQHN0vbC8Vz2rfES8NpdTKHwZsWH9BnzqU5/CF7/4JcSb4jhl281Laqce8FAo8Ht7eppMlawtdc89wAc/OFuaHQ4TJF1zjWe+tHs3AVU6zbURwwBeeYUflWKRfXAcsc7hEpDt20cwFYuxP319nmxwdNRzndU0fp/ffz/7NDXF16QjovzOl5LBeqJWuZRqdcTqlaE3mLBGLBQNoNWIRrxJQ9Mo76i12rfQACEHn5YWskktLbMHH8ko/fjHlH60tADbtnHf4WEmUOfzs9tejUFJDp7LWZVc4/wEf/17p+DCC89Ad9dxyI6udBWcJXurEVUB2ruAkfs4kTSnOYkOtgE9V9PZbrETxOIIzS5kXpJqAEociMU9h7/MPsrvHBMCBfn67lBKCBcz9a0UMeyUk5xcB1qYt2RmfLWlWoHOiykXLAkXPC3sOe75r41jU95WTgkpXROBWngNAUvbOwjCBr5HsKPHCRCLAyC4CmGmdpUrQYniATNYANJkPJw85XmuC+T7COKKE6I7vnMGyAh1XUIQVBgmA1WaEDlgQppnTtNZ0LV4HqEu9tVMMf8r+UtfLTCbv7WgYAgtHqswRGDScqZn3hHuIliS28wJV9wrjUyTXSAAyR8FmrYAbefzGIG45zxpCIdHKLwuA3fyftkFmn1A4T1QNMwYikiDjWCrlxdWHCcwkzlfUMnMQeHzWk7xOiymUPd8JRAqQZiVrgClk9WZ3uUUCl9mXPqeSzE9ncU3vvENvOc9J+OkixYvHawHPEg310yGIMs0PXdaYLY0W+Y1+YFHIjG7gP3RowRW0g3QND2QJQGR48zun7Rol4BvfJxgKxCY/X1u2/x98cU0e5JjyJ49nvX7YsK/4LdUGfpqGjI14s0TDaDViEa8BaOeASIc5grl889zkLRt1sMql/m33M4wOCgWixwwZfK0dKmSbV933eoOSktZlewo/RBPPfUUOs49Fx/8wIbld2I5MctVsA4tDDAboMk8lKKoswSXDIUeBiafINBaTLg2MHg32SjVIDhwHE6EU8+SOdIjnMybGcEISJmTBBs64Aq2Bjr75DqcdDs2GZDiKF9v2srJcP/3CRysLBDp4Q/AHKJ8P1/3MzQKyPSYGSBYAJpOZr6NkZidVzMzEU+Kmlli5ueWvbwrCWr0mGDExjlLDHVQlhdZS+nb+KMETWaO5zHDZvlDoeOjcj6Zq/KUJz/UogQupQmCFzUM6AEBZGxxXADBLjJvjmDitABBitnHa2YXPTBhF9jHddfQ6GPkQVQHWSK0CGWdqWcIkhWD13b6deDkPcDEI7w/+aMij6vMe1ieEOziUQIsyWIqBtu185hh4LQQgWSwQzgQ/oztwxbulBafs8Iw2wiv9ezaF1uou1YJhEoQFt0A9OwApp6rAGUVixvLKRS+AvH+970P2ew0nnrqIDZeYENb5JfkfODBDzIuv5yywIkJAqemJi8/yi/N7ukBLrhg7jFaW3mM9nayU7rORbdNm5ibJUuAKAq/57dv536FAo83OOi5ACoKsGEDj1suz/0+z2bZn7Exbwx54AGOLdWilnqi2oJfNRn6QkqM5TBhjXjrRANoNaIRKxRvJJ32YgcIy+Kq55NP0tZ9+3bg6qs5yA0NUZcvNfxnnMHzb2mZ3XYqtbqD0lJWJR959FH853/+La648u8AbF5+J45HyIm2zEPRmwCoXIVvOYsStKWsxOeOAKnnxSQczDVyTU6cjSbPsEMNEERoIcrO/AYUs2o1wXtPb2KfjRhQzHPCXRzlhHz8ccwANkUheDj5t1g3KnsImM7M7qdbZm6RmSMY69rtWcz7i+7Kws2lCaDv2wQjZpIAy3XIyulRoDBGACNz0eLbgc0fB2CzraPfIeMUP5UFfBUImV0FONYCzF9KPi1ywqJiOV/1+iRdE50y4LgCtKaBplNZuyvQTnayPAGEEgRd2dfJrEmXRNfmPupW3hNF8ySRcx8WkQ+m8H7ZRV4j1yXLJ2359/0VwXWgxbN2VxSPgXKKQEHIA2HR4VKPCet7AWIVh+0FWsjsDdwpnieXbZoZgmGnLOqPRYHeGzxDjFkAKUlZbNfu+VnZWiUQqoGwxPbZ/9vu3LaWUih8BePmm2/GySfb0N27MYrFsVq1cljHx5kXJWtc7dnDnKx77iGQkXbsmuZJs6VZxd13z1Yi+I+RTPK1bJZKhlwO2LGDC3EHD/IR274duOgi4DvfYZ8Mg+NEJkOAl0h4aZ/Vvs87O9m+fwxJ1/ANqqWemG+RsVYOV622VsOQqRFvvmgArUY0YgXijabTrlXYUWrlNY0DjmkSOB06xMHQsjxbd13nYFqp4X//++k+WDn4tLSs7qBUa2JRC/S+8sorePQ//xMf+tCHsPmkNyjIkjFL5hQV0qg0f6zpxa/EuzZZGwiHOackZHQKWZb4qZQUmtPe5NbMEOi4Yv8Ze3Wd7UjnvGAr0HYukB8ESilhKmFxhlWe9CbqjjieXQSGfgps/a/AmstFblJFKCBoKyfJ6nXt5u/8MIGVkWBOzpo9BFyBViA4IQoPT/km6A5t6ctJAsq2d9BVURfXzsp611kLAJoOWAag2D6zCcGUWQUAeZ4zhDRQC5INaj6V27k2+2eXeGwlzO1zfbxvxUkWg45tJGApjlHG5+rCWVFKAB0g+xoLOqsBMmlaWLBLktUSwDfU4RleFEYon3NLgrESF9OepvOivPewAFd8kByT90g1vHtsFwS7WaZkUxN2/06e/R68kzl8jkWApwV4zm07+H5pgqCzqeJzGOrmvRy6h9d+9IGlG1JUgrBaoKzy+IspFL7CoUDBBefruOP7/XjyyY/hfddei/HgtXXvX5nDCgBf/aqnUnjtNc+c4mMfq71Q+Nhjnr16pRJBHiObBb71LZpeKAqBVSxGd1qZKxwOE2RJkDM5SemhrnuyRX/7ld/nu3dzcc8/hsgSJv6YD0wttMhYuei3kPpjMWNOI96a0QBajWjEMmO1dNqryZBVDhAtLRxwb7nFA4odHfz7yBECKttmX2QxyXSa70s3KKnhTySqDz6BQH2D0nLOez5nKX/kcjn87d/+Ld7/jrW4/vrrF3eQEzEqZU6BJlGwVki02n2an3rsqu0CJ8pNWwH1qCioK0CI0cSCwWaak2SnyMm3HgbKJYIPXYACuHzdKXFCbzSxGHLnJcC+z4scpQD3t/KikHGrkBMCM6zM9GuUnGVfB4GLyP2RIMJoozRSNch+DN0jJJSDbEsN8NpYeWDd1R5ggkLWz3WBqRcIghSLErbIOmD9tQRpVa9zC/dTdO5nZX0W8+I6uw6Akre/YwJKgXlhRhNlmOU0oJQBLc5+pvcRtChgW9L9UAnwWredSwA1+ZSQ+03zPNQggZYjzDkS22nNb+UIGsNrOQOOrBdg9zxg4C4C0NTzQgIogRsIfq2cAFUBkeypAijzuZnJyRNhZkQts3YeK/UszynQBkw9S+CpGmzPddknM81r4RSrLwa4trBlH1sZQ4qlWLXXA8hWObZvz+KWW27Bfz7Sjosv1hZl9+43gEinaUYhnfympz1zikRi6UYRmoaZelVnnklr92KRY4qUCALVax9OTnKbyUmybarqLfRV+z6vBr4W0+fFslALnX+9Y04j3rrRAFqNaMQyYzV02seCIfOvRN55Z/UVy0svpcxkfJwyD00js6XrBGKXXOIlJvuBU63BZ6FBaSXOu5azlD8efvhhTE9P433vuxaa+iYYGStlTjJPyS6yxtHRHxAgtJ4LpF9Y2K5aDXCyn+sT7RuA5niGCY5FZiRxKifj068KBqMESuFMTrZhk8kJdrJPisZtRu/HTA6PY3Li23Qy87Gyr4scJTGRd2wyX8N3EyiFOgn8/NK48hhlenqM9uBWlscqjQijCZdW5+l9PL60rHdtAgA9KsDemLBIj9MSfyHThZYdBCi5Pm7btBkInQRMwGesAdFXneerN7EPHZfzmMVRINhCiaKZJkBRNObABTvZ71Anr3OwE1jzHjaZPcLcr1An242fShBlZkGG66DIhSuxrZYzWUBanpMWBsIdtFcPdQC5IshQyeuq8R5oEY9dVFSRz6YIEw/xv5Eg0Ou9Cci9RsMLLchCxXpYgNGg70K6QHyb6G/Gk+UBvHczcr4lGFLUAlMzVu2iZpksgL0Sscq1tk7ddio+fP2H8e3b/w5XXtExU/phucWM67FFrxeY+LcLhSglNwzghz8ELryQzFO1ttauBV5+mdLDeNyTFNaqrlE5hkizjXr7vNiyIPWcfz1jTiPeutEAWo1oxDJjpXXatRiyWnbpi23bD3LkTzrNY0WjPEYy6a0o3ngjsGsXcO+9TG4GqLWXhSerAaf5WKlag9KxdHB673vfi507d6K5+YmVbfh4RqXMCQAOfpU5QrYo6Dv2MO26w+vIDgzfR/MELezVHCqNiwnpuABVDokLu8gJpRYDXMHeyMK9atAzQ3DyQLlItqt1JyfYBWF4UU7SUc6Uzm95zNiWW9MEgmqAwKo4CjJWNif86f0EC4EWYPwRYYohDQykMYTiMRDpx4RRBdhPq8A6WZnXeB5qiIxS8inmQsW3ETC5DhA9ycvHqZxEBzuAnl9hu3KybwmbNi0MHLmDfxsxcX6iADBEbpJrExhFe4FNN3PbwgjP0TEJPowmgr/p18gCGc1sw5wmW7f2ckop+78LTB8BkGce16tfJgArT/K+BeKiXtSpwMbref0HfzS7cC/A61ZKCnYMPJaqsy/rrgUO/ovHbCmaeBZEASNZxLl5O9B+Ln+sLHOyCoMiB8zmdmqI+XyquE+KAvRcwWtRGgf6bvP61rVbmJIk2A5AQwqZf+fac+/PzLM7NXshQVq1Tx9k3TIzQ0fLbZ9ePtg6RrW2fvVDv4rnnn8Of/O3f4MvfvGL2Lcvhi7rLgD1A65YjN/dzz9PxknX+f98IKFeeZzcTtbFAjg+PPEE8PTTlKC/971z27rgAtq6WxYf2dZWfv/Lcajawpt/DKkGFhfq82LKgqy0PPCNlMvdiJWJBtBqRCOWGSv9RVyNIRsaqm6XvpgYHJyb8OxP6JVFK9NpJkmn097xu7qA3/xN7lss8n254lgJnJbKSh0LB6fh4WG89tpr+NUL0uhqAd5+7sq0e8KEX+ZkpsngSBAAlxP18hQQP4VMTHIvLc/NDOVk4TVkjcwUAE3kGanCm1kT7EVUTJRVsiyhTrbhlLgtHP5I4NN6LnDkNjoGGgmg/XyChXKafXBtQGsic5J+AVj/q5Qsvvplj0mBw0n09EEBSIqYZSoBCBZOsEWtFxNgaiGR/wQhX1RA4OaKWlOmAAxlskN6VPTJZL+yh5irVk4LY4xtZMPK6dmTaikvtLKeSUiwC3CmBTOnsc+KJvKjBOjSY0Db21k/Sl6fnisJ+JJithrppbufY4lcuGlg6iUygLk+9j28ldfGzAgpniVUgAbvNUAwMlMXqoWAzHUFAEsBfbfzWhUGhWW9Q6AV6gbaz6O00nEAKymuvSGMREo0SpG5aYrG81izhzXWMvt4HDsvrnmZIC7fL2zlTS4QjNxPds1oIhhOvUSXRzXI/jolWvMXx4FD3wBCbQSKqWeZ4xVoE+6bqbkyQ7tAIFme5n3QI9xn6B7W9wLEsx6p/rmqxVgtt9bWIpgwTdXw3z7z3/AXf/EXGB8fx9vP5ef8yacWPsxMGxpw7bVevSxphrHQWFWvPK67m3W2Jia4XV8fXQczGeZ5vfYajTcq88bWrCEAaWritmvWzLV37+9n7u/NN9dmuxbT58WUBVkpeeAbLZe7ESsTDaDViEasQKykTruSIRsf5+DjOEtneoaHgS9+0bPwTSb5umxDFp7MZPh+KERJoEw+lnIOgEnLzc18L5GYy2QtlZVabQcny7Lw9I/+C/L5PKxzP4ELLjBWpuETOaSjnsyxUVSyFqWkZypRmuBE2zE5mS1OALHNwiJe1G9yHM8lz8wIR742go/2C4Hks55jnQRkehMZneRebhdZz4n20D1kuQJxoJBlflPH+TxWfliwGinRlnTlMwE4rF2lRghWkBcgS9TVcoqAJWoyxTYDLWfQOCI/CDg55gsFW+hO6OYJKiSrYmY5CdeDlOfl+oH9/yCYGxMIrydgGL6fQDO2lUBl+D6g90ZvkqyFea45EACpBgCD1yTQwv/tIgv1lqeYH2XlvetjCTv1tVfxvmgRns80CGqh8hjFYZHfphFUFUd4fx0bCDZxWzdPC/biMNBytrjXSfYle5hArzjO9+JbCbRzA5gxzQi0ANP7gddeJ8BsPgNIvwxYOhk2mV9lNAOxTTymlfVAZ7CDfTWaATfDZ8y1xb2yvNpi+UFPQmmmeS6llMgnW0fgFFrL+l5HbhU5ZyFKUyef8UC3e4D9bj5jrsxQC3uGLXqE9zSQ8Ozsxx+i+yU+xWsT3+jd0/kYq+XU2loCE9bR0YF/+OI/QPHnxi0ypEphsWNVvfK4WIyy8iNHOJ4UClyniUb5nX7PPTTe8LflX6hcv36uvTvAsevoUf595ZX1ARR/n2sxSfUu8C1XHtioufXWjQbQakQjVihWSqddyZB1dxPkNDcvnen52c84yEWjZKQATx4Yi3mFJ9evpzGGLCB5zz00u2hpodzEcWjZe/AggdnatXxv1y5q8JfDSi2GGaxHflG5zYEH/jtGRkbw13/9q9i65Q0GspaSA6LHKOca+0/BailChiYmmIpBR7viKGs6wSEzUZrka45J5kELe3WtjDiBgR4Fmk4iyzT2gGA3BBgCCO7MKU7yHZP7BVv4Xv4oYGzg8RXBSJkZ5lKV0/ytitytGUZLAAzbJJBoPh2YepkmCa6QMGohgja7QEldKSns6AMiB+pUTvDVaYK89CvCXVC487klYfHtcl87JwCqzXwnCfisIhkmLcTz79hFYAfw3nReDKRA8BYQE3ArJ4wlCgRIrs19nRKvU3w7r5Ea4MRb1UTe1IBn1y5dH/Uwf1s5ACbBlZUjgFA1tu8UZj870weAwgRBTa6PQFgN8Nod+hdKPFvOouV9ro9FrhUFsMoiR26Sks/Ieu5nl/hs2AVer+Q47+WRbwHr30/AkDsCpJ7mPbOm4RUoBmbklK5wayyOAbnDYlEgTMCp6IIpSgCTe1mIW4JNZ5psIzQavxgJPkNWntcV6uy6VzK3Tt7zQDOZM9UAXvtHUccrCoQBvPoloP0sz6FyPsZqqbW2lsGEKVCQmprCl770RfzGb/wGgMVLHzXNq2W11IXBWt/Bfgnh6CjxfzzO7eNxqiIqx4NqC5W2zTGvv58gK5mkEmNsbPEAZT4maaEFvpWS+jVqbr11owG0GtGIEzD8A08g4FniAktjerJZDnJSly9lgbINf+HJQGBuzRLT5OqkbdPqvVSijLG9HXj8cWryd+6kOcZyWKl6mMF65Bf+bS7Zdhd6eyfxxONfxA03fBhbt2yt/8Id65CACmIyDSw9B0TRmH+VeZUTSVWnDAvgMawMb6rrAnDoFpd7HbNyihyTDoJwmceU2MZJd6CFDIg5TaZHFzlFVhYzznUynyf7KljXK87/rQJlfQD7BI0TzZYzPNlZ9gjbK1sALMwUk1XAibSZASLdtEk3szwvTUjmsgc44Q52CSYMfC/zKifZikJpYuwkYFq6F8L7bWY4oQ+vYbvlSQ9c6mECLThChuhSWhjt9SbIRpy/m98GhGJk0CSosnznUxgAzGaCydwRtmGmOFHXY0IW9yIldq7LybtbAmyNgGTGYt3m30Y3WZ7MfnEPNN4X1yIwGr6b5hiqzutiF4TRhSXAl8KJPlzW7ipN8G+ZL5Z+SeTklcRxNZGvJZhOzaDLoR6jHHH8USHNtHgMp4SZfDo+7AB0keOl87oqKmBPYkaGWJrg+WtRkW/n8nylUYffJVFRCGrDa/iM+eteFUfIWoXaubl0RiynBMiC6B+AUpqs1sj9zMWbj7Faaq2t5TBhAEKhIPr7+/G1r30N733v/15w+8qo5zu0GsCwbY4JY2P83pfOs5X7S9bs/PNpJy+NLmQx5GrjQeVCpQRsP/kJmazWVmDbNr6XTHrSR1Wd/1xtm6Cvr49MWyWTVLnA5y/MvJJSv0bNrbduNIBWIxqxArEaCa7+gWcxLknVoqWFgxzg5WBdfrm3n5QPyhwuf82S/n7KF02T26VS3GbNGg52ts3Brq9vrtxwKflq8zGD9cgv/Ntc/ra7MDEBjI7egda2Vrzvfe+rvyPHOvyAymgHcB0ntpV5NZVytfnCSAjziw1kcVLPeZItp0wJn2JwohtsA4qCfdJiBADlFGCJ/KSmk4TU6ygn5kYCMMQsIdQt3OKayL4YLZx4y8m1FgQKQ8LAQOZxgecX6gSiG4B17weGf8JztIQsLrqBk21rGnB1AQxMHr/t7XTgG7gLmHoelI9ZnmGFnMCqGuWQsoivI9ikQBtBhBby6jgB7Ktjcv9AGwGpahA4htcQWEIn8Ax3i1wz3wRZshl2FjAVshzR9ULq9gSvtWSnpDV7fpCsWny757439Rz7YDTzvPSYj9kMeSyRKhhHPUaAUBa6YNhefp4RZxvhdWSYiqMElMgToKgBsnjFIT4XpSTf18KUUk6/xnbC63j+lkOGS+1k3xXJTjmeFFWWBygIWaNpetLBmXAJ/vJ9vE9qkGBUVQnuVJ0sY9NmyhjLRbG/kMPqzQKcify35jOBTR/xjF2kWYafPXJdPh9rrwJe/1fhnmh7XXJKXEzQggTclWYclYzVUmptLZUJExEOhfGRj3wE/+///TVOO+0ogifVtRuA+r5DqwEMgA6C+/ZxDAiFaKRRSwKnacCWLcCnPgX8+MdUSXR1LW48kAtvpklgAjDXuFgEbr+d4GvPHgKoynOU4/GRI1wItG2vD5VMUrXCzIkEFxNTqZWR+jVqbr11owG0GtGIZcaxtGKvxyWpWuzezflLMsnB5fLLuXLnP4cHHiCAisW4fU/P7BXFzk6yXcWi536YyXD/piYOdlNTHKBWq65IPfIL/zbhMNDdBRSKv45PfOIKBIw6sqiPR1ROBgtDfF3We1JDZD3M6blytfnCTBNYlSYBI0KpHRTPnQ8qc1pUFdjwIWDoXoIBMwNAOMpBJ/ujN5HpgCsc9dKcpMa3Md9IGj6oQToP6s1AOUOZlhrkZNjKgWyQIYCNSoARaGGb7ReIyfo44OgEWnqI4EvmiykKr4tdrHLCqmChUpiRjwWF/Xmkh9fQdQnwAgkCqGCrAGFBILaFksHmNp57OU3zjhkTjBQQ2UBwEF7nMVD+CbJk38JrAXPCYzmsHOtJuYJlkvXA9CaR29VK+V+ww2M8gp1k08pJgodwl7DN14Dkk2SToPD+ZfsAO11xPSzKQXtvpNV9foDt54/KzrL95DM8r6M/AHKHRJtBgh3X4XWK9PL50SK870YzkD8ipJsAUCJADbQJxrOZBh1OWchBAwS5rgPPRt4lUIQDRDcK0FridYmfyufJTPD92BYg9YxwMGwi6I2s49/lFBcKOi+cbQgDVGePrLyQZ3byfKxpzFjxqyHPgfHod2ebcdRirOartVVN9rtUJswXu3btwkknfQ8PPPAALt/0SShKfXlbC32HVgNi993Hj83zzxP0lMscT0ZGCBj8MnR/jIwQtOzfz491NDq3P/MtUsqxNZ3mWKNpHH9CIW4/MMBx67rr5u4jx6Jsln22bfYznSbTVo1J8hdm7uvjOOt3ZVyu1K9Rc+utGQ2g1YhGLCMWWh1cSaZrMS5JldHZWfsLvrK9sTEOXjfcwIHh5pu5nczVGh8HTj+dg+bTT3MA7eryChbL9ldDd16P/MK/TWEtkMuNYfPmTmzevG7lO7RSUTkZdA1A4ohAAph43Ft1d5y5crVqIYu96iHAjQsw5JB1ggOgxG2sabJVcD0GykqBrE2CYGLiEdAkQSWL07qTQMu1gTWXsYaVoomcrhCBmlPiBNucBtSC57hnFwFFTGoVlzKu5rOBw7eKPLBmYP0HCK7MDI0nzKyY/BYAWFSPjT7ACbYeJpOhqCI3LM02rTwnsF27uW2uH4AGmEkBrjJkmjZcR3madBcM93LSKwGPnCC3niNc7dKiiO7U3GLQ/tjwIQC+/Z0yQW1hCChFCX5dhwyXESczItmxGVONPoItMy0Yvl7WwrLyQGmUeWqORTBr56t0QuXzlDtCa3xzGpjax7eC7bwXTpFASlHJDGohjwFzHWDjdcDYg+zLDACPE9jk+zyDDwAIxAh21ACve+olYYLhCBmhcIiUeXdqEIgKoJo/SrClGZ5RSbSXuWNTz/F6y9pwdonXxC7y3DsvJBAevHuuvLYWe6THmIdl5eniWBLsXzABWJPCPEbj8x/uoQxXygXrzZmcT/a7FCbMf2cVFR/5yEfwl5+/D8PDw1i7dm1d+y30HVoNiE1MeERjIkHgks97aoeOjtkutYAn2Xv+ef4NAC++yG1uvJFjxHyLlJXjkszZCof54y/C7D+mfx8JlrZs4fg1Pc3j7to1d6ysPG/H4b6yiPJKSf0aNbfeetEAWo1oxDJivtXBbHZ1mK6lJtXW+oJfqL1AgC5P8lx6e3kuHR3Usj/0ECUZx0IKUY/8wr9NKtWHQ4c+jcsv+xto6pbV69hyY85kcJq/9RjZq+RewBFOfuGuuXK1aiEtrQPtZCusHJB5RUx6LS83y8oB8dM4SS0MEQxpRU6mS5PCWMHhjwugnCVos6YJVCLrmctSHAPGHyMbZRc4wY9toezMyor/N1HeZhfJejRt4fn1fZv7aVHmIaWeBlrOAdrfQVtxqyCYDss7P6cApPYCzecAhf2YsZZvPpP1qfzyMckeKJpgsdqAyBq+rgbIDkZ75056/ddXshZ6jBPk3BGCs2qTe0DkLYn9Zybck8zZCrQIgxFxn0Nds9mx4givcXEcUMaZ77XmMoKggbto219OCpAWYh4ZzCoPgcPcp7EHyQbpMWECoQnWz+IzJXOW8v2YJe1TQMnpmj1A//eZ5zZTb21MbKML6eg0QXJkPV83ErzGTpHMm2sJBg48hpR4lsZ5LsUJQDlE9jC8VuTCgaYgfkDi2gTliiJYtUECTiPOY+b6ZxtLzMcehbqBkz/Oz1P/XUAaQHQzkJkigAu00OSjnPbaqjdnsh7Di/mYsDri7LPPxqd/91RMx+sDWcDC36HVgFhPD78uDh/2wIrjeAYXhgH8/OcegAI4/o2MiJRIIVsvFgna5ILffAuG1cYlOSaNjXl96+31zq0WWMrluN34OLBx4+x9ZFSedypFNisSIZhrSP0asdRoAK1GNGIZUWt1sLIGyEpaua50Um2tgdW2+aNp1SUPIyMsRpnLeXLD5QDJetm/euQX3d3Ahz/s4p6vP4CTTjoJ7zjv5KV3bKWjHilReC0ZLUUlAGjdKdiNjupytWrtl5JkhYrDYkIXoRzLaKEZhap74OLQ15hLI80FjISQq0mQpWEmN8ZKsXZRsIOyusO3EhgWhsmeBTt4bCPB4+kRAoxwFwFT50VA2/lAuJPn8No/89xkQV5FA4IG2ZL0PjGBjvpyj3zhWEChXzBDPulU5QTWzx7I2luVLIJ/H9eX31SNxQDI4hUG506ipZGD/37MyhGyCaw23sCcKMmkSQBQHAH2f1HIPZt47nqMAKbvdrJOjikkeXleN0WHV8PMF0qQy/F2CXDTBHkAZaQAZ6K6TpbSylC+6JiCHVMJQO0ywYYWBWIb2YY5zRymyAYhuwQBfbANM4WNtbCw+M9xW9cB1KgwsQBfM5pELTCXkkMzTTAXP5lmJoVB77rKe2MXhCW+ZH/LtPG3i57joKLNXoiYjz1SNDKcay4n0FIVPsN6SJyrL39qMW6ByzS8qCcUKIhEIhjN5zE6OopNmzbVtd9836G1gBjA7fft42MTDNJ1NpslKNm7l0zR5s0cG+67j2NKOu2ZMGka84Ol4+F8C3y1xrnKHODdu72+LwSW5CJhtTGj1nl3dDSkfo1YXjSAViMasYyo9eXsrwGy0lauC61I+gFLpSOTdI0C2I9qrkstLZSF3HLLbCausiZJLbnhUgajxea51SO/eOaZpzA0NIA//9xHllV3ZkWjXikRwrQIdx3+332JJ1erzOfwA4DSuGg/yZV+My1SYUygnCMjsu4aIV+bILgyU4JBE0AK4ORy1sTdZxYgJYauAxy+hdtpUWGa0QrETqbsrTwF5AY5EY5tpESvEuCYacGymYJhswFXJatmtAD5IZ6v0QQUJwE74+uHwvyeUsoDY6E1nqNe5WTWD6TUeXL1iiO+QrtgYeDOi1lMWd639gtqT6KVikSUWjlCsOcyaQDw+r/x3uhRYf+uCHOJlHACVAE9QQBkZeDl3Oki90s4+TkFvmcVvL44Jl93TYLUUDvdDYvDAvDYBCxqkPsmnwMmnyQzp2pkIOOn8pqbGcowzWnBlIWYN+VfAOh4J5A5QLYTIj9LC3n5X+FusnZGhEyjaZNhLYwSjBptc8FJJftbTrPt8pSQuk555iW17n+1CHUCcIWZRrr6503mTNYDnpZpeLGY+Kd/+iccOHAAX/nKV6Dr9U3r5vsOrQXEPv5xjh+2Ddx1FxfabJsfXV2nkcT69fwuHxwENm1iG8Uij7V9u1cgeaEFw2rjnKzdeN11Xp6wqoqvjhr7LAYs1TrvhtSvEcuJBtBqRCOWGfPVAJGDyMQE85jqqWi/1GMCcwGLdGRyHDoq3XsvE5MBDnrXXsu2ZHvZLHDnnV5CcC0mrp6E6npXAVejkKPjOLj11ltx1VkbseOsHUtrZKWj2mr48H2zcz/kZFDWczr6HzRUCDYzP8VIzAYqfuAWSHACb6aYh1UY46RaDXr5XbIQsCkKyOpRz6BiZjhwfL+rsCTQRZHcIWF+0ELpmlPiJL2wBpB1nlJPc2KdOE3sWjFjcWzmX7mKyLESrnSBZoIwLQyknifD4lpkRJwS+6RFOaF2TEARuVlWliybrPu12NwX1+Y9mXqeLJBdoENfSphFhNeSJXSc2m50tsPzdwUT6M+3gjOXkfQDACvLn0BC5LLpPC89Jgwm2inFtKfJSCqamGW6AmyFafoR3QRMPkZgCwAQAMp/L2Xx6VISyL4u+gsPuLtCLgrXYwIz+zGT52bleQ+0Eq9ReZK5TMURFqoe+wX7HtkgHCzh9dOI8xo4FvtWTonjiHwxM8OaV6F2GqLMMhupZH+7BCAViwXB1tnM2mJDjxJYVmPAFgOeVsDwot54//vfj9/93d/Fz372M1x++eUr0mY1IKZpBDoAcOGFzNFVVUoDu7rIGqVSs8eGUIiv33gjGTD/d/p5582VngOem65/nEunPSZLLsbJsUZR+JHUNI53v/IrbEcuJsq/l3rejWjEcqIBtBrRiBWIWjVA7r8fGB7mIKFprIe1UrlafnOMbLa6XFE6Mv3Hf7DuyeQkJR+6ziRlXQc+8hHuK9mtdHquxj2b5QArAVQgUHs1crHs1GoUciyVSti6dSt2795+4rBZlcyGnWPuVWmCeSh+dssxAehkdIJNnNiNPjBbolQJ3HJ9ZLTi2wly7CzZJKdA6ZeicuILcDLqmMLBLSomqRYIrIRrHhQBxMoAStxPCfB1VScQ0cICKIncKUVljowlgIBjEVgc/ndg9CHg5N9gvpEMVSNb5Vrc1xEAJdvHIsN6RNSREn0LRIHEuZSdWXnKBoPdovbVNNuLbwOOfqd2Ds18RgZ2QbBGis/yW7gcliZ4zlaW17n3Js7w/JPo0jgw9CCA6wiS176bTchCuvL+1GIktTDvjZRJloWxx9rLCRqkeUNmH9Wc8W0CDI4LYCrcFU0h3VQDBDnFCQHIhARUMZgL55hA4agwudABPch77BThMZy6YEVdukhOPO7Zr4e6vXxCx6IkNf0KgZNd4H3Swjxey1k8t/wQkH6RxzSaCSBLSczY1htxvlccYU5fNXAi2d/cEWDsEbJYjkmA6VrMDVsucyQBsJSRVub71QOelml4UW9s2rQJ73znO/Htb38b7373uxEMBlflOP5Yvx444wxgaIgqiOlpr+C9HBtyOeDVV5nD9eCDXPjr7uYYIa3iAeDkkz0JYDU33XAY+MEPZo9tP/4xwd6zz3pj3OmnA889t7oOwI1oxGKjAbQa0YhViu5uDgC33krHppaWpbE19djfTk1Rhz4xMRuwpASBcfSoZ8mr63QMTCaBJ5/kXPHKK70BrdogeeedwFlnzR7Eduxg25U6/sWyU/PludVbJ2xum2H8zu/8Drqsuxa342rGrNVwB5h+VbwemZ3rURoHBu4DcJMAYU1zJVSuzfdKSZ+MSdii5/qA7EGfwxs4+Qyt46Rd1YDIWk6MtQhgNrHt0ggZJj0KQCOL5JiAppNJgkvmSbIiepSOeMUhTsKNOJkruwBkc8I/QwA0ODzHw7cCZ36eAMC1ebz4KczFkrbrRozufOUkr5ECcLLvcAJu5wnYAGDgTrJKsV6ee2QDWZdquVP1GBloYV6jzAEh4VQE0xgRrF1ZAEKHx9l4vSeHBIC+28gkApRnDt/Hv80UAVZp3LNwB6r3R9bRKiWBRIwgK9zD16R5g5UFpl4BBr5PMGbEgB7x7JTTdO8LdhDwaCHKDCVrWhzx7osaABxXyA5NUVBZgOyZwtXifjumAE4RAdqn6WBoT7M9RRfOlkmxnytYQXGszMtA0zYWxXYtFsKW5QDi23gNM68I8B8BHRMT3rWqFhOP8fmLbuKzUhhgPuN84Kdex8Ba92ex4GmZhhf1xoc//GE8/PBD+OUvf4l3vvOdq3osOe4MDlIpcfQov++vvprf25deyhytvXu5/aZN3Pb++zkm3nsvAZIjUitfeQX42c/4dzU1hX8xDuA2L7xA8NbayjaHhjg+JRLMA1vJvOhasRr1Mxvx5osG0GrEmzZOhC/Bcpn5Tu3tS2NrFmN/OzbG7aSVrjS1AHh8WUNEauZdl4BrbGz2gFRtkBwYAF5+mX2QgyAwWyuvaQRGlexUMkkA2N5efxLyjh1k/2QtlF27mMhcz30cGxvD3r1P4ZJL3sMF/BMl/KvhhXFKpKKbCFCgcjJnZfl+UUzWyykgU+LkP7oeM450M3lYQ0zaR4+YzG8TznCCERPz3Zl6UZE1nPQ176D1dr6fk9mTP85J9OgDnJRrIfYle4ST6sQ2WrAnf0nGwpwG1Agn50acIKjpFOZpWXkhI5SSRGDGGr6U8mRi/T8kwLLzdJiThg7RTZR+AZyJOUK+BvA45RSvg2R4hu8jYxPdSAfDwbtng8/iOM9Fj9XnArdmD7cff5wgKtjG61EYEUVym/haOcX3/bK/0hRgtNLIxGgVTnrw9UedbeFeS0paLZ/N/xxpYWDgB3xODOEOOfoL4G1/BsCem68XbKXML9Ascrd0QAvwPS3ANiSLpoj8JtckEPY7PaoBAuxyWlj3J733FU0wjy48QxBx/7UQAIUSRUWjcYaUiRaG+LzEtwpDE4PXNNgmih+n2cfKa2Fl+TkyWkSR7TCfpXXX8JmuFv7Pjl4BYmW4DvPa1EAFY9wPDP6EjpayQPQJFD09PfjABz6I9vb2VT2Of9xJp/nxjMf58+yzwIYNlO9dcw2/9yMRvifHhldfBZ56ivsGAvx+dxyOdYZRXdngX4wbG+OPonBdICf8XaJRtrl+/crnRVeLxSo3ToT5SCOOTzSAViPelHEsigjXE8txCFwod6ma5E7T+H8+z+Nccglfn5rywFY+z4GtrQ3Yto01UWTBSVmf5KqrZg+SySRrknR3e0Unp6YIsirli/7zHRwkqLv9dq481roPfi1+IECQNTBAff/jjxP07dzpSU/miwceeADf//73CbROtJCr4VbWY2PMDCfF0Y3cpjRFR7USKKuyUkCikwYMlXJBPUSQ4hQoY2q/gAxCSeRMSfc1VafxgmRLpp7j5DTcTZlh8ilg3fuBzb85m6GxspzMTzxOkJU97MunyQKKSymg0Uz5llUU7obbRXFZX76XW+ScPNdP6VvyacoOnQLbU8NCeniYwMDKAOEOAhxXZtxHvfpWTpmg0Clj1oResoZ2jiyHavBad+yqz8gg1A2c/NtA16XA+EO8PoEWytgKQ3Siyxwg+JX5U4CYfEeAggAsZhKICDamai6XX0oa5fWb3EtwFhZS0lqT+dIEgbXRJBhIiBy1DE0kXJv7tl8IDN9L0GemCcDbL+C1UAzg1X/03A2tEh33jBYhDWxigWorxyK+rpBNSpt9VzJeAs07Je9/RReMqpAehtbwvLOH+b5TIpNVGvPKDWQOCJOMCCWK+T4AGhcDwms9O/5QNwHT8H0smOyYQNNWsmOyPla1kJ+d6YNcKCgLh8Ntn54NtmRepB7hdTbaeFrFCVGwG0DPldUt3Y9TdFl3YVS/Gh/96EdX/Vhy3GlqAkZHCZQUhSBp716OGx0dlAJ2dPB7XNah6ulhXlepxLGjWOS40dbG73XJaAGzx0q5GPeTn9Bi3jA4nmQy3sKiXJTLZDiGVBtrVwrsLDav+ESZjzTi+EQDaDXiTRerYa6w1Kin7lOtmC93KRzmeSYScwemao5M6bRXcPjXfo3a+KNHgQMH+F57O3DoEOUYcsAKhZifBXDfchl46SW+19REXX21nCwpKUwmOZCGQtxuofsgc87kymdLC2Upts3z6Otb+D66rosHH3wQF1xwAfMUrOrbHddQNK64d74b6P8uWR0FBBBWlkAhKxitQCsQWMNJ8eDdnlW6nJw7HUDAAjb8qkjiD9NAINJDu3U7TxZj8yeA9nM957T8ENspDHECPvUSkHoOSGxnvSZZDFmPAZM/IlDQYmzTMXks1yJYsE3gpGtpZNB3OwGTESPoSb8MlCfEiRsEPUdvBwKdwkJcAjGX7RpNbMfM0gRh7VXAkW8JyV2TqG3UTOCUHwKmD3Bfo5U5WqMKTUNGfs78N4DnMmMhXsPAoto9im9hIWfJPknbdXOa908PeXlzM+zRBN0dAYKDNSJHq1pOj5SSTh/k7LAwRIAS7Z3fNrw4AgzfT9bFmeL9twsEWIEWj7XJDxK8yOtjCJZo4/WeScS2TwND9/AZMDMEPIoinPxUAqxwE2uqWVNkggA+j5It9TOOaoAA1HVE7pbDZyWyHsi+xm1iW8TfIldMNwTQExJES/Py5GDxPGTB45H7gXUfJLNUHPMkg7nDou7aBbWlgbLkQTlDcK+Jz9LQPcBJHxOnoPA+BJrYfnmK16Q0ScYv2MrXa92b4xBvP5e/n3yKMukfP9sFRVGxc+fOVTmef/FQVb3v6tdf56MTiXj5wZVW7BdcwNyqUIhgqFzm4xMOA+95D7/Xa42V3d3AzTfzYyzBmqZhpqrDxo2UwEt5e+X+Kwl2atXrkrnM/jiR5iONOD7RAFqNeNPFapgrLCfqqftULWrVtxoeJssjDTZiMbYtB5ZAwHM3lI5M8TjQ2cn53KFDwGWXAV/+Mv9PJGiQcdttnjTw0CFvtXB8nANqezulGpkMVxRl8vL99wP9/TxGfz9fu+465ofdfrvHkgH13Qd53keOMMHadTl4d3QsvP+rr76K4eEhfPKTn6zvIh+vmHqR+Uo5ccGaTydDMfoA0HQ6kPweX5eGAcUhgqviKCfBVg7ITHOCbMSBgR9S5hVspiwQIFulhoC1VxC0yFCFZKycJFiysiLnJkdjgal9QNu5wNrLCLRKSYIcLSwMLkzPjt11eExZyDfY6jmyuWW2M/mMML1oJrgypznxdoR0TE7SFZEPZcSBTTcQOCgawcPQ3QRgwVZKE/MDvBbWNM/RzgFl16vfte4aMhAAJ8bmdG0Di/kmy/78GiPB3LbIehp1mLnZck/JMjoa2cj1HwAM8UGsldPTeh6QeoH3XtEo3yyOiZyzqblsm2RlikO0WU+/TCYssh7YdBPbGLmfz5X/+jgF1jO2srPd+MI9BBmlCeD1b/DYrsPrHBAStFJSAPSC57yYeUUwZAV4MkGFQLr3ZqD5VN7f8iTZ0NKEJ5UNdQnmb0SwoHk+S4oG6AEuFNg5grDyBJ/R4jjvm2vSWCX1nGBOt7FAdWmS7x29g38HW3mv/Dl4Wph9LQ6zr4oqAHpW1OayATTxOTXCgCzSHWghqxZs5fFcrHg9rJWIt58LPPkUkH/tS5jOZICdd9a132JZHv/ioaZxLIjHyW5t2sS/JQBLJGaPfQC/u6enmSvsuhyr1qzhtrFYdQdf+X8gQLWFZXlGGm8T3jof+ACB2ymnzJazy3NcSbAzXy5zperiRJuPNOLYRwNoNeJNFytd0HclYimWsdXqW2WzwJe+RLnf+vUENoZB96dqBYMLBYKUtjaCqUCAbQUCtNqVLlGpFNmq9espDZyeJqDasYNJxhJINTUBW7eyrUSC7Q8NUS4yNsYBVtM40LW3U94xMMD/Mxm2v9B98OeJDQ9T6qiqdEk888z593/wwQfR2tqG008/fXEX+1iGUwYOf5PMgwJOJLOHCEryg0DyeaCcBwxwcprroxRPyt2gcAIrQZaVJXBrPtMDORuuE/I6myDHtb0Jvsw7cooiF0wFlCCBkV0gIJl4jMdYcxUn7WXpYhcENJHBDoeT2I6LRbe0uY5sHe8SRZNHATVP4BjqAnp+ha9LFsd1eK5agKyaBFnFEcr3nBJZj/bzyUDocQCjdMiz88ImfIryPslQhdo5yZfugdUMLBbDSEhHwPwAYAY8RgyYLUl0DQItpwwg4F0b/6Rcsk7Zo2QJ1TCgiaV5S4DCWO9ctq3SuTLQwmt68scFCBV5YvL6qCFxbTRP5ljZpqKRhYr0CFMTweaYad5zCYZCXUDvDbymisbnZsYsQ+X906NA9lWPPQ22ArGTKqSyWT5Pdk6UHnA8eWv8HO8a2GV4xY01skuyLpwWZl0192Uh4cxyu/IkgaF01KxknlTRb7cMuDo/A4EWtjv8MIDrgPRLQrLaz3MKrQUSp/I6u87CBcOPY7z9XMAy1+Gv/u/PoY18A3b3r827/UI5wLUAWKXUu1DwyoJks3Nlf/6x79JLgUce8dQOgDcmAbO3r9U/Wc8L8La94w6OQ37rdxnZLBcMW1pWBuzUymWWhh9+AHcizkcacWyjAbQa8aaL5cj1TrSQzoUTEzyfo0c5AFoWcPAgz0lVCUiqFQyWX+bJJEGS/JJvafFAUCBAdiyRIMACPA1+IkFJiGV5uvp0mhIQ6Qo4Ocn243HuZxieXfyOHQRwfX1s6+qr67sP3d3A9dezvX37uI/jLLgbzjnnHGzduhWapp1YjoP+KKfEpDfByaaVE1blQupXTgF6K7e183SFKw7zfzNFK3jFACIbOXFOPuXlyxgtnGjn+ykvS+/je/EtwIYPksHQwsx3cUzQjGAEgC3qaUEwCGMER+OPkWVRdPYr0AK0nO1NkrUAMHwPkGz22IMN1wkGI0Sp3qabCCzNNCfrm24iw7b1kzRwKI6KSX0zDT/W7BHGChX5aCWRKxZICEApJ8xgrpiic7IOcP+OXZQPOiLfKNxFNtBvYLGYqGXtrccqaiuJD1Gtibg8r1w/r5NT5mtamKydHmO+XjW2rbKOkzUFRNfxmvjfz/WDTjAK75OdpzR17eXVweWsc0syD0sPEWSoBoH5po8CsIGxhwmGp18V+YATZMjUAPMApdmHvMZSKrtmj9e+NFtRDQjkxOes7QIg+TiNVhybQEuynICQuw6L/Szx7LqU2BpxAlijif1Uw55tvB7zFhGgiC8TkwsGbeeTSZZukY7NHEKjiQxc/gjlhq5d3Z7/BIud5+5ELPolJJP3YKswxhjVr56z3Xwsz/j4wjI7PyAKBMjk1DPmtraSdRoe9tppa+PY4q8zuRALJSV6MkdraIhj1sAAAdA117B/4+P8/8gRLlBu3UqQt1yw091d2/DDD+DeTPORRiwtGkCrEW/KWKpcbyViJd2F5Ire+DgHit5eDiYTE2R6olF+oTc3e4YW/hU6maO1di0Zp85OMl/Sgld++W/YQFD03HMcqGRe19NP83dzM4FWoUAg1dVFwwqpS4/FeKzWVm/Q1DTPbnf9ejJazz3HQsn1XJdymfOgHTu48lkscqCcbxXy3HOZsCBBlsxfOKEi0MKJZ3FUTMaznKRG1onVeIeTPQVcxQ8EPLe+yAYCovxRTkLD6/ieU+IEWI8ArWdRAph8WuTdlMkcZQ8D2/87wZacVKsGABUojGLGyECyCACBjGVxkq5HaOeuBcg45PrJqoR7vJyijndRxjj9GpuLbwfWXwuc+RceUCsnaYMuiyz3flhICStYpkr2BuAkvucKMm6uK8wKwmwntIbXTU6so720+s71sf+VTMRibL5l1LL2nlVAdy1dBxW1ehvyvPQ4gDEan1g5z8nu5N8ig7IgIJqaK3/0v69oAiS1eCBLmj5UO3d5bqWJ2bl2gDC6sD0glz3K85OgVQHPwzWB4JrZIFMeK9jB/LmhnwrWNkNw5bq0iLcLwOtfE89BkF8oJUs0ooq6cEKOKN0NFYPXoTwFKAMElG6ZIN+cJqNWSomSCACmD4vnI0RQ65SZ81ea4j4Q9821hcyxk8+5mQFadpDd89vzn4ARMAI4Z+c5eOaZZ3DTjTfhyaeqb1dL0pbNLk1mV++YGw5TAu+6HMsyGUoHK0FPvZI7qdpobaXSIpfzTDna2zlOplJknF59lWYaO3euDNiJxeYaflQDcMdzPtKI4x8NoNWIN22sRoX3hUDUSibc+lf0WloIMl57DdiyheDHMPjlns8TwEgJYLVzvvhi4Kc/5SD6wANevyq//E85hXW/ikWyW+m01xddZ9u6Dvz85zy/1lYxT7K57/S0N2jKgVJa20vZYr1yDb/koq2N5zbfKuTevXuxOfQgtm3bdnwB1kITeDUwm+WJ9pJtatnBQrtOgSgTEHZezZy85/spa4IG6GHh1PYK6NhniHyrPJkqc4w5RI6JGXlXYZiT3JN+jRPFnl/hMRwbOPSvQO6QAFyV1KFDICCd/3Kvi4LIBUrFwmsJhrIDwOTfCvZN5flPPc+J6cbrPXc8P0tVGCRo2njDXJapkr2RUr1oL3+sLC3i80c9IBXs8Cb50qq9GihZqJ7WfFGtLpIfgCEMpCDAU5VnYBbrpAoQ0kZAFO2tDbL8gGW+Ok7+vqiBuQC2MEj5pZUlEPGfu5QR+nPt/KYhiiZKA7xA0KuA7zn27LwoeSz/dQ4kvMLNrkkG0sqKZ9QGYAi3zDKZSTUgJKUqQZOTEwW0c5h5Rl1TmKq4gJujNNCx+BnSVYLGV7/sSR7tvADACs0wICSJRhyYfE7U6rb5fvYQmTczzb4HW8kOVjJ2J2Bccskl6O/vhztTE21u1JK0AUvPKapnzK1keNavrw566pXcyf/Hxsgqvfoq/49EqKQYH+fiXjzObfN5MlGVphVLicWwVasxH2nEGyMaQKsRjagzFgJRK51wW7mit3UrV+MA4Pzz+f/3v88BxnW5gvflLwOf/rRXP0vGQw9xu8p+VYas+9XTQ7YslWIfRka8FcjWVsoJN2zg4CX7JfPG5ECzXG36YgaxLusupF68Fc8ZBj5y87b6DrDcqAao6p3AN79tNssjzQmk/XpxGsgBaNoCBCKc4JnTnKgGOzkB1cPC8lwHtCgAm5NUR0iinAJfgwJA4yS0nAamXwfGH+YkN9BC6VS4U7jKTYmcHsCzlVNFvaxOSsWsrPe+lQWmXgaCCQIHO0tGTjW8CWu+n8YfVr7CNVHMOmoZCyzE3hgJGnbUeh+ozkBVShLnc/hbTEgAlhsF0EEgHYrOfQaqsk5tnn15tT4sFhj6waB8tgCCrP1fJAAJJLzaWZW1xLovpX16acJjQBWNz9fQT4DcIPhsqQQpW38XM4yXbMe12Uauj8Ya2UOUpKpBAdRzEMhGHFfx/a2J51gFoANGBCgVRbuu70RVwW6B2wU7RN6hw75oQZ7DO7s6GwABAABJREFUkVuFbX2YbKwr2lFs5o5phtekHgMUiwAr8yrPz2jiwkUtp8qlsKOrGGftOAtn7Thr3m1qfb9KhcRSv7frUXTUw/DU+/0v7eQnJjwzpq1bOTYBBFrS0Eku1q0k4GmwVY1YKBpAqxGNqCPqAVEr7S5UCVSKRUoerrmG76VSZI9k7pRhcFC85x7gYx+b/YWfTs/t15EjwGOPzQaOHR3eMR2Hx9iwgQDq6FG+n0zOrlfi71cs5h13JbTptQYx/2C+1r0LlmlicOiH+MjNH1n8hV5KVJv4Bjvmn8BXTsbUAHOW/CGBQbkAvASCiam9nBSWU2LSbFMyZQqgZOUpvQI4MdWFQYYaYLK/nLxqUa7QH/oqwY4epiRsci/QtJnSu3IGKOucjPqLDetRYP0Hac3uiuMDbLsw6rkQqiEyD440MRAMABROtqVrojSomM9i3X895HUDeG7yGtaS8vmjkoGqJklcKRc512a+D64joKgF4hZinSrbXAlg6NpkskqTvJ+2AC7+PKY5+/j+Lo4AAz8CJp8SOWUR3veplwXT1jr7WOlX+Gw5JcpWFZ21xdQgoMXEMwZwGmKJ50oALy0iil5bZLfMHJ8lf800AAR7Yn9YXIxQFCG9FQsEeoyvR3tZeDv1jHA11Llv7jDbVOPeSUu7/GArQbAe43NbDcwvhx1dxdh/YD8ymQyAt9fcRn6/+o0llvO9vRhFRz0MT7Xvf/93P0CFxnXXsSbk0BBVFYUCzymVIpsViXAMXGp+1ELgscFWNWK+aACtRjSijqgHRK20u1CtAa9QAH70IwKewUEOIPE4U2lkQm4luEskCKwAru51ddH5aWhoLnC89FLghz/07HM7OoBduzzL3vXraWpRWa+kmhRjJVb7Kgcx/2B+yba7cN5HgWTyNZTL5rFxG6w18e35ldoTeGkBXs9kTNGEzM43y1VUYfYQEPknGQI7KYnK7BNMlAqknubEMtDC/cpTbKv5dJHQn+REtpwUdZNynPQG2mmLPnwPUNTYZ1fUQQqtISMRP5X7WQVwwqsAKJFF0EOeK6Gd5wQ5cRon9EaLd02kPM3KL85ivdaEtpqUb76oJUlcCRc5uyCAJXjdlLb5GbtqrFO1NlcCGMrn0IgTgCs6+5qIzc2pGrmf7JeUdw7fRyCdec3Lj7Lz4BTCJEMlgZYsJpzcSzbJtTHjTAjVY/GMuCdHtUWbrkPWU9XZphbmYoMW9EoN2CUWZnbEPlAw44BoTbNt1RC116JAKM4FhnKa+V1aBAhGfTLFINtDmc3IMgLSyt0p8XMha5/5n9XVYkdXIO677z4cPHgQN91UG2gBtY0vFvu9vRKKjmqAZj4Xwgsu8OTtoRDHqmCQx8/nOTbt3s32ikXK2APzfNSqRaPYcCOWGw2g1YhG1BH1gKjVcBeqHPAA1ruSg1kkwgXcXM4rJNzaOhfc7d5N56WhITJRAOue9PZy4GlpIXCbmOD+sm5VRwdXBZ97bnYhZE3jSmE9A/FKrvZVDubSjbG1tQ+apmLDxg0LN7LsTtSY+ALVJ/BqYOmTMcekbbsW4iQzf4Q23IHTPXOD5tM5iez/HpB6VjgQupxUhnqA+Fb2Y937gcO3CDajwLadEgCNk13rCNuARsliaVRManM8dvIpYONNnGiPPy5AmsMJu2NyW2gEgqE1tBxvOol5Z/5rEu5hIWJVAI1qbF9lVE5ocwMsWrvp5vlBSrVYSJK4nNCEMUcOwk1yBUDcSgFDaU9fTgJlUBoXbJ/rRFjt+c73A/lhPlMz4QAo8zk4+l2g9zoC35H7KRd0bAIka5oMqKITRJWnANUEoFLe6opnSA0SYEU3AuE1rJUFhYDHmuY5x1zm5KkR2sgrGs0uVINfhHae7YXXimdaLBas/wCQeYnnEWhjGYDJJwi0ShMEnqoCBEFZb3mEIEtea/mcVsZqsqPLjE2bNuEXD/4Cjm3XnOktBI7q+d6W4Mi2F6/o8AMr6Q4oTSwq61FV6+ujj3pjzzPPEFydeSYLG5fLHLu+/33mNgMcs669tn6g1Cg23IiViAbQakQj6oh6QdRq6LX9A560j5WD2bp1BEXSFbC1tXq/OjsJlG65hQNQWxsZrr17Cc4ch+3dfjt/T06S9ZJuglNT3M8/YB4PuUQls9jUBEylgN7eTlx15VUwdGPBNpYdtSa+eqz6BN4pL30yFkgAxSMA2gC3RBe9ddfMnvgpmnACzGLGhMIuEPgURwl2eq7ipLYwzCKwfkMBKIAjDAUKo7zh5aRXTwku2SdVAwbuALb8V05sJ34pgJrCQrOumFi3ngOsu9pzuPNfE0NIHY98y2OlgIXZPv+EVgHZiuwRAjz/seqNeiSHSwlFo7NeCrw2KwHiVgoYynYAUYQ6NtuJUEbl812eEHLPsq/ItD8cYPw/KcHb8l/FfWz3HC+VIGZqallCsqcIExDHIsCS8lRFodOfkSDAyh3mPY6up6OlKegLMwO0nElmtbxX5BC2CyOMaT7nisq2i0PA6M/obJnY7tnKaxHhPFj0WDZA1OvK8P+FrvVqsqPLjI0bN8K0LCRTKaAGsFiK3N0PjkZGKFXPZrlYJ+XrwMKKjpER4N57ueAnJekHD/Lr57XXCJo+/vH5pfmpFBmsytA0Ml1f+hINMQDmHD//PMfLG2+sb2w+FsWGV9KluBEnZjSAViMaUWfUC6JWE4DUYtYq2aZq0d8PvPACv9izWS74Fov8X/4Egxz40mmvPsmJVGCx8vynFdr2XnDBObjownOOTSfmm/jWMl9Y6mSsazcwft/s4xhVNJpamJPb6dc4iXYtMj1GE7cPtJJZqprnYvr+tgBHB1D0zCwA0GgDQO4oMHgX0H4hMPmkYLEUUb9KoRxs7RWzJ+/ymsiitflB9is3QIkZ4MnUarF9M059AwRZxXFOpCefYv7Ptk8vHmwtVnJYb4Q6Abh0lgysEIhbKWBYb06b//mWxaND3YD9HGAWqzRsA/k+OvxFe4WUVbhVGjE6ZxoJAA7lp3qUNdQAAC7BTikvyh6MAYrIL5QLC9kjbFsW6V73fjJa5TRzqIpjfC4caZhR5hecUwCg0tTCKZPpiqzjfs1vo2unC7Ypv/DUkOhzHFj3QeYy1op6QPBxMsrYuHEjAGB8bAytNYDWYuXufhmdphEQZTJUUySTzBnu6ZmbD1UJJmybyoynn+bfiviaicUof5+epnQ9m/Uk6dX62tnJBUYAOPts7mea3O+eeziWWZaomOHQN2hiYmnOt/Vcn8VGQ5b41ogG0GpEIxYRxzvptRazFgjMrz13HMosTJMDz/g49w8EuJo4OsoBKxikbEPTvBokJ1KBxcrzb98EvOc9LvbtewmbN29GJBw5Nh2Zb8JaOYGfz8VtweN01jfBllbm5TTt0pUAC/RG1nN1vpwSFtstlHGpumCjHMwGXaL2kyz8G+pizs0M4FI4adXDLJisjbNorGNxEqvHOOncdDP7VNlvWaS3OCrMCoQ73EJsn7yGgz/hpFtRCRrVENsbugc46WPHPS9mVkiGZqVipYBhPe1UmnVI+WfibcwJhFV9v8KAMLUAnyEjQbv6zR8n+Bm4k6DaMQA4wlRF5HApOp93u0SAFO4B2s8HrCLw+i2eU2JxjP2JbqAMMNjGwtyFYXF+IbK//rCy3D/YBqz9kDDJiAP936XM0WgGki8DAbDMgTUJZPvIavVcOb+5xXzfBcfRKCMRT+C8894B3ajN8i9G7l5ZbuTZZwmoOjq4YAdQUfHhD3uus5pWHUwEAty/VPJKgVgW2abF9HX3buDhh/m+lAquW8e+JpNs07K8EiTSFGo1nG8XGw1Z4lsnGkCrEY1YZBxvqr9a3lY2O39/CgUOMuvXU56RyxF8SYCmaRyQUiluu2FDfSzZ8Qj/+W8ygObmIn7rtz6LP/iD/4aL33nxsVtB9k9Y6z1mpepqsceZL0LdwJbfZj5Xvp/ARxbpDbTMLjRrZ0VnpJmADk54QYmgGub/ehxQxnh+qsixgUtAF+4hezH5SzYTP4VSr8mnvAK8jsnjNu8Aks8Amf0EeIE2Xi9FZ/+KQzz2fGxfqJsAzjF5DDXECXMgwYn0CZAX86YK/3MnWZv8EJ+rGfbI/0ALUFlOAR3nE2TZRa9OlpEAOt8FDN1NF8FgmzCksACovL+xzXw+ui5hCYL9f8eFAitHqR9AtrYgnpdAnHmIwVZRP25KyGL9IRYTCiMEZ0M/FkxYM9ByFsFwadIDxWaGnw89xn3qyaes9hk9AYwyPvsnn8WTTwGj82xTr1LDL6OTY4amcfEuEOD4EovNdp6tBSbe9S6+J9vQNFEVQiVokznA4fDssa3a2PeOd/B3qUQgtGMH8OMfUxqfz3u3VVbCuOCCxY1nq2XffixkiY04MaIBtBrRiEXEiUL1S2at3v6Ew5Rg7Nvn7asoBFdyALEs4MABtrNjx8Is2fEMeQ6qBaSF7VRzc/PxWUFe6JjVXNxG7gc2XDe/rbd//0oQ55Tn1uACmFvl2pxwmlNAfDv7owY8Vi3Xx/ZcG4AGhDoIrIqCEYDKSbTRLAq8imFCj3GFP3EqpX+FQW4Dlw9T9nWvT+lXAMUF4qcR3KVeAoyoMEOwaG4QbOdku/NCsnD15B+pAeZkZQ97DIfRxIn2CZAX84aJxS5GhLr5vB6+VYBoneDEysOTnmp8XdFEjlPYA/paGJh6kbXFShOiRpbu5VG5wsGyPEkWNvk0kHpeOGaKvDA7T4AlnTD1KNkup0B21UgAyWchrAOrnIQFTB8WxZU7PCnvhuvYp/I3aRLiuuyvLuSDhXHh1uiT7NZz/U4Ao4xCsYBMxgRa59+uHqWGX0bX0sLLFInw9XSaCojLL58NRGqBiWiUsr/BQQIk1wXWrqX8b3ycY9jZZwPf+c7csa1y7MvlgN/6LZpnrFvHfQYHgY0bgWHxldbUxP3icR53oahcTF0NJctqyxIbceJEA2g1ohF1xrGi+utlzKr157775tazArhSuGsXzS9UlQPP5s0crNaupcwiFOIgND1Nl8Ht208sJqtWTE1NAQCa403HfgW5nlXrqi5uw14R32Azc7GMRBXp0ZiXoyVBXHGcE1YzzX023cR8E9kXM0WAVRonsAl2sK1gB9D5bkqstLcBuSOcECs6EGoFmjax/yVhgV2e5KQ22MZ+OiVAi7J/LWfxtcw+YSSgC0v5VtbkmnqBdb4yr/KBM3Niwj0FIM2JtiVycqK9/Kl34h/uYU7W0D2cAAdbV8418K0Q9SxG1AL3VpY/TlmAbIXbOj6pXqCFz4zfDMS1+cwWBslyuQKcqSHx/ARZ2yrUBXTsAo7cLsw0THj27TblhzD4XFt5LhJ0XUJglu3n4gIg9qlCH5dGRL5ZBz+PpSlKBMd+IYopQzCkSR4z/TKNZgbupDQ31F3/Ys4JYJTxr//6r3j++SCu/sSNy26rUkZ35plkjI4cIeDq7Z07XtQCE1I1MTnJBb61a4H3vY/GFVLp+OijVFhUG9sAb+yTC4u//CWPNT5OIKgoPH4ux2OEQhzTYrH5x9hjtZi6mrLERpxY0QBajWhEnbFcqn++L3f5XjrNAoz1fMlX9ieXI5CamKBu/tJL6Rwoo7eXhYX7+jzb9p07gfe8B/jud9mvWIws1htJwiCBVqIpCExMHdsV5HpWrWu6uFmsXZV5jav3kfUeaDDEjRt9ACj6LM0H7gKmXyXY0qNkoQ7fCpz5+SruhiqPI+sn9f+QuSzlFGteRTeJelca5WAdFwPDd7Mf2cPCdlv16iCpAVrFmynayGthgrdgB8GZmqKroKKRsXJEHk85zVmPOSWMOGxh961gJj9ssflH4R7mZFUDZ8fJfOANERKM5/opC831ewsDAK+bmeZzV1mM27X5zJXTBB/lJPGMEQOUZj5LRjPlfHpstoV/acKr5+bKnEBhVqEEQVYsAEDjs1GeAmyT28h8MDXsAS9VHF/VgbGHyJaVxjE737DqBSCgSu8Dgi38/L32j5QIKhEgBD63oQ5+ZhSFnxM/C73Q9ZPP3WqWEagzmpubkctNrFh7fhldIECX2lzOG08qFx5r5VU98ACZrF27CGw2buS4NDjI8ezoUQImCYwqx7YLLvDGvmiUxxoZoZX7kSOUM+o613jicfajpYX1H/1OidKlV46x5TLwk58AY2PHJm9qtWSJjTixogG0GtGIOmM5VP98q2TyvWSSda6CQTJLC33J+/vjOMCrr/L1SGT2vv58/F27+NvvCtXRwQGn1nkd75y0haJUKqGlpRlNzZ3AdPOxXUGuZ9W6loub0QLA9aR8dhEoCY3PuhtAKVV6tqX59CGCGKhkABwbsI+SOUqc6uuLw+2jGzkpHb4PmHpe5FoZgJnn5DJxOl+zcsDk4/w7c4DHdUwaTig6+xdaSyBoBoHiBPsU7PJAnWqQyTDTnHDLyWawVbB1giVTdCFHdJmzlTvC3JzFRjVwdhzNB94QYReYZ1WcADCGmQLCuSNCvpnk+3qIuU/5AQJ0PcJnQtWEbFTap4vnXFGBlrOBQDO3KwwBAz8gWNFjZJ2MJlGHS9R5k+GaotB1hM6FR/+DBYRVg19sMhQDMMLCUdCmrE8LUabqCJdBqKgNtlQew3VYxsAxgeIkjVlmbRagTf3A97m9ESc7W5riIsW8129q9nO3WmUE6ox4PI5crm9F25QyumyW40hlGZDKBbpKMFG5QKiqBGmA95rjEGiNj/P1yrHt0UcphR8c9BiwVIr5XZs2Afv3E5R1dwPbthF42TZf+9a3ONbG4/wNsH/j4wRZTz3F47S18We1Fx2Pt8FWI1Y/GkCrEY2oM5ZK9c8nOQS895qa6P7nuhzApDa81pe8vz/j4xxwenspkWhp8QaISIQrdPfdx9cSCeCKK2iMUS6zrWrnBQCHDnFQS6dPXPvZi995MU0wgGO/glzvqnU1F7dcPyd8plg5L04A5WlOau0CgAhlTPmDnACXU2IimwRX+TWQITCB8cfINnXtBo7eAUy9zPeMOJA5yGMBgN7E33aBLJYWJCAzWgj4SpMEb64JwBESvxyZDCNKeaCZ8qzUC4P8LQHmhuvYtrRx12MiT2cjJ7hGE9uw8zyGogHjj1I6uNz7dAKYD5zwoQbEs5QUAGJKsEKP0JBEbxI5VAmgKQrAoTw02EFQbU6y2K9j8T0jDgQ7WUi7NEom1EzzvWCK97ic5kLA2vcCR24VzJYMKQsEn4nMa+LZB/ul6gJsBQm07DzfK00KoDQuHCgDPidNKRsU7frrxWkBgjK9ieYtqWdFLS9j9oqUESerlR9gO+UJLpBo0dnXr5zifqMPU5ZY7blbrTICdUQwGIRt23BdF8pKOmBicQuPfjBRbb8e8XUyKL5OUimyWZEIwZFhEEDF43x/YoLs1BNPkO0CuFgYifA4oRDw8st8TVE4PhYKwFe/yn1bWjynxGSSoPH++zn+RiJ8bf9+5p2tX7/4vKkTfXGyEcc2GkCrEY1YRCxE9Vf7gp1Pcij/lpazrsuBIxbjYKPr8xtSyP5ks1ype/FFrhA6DjX0coB44AHW0YrHPaAXicwGUP7zGh9ne3v3cjVw69Y3iP3s8VhBlkYB1cwpqoXfqny6jzcMEDcux4mubMPKc8W9lKRTX9MWTmTLSVBCpQHQgORTZLq0EGsDlVN8f3yExWShUaqoxwRLpQGhdmFsEKJlupUGikkhF1Q9R3c9Rre23FHA3Meir2v28L1KgKkG+LNmD5mQzD5uZzSTsYudDEy9xDmwYlCWJeWNy52MLsd84K0iN3TKZB1dU+TfCbaxNCmuW5TgvpwBSimCZBeiDpbQaDkFoHUHWS2jmc9dfBufITNN638zS3ZRj5AVKo3TkXL7Z4GX/4I5e2rAV2LABhxV1L1yWZ7AtfmFqAYJoqw0t4MKjxFzhHd3SYB6SzBb4n0tIo4jGC9N9KdpC6+DFgWQImhzXCAIYRuf8DktDgv5q8YFEiMCuK08pgJ+1pJPMzfxOJle1ApVfLc4jgNthb+0l7rwKPe77z6CnrVrqbQIhTzZvF9tkc0Cd95JEDY6SnbLMIDHHwcuucSrs9XVRdmg47BdKTuUTFcgwLYUhbW/Wls9p0RAlAtp58/+/cw/6+qa/5yqjfcnimFWI06ceMMBra985Sv467/+awwPD+O0007DF77wBVx00UU1t3/ooYfwmc98Bi+//DLWrl2LP/zDP8QnPvGJY9jjRrzZohbVX+sLdqGVP/leUxMHgWCQhhS2zQGhrw/YsmXh/sj5erUYGeHgMzbGYwwMsLhkV9dsACUThe+/n8eVhYxHR8mW+WUUJ8qq3c9+/jPccccd+Kev/BNfONYryPPJ1eQEvlrey6abOdEc/yU40bQ48Qu2i1X9JjIOidO58g4TlOgFATVCeZdVAGBx0jf5JGbQ0Yz1tphwqmG+Z+e4Ep84jQzDyM9ZF8m1Odl0SyKHRuXEVDHYdvYQCNYE0xXs4HWuBWqDHZ4RR7CDwLCcFgxIGyf2wTaCv2Dzysg7l2o+8FaSG2phILJGSO+aaDgRWcf3JDtpNHn1rYJtBPmp5zyHx6aTgcQZwJHbRPHpBND9HmFeUcJMHpadJ8ixMnwsUy8AbecRqOf6ub1rA25R5O4Jeh3CuVDRvaLZji0WIsTzrGh8phWXnwUtCETXc5FC0QCjlZ8Z1yYLrEcpo133PmD4pzxXc5rSxsqQBYr9TouOyTYKI5TdBlpFTpjC83eKzJ3UKpwWj3O8+93vRiTyLkzMMzgs53t8uTlGhQKZJ2nKtHs3gZMcG2W7u3YBjzzCAscA2a3BQQIzqQzZvRv4wQ/orAsQpF1yCRcrb7+d46plEXSVSl5u2eWXczyT47CUDJ52GnDzzbUXOquN9x0dizfMOlHG0UasXswzNTvx4jvf+Q5+7/d+D5/97Gfx7LPP4qKLLsJ73/teHD16tOr2hw8fxhVXXIGLLroIzz77LP7kT/4En/70p3HHHXcc45434s0efnlgMOh9wcpaIZdeSnAla33IVTL/e7bN3KxIhK/bNlfjvvpVT1JRKwoFMk9nngmcey5/m6bHmqVSlEM4DoHe9DQHhVhstg5dtjU1xfebhNJseposV3MzB4SREeC224BvfIO/R0ZW6cLWEcViEaOj81WKWcXwy9XUoCcbcm1O5l7/N+DQ14D9XwSmD3Kb3ADZrIK8aEKiF2zlZDDS47VvtBKcxLdx0moXgJYdQPtO4QCokJHSxGzAEXbXlXkwTpH763Fg66eBkz9O+V/b+QIgCRniDFgSdtuuw4mjIwoLuzaQ3u9NUCWorWSB7IKoVdTF/gfaeX7hbvGzhj/R9QQ2ANt0q9ly1xmKRulksFNYftchHZ3v/r0ZQ7Kp0XUE0tH1ZB+7L+F1s/NAZAOw9b/SbESP0dzCECyXVaRpSvoFAq/E6fydfkVI6tJ8VlyL17A0LgwvdIL05NN8Jlwh15Pug7NCPLeuQ7leQFAWaoRgR75nF0XBaw1oO5cLF5F1QPQknl/buQRZjkXWzRXM2Zo93M7KCvmqDmhNXr6ZVfDki06ZiwKlCSB9gL/1iFgMKfGZTpwKNG3l+Vj542J6USs0VYOq6MjlFNhVHumV+B6XC33zAYlsFjPHl2Pl4CDHorExLuT19xM4SUXFbbcBX/kK8D//J/C973E86+ri2NbVNXfcam/n2NnRQTYrlWJ7LS1kr1Ip7hcMct8LLgA+/WnKFivH6A0bgCuvrA2yao332exs9UplH1fj+jfixI83FKP1d3/3d/iN3/gN/OZv/iYA4Atf+ALuvfde/NM//RP+6q/+as72//zP/4wNGzbgC1/4AgDg1FNPxd69e/E3f/M3+MAHPnAsu96IN3ks5Eg438qf/73hYeBLX+IAJOt+TE7SJeljH/MAWGU7ftasrY2Dip81a23lIOA4/FseC5i7rb+tzk6+r2l0hpK5WydSRXvDMGBZFhzXgaoc47WjWnK16dcJsEoTfN1MU24UcoWM6ggnp0aUVunTBzjhazqZkzTJyJlJQGkiUGrdCay7xnuvnAaO3g5M7hXFe6fgFSCutLZ2OTHVApwIKhqZnMnHhVSwRLmWons1jeBwdd+xAJjMU7GL/MkeAZpPZzuStZMSLS1cm12StcP825bGgb7bls8oFUfIGs4YMOxeuJ0ToNbRMY9KeW1pXLCt4yI/qx0Yfwhov4DPWKiH+VqlFABb5PVNETwbMeEAOEmgCkeUBbAoY3XBfRSNslEJaM2M6IwvR0s+c9DJpMVPAdZdCwzeBYw/QsDmiNm6ovG4gWag+Qxg7WWCPW31zGDsaUCL00AjtIYLBsP38TMka2fl+uhC6NoAhKtCIOGxUWqAEsnCoPesA8C2/0ZgVRzj58XKAi3nAOuvrb7wcJziJ3c/httvfx2j+tVzZGwrUa5kITamGusTi/F/mZMcj3Ncisf5usyXGhgg4EomCbIsiwoPRSG5WakMka69HR2z85TL5dkSx/PPJ0PW28v9ZEHkxbBztcZ7oP68tWNVLqYRxz+WBLQKhQKSySR6ZAajiJdffhmnnXbainSsMsrlMp5++mn8j//xP2a9vmfPHjz22GNV93n88cexZ8+eWa9ddtll+PrXvw7TNGFIuxpflEollEpeTZBMhgOC65pwq66+vflDnvdb9fzriXCYK2pDQ9SPT09TCiHzrgAODtKK1q2YB8v3TjoJOOcc1gSJRPhl3NzMVbZCgXKHBx7ggJJIUC7R2cn99+zx3uvt5XuKwnvW02PCtimjOHiQg9bgIPt52mncVxVqMdnWj39MrXo8zppb73kPVwRzOf50d7PPhsH/CwXv/I5VOHARi7dAN8KYmsqiKd50bDuAMGC0i0KqBuVI4bXA2GNAKQforQQqbhAol4DMIaCcF3kwWe4T7QG0BFfS11wDGHGYNh8QM7SBICXUC3TuBtS4l9uvtwBrrgWmRwiClIioM1SlfhAg5GBNQHaQif6DDzD/JHQypYG26K+Z5URZ0YFgL4AyjTpcm+frqsDr36TLXPMZrJlVEHlkwRYyVl27gfZLhCQvDYR7gY7dPF9FuMnZYJtDDwKFMbJ3uTH+v+FDBID1huvMbqeYBIYfrqOdGvcPYcDy523V35eZe2fXuA8nRKiAEgVscd3yY7xP5SzgGICjA86TFdemIBwz43OvWWgNkBulR4sS5DOqRYBwFxcZVA3ICHdNIwoEerwabq6JWYAr2A4kzgTWXk72CyFAbyPog8V2Q13MiVr3Pn6WFJXH7NgDDP6YbpaOKYxXYoClUPaYfBEoZIBQm3DcDAKOBsCBCc5uzY49zBeDy3N2FECJCbMMl//bNtB9lXcsAAhYQLnIz2itz+AxDNsBHnt8AKVyBrFmE2NjwIMPAh/6EL/j5Xiy1O/xsbHqY5EMx+HxxsYIRuTxP/ABb6wMh7mQ19LC464TKtZcjguCUlmhqtwnGuXr+fzcMS4cNhGJAC+95OUpn346jxGNzralL5cJ8h56aG7/a43RjuOBsFrjfSxWfRyWY6s/lnv93wzxRp5bLqbPiutW3v7543vf+x5+//d/H62trXBdF1/96lfxjne8AwBw9tln45lnnllcb+uMoaEh9PT04NFHH8UFF1ww8/r/+T//B//+7/+OAwcOzNln69at+NjHPoY/+ZM/mXntsccew65duzA0NIQ1a9bM2efP/uzP8LnPfW7O67fddhsikcgKnU0jGtGIRjSiEY1oRCMa0Yg3WuTzedxwww1Ip9OISzvMGrFoRuvzn/88nnnmGXR0dGDv3r346Ec/is9+9rO44YYbsEjMtqSotChdyLa02vbVXpfxx3/8x/jMZz4z838mk8H69euhKHugKPNfzDdrELnfD+BSKMpcFrARXjgOpQjAwgYV88XwMPCjH9FeHWAtkIsvpoQwHKbsIpcj03XTTd4KWOUq4yWXmGhv572bnjbwr/9KLXwoxO0LBSYW//qvz15Fy+WAb36T+vNo1DvWnj1k20ZGuBLZ2kqWq3I181hFp/1TbD+1gEOHDuHkk09GSJ7YsQ7X8dgPgLWAsq+THTIzdAzc/BuUZBXH+H9xCLBKQKSbboVdu4EQL6Jpu7j/ReDStwGGVoctc2EEeOkvhKmAwlwRVQeatgHplwHYtLR2hOFAsEPUD7LJBigGV/xVgxIv6TwHG+i9ERi6m9bdxRFhR69zG7vI/LH8UcwUOA500m3QtSih0kKUm7W9HVj/AaD/DrIhRqtnkhGI85qYSTJKS2G0jv6H1+5i26l2/5bY1qLv3fEMed3yQyx+XRznc6M3Ac1vY56WawN9t/O9gO96rP+AJ/+0ssBLn+dzp0f5jDtlbm/lMWOgAofMp1Pml6MiihQbUVEAWaO00c7ymTn1j4GRe2m6URwH8v3stxoA4DLPcNtnyKQqKl00D38TgALkXgfssihPECa71XwG+15OAhNPArBFvS4LJiK4P/xlXHpqHkbQlwv2+r8B6ZcwU6MrcbpXLPvgV3muEAYyoU7mP+rHn5KwHeAP/uDvMDW1DvnEN5BMknWRjBawMCtVK2qND/6xyDSBz3+ex2hqIuvT2Qn86Z+SvZEMkWSYwmGvX/v2Ad/5DscYy6LF+qZN7B9QfYzL5y/FN79pwDA4vhWLPKZkwBIJ/p6a4tj8wgtUa+zYwdcr+y/DcYD/+A/g9dc5tss2P/EJjn2S5VrKWL/U6/9miTfy3FJRMgtvJGLRQMs0TXR0dAAAdu7ciYcffhjvf//7cfDgwRWv0+CP9vZ2aJqGkYpswbGxMXR1dVXdp7u7u+r2uq6jra2t6j7BYBDBYHDO64pivOEehJUM121cg3pifHxlrF27uigdjMcpnTh6FPiXf+HgIe3Wi0VP/60INct993ma78OHCcxuuon3LhYz0NZGe1yZP+Y4HPT8NreAJ7eQbclaJ488QslhWxv3b2qiFGQ+C/rVDBUK4rEIzjrzbcenAzNR4XS49t3AiMVJpX4yZVDhHiC4x3O4i28guDISc137RJ6U4UzDMGrkfPgtySNtQLCJ4EmPAk6KeVfFIwAE6AqGgcKUKBacAwIh4dIW4AMU6wEKA4A1DmgqYE9w0hsIA2veCQxmgew+yhMDbUB5jLMLewpQTE5e9RiQ2ct+KRoAnXk1GoDSMGCnAHMCCDQBRpD5Z6rNibKVBaKdQPe7AX2xSQqauObi2i66Hd/9s7Jz+2hOACgAWr15Wy4MTTnxgZa8bsP3AYVDgCJyq5QS76kGghU7zefLfz2UMhCUuYRZ7mtN8scpMhfLSQMoU8ZXSItjCjdMR+EzEuzksRQTcAsA8gCEe4Dhu69uFiiUhHmFsHTP7Qf2/S8CqPXXEsyFoqJunMnnLdjCXC4jyLbtKcAaBdSycNuUrodMGTCcDIyZ+6wBG64Ehg1+VoLtNNPQRY5YeQQoj4qaZBlAdQAjAKjH/74bGhDQxxHQN2Msa6CzE3j3u2fn/3R1EXgt1vWu2vjgH4sAgqdolOOYafJ3NMrXA4HZ7r3+8cO2gWeeYVudnV5R5A98gPvcdpvn0vv662z7ppuAQMCAYRgYG2OfJia4bz5Pmd/Bgxyfpe17MOgVRZ6entt/GYUCAdHkJMdcXecY+NOfMm96OcWGl3r930zxRp1bLqa/iwZanZ2deOGFF3DGGWcAANra2nD//ffjox/9KF544YXFNld3BAIBnHPOObj//vvxvve9b+b1+++/H9dcc03Vfc4//3zcdddds1677777sHPnzqr5WY1oxHJiJZNbCwVPux6NciBIp4FTTiHLdfgwsHPn7BofMkG3pYWDz/g4B4ibbuLvri4yUtksa5A4DgeycBj4+c+Ba67x3KOq1Ui54ALg7rtnJwDn897AeTxtan/wwx9gTfcanHfeecf2wLWiVj2veup8FQaBvh8B+G3g5c8D8c2cRPqNHapZkm+6iav55hTzWBSduTGaWDiyyyKh3xEFX0vgKr3NiaJrAfHtdFUrDJPRUgzg0L9yf1m4WGn2gFsgzjwcBQA0Wnm7Do9vF0T+jQu4IdbtCrSQCcv1AXA8K2xpkrGcOlYrVUNtqTbxxyNWov5XqJsGEcUJMj9amEylY3ptz3c9XJtmGoG4AFSDIJByAGea2yg6ny/J/EDz8rPKE1yE0KPME7SFS2F8G/cNdvD5KIwCr36RiwmuJdw1NT7XU8+zP+uv5eLFyM9FwqlOg4xgB81k0i8IIL6JwDq9n5+FmfpcAIZ+Cmz52OzPbO+Nc69ztZpkwTbP7OUEiI985HocONAMZ03t7+Va5Urmi3pqaIXDZNBsmwuG6bSXtzxfVBpNBALeOANQ7TE+zvE1m6W64qabgFtvJbiammI/urr4u6WF7TiOB6xUlUDNMNi/+WqAhcPcP5PxQGMiwWNLs6vlxFKufyPeWFE30JqenkZTUxNuvfVW6Prs3QKBAL797W/jU5/61Ip30B+f+cxncPPNN2Pnzp04//zz8S//8i84evToTF2sP/7jP8bg4CBuueUWAMAnPvEJfPnLX8ZnPvMZfPzjH8fjjz+Or3/96/j2t7+9qv1sxFszFnIeXEyk00y0nZwk0JKM0+QkBwnLAt7+9tlsWTjMgeP55zkomCZtagHKEz70IW5/440cuIJBsm7Dw8BTT3HA6u4mGOvunl0MWbbf3EzpYbnMPm3Y4Nm9H88ijY8//ji6urpOHKAF1K7nNV+dr8IgsP8faAoR/m0Wdp16nuCn90bP+UxakhttniX5xhuAM/+C/w/+SNi+h8iq5Y5QMlUMEoiVpzFr0guHk+c1ewA9ARz+d5p4GHEeHwCazxTSOQuInUJQFWgjGFNDQKyXrJYW4YQZELWUDKDlTLZdTlJKVhrnT3z77ELHq3XNF9uGLFbrL8Z8gjjJzcRK1v/SY0C4Q4ApbXYtqIWuh10QBbXbyWypOliHDcIBQBVW7uLZdcEFAEUCLo1AKLqeTJSdJxtmF4DXb+G+ABcGgm1ksgrDABTPIt62gcmn6HiohQj41CDLJbg2Wcr0C7MZ5NI4MPAjgjIH3oJE+mVubyS861Ptuapak2zNCQXId5y5g8YPq+AvvZBLXyUY27ChvoLG89WdtG3+n0xyDCwUOI4BNME45RRu09bGvn3ve147qRTZrEiEY9fJJ8+u21WrX5rGWluvvkogl0gQpLW2LgwaG9EIYBFA66KLLsI999yDddIWpkrs2rVrRTpVK6677jpMTk7iz//8zzE8PIzTTz8dd999NzZu3AgAGB4enlVTa9OmTbj77rvx+7//+/jHf/xHrF27Fl/84hcb1u6NWJVYqDBxvWHbBEahkLcSCFBDns97kr+vfhX4vd+jft0fjuPV75LEbTrtAb5YjKt9Bw9SejE46A1ahw/zGB//OPevlEJu2MAB7ehRDjg7drD9421Tu3HjxqqGOMc1Fss2uDYwdA9X7h2Lr1lZSvuK457leC1L8nKak87QGk5I8wMA2ighbNvJorJ9InfMKtAdzrWZVxLZQFbDLtBqPfksCyIbccys9Gsh1gvKHRY1hDrJcuX7+dtMA3CBYDf1N47FWlmbPw7Et7CNvts4iY9v50RXFjU+0WKl2LHVivnA9lL6uhCYqnY95PNdSjLHqzQuCmWrIs+rhbI6RRclBGxK78y0VyPLiAHRzUDXu4Hhe8l4GpsIdqYPsjDy1PPCLj5GMGO08JktjYPOgOK5U4t0vJx8mscKd/O5VHUuEuQHyLzJaxTqpmvh2MPcXp6rOe3ZyFe77v5r4L9msibcCfKsDAwO4Om9T6Ot/b2rVshnITZmMZbpfkXE7t2UvWezs9mmQoEAp1jk2CQljAAXIEMhygTzebYngV4ySfXG5ZdTii/VIvVK3nt6WHNL9qm1tT7Q2IhGAIv4+O3cuRPveMc7cO+992Lbtm0zrz/77LP47Gc/i7vvvntVOlgZn/zkJ/HJT36y6nv/9m//Nue1iy++eNWcEBvRCH/UI6eoFf5BRjJjPT38f2LCk0jIWh2aRmbpH/4B+P3f57ayaPGOHQRQsoYI4K3ayeO8610ETFNTBFmyOLJkxLJZDqB+ANXfz33icYK76WnguecIvlaKyVtqbNiwAT//2c9h2RZ0bZVmFYuJpbANdoGTPJnDAnAVv5SlMUMp6RUNDiSERAuUcqkBYN//5aRTjxFUuS7Bl5w0Bzs4sbWmwdwpIXGycsxj0cLAwJ0EYnaB7EApxZV+VRdyMmF+4ZhAci/zVqQJkmKw33qO9cASp3m5aQBB4yyAqLJ/J2rNqpVgx1YrVqL+VyVoWAhc+q/HzPMtQJaikAEqCCbTaCarGVoDNG0h+1lOcwHAaBILCa6oqZUC9v2VyBfUyVLZZT5zTgkz5i6KRnlheZLvBdoE2BLW8FoQyB4UJiwqmTE7DygJLhKgjf2VuVaKxrpyRlyULhB1E4wmMm6VkTtKUxi7SHt4+Zk+QQH5Cy+8gG/82zfwh3945XHtRy0w5h/z/At6cnGwVOJ+u3d76ggpR7TEOtTUlMdoOQ4BmL8upNxfAiSZSWKas5UX9cjee3qYk+U3u2pEI+qJumckX/va1/C5z30OF154IX74wx+is7MTf/qnf4o77rgDv/Irv7KafWxEI94wsZgVPBmVsrvdu/n74EEvN6utDdiyhSDINL28qFTKK2bsZ9TWruWAIJ2Q3vEOHueBB3icSITbtrczX8t1PcCVyXgDjx9Alctkstav54peILD4Io2rFb29vTAtC4ODg9i4YeOxO3C1WIhtqMV0aWExyVMpxZOhgPkz+/+ezJAjnNKMBMFLsJu1rEoTbLs4CrzeB3RcDPRcAUR7MVOg2CmLnzwbdk3A6CQgyvez+HF5koyDGiCwCjZ74Crcw2Nm9pNd8E9QXQuAysnsye+iO1vl+flzfcoTZDVOkHyWN1QsN4+s1kJAPeDS/3xrTcxxCsRZYNgp8f9Sks+tFiJo2Xg9EFnv5eEBfI6Ofh9IPSvYWIdmGE4BgEKwlTkg5IY2gbwtjCvMjJAfiv4qAmxZAugpCplgR7C8dpGuilYROPJtfs7WXs5zbhasGcRnLnGa56QoP6Op54EDX2D7WphMLeB9pk9AQH7kyBH09Kybk+qx3FiJXFz/mCfdACXL9LxQKp95pufKJ9UR/sVMXSeDJUHY6aeznZ4e5hPLvj7wANupbFsqL3bv9sbFhWTvK2V21Yi3VizqE/i///f/RiAQwKWXXgrbtnHZZZfhqaeewtlnn71a/WtEI95wsZjk1moGGg88QCv3l14i6JFsVCBAgNPfz78jER7Hn5TrZ9TOP5+adIBgrK+PA1NPDweesTHua9dQyVRKIaUF7fQ0jy8BVeVxF8PkLTdG9avx5FN3oVw+BVdffVVVx9BjHvOxDVa2NtOlaJz8ZV4FIKxj1RBX5/UoWS07D7ScJSaNBUqoHMGEuY5n7+5YBF96GNj0EU5UB39ChspoEUyBsHSPbyHb1Xc7X3dMtiFZjtjm2flhh74urKJUzFhe+8O1mC+TOH0uqOzaTXlkaZyTa0UDjn5neflFxzpWwoBiubGUPDLZbzWwPNnhrOc7SkaonAYyrwggEhSW7pp4Dl8kEOm9URhtiGtXmgBSTwPlKQGkAsJ1ENwXLhcNwj3M/7JyYpGgxPccE3z2FKD5dDKxks2CQjCmBcmSpfcJBitIZsrM8HO27dM00NAjLGRcANB+Hp/J0hSZ47a3A4dvIROsBgjaCsPChn6ZbOwqPksvvvgiTj/99BVtcyVycSvHvL4+AphTTxWO/8L1T1UJjirVEf7FTGkNDwA338w8qqefpmlTczMBl1wsDAS8hcdQiK8lkxwbpVNhNdm7BJaaBvzkJ/Nv24hGVIu6gdbw8DD+6q/+Cl/72tewfft27N+/H9dff30DZDWiEcuIWgYawSBZqfXrCW7SaTJZH/848LWvcfUvFpublFs5CN1xB3D22RwIZCJvNEqZRX8/99E0slmaxn0SCa9v/tW+DRsoS3zuubmAailM3krFqH41unAXduz4LRw9CnR3HbtjV41qbEO4hyv0w/exJpDRBOSqTHDDPZz8Df4MSAOkBRTBMtnCSS1IYFXOMLeqlBKr9nKS6nJyaeWAySfFpBdisqkC5RQfAJQAtYUGBuUUJ8tNp7BmkJXljEePMG9Gj3lAK9gOKK8J+VcFyIJKeZiVowHHxGMeqGzeAUw9x74XxgE9SFZuuflFxzJW0oBiubEY2Zq/33qErNNiZYd+oOZ/vgOChTWnCUzMrHhWHebyQQHyw8D060DyCQ/AWGI7RRXgqewdS9YrUwN0q9SjPF5uCIDlmafYRbZfGCbw0sIAfAsO0V4gdpKoEZZkm07JM8MY+ilw0q8RBJYLwEvgAkWhn5+h8X3AxBP8fCgBtqlqXPDQQsszvljFZ2lychIDA4O44YYbZ15bLhO1Uq66lWOe49CQ6bnn2E4qxe2ee45fd2eeOVcd4V/MNAxud8cdVGeUSix/cuQI204kmIfc0iK+9uBJDDs7udhYS/YugeXwMAHW1BSl821t/DnWEvlGvDGjbqB10kknYdu2bfjud7+LK6+8Evfeey8+9KEPYWBgAH/0R3+0mn1sRCPetFHLQKOlhQBKGlak05T5NTUxJ8uflLt79+wBVA5C2aw3aMXjHHAyGb6WSlF6cfrpXAUcGeFgFYsR3N11F7eVUka/M9P27dUH7ONpUzuqX42pqSnkX/siHPsMnHfecZywV7INRgvBzuF/Y4K/ogFFjZNJRZs7wQ33AL03Ac+DhhRmluDKtZn3Yk0TFBkJ5la5pk9+Z4GSQKEDDbQC6Vf4lhYiKybzXqDSZEOPAUqYckQzQyYq/TK3s/KcEOeOeBLENXv4+tTznKzKOvWuw7aCwsZ9/FHmkRltBJWplzjBVnTW61J1yiDD3YvPLzoesdIGFPUcbyEQtVipn9FGlqicFrJP1Cc7rAQFzTv4emmK+XgdFwMDPwRSL9BZUgJwK8tnNq8DB/+ZgCm8jvb+pXEgtoWSVVnweqbPJtnccDdZ28wrfJYdi8+OY/HcVYO/A808ZnkKgEoGrDRBIKYGKa8tTjKHUQ0ClgBdqRf4bMc2iyLDLot/F8cJRl0TM7XT3DKAIH/rTcDaK7z7shTjG/89yfWTcd5084pIaS3bwp49l+Jtbzt95vt9uUzUSrnqVhvzdN0DQQDHIsfBnJpW1UJud/Ag2yqXgSef5Jg1Pi7rSLKvZ57JfUyT46xcSKzlcCiB5fg43wPIgu3fz/F4/fqG82AjFo66gdY3vvENXH/99TP/X3bZZXjwwQdx1VVXoa+vD1/5yldWpYONaMSbOWoZaAQCHAReeokgKx7nyt3Pf0579o99jANcOl1bX55Oc4AFgBdeYJttbRxANm703Jc2bgRyOU+C+NJLBHfbt3tSRv+q5Yla92NgYAB/8hdP4e///kaoT+0DALz93OPUGck2WFkaTBQGaZteTglWqAuwpoQ1epWJlaICcOnyVwwKMOMIAFUga6SHySJMv8p9wt0EUnDBlfcAZia8igpEN3CSDYUgRzE85mDfn3PSDBuIbGRNIEUDAh2UfmX2sw7Rmj08t5M/znPLDwMTj3BiWp6kQUGoE2g7Hxi+hyBTCxAM5Po4oc8PCBbD5D5WBmg//4Syxa4aq2FAUStWku2o1m9FIyC28gvLDqsBTGB27TPZppWt2NkCXEXUbSsLoNVDqWpxHLDSrGllThE8ybxAKwdABUI9vBYueP6hbppnWCLHUAvz+ZL5X6VJriHAoUywOEpWVwHBVHGU0kGo/Py4JjD2iGBpY2yzlBIMsinqwNnM28oc4GJFYA3QezM/T7XuVbBj/vvsvycyBzMnHJN7rlw2s9XV2YXf+dTvAOBaxkowUSvlqusf84aHOQbl8xxT1q0DDhzg/1Jh4XfMrRaFAmX0OVlRwiaQymRItO7fD1x/PbeT51EuewuFtWTv2Sxfa2oCRkcJ3GyboDCfp3Nvw3mwEfVE3UDLD7JknH322XjsscdwxRVXrGinGtGIt1LUkt0lEpQPtrVxUEulgL17gV27gM2bue0PflB9AAUIkGTKUibDgepTnyJb5nd6SiY5gMoVxWzWcznctOmNI4845ZRTEA5H8MQTT2Dz5hvRZd2FJ586jmBLEcn65TRX53OHPUkVLK7QB1vnFjh1beZfISKS7kuUGhbHhFRKY80qqMKNzRC1i4R0yrHIGjlFAbxUIVU8KmyrVUCNcR9VY7uuy0m4OU0mAADg8D2A++T6ZjM4RoIPaXyLmDimgJH7ONmefJyT1Kl9mMnj0sJikpz1JudqgH1teQNI0FfLgKIyVpo5UwOUCxZHZ/e7WpHoakCwFsB0ygSYrk3WNL0PHr0p8qRg+15TRD2rl8lAKRqfmVLKq0OlRfhcGgl+IeUOe8xv9rCwj9cBPQ7ETyY7Zgnpa2gNFzQcW3wOTB5bUcRvlSBPAv1AM5mv1NMEaME1AK7jvXHbRCFjiDpeLp0811xKUCY/r9XuVf8Peb3L6dr3WT5LuX6CrHKS3wXFsWWzpLZj4xe/+AXOP/98vPRSBKXyyjBRy3HVrYzubuC661hk2DQp9xsaIqApl3nLVJVjXiBQ3YZdSiHle9Ipt1DgvoYBnHQSgVp/P/DYY7MXJKvlfPnHXz+wVFXu29rKnzVrmBNWrz18I97aoS63gd7eXjz66KMr0ZdGNOINGbY9v6lEPSFZIn8Crm3zi/7wYQ445TIHpUcfre4K6NeMFwocuKQVbTRKgNXS4h1HDjDXX8/VuVCIxwuFOMfJZAjGmpvfGPIIwzCwa9cu/OIXv4DruhjVrz7eXeKEKpAg61SeEuBLITgKtgGRtd5E3bWB6deA17/B5HuAMr7oOjEBLnEV3ogLG/cIcNLHgJYzRH6W4U1KnRI4yXX4Y+U4OdZERriTBTQDiG8VE1FbGGrYlHTZBR7PynmMTbCDbVhZHt9Me/WHtDAw/gugNAaoYZFP0z/7WkTXAeH1IBMR5LkFW8kSjP6cNbaKI8fgpsArYusu4kMrJaGRdby+iylk7J+Qq0EPPFU7fiWwMdo85myxURwRxg6TnPjLQsSySLTMvZPb9t0GHPrG7HshQYE5SRmrOcn/tTC3OfIt4NC/EOx4OtLZ/XCKfE3RuIhg5+lUmNgOhDqA2FaCp9IYj2EXKZsNd3EbNUCJX34IgMPXjQRmbNzLU2R7Oy4EOi4gsNFjBPAtO4DE27i/NU2nS6hc8MgfJSBzLWD8EfZVAr/mtxGMaUEWPl57GYt++xdF5tyrFiCzj4sS891n+SyFutj/YCudPQPLuNcinnv2OXzhC4/h/vvTGNWvRipyNZqbuViXzfL3Ur/T5Zjxa7/G34uRH1aOk+UymaG2NoIiTeO4o6reAmFLC9+XhhcyRkaA224DvvEN5mYBBECWxfEtHKa0zzS5FvToowRMwaC3IOkfr/0qDdlHTaOqpLOTP11d/Nm4EbjyygbIakT9UTejNV+0tLSsRDONaMQbLlZC+z5fm65YkDUMShi6ujwpxXxSDtvm/9J+PZNhO5WDg6ZxQOrsBA4doqOgzPMyDA4q9axaroTl70q0+653vQs/+9n92L9/P0499dSV68hSQ9GAjl2sOQWVDJVtkg0Id3sT9eII0P99YPxxTuLVOBAE0Pdd4JTf5GSv73aCGMkqlNMETmvfSwe10gQnn3aBif1QQfc2m3klWoD7owWws5zYbfwI8NxnhMlBUEzwXECJC2ZMSBiD7ZRT6U3A4W8C0wfYh/h2urZpYRpcGC3sn1MG7D6aawSEy6GZYV/CawRIK/Na6GEPnB0LU4zlyPKWWjdpMbLD5TJnMirZFmlksuG6uXJVuW1uoLpRSzWHQ0Ds08dnRQsCju7ZsashwMnJAwCwaSjRuoPARj7LdoELEXZJbCoWBuwSWSo9KoCazX67Ju+hOc2FimCXOLc29mvsF3yuFBWY3i/cDEVOlxYFlBTI1o5yEUSPAxOPAwhwRmTnvIWQ9vP5+ZX5iZVRea9K4/wta9bNd59D3czJAgSrvIx7LeLJp4Af/OAoOjo6oKz7OLu4gkyUbG+x6oZq42RHB/8+csSrmZVIeMWIy2UCp3h8NiisNOUYGuLrv/VbwL33ct9UisBr7Vo6D95998KMXmUfpfFTNsu+3nCDZzzVkAs2YjGxIkCrEY14K8ZKuTDN1+bEhOcuKHOqenq81bhaA+iRI7NXDyXjJetv+UPTgD17uLq4j6lN2LkTuOwyoLd34XNZDbC51HZPP/10XHrpHgROpOXGaC/zm3J9nICVJ71JlhrgJHH4PtbqcUqctDp5Aq3yJCezm27mqne1ybeVZV5UYZATOiMBAiwLs5iF8hQn2m6R8qqplwDlNhaXtbI+kKXzt6oDSoTHhU1glx+g26EsYiz7rMeB/BGyA01bhbNhmTIxI04wZZf4frBDrB7EAeiCCVhiztNiYzmyPL+sbrH9Wwx4Wop1e7WYA+4cr0B0JdCyC8y3K40TgCjCZ1sW9w11E6CVUwTOasArQK1FyUBZee6nRT0zFug8rizCrahA57uBycfoFAibIMt1MFMuQAGfyeI4kHqGLp1Wmv10LT53Vo7PsH4qLeYBX+mEMQL+6Rz7FDCEFi0AZF8TuWAhYaYRZZFj+OiN0gQQO5O1vwItwsGwRlTeq+hGPt9miudS6z77n6WeK5d/r0GQVSqV8HffyeD6638Nis9JYqmusCuxgFYu17ZFv/RS4L77CI50ncDolVf4t6qS4fKbZAAc18bHyXZFo5ipl97c7OUuS9t3CdAWyi2rNpa/9BKBX3s7+/7QQw0r90YsLRpAqxGNWGKslAvTQm1K1imf5+CSzwO33OKBj8oB1LYplXBdJgkDfK2722O75PbymB0dtI73V72vZ0BZDbC5nHZVVcXv/M7vLP3AqxHSqW9mMrbBk24BYkI8AUATLEAWIqOfk0gry8le96UEZMUJ5pp07eZ7Q/cC2UPMb3HFZFrVhf26C05eA2SQiiJnS1HY5tgjZAgUlTljZpogymimpAkqsOljwOQT3L48JUwCdECJMrdk/AnKwCIbaYudO8zzCHUBZo4A0HWEw2KZUjEtDKT3i3w1m+DMKS5rNX9OLCbfaCFwt1xzimrgqWt3dWbMtdmXajlUiwk/uLNzBDSqQXMWaWoirxE0r9CwERdSwxRw5Db+37qTLpPFCdqtr9lDQBFICDYIAFSCaU2hZG/6ANtRhS06wEWA0ftpLGFOA/oA34ttEW6IST6ypQnQpt0SuVJlMaN2RA5WiP9PPUuQH0gQ5FhZ3ltN2L8HDEoHXYft5I+K51oDjAivqytqcclMCsfkdXItr57WfPe8kuUsjc8PnKo9S0thSUU8+RR/j+pX4+cP/QzlchkXX3zx3MdhkUzUUha6KoHZyAhB1lNPcSyqtEXv7qa5065dHLMmJrhvby+3yeVoZnHkCPOSBweBn/6U/xcKnswd8PKQ5Tn619oWYvQqx91ymfW91q9fubG9EW/daACtRjRiiVFNuifZJqnxXok2161j4nChANx5JwebSvDh//KXboRbttDoAuAK4a5dsyvby/pZjsP9L76YycOyjXpWMVcDbC63Xdd18dhjj6GtrQ1dJy+9Dysa80nOtDBzM3BA5HDBs7rWEyKPKexzdHM5CR64E7CKolCrwwmxa3O1X48DbphAR3HFj0h8cAp0gpMTV1mc2C4K+ZdJQGXnCLgmHyerUBwHzKQoGlv2GDDVYDtmBmg+gxNoqAQy2cNASdQCUxSgNAqkxbEUhY5zucP8ad05e1K6nGKutYDRUmR5K2VO4X8GzDQw+sDc/lXr91LZPQnuhu8T0lXwehcGeYyu3V4f9AhZx4BgLxWVgCZ3hDlTow8JFlOwQlaezpN+WWygVeQh6pTdKacCyac8SaA0Pkm/Ilglnc+MonGhILJOsLIin0vVhc93gfupISGrDVDmKl04i0N0rlx3LZB5WdzbFsw4bjo2UJ6gcYY5xRwxmeeoBgn+zAxmgJYaBNZcyWtTS0pZ7VrL+zTfZ32+Z2kZLK7MR21v78AHPvABdHR0LLktwFvo6u+ndK+/f+GFrkpgJq3TR0cJsuazRe/qYq5wNgt873vAM89wXHJd/jz6KKXs//iPHhjLZPjT28s27r8fuPpqslCVfVyI0ascdzMZrxxKILB0h8VGNAJoAK1GNGLJUal9r8Y2LXYFcD6793KZAKoa+AiHvd/hMAelffu8gWHrVg5u3/mOlxT8xBNMFjYM/n7oIdYZicX4fz3nsFKWvyvZrqIo+O53v4uOjg5c/EdnLK8jKxm1ah5J8wlF48TRaAP0Zr7XdBLQ/W5O0AZ/QvmhOc0CrNCAlrP4npkFJ57wZF9aE9uVLoTBdh4jfwQzUi6Av11X5LEAgCrAmMV28kMEQpZguKSLoFNkzlagVdTcmiYTEd3I9nKvczILlxNOI05JlZkFNJ19KQwJ9qsdWHeNkD1ieQzSQsBosbK8lbB1lyGNQwZ+MLd/G65bPKBbCIyGuoG1V7E2lBEX9yBL5mroHiGza2OOkFUgQNIigPki779T5v0pJ8mIhnt4nzP7CPz9slg1zPvpOiz6azR5Zg9Q+LpdEPlWECYUDq+paxGEt72dNbPMrK/em83nMNgBGrsUyFgB3F+Ps93Us8Dayz3w2HymYPJe4bZGgvcrUCTrC5sS3bVXAMM/BSzxedj860CkCxiolFJq9d/zWp/1lXyWqsSZZ56JM2WxqGWENFOamKBsTlU5NtVa6KqmQJC1Htvb+bN//1xbdD84Mwy2NTlJJisSYU5UVxcl83ffzfeiUQKgksDvcjHxoYfInG3fTtn7+vWepbtUaNRapKscd9evJ2h77rmVyWtrxFs7GkCrEY1YRsiVsmy2NttU7wqgBDX12M0CHvhIp2nz7l9JlCFl+qrqsUQtLTS+sCz+mKa33dNPcyVvx476zmGlE61Xqt3LL78cX/nKVzA62gWga3mdWc2QoMBMkQ0qjdMsYt2NwEsANnwIsMaBw7eyHpBVpFugLEpcGqW9+vRrADRAU4H4KWSgzGkg2MnJtLR6V/0XUOalKAAcIZdymN8Cm4RAeYrtOiBYk1bZjiMYCg0zbnKqRpDVchaLFZdS7INjAW6ekkM9BrSeS1akOC4m/hm25XdfXE4x14Ums37GQQ0QTEj3xGqxUuYUC/WvnFrcJLweMFocIaNVGABypifRDHZ6MrtZtbXahKGDQxBiinpUUmLn2piV9ydlscP3AZN7PWMTM8PnIdRFkFKcEI6F495+ThkE7RaghNj+2svJ4Kb38b67JplYPcq/w51keXNHyH6pQcHEJcT5JGbf277buUAQ7CBYtHIEeJqUM7q8Hud8CciPAwcBdF4EKCYXDYoTbHO+mneLiZV+lnxx1113YcuWLdi2bduy2woECGCSSTJaEgjVSn2tpkCQdusyN6utDTjtNM8W3baZn9XXRyD2/PPc74wzuJ/jkK1KpWjWND3NvhQKbNtxMFPvCuD/+TzZrxdf5GJiuUw1x/btHttVS6lROe4CwAZRKq1eKX0jGlEtGkCrEY1YZkgmqhbbVO8KoB/UVFt9qwY+/JXt/SuJpRLZqaYm7lsoeHbxR454xR0Bzp1dMXeWoMu2Z2vp55PrLTXReqFYTruXXHIJ7rjjDvziF7/A1VddtzIdWo2wsj63vjhYG6uAWcn5I/dzVV0L0RwDIVCKp1IaaOTojrb2Km7vFIG+/xDs1YAn3YNbO7FfiwBtO4V74ThBnGvzdSsDqAqgNHGyKyeqoTVs0y4AreewD9Fe5rWUU7TlnniC77sOJWSBZqDrnQSWjsWfQMvsemLLLeZaz2RWFtethzVbKXOKqv1zeL2jG8V1WKDfMuqRM8ptCoOUDE6/Sole67nAmveQ+ak81roP0to9kuM1l4WDjSZPMqrozKmS/Qp1895PPCmAT5R5iK7Ne1cYECYZIf5WDbbpWkIiKxwJXXAxofsStmvlhY3+Brahaqx7NX1QLADAY4JDMU9iK9kkKytqWXUx19ExRcmCPLeRjFs5zecs1osZEJnrE2yszd9GonrNu4WiknFc6WdJxPDwML7+9a/j5ptvXhGgVS7z+980OS60ttY2UwL4/ZxIEDQ5DsGRf3yamiJokeoMgOPQ3r0cazIZ7qfrbGvrVpY1yedntyPLnFgWgV80yr8BLiAmk57yw7K8cfTpp4HXX6e0v7W1tlJDbr9aBk+NeGtGA2g1ohF1xnwOTIuVui01B6kSfCy0kihdB/v6gB//GDjrLIKq8XGuDuZyHMwAz0reNIEDB7iKuHFjfXK9pVj+rmYYhoGbbroJBx7479h/YD+2nbL8yceKh2Qb/G59lYYQEnQE2pnHVZ7ia8F2AXh0TtLX7KG0a+R+ysIKw2S+SpNCgiVLJjpz+6GEvL+dknB/07wHItAqiru2cJLrlDmhjqyjxFCPAXCBwR+TBShPcWKri8mtqou+J/ne2MPCrEPkijkmJ7LynGcVcx0nuAy01V/MtZ7J7Cyg0gJkj/Be9N5YW4K3DMOCqv3r/yEleIDHuNQ7Ca9HglYJWNUQgZNr8v32C8g8ltM+y3abQCS8njlN6X3MmWo+jfeslCLwsPME1N2Xsu8Tj3Nf1xby0DTvvyZYT8dknmCwk/1KnMbFg8IgwbweZ22ssgA1G6+noUbyabJj0fMJ5sYeIktqxAnY7BIBXHTj3Gsln6Ppg8BUUtR4M/jZMWIiZyvlfd5ska+YGwAOfVWUIFAEg2ySaV4M81SLcVzJZ0nEt771LSQSCVx11VXLbgvgd/6aNRw/mpoIhNasqT0WjI9zHBkfZ07W9u0eOKm2WCYNm0yTf0vjC2nvXizS+faaazw26dJLuW8i4TnqxuPsG8DFRVmsWEodVZVgbHyc22/YML9SQ9b6uu++xalTGtGI+aIBtBrRiDpioRWuxUrdlpOD5Ac1tdrZvRv4+c8poQAImAYHOW++/npg2zYmHfvBlWFw4Jqe5mAZCHCgO16Dy3JXFS+66CKcErsam0/avFpdXHpUYxtmGUKI+lV+9sNoE85qeU4Og61ejR+ATITcTg95crQZcFUFZAGAWwCsEjD1MieirTs5SSxPcXIdbAFim5hDlOsDhu4Gpg8RIEY2EKSYGZHTY3Iib00R8ElHQysvaivpBIHlKcywcpX9kkCk7z+AwoszhnXQQvXnsyw0mZUgRA2x/9Y0maWOXUCsxvNSK+9mKRHsoAFFsIMT/9K4B/TqmYTPx9pJFkUNCMA6wPbLKYLm3FFg/xdZg8poBrrezcLVstSA/3kLd86u93T4FgA2wZBk0Xp+hQCpaatwDkx5TpmacPZTxHOhh3nergM0nQxE1gPlcSDYzWcmsm62UUggAfRcwWfcLhAoGnEuSMhzbTlrrqxUXoOOi4HUiwRZiips6XNCMlryAGZpHBh6EMB1wGv/DJjCIt7KiGc4zmejXlC0EOO4gs/S6OgoHn74YXzyk59EUFb6XWZUy1mqNZ5J+/ahIU/Kd+SIt8hXbRFOGjZt3cqxZnqa48+2bRyL5PiZSHj7+EHboUMsWJxO0xIeIKCS7UQiXGgE2B/L4sJhSwvHtfnqaI2Osv8nndRwHGzEykQDaDWiEQvEfDI/wFutW4zUbSFgVm/9klrtdHcD558PvPACtxsf56A1Osqf/fsJXjZs4H6pFFcuZTHktjYOSs89x9XJYw22VsI2XlVVnHnmDhgGYDs2NPUYn8R8UclIaCGClbVXEUDZQsKkqLNt3ZtOprRKMkBy4idrGsn2rARX8hUAMDwXw5qhcUKpxUUx5bVsUzVo295+ATebfIJsRmI7J6eFYWEJHyZ7JgvDqrpwMQz5JrcGpVqBVu6XOI3yLbsoZF0+ABVo9QrkuDaBn5Vl/ky9rMJ8k1kt7FmTy7wjRyfDU6s47UqGXSA40WNAtm8u0FtoEl6LtfNbiwebgeYdtNTP9ZGRjG2iS6WZYT5W5gkg9bQA+OK56riYbVjZ2aUIsodocuHYgJknA1WaYn8kOIv2EmjpMUoMC4Oyw4AqZKfhtcyxytpezl85xeLXHRfTpKM4Sha3MAhMPMZ2tTA/G+UkUAafu2AHsO7q2SDLzyTpEQKzYCtBH8DnLdRJ1izYztf6bgMKYmZuTokVKABGKw01Ws7wFjTqvb+raHrhj0ceeQRr1qzBe97znhVtt57xTNq3P/kkWahgkGBkcpIS9o99rPp+/gXC3l6OTxs3Ar/6q2SoJCCqDAnaTj8d+KM/4jHbxS387d9mXw4dIlhra+PrhsGxTSo4/IuaksGS+WKHDvH4sujxOeeQKWs4DjZiOdEAWo1oxAJRS+Z35Ajw2GNzGZd6V71qDWQLMTmVIKxaO7YNPP64t6o4Pk45oK6z345D+/fWVg5ohkEgNjLC16TM/3it5K2kbfxdP74LDz/0MP6///f/QVXUhXc4FlGrxtHQjykD1Dsw49QmQzI71QBEZd7P9AHmP2lhkVcjVvABsJBxZdjeSn90PQ/Wfj4Q3wZk9gODd3PSWpr0Jo+uRbZEiwi2ShNmHUFR2yggpFLtrMHk2mQwrIwwwZjiOfvlWwAnyoM/Zn4XHJoQOCYBXuvbF8cq1GKGFM2zJnfU2fk6q1kwWUYtoDf6IK9RPXlAkrWTtv9amHI+P4sCiG1ytFVP7yNQCXYIYGzz/KdfJaMZbKE8UEpFO97l1dsae4RSPdehzb+V5jOixzzQVxzn/Y/0Avk+r6+KqFNVmhD2/64ANMI1MLoegAOMCFMNLUxHSy1GZlTek26hHysl+f/ay+mEKKOSSSqOCut2EMzKgtyhTs+Fc2aRohUogs9mWXwWzCyv1dr3Lvzc+Z+3VTS9qIwrrrgCa3aeA11f+encfJJwuRg2NsZ6VpOTXlkTKe+r9X1duUDY20sDpu99b2EFQ+X4uGcP60A+9RTli729HOsCARprvOtdZLhkrphcjBwfB374Q7rzOo7Xd5mTlkwyr+vtb/dki9nsyuYhN+KtEQ2g1YhGLBC16mU9+ujyddyVA9lCTE4tEFbZjpRmnHwy/y+VKPEIh/l3Pg+8+ir/l4nLH/wggdjw8OyE5kDg2A8wK2kbv2nTJvzLv3wVjz32GC7cdeGK9nPJMV+No/4fAloCwHXAkW8Cbk4k5LfRTXDwx8C693OiLid/foajMM4cqlAHJXt2kflbaoASreKgl6czEw7BjGNzgrvuGr48eBeLvAY72DczK4CBQ1bKLVF2CFc4ExoAdAEkmoDYOkoO8/1ePlCgjUxXro8T4cR2L7/GtXlNMq8JYGiBCFMBHAUYe5Dt+ifX1cLPagQSnsTSP1mO9gIt59CGPtTNif9KT4Zrgb1KoKcFCYgn9/Jc6zH9AGYzWHqEQMZoEa56LXxd3nsFbFsR+XGWMKLQYzRVMdOU5JWStINXddZB2/b/Z+/Nw+Sozqvx0129L9Oz7yON0AJIgASIRQgMCCMTMAhjG7AAL0mwncQm/jn5viTOFwfiJLazx1tiEyeYLYA3MAZkyQjLRiBWSUgIbUgaSTOamZ6Znp7pvbu6f3+currVNdXLbFpwneeZp6e7a7l1q/re99z3fc97D5+hyBvymgoODgYNKzQxCh3pO/oU720+y+ewkOU5kdcENfLavQZYSiBNEhTdrdXfsrPwdeIIt/O2s00An8NqQkKNaoq+TiC2n+9rFnMxQ+x7PCdQ82g5A4C9BfC18bdgJHNm99UsH2sWRC+KmoAC4vE4vN4A5s+fnfDocpEV+sWw+nq5EOZy0YNUX19+vNYvELpcsvRIufnUbH7cuJF1JqNResIOHZLiTv39LGOydu1ERcFHHqHSoapye6Fk2NzMz9rbOc+vWcP9Hn2U1xgKsSZld3d182G10SkW3ruwiJYFCxVgFp532WWs63EiC/V6vdWH0wmiIuLUnU5+Vl/P9yJZWKg6XXutVGoKh/m3eDFXGR9/vPo8qWlNKnkVajaJZNoLr1+ZMdn4ROIcXHjhBXjkkUewYsWKUyeE0NNKQpMeoldISJ2P7dI8WgCGXgHy48xDsYFkZ/QtYGQbUHsO0HWzNMiNxu74fiAzzv2UIA1WaIIEmRFQwl0jTVBo4NrAIrO5cXoexnZrYWMH6X2y2ekJGH2bXg27G3D6gMwYgCwFEADAVQME58uws8B8emqSA8CxdVodI4XniR3SjHcVGN0JhLdoOVzCm6fV/MqngfDLmvH/x6XJVj5DOfjUIAnd0MskNPXLaWC7m2TRYDXJsDURumZmDE+1cHJqEAivL61qqK9BlR4hiXXVk3yKfB6g+Nz6tgAG780g/2KHZO5brVZTKZ/l/4qH54ofojdJFBce20OvXkHX184gvV59z0mvolDlU8f5jA6/zPsvQlmdISn3ngqT/In8PMVHEpMeKj6W3cHnVHHLe5HPAqKQdjYK7P0Wn19nCeIjUMqTNOc29hughTUaSG/rtczRSgEInAG0vW9ieO7x+2ogVaLws1k+1gyLXujx5htv4uv/8A/4vd/7T6BpRg8NoHJkhX4xrKGBoX+JBPO5hLJfpfFaLBDGYtVFMJjNj9EoX0MhYP9+5mkVCiR7TU3Fx9ELRg0NcR70aRGlNhtDC2MxhhkGg6zh5fUCP/sZr9PjYaTI669TrGP16vLzoaVeaAGwiJYFC1XBrMbGiS7UO5lwOkEOX3iB75uaSILEJORwABddBNx8s9z30UfpxVq8mETL6wW2bq3eazetSSXZj9j+DTh2eBSj8VocVa/Fiqtbpy0bP+C4ES25p3H++Z/Bf/3XZ7Bu3TrccP0Nkz/QdFDOUHcE6HkShmGqj/ZnLs73ig/IjTAUUPHSkLYpNIRHt9OQ1Svl2RRp7OazJDbOIL1GhTyJnLcFGDsI5CIUzbC7gMwQjk8HmShDzBQPPRxC4ltxaiIIvZrYQY5LwM4asNF5Kaudi1Eq3KEJFsQPAcd+AYzuooqgTWHbHUEa/od/zM+GtmjnE7LfeuR53HgPt1/0RxOVBOOHGH4nws9sNhkeF++ht9DhozGf6OP112j5ZkKcQo9kL3OGcjHm+UymcPLARiBlML47P8LQSVcd+71tNUlhopckK3QW71MqzFyq4S3F+Vaj2+T7xssM3ps8vUDIQ6pMwkA+GuiFbFiuSbK/rIUS1hWLjSheUPSiRiO9dopdJPt5nEIe8LZqin5vU1hD3z+t1/A5GtulqfepJMBCMTMzCuS1+5tPa8p+Bcq4Hy9BYOP9yEb4HOfT9LyN7aWXzYxslcpds7tkOGZB5f3U/x49raxZFwFfHSUGGzORC/F8lMrHmoUw1Gwuiwd+8ADmzetGbW0tBmf4+NXkyBoXIBcupAhTuVpVpSDmvSNHpDz7nDkT51Oz+bG7m/+vWsXcrHCY85sodGw2L3u9zO3at49zorieZcs4j8ViJFXLlrE9ov6kEPmw26nkW24+nIk8YwvvDVhEy4KFKmEMz5uux8XM+1NOJGOy4XStrcCtt/L/P/gDrsrt0tSkFy8GPvABqepkXFG023l8oDpiN61JJa9C7duA4aNHMTregHr/UWSiG/D8hrW4fa0y7fywAceNsHcBF1zwJl5/3Y4brp/e8SaFSkVljVLfBdCrlBkFXACQ14z/AgmIzUmDVhR8TQ0V5xQJUuduAlpXA2PvcJvhV3hgm411hRQnkHMAUJlDlYtJ4QDYeZz0EP9HVvNmOUgGxt5BEQlKHuNx7B6SOpud3pncGPN4RDHb9DC9FoW89C44Fe4ztg8opGhM2x2asS3OYaJMOL5fFqgV/SzCMPMZ9lN6mO1SfAw3dDeyj91NJDrpISAfIoGAfWJ+VvwwsOcbJCKuWs0LiMry8gKZaLHxPX4AeOuvZLvn3QnUnisV/ZL93Cd+gO3ffz+JqqeNXrzIDrbbpRn44c0MixSCE+kw+67mXJIIITKSz5iTD08r73nfOl7z+AES64LKV9Sx3zzNWvt6uW+qHygosr12G72VscN8jrvvBPqf1/rLoZFd7R7mErwf/nkMSYWNvwvFp4Ub6u+zVmMMYP5fPiPDI/vWAWd8cvJS/OV+j0Lps1wep1loYi7G/ksLMY3Zy8cSeOihh3H06FH80z/+E4ZHbJV3mCSqXdSbqRqKguTs3AkcPsx5admyiccrVUsSYMjfHXcwrG/zZpK1UvOyotAblUjIOfGsszjv5XLAvHkkYNu2AWeeKetPlvOWTbUPLbz3YREtCxamiOlMMuW8P2beM5EjNVlyZ7dzYmhrA+6+m8cBJla6L5WHBtCjlc9LZSgzYqefVPx+rgKOjFQ5qahJ5JOjiMQbYHMEkC4AdcFRvH00iWQyMGOT0vkf/DbaC8/i1df4/uKLZua4JVFNUVnAIPXdpCn5aUab3U2DztdJ3jHyGg3Ngpbn4vAUi0jo85KEUVsoAPk4YPfSQE4d08hHSEv2b6SyYPIISVhuB0O5CnkAKg3PfFYLIdzPz6CJG4jcLmeQ2+fi9Jp5WihycOSH9Mzk0zIczFlHozSfAuwNrLmVGcXx3C5Rpyuvoli4w0aD2+GTwiD6fo730MumZgGnm6RQyHp7WjTiqPW3M8jrz4xR/EEdLzaOk73A3m+QDNhdUnBCL8xgvNfHPUGaoe7wAWkdCYodZB85QwwPPPgwsPQrPH7DxZROjx8lMak5i0RP9VBgJDvGHDJ3kzTwM1FKnw+9xHvunys9QFCKRUYUL2XYAdn2bJSEKDXIY+WT3M9Zq+XHFUigWq/hs3ZsPZX5bJpISyHP58rm5/bje4HRFMM/1QT7Q9UEWBS3dt2D9Fqlh3lv3Y0Mn8yM8jkRYayiYLcgV2w4z+Pw836UEy0xE4yp9vdYDqVCE0X44CzlY+mxddtW/PSnP8WnPvUpzJ8/H8MjM3+OySzqzUQNRVUlqamtZeihIDlmirfG+VHMcfk8P+vu5l+lebm1tXhOBIAHH5TESMjAZzKcZ9evr85bJjCTecYWTm9YRMuChWlgKpNMtWEZpSrUT5XcCTWoUt+ZkThAKjMBXMULhyeGBIpJZd8+riSOj3PbaLSK/lG8sHtrEXQfRc8xQPEN41i0EwXFO6OTkqIoGMCNeOGFF9CSexrA1bNLtqqVeBZS3+4WXQK/nxLWniYgM8BQN2dQExcYp+dC8eG4UW80IuM9NO4DCzWRA83TVMiTfDgCPG8hB0TeItnJ50g6vJ3aMfP0iqhJCioIQxzayr8QqXA3AN0fB/qeYl6Xp4XemlSf5mHKATntGGoKUMd4HFcTPRvuehrOozs041TzZDkCPHYhqwlv5AFHLaA4GO6neLlfQWW/Kn5J9DKacl7defQIZcdY88tZq9UW05QGbU4AqjSWRf2pvnXsC7uLBDGX4HWElkz0VBi9JDUXADibZCIzqhn9Xh7bZqfKpOJlO9JD7K/wZi3PLQ8UbNr9DvDYjhSOE9v4AbZbkCh/t6wxpXiLxTHKSb5HtgKJY5qXqovXZnOwfa5aXi/y3GdgI/fhw6oRN4eW6OlneyPbSK4UL0nkcbEVzUOl5jXSpRHnfArHBVWSx6RwhtGT6e1kPyR6gfSAtsBgl7lbkwnLm6rkujH0t5R3cBbzsfRoaWnBmjU34eabNcGavMoFE8XLhYgZwGTrQk4XRu9PqVpX+vaJz0UViCeeYN7VZMLW9XOiqpYmRoFA9d4y/bFPZB9aOHVhES0LFk4wzEIKRkY4SdTVSXVAoDQhCwRkDZBShEuEJopk30pobaV6UyQi65ioKvdvauJfJGIeEqgolNLduJEJxV4tPWbjxsrhg2pBQTx4LSLpDXA5RtE/3omXD12LjvmzMyONjY3hX7+/D39dfweAvtkjW9VKPJtKvQfkd66Q5gUaoJHZeBmNbeElEmF4xnyddJheEJvCED5XPeDy8xzZGJBPaF4JOw1cZ4jGcPIYvV8ODw3uVBawaV6sQp6vyPNP8QA1ZwKJg7w2uwdovx7wdQCHHtFC13Kah0QfFlagl2PexzVD+ghrM41u5/HdjfzztpMExnspF+7rYj5Q3fmUMhfeO7vCsEA1JY+f04zeObeS9IU3kwwI8hNcQHLlCNBT0/+8VtvKx75z1miS4GD7Pa0UYjDmhRUR3KPAyD4A95LUIUkiCbtWWyytheZF6Jk5tgFouoxtF/2pJkiGvZ0kgnYn2+jv5jOgJiZ6TQRR8LRS+CETYZihTSkuZB0/Cgy/yX6y2XThkn6Sbjg0b1ECsId4b+JHgMhOKfkOcNuAltuWHQeSfdpz3MiQwkKax4IdJFeG0E/hsUKB9bkaLuIxk8eYn3Y8zywvc7xE6KuQZO9/vjg/0QgjQapU5DmXBGAYLEuFGpqRqpksaG12OSggk86gva0dv/97v0/PfDrCvL3xI7J93plRW5ipsMBS0IfOl/P+VBJYyuf5WPT1MaRvOgrA5YiRogDz51fnLROY7T60cHrAIloWLJxgGCeV3l4WXvyf/yHhCoUYPrFyZekY71isvPCE8ITF48CnP031wZYW8/YIwjY4SEWlaFQeMxDg+5YWmbtlttKoqlRistlIyPL56sIHRTvD4VYc7lmLhWckEQh50TFfQTY7O/HsN954I7Zu3Yp/+7d/w5XfvB7ALBlHpVa/zWo6tayiultEqzDt6wYSoAejZr4kT6kwDUTFNbH+VJERGWH4md2l5VdpuV2+dqDzQ8DBh9i5iodECHka5zYHyYXNCWQ0o9bmAOwFLVxMeBwcUtbb7mHYl6eV5w1vYphaJsr8p0QfjWUARVNOJkoD/dhWen+Sx3g93nYtVG6MIh1qnETO7mQ+WfNVPEfiKAlovIekqCBC9oLS2xV9G+h5hNeYjZBs5HPcvvMjVE48/EP2eyHL9qYG2M8iPC2fA7xtwJmaAIPegDd6SQoZID5Ax5/DD9ga6amygd6w8X2a4qINqFlEAji4SXMQ2kh28xn2dXA+PZrj++ipy8WY09V9x0TlPAGRq5YeIulpWqm1T5N8d/g1L5kfcIQAJUUybbPzWSkUQG+flrvmrOH1x3towDuD/Dx+kCS6ZiHQeDmw79vMBSyoKAottStAXtHCNxt5n/MJ8eDTi2VzAh1rgMNPUOWSMpnaMzmihb9mOKjY3ZpUvG1ifqKxH8wIktnvMdVPD2Y2DeCzDG/0t1QONZxBUqXmgWQC8PoApUSK2LPPPounn34a//qv/4odO7xAXsXAoA1INAEud3H7ZtCzNRv5RGLcHxlhqPmVVzLXyqzWVSWBJbGYWF/PgsnA1HOhjJLzmYysryUw2T6ZrT60cPrAIloWLJxg6FfORkZIstxuEq6BAUqxHzlC8hMK8XNArvK5XOVDD/WhiWJS2riRwhjGFbX+fhkaGIlQaWnxYnnM226rLs5ckL/aWl6P0ynDBkuF/+nbWVcHpDMKdu4OYOnSyvHv04HdbscXvvDH+Pzn78FTP/sZrrzq9qkXMq4k/V1NSFGqn+FZmVEa2IGFzLUR9mg6DMDO3CqbwlVsMzlyvRHp1DwPubisPeSulwREEIZCliTouNIfADgAd42WH6PlwygijwpSFMPu4v9DL9MbET9MGfdkmOFM7lqKVuSzkIWXc6AhXSCBGvgVkAnz2Mk+TSihm222a+RwVCOf/nkyDC4XA2xuekNyce5r06azfFrmGCl+Erh0mP2FAr1FicPcJnZIk3lP08OWHGCuU+IIyYEzxH4KnimFJ0QujpD2LiK4Y8xNE8qRuWGtrws8Z+g8eiBcdeyrbJzbBRdQZKSg8pyhxUD3XcDBH2jiDFqfwS5JllHqPRcDjvyEIZiwUbI9O06je3Q79y3k+CqS3GwKCZ6nBXAsorql3UmvXnaU/Zce1FQud5B4OQOsP9Zxo5YzFwDmfYI5Z9korzcbo7qkyMuz+zViUiCjgI3v7W6u3mSGeW41AZIsjWgVCvQMqikAcYav5rVnR3GbC06UI0jG32OqH9j9Da3+mCb6MbARmHfr1EMNJ4n+AY1MRIDaOo1MGBbFeg734Pvf/z6WLr0bO3Z4MeC4kX2c/h+KozgM7bPPnmU/3bpQYtzfv5/zXzgMbNoErFjBmlVCtRCgEq5xnrvtNhn1IUSiAB4rGJx+LpSiVF7ItGBhMrCIlgULJwFi5WxoCHjsMdoahw7R5gGofLR7N/D5z7Pgon6VT8jNllIzMgpTACQ9Zl6o9etZtDGb5XFzOZKvefOKE4HFpNPRwRpiRogaXSMj8nyNjcB115WejI0hlIsWAQcPFtf2mq1Qi9raOnzhC1/Asde/gng8jmAgOPmDVFIUFCi3+l1kFNYBUIHYPrBgMYDgWWStmQhFEVw1zDkykyM31tFK9tJITA/SAzR3Lfc7th5IHtYMMrfm0QKkMZ/jdt42Lb9pmOTO3cxrhqqFt2mCBgAAhWQp8iYN7b6fs27T8JuSIBbE8UUOTh6I7iC5EgIYapxhdJ5mwD8HaLuBHiGhiJiNSWGKyBs05EXxW4eH4XlCGt/TAoTO1vLSwiQ6iV6ew+4DItslEVWT9OzYR4GU5gWsOVvLe9Lk9ffdr/W7R1MCPAQUnqdYhF4IoXkxcBgkJ75O5jeFN2siJ2M4riCZ0gRBRH5Y//PSE9W2ml6cXIztcBhCRXMxoO8XDNNzasQrGyOhEosGaoJCGaFzdM+inSSvoGrhg3b2q6eNXishMqK4+bzlYhrBtjG0LjPKfDNnLT1Q+TSf7fbrKOyRiZBoHvhvYPDXGuG1keDl0ySUNi08UfGwL2rOAsIv8hmDTXum7AAcvO+FrHYc3e/J5tCRd91vSU1qOXsjgBJk2ClQTJDE77Ggarl4w1xQyKd52kxEErFqQn+nATWvWzSrNyyaabcxnUnjvvueQ23tarz//e8nyQImti8z+2qHM1EXKpkkGYpE+FoocJ7Zvl3mQgmyY5znjh0DHnqIc4Q4f0sLj9Hezvl0qnOHIJCVFjItWJgsLKJlwcJJgqKQjNTXy/ocqkqvkiBczc0TY7zLJe0CxaGJTic/068SCiSTsmhjKESylUqRJIXDjEUXicBr17KNmzezULNxkhVeOoBkKxAgyRLKhUaIa9V77FIpFoFcs2aiKuJs4MILL0TTuZ9CMGBHAQXYiqTsKqDcqjlQfVK8cdVchGXltLyrjg8CvkYa4D2PMXfKGYCpHDmgGaHKRGnx9KiW17KBBMw/j7lgAFfE8zlAjZGEAABy3N7fATTfCRx9UoZ1FaATLSiA3gfguJCDt5XnyGd4XMXL7YSXCU6GsaGg1ePKkEg4fEDOTsLjaSFxdYUAb5NmTNpp7Ho7tKK2Oa1/bYBNO74jyJC4zLB2n/IyjHLsXZIPm5Pb5sa5bzqshUWmgXSe4XH+bnp0YCPxBUg+0sNSCTA3zjDDhhW87/FDJFTDrwO4gGQp2MlcskxEC3uzk4jkc8C4lpvUei3JXqcmbuAIsE2HHiEZzGcoCuJuYLug8LvhNzWvpBYKWbtU63MhRKGRm8hbQN1S9mk+TbLnruerq0F7BsNafxR4/d5OXr9d0foHmrybJqgyvk8TJwloRbb3ytpW2agWHmnXPFYu+SzMvZ3n0JPKppVcGMiL/DotB9AG3k9R8yqniYg4/Fph7Lx8/vWLHnZF81SOs19cQRI8IwERhNVZw3Pb3LL/ywlfzKDQRTJBT1ZDPSDWekYj/FyQi69//QWMjIzg/Z94DCPeuXJne4n2zVJB9pmqCxWNct++Phyv6ejx8BhDQ3JB0BhiPzTEfXM5zpv689tsjNgo5Wmr5IXTE0ifj3Oq2UKmqGdp5VtZmAwsomXBwkmEICjr13O1LhrlpGO3M4RPEA69J6qapF3xfVyzm1etmjgxGIs2Kgr/XC7KuBtXBV96iaRIFG5cv16uPgLVJ/7qJzWnUwsbTMvrKKWMOBuw2+149rkhPP300/ib+z6IpqamyjsBpcOK4oek3HY5L5eAcVU6n6Lcddsa4G3Qs2MT4hD11a2um63EezvoGUoO0HPmrJHGq7OG5EBNQSoKamFmDSuY1+UKsdCxTWFekc3B+kl5TQJehHopAQpW5JKasZ2X3gibQ8vxygM2Fw1CxU2PlvCUKAWZtwOYG7uNlwG9P2cuVz4JwKEjAy6SD7fWb0I4ovEyIP80t08NaiF0muBCXmsTIPPZFA/7PD3Ez4Q6ojOoyePH2V+FPPDu/cCiz/G+J44CSgOPNfwK4GvQnpMgSZmzlu1TXLzXhSzzwfSeUeHdGt2hKUVmGRqZHmI/H3pII1kZ9mNe62uHn21M9qFIFTKfoMqgt50e0eACCmYIERUhLJEOA3kHCVlmmM+LM6O1Ia2lXinSg5iLacTRTwLat46eraNPAWNvU/pdkHCbXW7rDDHPTHgmFS+fgeOkvSA9bd42jVQV+Izmk4CjkdchQmGNXuHR7Rr5DJL02Z3sUyNBUrw8RmaECp/ZBOAE0Pp+ue0sqwl6fQwXPL5oNqItmuk0ORYsWIBB502YO5ckq4g0eA3tmyWSBUyuLpQZsRG5wM8/TzLj8wFjYyRbXi+HksZGzj9m5UxaWnisurqJJUR8Ps6ZxoiNZJJzqsj9MvPCGQnkwAD3UTW9FrGQGY0CP/2pFU5oYfKwiJYFCycZra1SOvbFFzmwNzayoGK5GiDlSI3+e4CeMSPMijYuX85Cxt3dxccUk6zHIws3hsPABRcAZ59dTPLKJf4aJzVRr+uDHzw5ScMDjhsx7BxGLPa/+D//5wn827/fgdpQbeUdS5GZ8GYZsldNnZ5Sq+bOGgCaAIVQz6t2dd14TGcdjeh3/pGeFcXDHCB92JqaAAaHtCVmH0PwHDWAt1knP99KCfpsVFOl85AEFIDjpEVxaRLrEfaH3QGEXybpUdxAwal5Qrz8rHYp0H4D0P8Lel7sDopApPrM82rsLq1IrpMEN6cp53nbtPsQk16MwHx6iYTHz1Wvqf4J5UQx/eUBKDymmiRZzsWARZ/n9YswzGwccPqAtIPkTEihp0eAvmfpAUoNAdCEP5L9fHXXavWx7Oz/gtZXngYS34MPa20Ocbu+dVq+Hng/bC5NDEJlvybymgdGI2Ei3DM1wGtMDvK9IC0At81G2X8tq0gu+jew7Y4AP6u7ABh5Q6uD1krC6awBPKOUgi9oYYCOgPYMJHlcRSWpyY1T0GVkqy4cVaWHzVUPBBfKhQGj5HzDxSSmuXE+VwA9eM4gEN2pPVtubhuYx+/E85+LyUUPxcVtbS6g9jx6aEXeW6nfCaCFGtbx1olnSb/dLKkJKnYdmYjoFs3swJ69e7Bw4UIsWLAAwbM+AKBU6J4yqzlZAtXWhTJrIyBEjzh/dHYyBH3rVnqq0mkSqLlzgccfNy9n4nLxu/37Of+MjjIaJBKZqKyrF9vo6+O81dZmvkBoRiBFtIkIYxdCHVY4oYWpwCJaFiycApiKdKyRmGQyxdLsisKVP1FnxAzGoo2lQva8XnqaXn6ZZCmX4+T4ve+RnK1ePXF1z2xV02xSO3aMK4X6uPsTuVLY0NCAK27/Af7sz/4Mzv/zQ9x111143xWe8juV9LQ8O/nkebNVc1W7aYefALJD0jtW7eq6Pl/ryJPaKr9KMpGLU6Si4WLpcVv4B9wvugvHa1mFFuO4sp4QgnA2UCwil6DxOr6Xxyyo3C+fpXcjMIfHLqhaDaQhbq+4STTczSQxbas1SfKPTszFMubV5GLAoUc1Q17L6QqeQTW/9uvY/r513M5drxHWkMzdaVghvSIFaJ40LcQQds3zZpf5RMMv0/PStlre5+CZbHtkG713UDUZ+ASvMTMCOJvI49KRYoKcz9Cgz6dJJnydJD7xQyRO6bDm+bFxv6x2/SKk1e4l2XI1SE+WUPez2UnsQmdpwiLHIL10btYQ83XyM7sXOPpT5mRlY2zz4G8o0+/rYBFkXxdDHhNH+b+a5H1TggwxdQR47lxcI6/g+1SYn9ns2rYJjbQHeF8OPy6L++rDbgFg4T3Aof/hMWyaZ02c12bjcWrOmqi6WLToUSevW4SHlstb0v/24AW2l/5JzRZaWzQyoVMdfOXVV/DVv/8q/uhzf4RQiExlpkL3popq6kKZtXH9en7X20vRp+Fheo3a2ujFamgAlizhHCTC0s3KmQAkPDt3kkAVCiRp998P3HuveRuEOIbHw9D0WIxkb+VKzrdAaQKpF92YjDfPggUjLKJlwcIphKl6dXbsAB5+mOENoRBw553AuedWf85K4XqKwslJSLjncpw0VRXo6ZETIlA+XMM4qYXDDB8RE65+chXHOhHx8G1tbbjvvvvwpS99CT7fj+F2r4XNZitfY8tIkICpJ88bV82F1yV+GPCEir1j1a6uizCv9DCoVufTxBTSmoR4Vm5rdwFzPkKPRGaUIYv6WlV2Jz1j+TQlvUX9qcM/AYa3AAVFs/ndDDGccxuPCQBn/bF23Cjlyluv0UiXjiw6AhNzsfR9l0sCh38MDL3GdtsUkpPsuNYnWgjZnI/I49mU4twdV4hkIu4jAUgNaGGKiiRfQkUveKbMgTNTqktooXyOAEm1K0SvUyEvZeadQbn/nNsoqZ/P8J6qCWBkOwlpISfblxklyfDP5bHzGUliC2l6tCJvFtclUwJaIWUPiaynkc9OepDbOGuYN6fGeA+P/oT9mE9JAlvIkWSrSf7A59wG1F8KqJtInBpXkOREtgPDrzGcT3EDKZ0gReyg9nylSIpskKGc2VGSr3wKUDWRD+OCRMcZVDOMH6D3NNULxHq4jcNPwY68Fs+lX2wwLnrULuU2+Wx1eVXit6fqhVpOLBRd2NvOnTvx9a9/HZdceglWrVqFN97g56eCsV8pksKsjUNDfBUh53oJdlUFzj+fJUEUhWq7XV2lry8UIkFLpUiCnE4SI4BziKJMFIMKBrmYl0oxvDCfZ65xd7dss5m0vMvFP6B6b54FC2awiJYFC6cB9IpIemlbgO8ffpirhDU1fH34YeArX5FiGDOB7m56r959lwQpl+Mk1tTECerQIeZxjYxw9dLl4mRkXHnVr4q2trKNtbXFk6s41omMh583bx6+/OUvI5PJYNC5FC25pyvvZCRIM5U8H+8B0M18olyE5KWUd6ycxLzipeEd28eQsFyM2zsCMjdIqBEObKRR7aoz1KpqkKGRIhRPnKflfcDoVhrAziC9ELmk5nFy6dTtnFyCzme4n/EahLEsakB5O2Tfje6gzHn8kLa/guOS59lxIDfGgsz6ULjW1czjObZeeuJi7wKpYRr9eZXHCJ3DMLTRnSSkzgBzmPJJEj9B9PT32dsBdK9lrlR2nOIY9cuB6Fua+9gHpABkBhl22HoNyVN2XIaBosDcqWwM8M3V1AjzDLFz1vA+1J1PYjJ+QHq7FJ8m958Hp++cFCZx1fL+etpYhy03xnN6mnkeTzufk1SYyonxIZKqghZmKKT+40eBff8JxPaTdwQXAs1XA+FfaaqLAdY3K2j33BniMbLjJOHpYe3+O2TfOYO8lgwA5zjfpwf5vSDVgBa22EG1wPG9muKg1i5RR+zoU1ooa630yJotesxSXlXFkg7TwLvvvou/+cpXsHjxYvzpn/wp3nhDHv9UMfbLLQaatVEIIvX0MOTP4eCc0d7OuSQep6dJLBKOj3PuMLs+r5dzTjzOcMFslucDSoto+P2cY1wuzo8tLTyXcY5ZtUqKRpkt7F12GQlaNDr7qrgW3luwiJYFC6cAyqkiiXjzY8c4+dTXc5IS5CMS4eBfU1Ms5x6JmOdmTRUip2v9eh5bVXn8SIST6ebNcnLr6eGEms2yjfqVSWNRyMcfnzgxb95MslYuRGa69VzMcPbZZ2vHVrF9+zYsX37e5GpszUTyfEFlvgq6NeN3nESiccVE71gliXmbwtC3XIJkAjEa3qGzaUTr1QgFqUoPylpVeq9DJio9CAL+bpKMeA+V8/RFlEXx3JHXNel0FzCWBsb2MVTR4WUeGFR5XYUCoGZlvGs+wxym1JDO2aBqIhw2rTixH+j9KcMhM2MMhQv/BvDPp9cqeAYN97GoJAp2aPlYB0ns1AT7z+6mZ8YZAtrPk4INenJZUEmqXA2aOuE43wsRi5Ed3M7XTXK3+216lOKHmaPlrKHnzN5ACXtnDdvpqAHSA5qUf4JEye7RakuBIYueRo1o2TSSpIU6OkMkl0d/KmtmIU/SaHcDtpj2LI2S5LjqGNqYGwPg0EpraWQQDiB/mNcJUG6/XxNOcTVSJCT6Du+vzc7naWwP72c6QoKbi1NAJBOlImRB1Y4f5fnbryuWxG+9ls+Aw8e+yGc0dcRG3t9cTPM85qrLgZytvKpqSzpMERt+uQGdnZ34wAf+Clu3cZVMyLlXE7p3slGqjQDnjXCYP93WVoaKL15MD9fgILe94AJg27bS16coVLPdu5eeslBIkj49Ibv0UtbmisdZNqS9nXNLU1PxfKWfYzZuNA/D1OechULA9ddPzGG2YKEcLKJlwcJJRrnaJPp483CY3qJsVn6+di1DMkIherIAhuK1tPDzmUZrK3DNNWzr/v1cFVy8mGGFP/oR2zg0xDbm85zcxsY48akqvW/CIycmSOPEfNlljNUvFyIzE/VcymHPnj148WdPo1B4FXfffffkpN+na+QJ8QmAoV65IRrmTSuLDcpyEvP67TytwIK7ecyjP6FHo4BiT0KRgmJeIwQhrW5WvphAGa+19RotN2qcZKBlFb/r30AClkuR/BRAQzp5FNhxL44X3fXPoXBFZohkCXYgcYj90HkTjXNHgEQhp4Lyd+B2Tj9w+DHmJ6WGmXOlamF16i6G8mUi9Mokj9E7ks8xTM+mUCwhn6M3SI3TURRaQvJ14AFNPj0P1C4Gum5hXwrFSZfWXzaH5iUK0OOXHAOSIElIvAtkR+ghS0e1vCpIBUNPI/vr2C+B2AGGysHGa8yneS02O9ua7KWHU4QMFgr83+YGGq8gcYm+QzLlCHKf+FGG6rkaSPQSR3h8Vy1FH9J2neiGjffcXQskU7xXAD2S6VFea2aIZMvTSFEKZ4jnczfwGREeS2cN72vQzVDA7LjmhWokyfJ2FC9IpMMsX5Dq1559TWlT1CwTdd1ycfMcyGx0Yn7eDBIg9neVv7cpIF/Iw26z4+6778bmzVm43W5ZL0sHY+geIBX6ThXDv1R4oRB80nuF5swBnnmG4/jwMImWfhEuk+G8ob+2jg7gnnuAdet47WIx0W7nvPDkk1LcacEC4OqreRz9eUvNMbEYjhdBFqVU1q/nwmFTE4nZSy/JsEMLFqqBRbQsWDiJqJTgLOLNg0EZGpjP81VPPu68U+ZotbTwvctVXghDnN9Yo6ucl0hVufIXj1NtsL+f27a3kwQODzOk0KYtuDudfI1Gge9+19wjZ2Y8lAuRORFJ4YsXL0bN9dfj6afvQzAYxMdu/9jMHLgaKF5NgQ40VjNazo6/u3g7U4n5EVmfSG/82RQaoB0fnBja6AjI3DI1rtXXssn6R+kwULPYPAwy1U8DPzXIP08z39dfBMT7AGc9kH9XKu3l05oinV07fhKIxkiCcgkphpGJMmeo68N8n+zXvFjacQBNit0FDL/B3KZ8AkU5NmocsPtJ0Mb2aOd0crt0RiONmhqi3QGodm7jCJD0JPv4PQrAwIskaQv/oFh8QfSX3SnDBD0NJFqZCAlAPkcSKAiSI8AwPm8z+zQ5QK9fohdAjmIVAK8NBZKm7Ag9V4WMrvMLAFwkmwe+S1ImCvYWMkDgTHrnHAEtFC/GfZQg+8vdCCz8HM+dHpbPTTaqy+HT+jOtKRkKr6ZfEztx1fM6MxFg33cYkukIMtRVTbM/hux8LkMBSbLEMykKBwvBFuGJ83UC3Xdq4YqjQKC7WEQDkAsF6RFg77fZfleIpB6YEQJUhFIlHSqJ3VTA2NgY7r3vXlx6yefRPW8eooGbhW6lKUTo3mwvNlVCubnCLLzQKPikKBSxGBzkfDY4KEPeY7Hy19bRAXzyk8VzxtgY8ItfsPCxkGbfsYPzQ0cHFx6FNwqYOMfU1QFPPcW5SpwzHmdesqry/5YWSwTDwuRhES0LFk4iKiU46+PN7XYpaRuNcjVQTDLnnssJSq86WAnGiXrZMhm2UWri1su8i5j7SIRerdpafj88LAleNsvrGB/n52YeOVG/Sz9xlQuROVFJ4RdeeCEaGu7EQw89jEQigU996lOTCyPUYzJ5HTaFRmUENO4D3eYkxygxn+ql96jnsdKr+qVCG0V+1Mjr0FxPNMZddTyWw8fQQOM19W9gKGC8h6QjPULCdeyX9KTYoBEGO49rcwLIktzkMwBsJGH5LHN48k4tlC9JUja+j96SRK8mAKGp7AmPT/QthpYdL55s7Hch+FHQRCIUzRAvaAIISf6fibL9zhC9ItlREhu7i/uoCSC8haIMHR809BcYJpfsBY4+TWEQgGGDDh+QGte128Y+8jRrZHIPcPB/2NfH1fKS7H9bDrD76CkqqDhOMAXsLtl2jGnPDrQQvRiFK+wOhv75z+B2SlATDsnSAzn0Mq93fB+OH0Bx8TrzOelNc3hJmgsFkrE5t7EfDz+u5cX5NQGRkeIQUn83/8o9+7kY21hQtaLV4/Rs2hWeJ5+R+xpzIFtW0ZOVHmYb1BSPmR6ZNgGaALOSDtWK3ZTAsf5j+Is//wlS6U7U1NSYerHMcLIVCPXy6ZWK0xshxnpRr8oY8j40xFpbla5Nf5ymJuChh4Ddu7keEwzKdqoq50q9N8oY4tjRwVBGfSjh+vV83MV8NTLC9q1YYYlgWJgcLKJlwcJJRKUEZ/2EoCj0EOk9QvqJx+XiilsliMKR69cXTyw7dzIEsbGx9ORWSub9v/9b1uwCSAqdTu6byXAyDYdLe+SMKKdudSKTwru7b8UHPtCNWOxl2GyTCB/UYyp5HZ5mAAVg3p2Aq4SBWmR4jpBkOTz0iOjDmoCJKm1GA9TTyrC31BC9M7F3ZS0vV51U4NPvpyZ53myU3gu7i4QkHuV+ik/zjCRJsBSXJoqRowVTEGGALrbJ7tEIlvCk2CjKYHeSbGVGNKlvh5Y7lZdkrRQBFuF1Dj/Jh/DUuWoZ5ujw0qOUG+d5as4kgXPVM0ytkNO8cWCB5uQx2a+iv45L0o+RMLg0i9PdyAc3PYLjhZrzWb5GtvLaB36pNVTzpgmyhRxg8zC3K9nHXCwheiEKSudT8n/k+b/I2YIW8hiYT29Y4gjDULPDmjgJWKA3+jZJrxpj/+d1/e9t0fphnCRLeHFyCd6n/g1aXtw4r90ZpBiGmdrfZAhPPkcBmEP/K71+Yn/jQoGa1HIJazQVRQef1VBgWgQIwMTFkVI176boNdu9Zze+/OWfw+v14uo7H0G2pb3qfU+mAqEgeaKe1dgYc6buuad6sgWUDnn3eCZXGHnjRkqxe72cj2IxzjGFAt83N8vFR2Ou8G23caHQ6QQeecRcLXHRIrZxfFyq754qYZoWTg9YRMuChZOIahKcjeIRRtXBcsjnGbonpG/FSqQoHDlvHieWTIYeqnLSuqK9ZjLvY9qCut1O4uXzARddREGMd97hscp55Er1jZnRcKKSwsXq8sUXA4XCRXjtNRvc7u2YM2cu6oTUVTkUVBqBeuW7yeZ1OPzs6FIQhmd6iJ4su7c4rCl+CBh6ScqHN62kh8Hs3EJiPa7l8WRHmduTHQP8XRMNV8WrFa8dp+ckn9KMfC28r6CRJX1NJKcfcJ2hhfKJXKscSU3NWVS6Q14z+tM08r1tmqS7RjYKOZ6vkNf+CjBPodM8XzYH4KzV1AZTgLddyy3SCKGvg7ldrjoKUmQi7NdUP9uFAsmZu5neGn24mF6SPh3mad2NVNfLjALqCMlKepDHOU6kxLUXdO91ZNEeBPztvD63Rvqyqs6zZWe/Hb/OgnYMoUaoEa9UH1BzDq89E9FC/zQBC2cAxz2Kdo8M6UwPgCqEecrYK25JEIWnCiCBzIyzTx0+Pid2F9D90WLxkEpwBBiaOrqdqoxqis+Jw2/+e9EvFChe9k9mhH2e1eWBTSdssNTiyEyI3QDYskXFf/zn89gZuRR/+Yd/iZqamkntfyIWm0qFBiaT9O6Mj1My3ecjKVm3juF81YzDIl937Vrg0UeLQ95DoeqvTZQSAejFOvNMYN8+zjV2Oz+rqWHYn/E4RpELvVS8Xi2xt5desHCYBZWt/CwLk4VFtCxYOMmoJsFZTzqqCQsEOJG88AJX7Z54Anjf+2R1+7o6hkTs3cvzjI1xshGT1tgYSZfXO3HCFTLvBw4wrj6T4ec+n1z1S6e5j6oyrNDnIyEr55ETqEZNsFI9l5mEIFyN6Sfxz//8G7hc38SXv/xlzOmaU3onYaglwxR28M+b0byOItgUGpfu+uKwJm8HEN5Mkmf3MExs5HWqBIpCwcbjtF7LfJnEEU0BMMV9m66cKMShJrn92F56hQBIIpGXHhdHDYsjZ6MMUbOB9bQSac3Id9AqctUyvyeTJaHKa2FgmQiJks3ONmc00QVPK/fNRDRCZAMg2qgjIYoWUpbPUlihfjkN+vQxEofYQW6f7OM1BhZSwMHuAhQbvT35LInT6HbWaTINZZtDApceke12+ellzI6yzlVaBSDCGbX8r+NhhRrpsntJ4HIpeghrztJC++zglK3IXDPYtMNoni27m98XwP7KxYGx3TynECNRE1wAsHupCCik8u1uTeEwz2fT4dXI2SivX5+rp3i5fTZKQlTIksjn4hOVKfXPixk5sSlA182aUMoxIOHQhDZqeE3lfi/iHgBS2l+fBzYVFPLlRS+mIXbzyqsFZLNZuFwurLz1f3BTQwNc1Q7oOsz2YlNvL/Dcc5wPmpqKC9ILIaOxMSmxHgpxzqrGo2YMWf+jP+LcoA95r/baRIQFQDKVSlF46YMf5Pax2MT6WACvSx/R0dvL83d0FMu3A7Idc+dykdGChcnCIloWLJwCmOkEZxHeMTjI9319UqVJhEcsXEiyFI+TVK1cSSWmI0c4ed14I1fxzNojZN5HRmjjORwyBMTlot189CgJ2erVnKyr8chN5vqNHq/ZkHvXY8h9M666YyVefPyT+OIXH8Nf/dUHsPS8pRM3LFInq6OROr6XRmYp9b7pwiysqfEyoPdZtiF+iO3K25lPVcqr5m6iwettB7w2hpaNvAakjgFzPgrUX0iDW7/a371WI3FvyvA+6IQrvG0kOtlRkgJnHQmo3Ukj39VAL1U+x8+Ql4VpoWiJEhESmUWfY5hieBON+kQvVfDyOUDVyJXdoYXQ5XG8SK7i0kIGa0iyMmGGzon7k4kA2TjJUOoYj6OmdGlfec0jlmEul4DwcMQPkdSqKc1TBnrIQvPYjlwMgEMrHi0gwv7sgLsNUBz04NkUTdI/xr5z1mg1ybScKcXFY9lrNBGPFO+tt419FNkG5AtAIc1j28D+cPjonUoNsA+Di9ie7DjzoXxdvJ7oTo0YZbRctQLb5KzhMQoqvafpIQCqpiaoqSi66ydfgkD0Y/cdxcqY2Vh1eVCVvEyTrXs1S6IXW7aoeG7dOjz+YhBf+9rX0NY2vUFqqotNlcbJ3l7gn/6J5UTEAloiAdx9t8ynNUqsB4NcQKvkUTPLLdu0aWKIuri2WIzvS5E3RQGuvJL/J5MME7zmGrYFYNv0fRQO04NmjOgAuDi4Zk2x6iDA/Q8domrhs8+eHOERC6c3LKJlwcIpAv0kFAxOL8FZxPCLCae+niuQgQDJVzzOEAuHg5PKFVcAv/kNJ6auLm67dSv3Natn1dpKud4VK+g1e+MNbuty8Zh1dQwNXLNGrjhW8shNJ8H7RClwNTU1YfWnnsDLP/o9fPnLP8ctt7jwiY+fbbgQg6EWXMR6TWpi2nkdZWFWtNVdC8QOafWRQI+RMfzN2HYhwz38mhYKqJGzPd+k+EA+TeIjVvsBYN4n+Dq0RSNNGc1b5cNxkuKfy1yr9BANe1GnSU2SMLhrSS7SEQAaMbG7SY5sTkrU+zUvYvAMSpnv/TaJXyEHKYsO7fq10EJooYWNl5IMZCIkdzaF3q5UPwlWboQEJJcEHG4t78wBybbs9O7Fe7S8oJDst6GXZHioamMYm6uWZCUXpVDE0CuQIYMCWliiv43nss0FEj1AcgjHiwCP7mDooSCm+Rzg04hJdCeQHGSoXcMlJLz5hEZaNVVFuxdQx4B0P9sPG59Dbzv7yNNKr146QtGM4AJgbD/DKQt5jVxlSUwzI8DhH1ERUng8obXJ08bnQ09qJiOJfpzAD9OLZlNK/17M8qfMSNBU8iNnWPTi1deAdDqNP/6HHdi+vR+f+9xHoMzQSlC54sFmqDROqio9WceO8fbm8yQ7u3bxVYzlRon1+vrqPGrlcsu83mICKBb5yglu9PeTqN12G+epYJAeLP11iT7Szy/GiI5IhF6sQMD8Gl56qXJdRwsWSsEiWhYsnCJIJjnBhcP0DtntOC7xbpYErA81NK5Qihh+4dEaGeFq36pVVHR6/XXmVykKSdKBA5xEGht5LpdLJgOXSkoOh4EtW3iOWIzhHzYbJ7tkkpPZZIyAqSZ4n2gFLr/fj6vueBgPPfQg2tqcePU14OKLdBsYDbV8iuFqnWsml7syFRgNTqGOlw7TavK2lPeqibaP76fowfG8IRvJ0/gefh5aXLzaDxXovFEz2MM4HhbnbqTXyN0ANF8F9P2cxKCgMucJOaoShhYDrR8A9n5L89oIYYw0j1O7mEQtF2MbCypJRWZUpywopN/t/MwRIrm1gWSj/ToStr5n+XlygPtnoygKNczn6S1SvJqIhZYAZrMX54IJY7+gFhPrglPL0RoDkgdJyGqWaF4tG6+3oOU8OWrpoUr0aqIUKXq1kGHfASQedgc9dzYHPWqeNqBmEe9n3zoSsp7HAcVJ4YpslOewu0mYPE0aMUoy1K/1/cCx5zRPYErcfNY4czcAtecAI9t4PsWN48WG1RyFPESf51WGRrrreD39z2tEvVaKWFTjHTISsoLKdsy5TVNX1KFa8jTVulc2+4yKXkSjUdx97ysYHBzEfffdh6VLTbzgJwDVjJNiDFYU/gwcDkYg5PMTj2eUWK9mrC2VWxaNAj/9qSSAq1aRMAnBjWhUCm60tnK+ETWuwmF5rGSSbTUb/43zy6JFwMGD9NaVC088mcIjFt4bsIiWBQunCBSFpGV4mCuHo6PMaTJ6gPTSujYbJ0NVlRNUKMQJ7dpr6W0CmBN19dWcpNas4eR09CjDJfx+rugBUpbdmAwsPhPJxPpJe3iYx1FV7p9O05t13XWTIzpTTfCudiKcydBCh8OBT33qd5EG8G4shue/9v9w+eWX44rL3aXVyfQekBMFEZLVtJKhbZloZcOx8TIa1OMHtDwpTclOGNvZGA1yzCle7XcEgLPuocT5yFYa9KGz6BDKxYCjTwJj7+A4aXMGAW83jeX239GK5dZrtbsGeV67Q9N5SDJcLRPV8pMywOhOyBwnXW4Y8rS2clFN+ELzKsIO7P0GPTfOGhKY3JhuXw2OAM/RsJztzURJ+GxOGv01i3k9vT+TIiN2p+YBygDpJI/jDACBVvbZwAs47hkrqPKcrlpeYy6pkTYtbNLmYP/55wNjOzUlvpjcJj3InKTwJv6vBHk9ziBDFrNjHBwUlyZhbwNartFCFwv0vqlZTXAkpuX5NfGcY7sB7xzA6aUAh5og+XM1ajL+CV1nafll7kbu527iX+wQCf7c26vzDuViDCd11smi2VlN6VJPtCZDnqYTAjhDohcAcOjQISQSCfzjP/4D5syZO+XjTBbG8c44TubznAeiUc4xXi//mpsZLhiLcSx3OJhnW0qYaDJkwyy3TJAqPQEUnjIhuOH3cz748Y/ZHiHjrqqszQVwgS+bLa1o63LxukSIeyrF0PY1a0p7soATq3Jr4b0Ji2hZsHAKoL8feOYZThAAJ5D6ev5lMpJs6aV1x8ZkHP2FF/KznTtJqkQox623cr9bb5UTSSDAiWPXLk5guZyUdW9qKl7hAySpEx4xkWQsCin397N9qRS9WoUCY98nG7pXbYK30YCoZiKczdDCd999F1+5/yhue+d+hMM3o7OzExdfNHOG2rRhUyjzXamekd5T4ApRWr7/l0D8KFhfyUvCpXg0YmASCuntAOb/LmB/UJMl15TqXA1A5C0SBqHsp8bZrnSYhWjn3Ab42tnGbBSwazlbDp/0sLmbNI8KNKU8TXiiSBodJAzIsz2+ViB0HsMME4dpuGci5iQLkPW6GlaQWCCqEZ8AUHcePXeicK6zQRMb0Y4Z7yHpAUiAsmEtHHJIdwKNHArxiZymJOjwUfgifpChlrk4EHlTU3MsaGRPAdwtFKro30ACpAS1/Ck/+83XqUnBa3DW0uOVHWNYoauBOVA2B5CPa+GVNhI0UdjZ6QfGkwyfdNVoioQ23jMhqy6k5kU4Zj5Pz2H8EM+XDpPgV/IOpfqBvl9QgKSQI8lLHpFFoPXCLZMhT9MNAZyG6IWaV/Hqq69ixaUrsHTpUnzrW38C7wm0zM3Gu6YmOU7GYsCePYya+NrXSHCEQNHq1ZwDdu3iLV28GLjllpmLDjDmlpktlIkIiWhUzlHBIMPdMxkp3T42JsuKiPnITNFW9MfwML9XFDm/hCqsfykK5z1B/mZL5dbCexcW0bJg4SRDL1xRU0NS43BIdT79hKGX1k0mpcT6sWNy4unqKg4LEdArGa5eTdn1SEQmM3d0MNbdKFahn2RE/Lt+0hZeLKFG5fPJtk42tKJSgncpwlSOoM1qaGFexdLF8/GNf/tX/Mu//Tse+cIv8LXPL0BevRyXXjp1Q21GUG0ei9hW7ylI9vLhOvdvmAd08CFuIwoN52IkXC2rJoZtZUZomKeH+Oefq+V+aUIQdhePZXdq3iM3jeV8BqhdRkKWjWr5QTWawEYB8PtY3yszyv2ddZp3KwuZR2XT6hlkSCg6bwR8c4GeR3kcu4vkoaCp603sCL4E5wORN1h8GQWSEuSZ0zUhHC7P+lnuRsDbCYzuBpxgja1CHMdDGm2a5L3NAfjauH10N4mU3aOpEg7QC5cbpzhHQeXnsLFP3a1A40UkuqkwkBnieVDgse2azLzikSF/UDWJ+BjDGWGnOEs+R49aRuWzET9CMuaql8IkilcjtHHeS3edlrdmI/FT/AwBzcV5npE3md9mcwBw0IvafUfpRYeCSpXL0e2aaMg4kHmbxFEUgdZ7rCZDnma47tXx9lZYPOk71od/+Zd/wf59+/HNb30TQNcJJVnlxrtrrwV+8hPWQcxkGDERi3Hu0BeRv/tuKUTh9XJbVZ36eGlcHNN7wkotlF11FUP7hoc5L/p8MqzR65Wh7Tkt6jeb5Tw2Z0758V9Vuah4223VKfj293Pei8XY5lWrLCEMC5ODRbQsWDjJ0K/oNTQwLCKRANraJq6c6aV1vV7aVQCJVzrNvChjcUafj/LuQ0Oc0JYtA7Zt47kATjodHaW9Rxs3kgSaTdpPPgkcPiwJn8vFSbEaBapSKBWOYmZArF/P0I+mptIEbdZi7JPSA9TursXX7/3/8PjPNuEvvvVDfK3zbtiVvQAM+VsnCpMVASjlKYAK1F/AELp4j1agOEZjPDNCz44+bEsQtmyEIXbpMPvJ4eex0wM8hs1BD44Q1vB2UDgispVGtksjBvm0Fk6YBmJ7tUqkWS3ELsH22T1gbpW2tA2t3lY2Auz9DhBcSE+Mwwek4jI/CjYUhx3aGB7o6wTaPgDs+ZZGCN2awEdKeqb0xr6on+UIAPHDJIJOrS9E7pe7RZOY165n4R9QHCNxFMh7+EPOa0Icrnrm9CWOMp/Nof2Q8ilKzWeiDIvMjGkEo8Drs/sBTzvJUv0FJGC5cQqPzP9dkh7hgYKQdbeTKOVTbH9unPdoaFSKmmRGNPESLcfLWcvwRl8bsOAPgcEXqGToDPI1k9KIUndxoWszkp+LkaQWVAq15HP0XNacDXga+azpPVaTJU8zGAJY6TdVQAEbNmzA/fffj7q6Onzt61/DsWNdUz/fFFFuvGtq4hjtdHKcHh6WoefGkLtQiCTjZz+rPhLALDy7mmiCyy6jqp9eWr21tVhwo66Orzt2cLtUisOBIEs+H+dMI4Ey649EojhSpNz16OecwUHOh5YQhoXJwCJaFiycZOhX9IQgRUsLcNddEycCo7RuXR0JliA4Xm9xcUaxf1+fVDLcuVOGChYKnHxvu42eskcfLZ4QA4Hyk7bPR6/b/PkM67DZ+P90amSVgnHCjMcp6jE0xLaUMgKmGmNftq15nQfIxVwRJbwRa29fi9WrV6OxsRHH8gsxtuufUSicCZvNduII11REAMp5CmwKw7d6n9Hk1Otl7pUxbMtI2LJjmtCDn/lLNge5Te159Kbks/RM5RLAgf9m2Jl/HoUQAE2NsJ7bjO8DbFkgr5GLQl6G9Dlr6DHLpXG8uLHiJYEY26UVVk7oQupsABx8YAs5/u/wUzRi0R/RGwSb5oXKSfVCV4jHbbwMGHyROU/eTp5/bDe9ZceJm4LjYiKFHPOlHB6qA3rb2F6bA3CJvtNCI+fezjC+nsdIXHLj2uF8/BwqC0AXwPNmx4B8kGTI20YypiaBQDdJoH8uP89pYYNOv0aUo9wmN04Cmc+wfbm8Vg/LCUlEFd7DfI6kuPYcios4Qzyusw6IHeD1FDK8lujbQPPlk1Prs2t5eblRIOsx91hNljxNIwTwOKr4TT3//PP45je/hdWrr8Xv//7vY8cOtlnU4TtRKDXeCYGjWIzfJ5MkWSlNC0UUDRbeK6B8JIBxfCwVrljuGMaiwddfLwsCx2Icz++6i5EXdXWco+x2hjWKkEER+hcKcS40Eqjp5FhZQhgWZgIW0bJg4STDmJvU1cX3pVbbjNK6dXWsgeXxTCzOmMnIMES3m+97engO/epeMmk+Id52m5ykRPL03Lkytl5MzoEA/xKJYkl3PSaTJ2VGckRxyp4efr+XDiP4fMXeLWNi81SKe/b2TpQuLmqrIBSuBmnEaaSjsbERALBt2zbce++vccklGXz1c/Px6mv+E0O2piICUMlT4G4COj8EoMBwugKKjWARUmV36Qhbnnk3KGj5UJrIgzNEw7/7Y9zn6FNaSOCYFg6necOymvCFvxtovYaKdvFDmpLeCImaUAX0tmv5Q36eJ69qnhvQk1QoaOqCWj6Uq4EeJLubZMXdQPISOg8I/4ZtsDu0fCSNPHnagPqLgMOPA4k+kizFI+XhszEez+bUOjWvvddIn93O62r/AO+Du5HkMRORIhdKgP3gbiS5zSVIFAHu23kjr2fwRXqeEkfZp7mYFh44zu0cPkmkhPqfnkg7g2ynzc7+dday/pbilYRKRGMKUqo4SfbmrWVfCfl2u5OeyMyoVInM57S0udzEZ00ffucIsL2j23ldNgdQv4zPWznhlpkgT5NBmd9UeDSJpsYmvO9970N9fT1yuQuwY8eJJ1gCZuPdsmXAY4/RIzM4KOcWQRiCQY7tvb3AW28xL+vaayXJ8Ps5d4yMcJ9YrHgsNxO02LABuOmm8nLu+jmnt5cy6vp5zKn9lLJZOWeIsMbeXuD735dEMRAwj6SYTnFnSwjDwkzAIloWLJwCmGzxyVLSuvpjADLOfniYE1g0SrIyNsbJNhwmURob4yRqnBAzGRkiuEuz95qauJ8+TwsorkViRKm8AbOcsFIkJxwmkRPy9zYbiy7X1PCay3m3yvWvkdT19gLf+IYsxjkyIvv2+H5GD1Bm4sr7BRdcgC996S/xzW9+E7d8fjf++I+/AKAPwCyHE05VBKCUp0AfMmV3ajk8aWkEH69/NELjt34590uGQZGHoKbIVwAcChBYoHlhMjxHJkLxhHxKyxkaZdHghkvpEfF3S6/akSeB5DEeq5CjmqDio2escQX/wi8Bw1s0T1ABgMJcJpsdKCj8LDNK71VoMfPAkn0kPSNvaDUKzqQIhN3J0Dp3LdC6mip/8SMkhKL4sM1OT5PDz2N7WrT74AGcDnrvOm7i966Q7Ne21SRI4ZdJslz1FMHY9032Ydtqhvylhxge6dJWL3oeBVJ99PyN7wWQAzzNWo5YKwUofF3sX/191BPp4ALm1zk1D93oTpIlkd+FAmArADa3VpcrA6CG/SVIlh42my5XzqHlU3kA5IsJvln4XdfNWljnEMMF21aTaJ0KQjICJr+ptNKG//6vB7Fhwy/x7W9/G0eOtAG4AMDJI1kC+vFOUYD772dOrt3O8dbvZyRCWxu/37+f473Hw4W57dvlwta770qJ9cZGjoe/+hUXvJqailUCjfMHUJqomHmLwmHmkI2N8fPt2/n50qXF3rBkkmVJGhvlHHfGGVTWNZs7p1rceTokzYIFAYtoWbBwimAqUrmlthcJvPE48OlPkzTowzMOH2Y44dCQXMVUFJKWjo7iCdHrpdeoqYl/kUhxnpaZKqERZpNqXx/w0EMkT2K1UlVJckQCtCA5t93G80QiXG0VtbtSKU7KRu+WmdiFWX8ZvWxC+GN4mMaIWC0VK7nH97eX8ADZiy/+0ksvxaJFi/CNb3wD9913L9x//1Vcc9ZBvPoav58VwjUdEQCjp8AYMpUdZuiYqAkG0PAf30+ylIkCY3sZfucIALu+xnpVileTBVdotPtaJfFzBKSARiFHL5CnlQa4XhLf3USD3NsO1NQDmUF6pro/VkwqnEEa6cIT5OtmgV13o6aWOE6iFljIc6WOMY8s3U9PmOIGEkdI4tQU0HmTVPJLj9Lrkh7WijJnKXuezwEBTbzB1cI6WjVnAR4/ADul7d21xeRGSO9nEyR0yT7mleVV5sMdeVJ6pkrVpVK89Hqd8Um2KbwJ6P05vVstq3j9ol9KEemCCkTfIjnLRnkf7ZrYSCELpLN0ajn9JHH650hNkmDVLNFCSYc0L5cLx0m2uM/lwu+675jYrpMpJGOE4Te1d9CHf31sMwaHRvB7v/f7OHy4FTbbySdYegh12J//nPUORZi4qsqi9ZGIVgVAYY6tw8FxMJ3mGHjjjQw1F3OHx8NFt/37eZx4nAt1QihC1G0U80cgUJqoGL1FBw5wPE4meZ5zzpE5yB4P547RUelNE4t2wuv14Q+Xz7ma7PwqMFWSZsGCwGlDtCKRCO655x787Gc/AwDcdNNN+OY3v4na2tqS+3zyk5/ED37wg6LPLrnkEmzZsmU2m2rBwqyjXNLxyAhJjMdDBSaAE+eSJZykDh8GPvIR4JFHgEOHeKxcTnM4OEhc9OIYsVhxiKDdLsM/WlvNVQmNIYHGSTUc5nny+WJhi0yG5M9IciIRnrOujtfV3MxQyMZGts3ppKR8TU1x+yZb6HjdOq7e1tTw/A4Hjx8ImISLeA2Gq918Bq6vr8df//VfY8uWLViyZAkGbOfgnXfewZUL9uHV12Ypd2umRADMQqYyERIQR0D7foTGuZqi1yY9TIN0zkcYkpfPSWlym5P9pid+rauB8IvcX3hTsuMTPXBqkqTDESARyo2zLc2XUyZef+0L7tYKBAOwuYAd90rBBuTpzTrjE8yDcgSB7G5QGbBA4pAaYFvyKtD7NM/ZuppepaG3NUEO7UeTHtTamqX3qusO4G0ACz8NHHuK5MvZQDIa2UkJe3c9+8DdBPhaWHcqF+O1OwIkY9FdbKe7RZKSObcZPCsRksBcHHj3v7RaWjX0+kV2UrDCEWQ+lafV/HkQ99jbCdScyfs5vo/3LjVIj53NQaIc3kyvlthfeHriR0kKc9o9sznZ9vbr5LaVQlpPJWJlBu03tf4Xz+Bb//FfOOOMM/C7v/v3aGpqOqUIloAY3/r6SKYyGY5lIo9JjPt2O//P5zkmp9Mc/7QI6ONlO0Qe8N69soixOOaKFcA110wMXVeU0kRF7y0aHmaUgqpKJcQdO7hwZrOxDSJiAihetBNEqxpxi1L9VIlETZWkWbAAnEZEa+3atTh69CjWrVsHAPj0pz+Nu+66C08//XTZ/a677jr8z//8z/H3rqn8Ei1YOIVQKek4GJRhb24397Hb+bnbzf3Gxvhnt0s59liME07eoHpdLrk6GgV++UtO5iKMpJQ3Sb+y2drKCbK2Vsb/i9XQQEBKD4s6Kk4nj7F9uybQlmc4yV13sc1PPUXPXCw2vULHsRj7Kail94hwmZLFl+0KYK88A9tsNqxYsQIAcPjwYfzZn/1fLFlyDj772c8CeAvASVInrARjyFSqF8ilSFCE18QR0AiQn+TDWSNJjq9dU5SrYVictw2Yd1dxEVp3Hb1HyX6+tymycLF+O8WrEZ2XNUW/ApB30PgX4YUCNqXYG9a9Fjj0EAmct401wtz1vLbYQTB3SyW5KuRIsHIp3t/YIYY6ju0Fuj4EjLzOa8xn6E3KZxi+KIr3CsIgwiIdQSoHZsbpMfJ3FXtzWq9lcd90WGtGnPlS+ayWP6UjJfnMRG9lyyqg7znu7/BTfTEzzPbkU8wdG90J1CzkdRkV84z3WI1pZMpOgQ+bQm+gEBbJxWTf6j09gki76iTJ8naUfpYmW9fqJELNqxgYGEB7WzvOX74CH/hAGy684ALYFeWUJFmAHN+amrhYNTAgF69cLiloIcZ7sdAGcDy8+moWvM9muV04zEW6fF5uB5B8rVzJMf2mm+T+laIJAEnCenoY2hgMcqwfGCDhW7aM81M2K8mbiLAQ88X4uLwmfQmTajCb9RUtWBA4LYjWO++8g3Xr1mHLli245JJLAAD3338/VqxYgT179uDMM88sua/b7Uar9cux8B5BqVwnfdKx3y/zsET8ej5fvCpYV0cCsW8fJ6pCgWEgoRAnzt7eYsJkllz9+OOceHfv5sQnwkhKeZP0K5suF/ffv1/G/+vJTT5PQlVXR9L10EP0vgkJeQFFYZtXr64uhFHfj6rKfXt7+ZkgaCKxe2SE13DddfTwzRTmzJmD++77G3zve9/DH//xH+OGG27An36sFq++5gEwQ4RrsvLupVAUMjVC8uHwsDBt4ijl3VuvJQkR3hRXkCTGEZAkIjUE+Ocw/0ZPngoq/3wdoDenhtLlvvaJBrhNYejayOtA3k7vlKelWEK8VF9E36LHJuAB2q9nWwDZvuQxilDY3YCa5zWmB9k2m53tSoeB0R1A3YUsfGzTRCAcPpJFbxvJkZoE4NMUF/sYTucMkGS56klEbC7pzREhhI0rgP33s5+dIRKa8X0MK8yNsc1CQELvrYwf0opBp4FMWvM0JniPBAlM9vGzuvMnKuaVDDV1yePanSRaZvC00tOWibCfoJp7UWejrtUJwO49u/Gf//GfGI2O4v7778fBg0246KJT04ulh9dL0rJ9O8dTm41kQsi4x2Ic9wF+X1MDLF8uF7LEQtqiRSQkQhBJKBWK8iKCHBkVa6s1u0Tx4NpaEqyaGukJ+4M/YDuEx6m/n3PB4KCsqdXVxeP8+MeyhEk155/V+ooWLOhwWhCtl19+GaFQ6DjJApj7EAqF8NJLL5UlWr/61a/Q3NyM2tpaXHnllfi7v/s7NDc3n4hmW7Aw49B7YfRKUECx10lMfmK18pxzmAslVgVdLpKTRIIiF/k8txfiEiL8LhbjpKOvUyVI0tGjnNjSaRKgfF6GkZTyJulXNletYvz/2BjPGYvJFVZR/6ujQ5Kw8XG+nncez5nNSkJXbQgjULyK6XRKiXx9/ZbZjsk///zz8Y1vfAM/+9nP8Nhjj8HjuQl33fVRtOSexquvAedfMI2DT0XevRxEGGJ6iJ4su7fYy+KuB866B+hbJ9XvjAa0zeS4piIbWRKKUga4v5tCEfEeht2J0LlSXhGzHLPwJsC3VuYtdd9BAjfwa4ph2B0kUblxWbg3PUhBitEd9IbZbCR8dgfJWTbKa29cIdsyuImELR/SFA9tmsx8fKI3x6aQqPk6AN8cErdYD+uXRXcwX6pjmewTkUtXUOnRK2Q1kpik0IfiY86Uzal5Bh04XjTZWTdRhdIs1LSgUsb9uCKgoikaGgitGakvRXrFeYTH8xQOFxwMD+LBBx/Epk2/xvz5Z+Cmm/4WW7c6TwrBmk5ZDIDkKBQCzj4buPlm4NlnScBiMYZip1I8bk8Px9gFCzguijmls5MerYYGjvU2mwz7rq/neGpWa7HatrpcwJ13Ag8/zPG+tZXvxTwSCEiRIpG/K1QGr72W2+hLmFRzfku63cKJwmlBtPr7+03JUXNzM/r7+0vu9zu/8zv46Ec/irlz5+LgwYP4q7/6K6xatQpvvPEG3CKmyoB0Oo10On38/djYGACgUMiiUMhO80pOT4jr/m29/tmGIBZiUhH/i0RgPbxeeqIOHAAOHpTqTPE4idPGjZyozjoLuPJKoKaG9+yTn8wWHbdQoPdJSOWqKvCLX3CySqdJamprOSELpcJVq+gtisf5V1/Piamjg+/9fk7oyzXRuUKh+NqM1xMKUSr+jDO475tv8lx1dSR2iQRJ0dlnc+JrauL1ZjI8X3s7jyvO8+tfk/g1NnLSf+EF4NZbi8+bz/PzwUG2f2SEx7n+epl/Vijw1e+X1zEbcDiAW265CVdddTncbjcKhSwef9GDYDCIbGEAUICsOoWT55IszOtopVR3wcn3maSmjDcV2AFHI+Bspnek4NTC8NoBeAGXH5j7yWIDOqcCfS9QfdBZDyTCfD/nVm7T9wIL8jrrKYbhbQe6rtcK09oB02u3A80foCctEwU83UDTKnq4YNi+kKeXLTVeoS/sgPcMoKMRSMdJSuIHAVenrC8FB/dVC0D0XaD1g0BqDPCCnq5cjG0OLUdW5VGz6QTg7gb8PpKfXJyqerlEiXZ7Zf/aUlq/NQD+BSRAIzuBwGJuKgiRmgTSCSBwDvtSHef1dH0E6HuW/eqs5XlyaSCym+cLncPzFfWxHbD5tTJgBb5v/xCghIDUMOBpYJiiaHMhz+vW38f4oLzHNju3OU7etB9iakjeP1eIx/Sc/MVP8VvLqgUUUMA//tO/YnhkGDfe9BWcc845sCt29CvXaQWvTxyOHWN4tijlIcbhShB1ppYvl2Qqm+W4d/fdHGvHxzkeirDrsTGOg9dcw0UoMadEIlQoFHUahQesqYltiUb5Khb44nGe3+8vPwfosXgx8Gd/xvlHiFzoPW7PPy/7QFU5P+zZAzzxRBaf/SwQDGZRWzvx/KUg5tK+Pu4zPl48p1iYfZzOtuVk2mwrFE7eI3XvvffivvvuK7vNa6+9hvXr1+MHP/gB9uzZU/TdwoUL8Xu/93v48z//86rOd+zYMcydOxePPfYYbrnllkm16dFHH4VPJLNYsGDBggULFixYsGDhtw6JRAJr165FNBpFTU1N2W1Pqkfrc5/7HG6//fay23R3d+Ott97CwMDAhO/C4TBaWlqqPl9bWxvmzp2Lffv2ldzmL/7iL/DFL37x+PuxsTF0dXXBZlsNm618Z75XQea+AcC1sB0vxmmhEgYHpYdJ7xESyOeBJ57gilptLcPoAIb5jY5ydc3okQG4WvfggwyLqK3lyl46zVAL4wpeNffO2M5LLmHbvv1trnDqZd/vvpvnEPsMDNArVFvLNrvdbPfwMPcNhYo9R8br0Z9bUWTNFhEa0trKEELRNnrpildHRT+++ipXOgEe6+KLzT1aos/LtetkoVAoYOvWrfjRj/4Xf/d3V+O73z2AL31yLhxOBy6cTDhhanD2vAZmXopCHjj8BL0xznogq3moAPlZZphtmHs7w9DMtheekOm2T3/sVB+9Ob5W5keV6wvRb8l+erMyUS3PycXQQTUJNF7CcMO08MxEgEQ/4HADnnZkMzFsSP8RrvX/AM7Y21pdrrOAjg9Wdw8KeZ53979qAhde5m3ZnQy9c3gBT7u8LnetFrZXR0VH/fUJr96RHzG0UPEA6QiQ7AF8c6ksWM2zYXyecgmKmzhrgag2cIXO0QRP2oGuDwNHfsx7YPcAsf30FIbO4fmdIXoUc3HmgM27cxre1ukhp6p4afNm/OyZ57DqY38P9G1AS+tqAMCg8jsnvD1iTIxE6GkaHqanSFU5vnZ1AR//eHlvjfFY+jmosbHyvHPllcCmTYwQGBykR6y9neOlz8f2RCLyu9pa5ts6HMAFF0w8jxhra2s5douajeedx9Iib74p1Q1TKel1q6vj9qrKgstHjtCrNTrKEMalS4H29ixuvnkDvvzla9Ha6kRDQ/VeP6B6j5uFmcfpbFvabGNVb3tSiVZjYyMahYZoGaxYsQLRaBSvvvoqLr74YgDAK6+8gmg0issuu6zq8w0PD+PIkSNoa2sruY3b7TYNK7TZnKfdgzCTKBSsPpgMVJVy5SLR9tAhvtfHjSeTnMiCQX6WyfBzRZHKgWbx4l6vjEW32YpV9mwmuTDl7p1ZO4XK1OAg2yTytex2xtLbbAw7vPVWmbMViXAi9Ho5WXo8nHibm/m9283jGa9HfxyR7GwsVtzUVD4/QfTjnDkkfkKF6uKLJ26vKFTTEjlazc2li1yeDNhswIUXXoJly5YC+AWy2QIi3ltQKBTw7DP3o62trTqxDH8LMO/WWSr6qkzMrcklgewQhTCcbsAW5PuO64Ghl4DEMeYl2XPA4YeoSNd+tczt8TcDrVezoPF0MaEtTVTim/thqueV6wt9v0FhjbB4D5X7shHu33EN26k0MtQxFwcO/1DLXXNRCTENOKPb4LRnqfRnSwO+xhI/UNVwnxQALsATAAoxEiVblmQv0wegFnDOAWLDFPDwNwPwAp4aoPvDxWIjUAClAfAEmadmqwPib/MrhwNIHQLC68vn7+UzQP/PKXnvagQS+0kAaxYDTi8QnMNQy3xU3kdbRrsHfop1FOJA3gmkepijhiRgawByWq6aq8TgNct4Z/c7+Md//EeEw0O4ZMVKAEBL62rYYcOA40bT1MLZhH48DgY5HoqcKIeDY9b8+aXHeiOM46so1yHmHa+X4+bBgzL8733vY60sUSw4GuUY3N1NcrdrF9/X1ZFEhUL87swzueh3/fX8LBpl2KPfz/Hf72dReSGooapcHKuvlzW97Ha+P3wY+Pd/J6kU5lg0ysW7ujr2gZCWj0b5/ZIlTlx/vXOC4mElWNLtJxenq205mfaeFjlaZ599Nq677jrcfffd+O53vwuA8u4f/OAHi4QwzjrrLHz1q1/Fhz70IcRiMdx777348Ic/jLa2Nhw6dAhf+tKX0NjYiA996EMn61Is/JagmkRbvWx6XZ0UrtCrA5qJSsxktXqzdg4NkWwFAmxLLsfPQ6HiWiX6CaqxkROkEOMQK6iDg8wnEzLpoiaV8XrEZx0dwCc/OZFYlZoIjeqB3d1M2p47l/+boZTYxXQTzmcSdruCQgH4/Oc/DwDYtWsX/uIvnsYfrnFj//6VmD9/Pi65uIKlZSw+PJsoJd3t72Yh3IMPMZ8nNQiM7aNK4Vn3zEytr2rbUolkCej7reMGqbjo8ANNV1KEI/YuRSiEh8fupvT96AiQHge8n6EAhqeGcvFju4tl0QVKqUMqXiov5tMUoijkNLGQDM+ZHmLelzOond8lpeaLiBaK1f6SYXrG/POoEAn7RGEMY/t6nwGGX6PAhruR158O8w92qhHWL5dFrIWQhrtWk8bXVj4cQcDdDNijWvHoxElRHozFYug53IMli5egtbUN5557LhYsWIumlmYMoIBB5XdOmtFnFDsKhej9sds5lrpcHIPD4cmp+onx00xtNZUCLryQc0hjIwUxXn6ZURIiX2lwkAt6gtQ0NZGoCXXbSIQLXKJIcX8/CaNYuFu0SKrgejz8i0a5MDZvHr8bGuKxMxmeMxLhOC5UE5ctY9ubmljWY2SEc2A8zv1WrWJ7LFg41XBaEC0AeOSRR3DPPfdg9Wq69G+66SZ861vfKtpmz549iGojgaIo2LFjBx588EGMjo6ira0NV199NR5//HEEhY60BQuzhFK1p/TEyUiYli7l56JmyKpVpQ3/mVLGM2tnRwcnukOHOLE7HHzt6iqvJqi/ljlzGBby6KMyhNDjYRhLJTWoalcYzdQDs1kSrHJ9Z3aOU72eytlnn40vfekv8cMf/hDfeWojfu+6jdi37yosWrTo1Ki/VU66W02SZORixUWN+9YBZ3xy5sngTMqIC5W8+CESq6M/YdtFceHgIq0gsRZOlx6kRwsgAUlnKf9uhkrqkMfraw1RoMLbytA8u4v9iAJJV2QrCVdwQWn1Rb3a31GtiHI2Vr6WlWhfapDXkB4BorspilGzmJ9lorJ/9SSyqP1hWsreFqkSOec2LSRzpr2tpTESGcFTTz2F5557Dj6fD9///vdRV1uLlSv/PwDQhC6ePSFtKQXjeBwMcvxNJvn5mWeSoExFhryU2mpdHY//wx+S3MViJDuiUHA2y//37qVgRVOT9D4J8QtVlQt+AM/T20sStXcvPWbnnktiJRbubDa2Pxql0EZvrwyPTKclaRob4+cHDjB8MZFg+/RzIFB9qKAFCycapw3Rqq+vx8MPP1x2G72uh9frxS9+8YvZbpYFC6ao1utkJEwA/49GSUrKGf4zEfJQqp2iHbt28f/Fi6lAVW5iN15LMskJtLWVK6VitdYYPjgVT5KxBoogiGvW0FB4/nmpQLh6dXnSdDrUU7Hb7bj00ktxySWX4K233sKPfvQjpHd2YdEi4DcvpnHpJXY4nSc59MJMIhyQtZ/MihqXq381G23RY0LIXhkMvUQilBoCMkNaEWYfkBwAAt2sUeWqJ4GxidDzgnZ9fnNZdDVJIuhsKJbLF32il54X3rPgAnrV+jdwu2yM4YM2J3Otyl2HKOLctro6Eira52pgLtfYbk0xcQk9fe6m8v1n1n5xPrtroudtlpDJZnD//ffj+eefh9PpxA033ICbblqDN96QbR5w3HjC1QTNYByPFywALr0UePpp5kaJMhiTlSEvNV5+8IPAz38uc2NHR0li6ur4XhSwb2tjGKJQJBRz04IF0pMkvG2ifSJKwuslOfrwh9mO7dtJ4BwO4PzzZaTD5ZfLMiHHjpFwHThAoqcostyIvnyIopAcWiqBFk5lnDZEy4KF0w3lvE5GcqGfML1e4Kc/PXGGf6l2Cul3AGXj3vXXooeI0Rd1T0R9Fv12vb0yJ2syxYGNIY/5PImVqtIo2b6dK6779nGSv/vu0u0/neqp2Gw2LF26FEuXLkU+n8eA3Y6dz38B3/nOW7j00ktw993nw1fK7XhCGmgSrmhTmJNlVtS4lAemEsqRJP135YoYV1vQWRAORw2AQcCh1cUqFFhrKx0G/HO1EL88/wDA5uCyfcNyoPOmie0sFeKo7xObAgTmMwRTL+meS7AAc42f4hJQJ4YllkI1JNTYPmcDw/1CLcC8uyRJqkSSzdp/AjxYr74GDA0NoaGhAYATBw824fLLv4jly5fD4/FA6GGdikWHzRbfmpo4D9jt5tERlWA2xkWjJDEi7C+VImlJJPh5QwNzsAIBhu3ZbNzWZgNuuKF43jp0CNi8WYaMO50cj0Ue1Zw5/Pzmm0kY9Ytg+hxc0dZolPPCa6/JPN90mudcuZKv+nnnJKT3WbBQNSyiZcHCLMLM61QpTO1kGP5m7VSU8jHvqlo8wQqHSjbL/RIJhgvW1MjvV62ShEcUoBwYEAmxDDO5557KZMvr5Tl6ekjS9u3j8X/0I5IsVeWEPj5Or1wsVvpaqgnzPBVh1ySyapf8KYb2/AQvbHwUL764Geeeey4+/ellaG05hWIfvR2VixpXi3IkqRKBKqg8/7H1WshfAxA/wjwkPYHQQxCO+BEAdiA3CrhqeCy7QpLVtprvo+8AyVHu56oDahcxPNLsuJMJcdQTWCNBU8fLF202QzX5e8b2+bukN2qymOF8QTUPJBOA1wcoOqW4zS9lsWfPHvz7j+J4663t+NrXvo7FixfjyrU3AQCi2t+pDuN4rPdydXQAeg0wVa28IFZqjKur4z5jYxwvs1kSILudoeIuFz+32Thej40BX/saj7F4MUnP1q0UuRC5WL293G90lKIWoRCJmqJwnrvjDvMcXD1xCgSYhwUwP6yurjj3Vj+HNjYCt91Wvj9PpfxbC799sIiWBQsnENWEqZ3qhr8gWC++CLzxBifYBQsoE2y3M9esp4cT4+LFnHwjEZmELY6xbh23yWa58ul2c6Vz3ToKYpSbEMNhErlwmOTM4+F5BgZkwnW1mElxkZOBzs5O3HPPPQiHP4Znn30W7+x6AFu2nIeb1wDvHjgEv78BTU3BIoP0pMDbQdIxHc9GubwmoHzOkyBhyTCQOERBCBsYDhg/zP07bpjo2dITDptCMQl3A3OmmlbSWyOuZfGfAr2/pDXftJLKiuWISbXepVLtMSNokwmJrISptG+W0T+g/VYjQG0df6uHDwObNm3CK6+8gh9vqcWSJefgi1/8EyxatOhkN3dGILxcYmHr2Wc5Ryxbxvf6EO+bbzYPMzcb41wuRhHs3cuxt6aGXq2FC3mcWIxhgiMjJCqxmPQebd/O0D5BklSV4+/cucA779BTNWcOF7u2bWPbFGVyi4833CA/nzuXxM44h/b18Rj5vPmYfarn31p478MiWhYsnEBU462aKcNfrOLNZJ1toSb1+usM5QBIlHbsYOiJCOloaiIJCodJvoQilSCLsRjDCrNZEia7XYarxGLlvXdioo1EaBBs3cptm5t5/GPHuI1oz+LFlT2BMyUucjLR1NSET3ziE1DVO9GWfwa/WA/84AfPIx5/Bp2dl+KWW67FVVedB8V+Ei9uup6NcnlN4n+z7xSvjoTVAfksQxkVD+tguesp+qAnZnroCYfdVVrIwdsBdN8JbAdrglUjVz+VPilFgCYTElktTqR6ZQWoeWlkBwJjeO3VF3Dw4FVYfW0Ie2JXwN61FP/5yWvQ3t5+cts5Sx6Ul16ix6ihgTWlduzg2CrqB27fzvH+jjuqF1Dq6GAUwU9+wsiAsTFuk0zyu7VrScIeeogKf2IRKx7n/NTVxTF8ZIRt6e/n901NJG7CuxWL8ZxmYfSlFh/NCKbPx8VHMYeKSAqzOeN0yL+18N6HRbQsWDiBqNZbNV3DX6zixePApz/N8ItJ1PY2hZi0enr4fz7P5GUhAS/I0v79nGQXL5bFhvUqipEI8NxzwO7d3FfsZ7PxWkWRylIwSiDX1hZLDJ93HvcfHpZ5ANX033ulnoqiKDiGm/DoOqCzNYZUajEGBrbh3/7tr/HII42477770NXZdbKbWR6lvDKV8ppKfWckaMFFwPi7gBonyao5CyigvNS5nnCU81LZ7AAK0y+8XAlGAlRJxfA9gHhMxb592zDQvwHH+skufrX/E1h41RVYs+YkN07DbHlQjIt0mQwJiFD/Azielqq/CJQe41pbGW3Q1CRVBfWEpK6O15LPc4wtFChmUVvL9y0tsuj8GWfIcV7klNXVAU89xW2MfVLN4qOeYA4M8DhiDhKS82ZzxumUf2vhvQuLaFmwcAIxGW/VVA1//SqemMw2bmThyums4olJq6mJBG5khJNtPs9Vy5YWEqZkkv/fcINMdBYqir29wJ493EdV2R4t1QiqylVa4Q0rZZwYyWogwGPkcrI/KxU5rgbVrkqfivH/xxUe3R9DIPAxnHfezzA6eiOCwZ04cqQNx44Bv960CXX19TjrrLOOKxaeElLx5bwylcLmSn1nJGj5FNBwEZXmUmGSrHJS56cDKqkYnsYooAAbbHjk0f/C1q2DcLub0NW1DK/2/l+cdVbolAqrNnpQnnmG+Uai/mA144XZNiJfanCQ7wVpGR+XRdoVhYtLk+0PMUYLZUFRpF6EC27YQAInvEdOJ3DWWcDy5Vwwi0apBrhypaxlqM8pSyQkUTJ6lSotPpqRJbHfrl2yoPHQ0MTFxFM9DN/CbwcsomXBwgnGbIepGT0+ACfC6a7i6SctsYLpdPIzt5sT2PAwr09vWOhVFPv7aRS43ZzMhSyv3U7S5vPRI7Z+/cTwF73xsWqVzPFKp2lcBIP8XBC0qV6rqNmyaRMJZV2dNCCM9+pUjf83Ghjrem5CZyew9oPAsAKoqoqHXngFb731Mvz+Hbj00kvw8WuyyOUWwOFwnDzCVY1XplzeUKnvShE0YPr1tmYyJ2o6qEbF8DTCsf5jeOWVV7BlyxZce+21uGbVNZgz5xbc+tEMnt76GewbtWHevFMrn1I/9gIcn3p6+P8NN/DVOF4YF4XMxhSx39AQP1cU5j+Z5WhV68HXwzheiIUuReF59+/nuB2Pc7tbbqEk/Cuv0BN2/fXF46N+jlNV4MEHS3uVKi0+lqv12NTE2lqA+WLi6Z5/a+G9AYtoWbBwEjCbYWr6lU+xAhkKTX8VTz9pjYwAF14IXHklzyXqqsyZI5OsAU6yQ0PcPhikEeHx0PsUCnEfgO1sbOSrWfiLsdgmILfz+bjd4GB1BZHLob+fuQovv8zQnPp6tvX117l6q6/JdTLi/6v1nlUyMBRFwd/+7d+ir68Pzz//PLZs2YJPvdCLhx/+A8x3vIAnnjiIa1fXoq62bnYupBSq9cqUyxsq9V0pEjYdsQcz75tzmjG6U8WJFMmYRWz69SY88cQPcfjwYTidDixbtgzhwW68+hqQb/td1LYBa88+9bzIQDEpCIc57tXXM9xt/Xpu09vLsfDoUeDJJ2V4dW0tF4o2biweU/T7NTRwDGhooNKey0VyVUp1cCrjRV8fQ7GdThacHxwsln8fHeXCWX09x+zeXob2dXdPPKYQyqjkVSq3+Gg2ll12GfO1Wlpk2GSpxcT3Qv6thdMbFtGyYOE9BEFIxMqnmMz0surTQVMTC2gKb8+WLZwEzSYyUSNrfFwWoFQU5mK53QwznDOHE6fI1xICFvrwFz2hCQSY8A3QwBga4sqmyA9QlKl77lSVRo0oqGm301hyOGh09PQUE6kTHf+vrzlWX1/Ze1aNgdHe3o677roLd911F4aHhxEIBHAsfwPuvu/jeN/De9HZ2YlVqwK45JJL0NXVBRtmuWDNbHtlStX5mkpoXSnvW+daADbW08qdYGJzIkUyZgCZbAbbt2/HK6+8giuuuAJLz1sKu13BggXzcccda6GqF8KtxYbpa16djHzKakiLIAXPPMP8qVAIOPNMjnli8Wh4mMTLZmOotCgGfPSo/H3rx5ShIb7qP0skuBDkcpUuw1GNt11/Ta2tJG8PPcTQ7tpakqzhYY6vfj/H7ECAY3p3Nz/LZKQqYam8sGq8SuXuqVltMUHeqllMfK/k31o4PWERLQsW3iMwelhUlQY5QEW+6UKvOChqpui9OPqJTNTIEsWKRcHJ5mZOjKEQ23b99fzuySdLh78kkyRq4bBcbQ0EuBJcKJDwBYMylNFVRqegHGIx4OBBmeydzdLgsNloUDQ1FatnuVwnLv5f9OfQEPtuZISfV/KeTcbAaNDinex2O77zne/gtddeg3PgAfzvo/vx4IO78fnPfx61tbUYHR1FTTAIu+7EZqGGpWodlcVkakudbJRVQPQBh58AskMnnticBiIZb7z5Bh7733fx7rvvIpvLoa6uDoGAA+k04HZfjpUrLwfARY5ToajwZEKEW1u5sLVzJ8ekPXs4Pp1xBvD22/zt1tTwWIUCcO658jcqCreLPCwRJgdwDBCfVRpnqvG2m11TIEASpyd1Qs49EuHY4/dznO3vZ4h1NMqFsWi0eqI0lUW/UrXF4nG+n6nFRAsWZhoW0bJg4T0CMw9LIjEzxzYqDoqaKd3dE704okbW0BAn5VSKn8+ZA3zsY1wBXb+eRsWmTZww777bPPxFVbm9Pvwwm+W28bgkQYpC4lZfL1d6J4P+fuAXv6C8cTLJ4xUKUl2rrY2GhlE9a9ky7m+2UjtTIhmiP4eHi/uz3CrydFFTU4NrrrkGwDW4NJPB7t27kW48D/2FAj77l59FLBbDRRddhPPPPx+LFy8GXtsCQBIus1pHrdVG1J2CtZtMUcr7JhQJk32Ayw/EDrFAcvcdJ+daTrJIRk7N4cCBA9i5cycuvPBCDAzMxUsvpfH01lZccskaXHzxxfSW2mwYmPXWTB6TDRE+fBj49rc5XhQK/J06nQx36+9nKHI+z2OJ8GdFkQRKhA/qxxSg2CMkFFxLjS2VvO2lrum228wXj+64g2O28HD5/bzOQoFjrsdTOWx7pr1KevIGzMxiogULswGLaFmw8B6BWdKwMW5+qjBTHBwfp5epu7t4dVUoVYVCNCQcDhKTYJBE5fHHOWEbjRZj+ItYcR0YkF4sgBNqPk/C1dLCMMTmZp6jvX3yHiVhdBw+LMNjVJXGg9/PFWe7nau2RvUsgMZJJlNs9MykSIboz5qa4v4MBE6MepbL5cJ55513/P0Xv/hFvPrqq3jllVewcePzAIB///dvYN68eXjyqe/C4XAhMtKAo702NNQbDNPJeLZOdaW8Ut63fAaAA7B7gPghIDsOpMMsYByYf+LbeZJEMjb8cgM2bdpEkp7OwOlYgeHh+Vi6dC7OuOLv8Y/vm+Uw1BmCUVyoXKic8Dz39HBc8nrpeW9r4xjV3s6xpaaGv+GGBlmKoqNDjhO33UYC5vFwXFQUSSqiUeD55/m9KF9hHFumouQ3OsprMwvza23l6ze+wWvPZkmyQiHg/PN1KqdlFn5mQ51VUXhPhKiSBQunIiyiZcHCewRmsfCrVs3Msc0UBxUFmDt3Yry918tVThHeJkJLrruOE/noKAmXy8VXswlakJ/9+0myRkb4WV0dicZ553GVNRaTq79dXVw1niyMJFJI1LvdvI6bbqKx5HQCjzxibpyYtX2mRDLK9eeJDpWx2Ww488wzceaZZ+Kuu+7C6Ogodu3ahTlz5gAA/vI7B3GGeyMcDh8CgS7Mm+dGff1lGI00IZl4D+ZJmHnfclr12Nh+oKDFNeXzQHgz4O8+8V6tWQ7HHI+NY9euXXj77V3YtettfOGPv4DOzk6Ew2G43W6sXbsWwMVobW3FsOdDGABmO9NvRiHGPqG8VypUTnieIxGZgyo+Dwa5rX58FqqBW7cWn6+/f2Io9c03k+y4XMCPf8zvFIUe+EQC+N3fLV7smYqSnyBigcDEMD8xpo2OyhpehQLH32h0YkF6I05VdVYLFk4ELKJlwcJ7CMZYeL2E+nRgnLj1NVPMkppFuMvICCfm667jiq2qkrBs38625fPA0qU0IGIxObEnk9JrJrw4mQyNilCI+wYC/H/tWiaev/giw/pKrfKWgt7oaG6WITF1dTzPf/4nV6Lr6tj24WHuVypXQhC3SmRysn1v1p8nG7W1tbhMx26//OUvY9euW/HDH76Nc5xPYfv2/TjzzE6ce24T3tqxBYcPH8KSJUuwaNEiuF3uk9jyGYTR+yYKFtsdQN4JOIKAtwXIRE9eTasZDMeMjEaOq1H+9b1/jTffJFNoaKjHkiVLkC/kAQBrP7YWr77GfQYcN2J4eldw0qAoMudqbIxjjlmonN6TH4txrEqnOQ6JRRH9+Oxy0bsvPOS9vQzPKxQ4PqoaX9++nQs911zDQu9btkhp82yW3z/4II+pJzFNTVwkAiaqEVZWJS0eq4xedaeTYdt1dWxnOdl0s4Wn9euBNWsmtsuChfciLKJlwcJ7DPpJciZDKiaT0DyZbeNx4LHHZN6TqC0TCNCw8XhIyAIBTuyLFkmvk7jODRskeROrvHffXd0krjc6wmEStc5Ohvts3cp2dXXREKqrI8GJRksbF15vMZlUVa5KT1WkAzh9JIp9Ph+WL78AnZ0XYMOGuxAfyaKu7hk0NwNbtuTw0kuH8cgj+6DY7WhsasIll1yCpUuXIp1OI5VKoaamBjabub/jlCimPBnUXQAk9gPuJiAbOfk1rSYZjvnqa0Aul8Out9/GYHgQg4NhDA4OYnx8HH/yJ38Cn8+HtrY1WHPTLZgzdw5CoVrYbDb099ODIXAqiFlMFSLcLRDgYktXF8eAeHzi4onR85zL8Xd7zz181S8kBQJ8bwzfGxrifnY7yRVAYjM4SG/ZsWMkOJmMFP8RYkFCuXDDhuI8r1IeJDGmxGKyeLx4NcLMq97SAnzucyRfQOlFJGOYYjxOQaWhIY7zlbxbp2JBeAsWJgOLaFmwYKFqTCah2WzbZJIkaelSEqhkEnjnHRIjvaGwdi1Xgffu5YTsdpNsOZ0kX3PmSE9SLMZQGlWlcTI+zvdidbka6I2Op54iqYpG+RcKSe9UOs2VWEWpbuLP5XjM3btJJifjaTPidJIolsTQCa/3ZmQUYOFVN+KMK1QcPnwY77yzCwcPHkJrbjlaHZdg0+ZN+Od//id4vT7MnTsXc+fOxZIlS3DVVVcBAFpyT+PV104zstWyCgjnTnn1xHwhj/7+fvT09KDnUA/e3OqAoii47KP/DdWm4o+++ghqa2sxd+5idHdfj3Mum48h94VwO9zouJgkKg1g8ORexoxDH+4WCnEMikQ4Dph5s42e5yVLpCfr0Ucnkp5yhXiF+qk4bm0tx5HaWnrd+/s5FrlcDEsUC1Pi3OvWmefBGsercFiGKebzXBC65ZaJY1Qpr7qiAD/7WXlCp7/OfJ5jOsCx2tg2I6myQg4tvBdgES0LFiycMOgn3YYGWSNGbyiIleKODq4GP/ccJ9yxMe7T3l46TAWY6MWbTNHOUIhkSBRlbmwkIYzHpXFVKtxFnEdVSSbPO4/yx0Ii3liH670OM2KoKArmzZuHefPmFX1+/vnn46/+6q9w6FAPenp6sHv3boyNjeGqq65CIpHA7/zhjzF37lx8ZEUEzU3NuPwKNxYuXAjFfgp3pKf5lFJPTKfTCA+FER4M4/Dhw2jvaMdFyy/C9m3b8eW//msAF8Hr9aK5uRkDjhtxGXi/HnnkkeO1rGYCp4OHwhjuVq0326ze06OPls7XNAvfA7i/Pkfroot4HH2BdrebRePTaRJAu51jVHPzxFpcpfJg168H3nhDerWGhzl+fvaz0782AWPEgNMJzJtHT5jdLtsWixWTKrPizb9N46eF9w4somXBgoUTBqNxMXcuSZbeUNCvFIt6VT4fw3Yuv3xiXlggQGNk+3YSIoeD771e4N13gc2bpWeqVF6ZHnqDIhqdKLWs31cYjfrtQiEaE+GwlNcXq86zWdD4dEZNTQ0uuuhiXHTRxcc/K2iMOZfL4ZprrsGhQ4fw7z9K4OKOn+Hpn9vxF3/+57j0UuCrX/sqRkdH0dTUhKbGJjQ2NWL58uVoaW6Bmldht9tnv9ByKZxA9URBosJDYYTDYQwNDeGDN3wQnZ2deOjhh/DEEz88vq3L5cSaNWtw0fKLsOjMRbhj7b+iuaUFsdDtx0M3JSGaOZJ1ungozFT5qvVmiwUGVZVlKUqRHr0nHZCLOHffzTElHudCz3PPSQVCEWJ9993AwoUcZ4wCSIKgAOVzSQcHOUbl8/zLZICXXuJi08KFpa8NMA99LDW+mUUMxGKybS7XxDwus+LN1vhp4XSERbQsWLAwZVS7Oq3fzmhc6JUD9WRGrCqLZPG+PhoBRsl6RSGBOnBAGnBnn81QPVFcuauLK8Svvw4sX146hE/fzkCgWIHL5aIhIv4EuRoZYRtdLrZfrH7PmUMjyOFgWGQkMnsFjd+LEAZ/TU0N7rrrruOfJ5MJhMNDsCvb8eprwJlnnolDhw4hHA5j9+49GB4eQmtrK1qaW/DjH/0YT/zwCZIwjYgtO38Zrrj8CiSSSby1fTt8fh/8Pj+8Pi/8fj9CNVXGm84SCiggmUwhmUggnojD7XajpbkFsVgMm1/ajEQigUhkFENDYcTjcdx3730AKERy9Cir2vr9PjQ1NeGKK65AJzpxySWXorOz8zgRbWpqgmJXNLEKP/xnfgFjKpCM8/nUG+8zRYhmWo1zNlFKla9a8QZBKEdGOG55PPSGmZEes74GikP6VJW5qe3tMix682ZuL+TgRZ0/l6u80IXxGrNZkkgRCZDNsr7hGWfwfanxvVToo6izaCaSpI8Y0LdNqNHqSZVZ8WZr/LRwOsIiWhYsWJgSql2dNtsOmBgmEgoVT+iVim4KqCpFKwIBEqqxMeDZZ1lfRVWZJ7V/P49rt5cO4St1PYoiw1r6+mg81dXRsBG1tnp6SKiyWe6TzbI48+WXS49aOWWuUsjnT/0wKz1ORFiY1+vDnDlzMABKynd28k8gn88jmyng1dcAt+cKXPm+OYiOjSEajWLn21Ekkjm43cDAwBi+970NRcdWFAVf+tKXAAAPP/QQomNjcLvdx/8uu+wydHZ24tDBg9j/7ruw2WzH/5qbm7FkyRJEx8aB2gC++Y3NyOVyKBQKcDgcuOKKKwAAL774IqLRKNLp9PG/97///ejs7MRvfvMbbNq06bg3DwDOPfdc3HzzzRgZTuPb33kVbrcbPp8PoVAbampqsGWLCrui4AMf+H9wOp2oqQkdD/WLx6GRqYXw+xcikaSq5uHD8poHHDdOyEdKJPh8zyQhqvb3fCpAeN7Xr6dXqr29+tIRRkLp8VDQIpk0L2pupsgnlAezWYYdJxLAnj38XUWjFKYY0IqCX3WVLABfXy/HrWrEcy6/HPjVr9g+m43jo9PJ+3LgABUOS43vxuiEujq288EHy88HZm1TVXNia1a8+XQYBy1Y0MMiWhYsWKgIowFd7ep0KUMCKC78a5RKBuSK6ZEj0oOkF8EQOHSInipV5URfX08jsb2d74eG+BoIyBC+kRFZ8FNRePxnnqHx0thYfD0A/z9yRIYCpVLFcsd2O42i4WESvRUrpPx8d/fUyccTT/Ccp2qYlf65mA0vSDUop2pn7wK6u0z2AaC2qrj9T25FPB5HIpFAPB5HJpPBgGM5ACDbYsc4BjGQSCAxxO9bLrgaTsdZ2PTuOjz55C7k83kUCnmoah4XXjgff7T0RhwY3Yvu2nfwz48NI5PJw2azIRAIYNHVbOcjv3oD0WgGPl8DfD4ffD4fzipcB6djHtBxJrouXQWfzwe/3w+fz4eGhgYMOJpRaC7g9//647Dbi6s+h7VXZQ6QBzA6yf4z/kZ7engvFy+eWUJUqYjuiUa1iwLJJPD221yIEfmh5Z5rI6Hs6OBnt98ux5tS2wL8vY+PcxwBuIDj8XCMicc5vp11Fr87ehT493/neFdTw/tWKLDGYDn093Mc7u/neQsFLkgpCl8PHQLuv59909FRenw3Cwmshpwb8zdL5audLmqrFiyUg0W0LFiwUBZmnp5AoLrV6VKGBCA/y+dpIBhVAhWFBT137uQKfCjE90Yit3kzSY6qMszk8GEaJbt308M1OspVWqeTIXzHjpEcPfYYjZZly4BXXwVee42TuVAZFNejqmxfIMB9g0GeOxAg+XO7pbHoctEwWrnSvCZNtcadENDo6+P5TsUwqxPhBZlNKIqCmpoa1Ah9agOuv/6Gkvted911uO6660y/mzdvHgqFd/Af//EfsNmcE76/9957Sx530aJFWLRokel3wnM20zD+RsXvMRw2z5ucKirVbpouJuNNNRvTWlqKjyXCloeHubiSy8nPyz3XpQilnmSJtrpcE7dtb+c4k8mw/zMZjl0rV/LeiFC6cJi/N6GEKD4fGyMR27Nn4qKHqnKc/clPgB07OMaMj3P/hgYuNCkKS1scOMDftd/P45Yi26JAcjQ6PW9lKVJ1OqmtWrBgBotoWbBgoSRKea5uu63YQBgaoqHichUbPKXi+AEaMfE45X6dTq6I6nOnVBXYto37d3XRINi2jSvt+vDCaJT5C/39UkL4rLNorPT3A5dcwnyDQ4c4+adSXCH2ern9zp1cDXY62abBQZKbZct47OefZ22uaJQrv6pKZa/6epKsVIptWbiQ1zN37sQ8MqC6UEu9cmEwKM8BTDRcToZ6m95APBFeEAuzD+NvNBLhffT5ph7yWgqlwsam+xxPRmSjnDde8FhBPoNBko+aGo4rNTWVf4eVCKWxrcuW8XOx7ZlnAq+8IkORnU4SniuvJOkR+7a2SiI2NMR2FAocj370Iy4W6a9PhOH19zMsURRTT6V4nrY2Hsvh4BiYy5FgRiIce8uR7ZnyVlqkysJ7ERbRsmDBQkmUyqvIZKQxcewYDTJFAf77v7lNNisNnlISxuvXM+QPoNxvby/w85+zjksoNPHcLpd5kVAxwXd20tgPhYD580mGhofZljfe4HGuuoptEUIXmQxJQmcnt7XbaWAIFa7nn+exHQ4ZWuNw0KiZMwf4wAd4DJGH1d09MQfDjJiYeXz0BlhjI8nsyAiNPaPhUq1hOZNkTH9On4/G3Wx7QSzMPkoRg6am8s/OVIRwBBHxeieqdU413HSyIhtiXBHCEcJ7HYvxt5bPF48rQoK8vn5i+HKp32Ep74xZWwH+1jMZtuexx0iYxO9KUYBLL5VqqeK4Q0PAt74lx2OARHDBAnqj5syZWFvr8GH+NmMxXpffz/EsEGBO6Xe+Q5IliKUY9yqR7dn2VlqwcDrDIloWLFgoiXIrlYEADYSHHuJkHApxpRRgQWK9wWNmdKxZI+vC2O2UYn/rLXqtzjkHuPFG83O7XDQUxLHEBD8yQuNQ1L0aGaHhL4Qq3nmHohn5PMnXokVsUyjEVdt4nCvaDgcNkEiEq701NTQ+RGiRyFkYHWUi+bXXMifCeH1GYjI8XDpc0miA9fXxGG1tPE5HR7Ea4/r1vK6mptKG5UxKaRvbNzjI46oqv59NL4iF2UcpYlDKuzAZIRwhKNHYSI81YK7IN5Vw02ok1I3weukl2r6d404+T3Ly7LMcz554Arj6ajmuKAq3r68vruFXieCZeWfKCYIoSrGHfmCAniRFoWiFPpQuEiHJEmHYdjs/X7KEY1YoJEMCRW2twUF69dNp2f7hYY5vixdLD5hYaGpq4n4f+9jE3DIzTCaf6nSopWbBwkzBIloWLFgoiUorlZkMc3MaGzmpizx9j4eTtt7gMRodgYAkCoOD/FMUGgLbt9Nov+aaYtWpZcuAxx+faOCZ1b3y+0lmcjmp/DU2xmMcOgQcPEip9xtvBN58k+GBqkrDIxKhcSXk2sWqdl0d97XZ2H69caUPJYrFaGCK5PCBAbZNVc3DJY05b04ttSebnXhP9OIf8TgJoFk4UzVkzIhSBpCZgagofJ9IVO8FsXDqotqwrckI4Tz5pCQ0+/ZJye7eXnqPhoaqywMyw2Qk1CtBLOYAPJZxgUiUdhDHFAV+J6uiaLZwVVfHfhILMU4nj9/dzfHLGIrc20sBjMOH2S6vl31pt3NcmjOHY9y2beyb5maOo9/6FscLl6t4QWn5cuCDH2Sb29vlGBiNsj+rIVkC1TxDvb2yRpZeJdGChfcqLKJlwYKFsii3Uqk3HOrquBIKkNRUqhulKMwbePpphro4ndLQSCYZkmisY/X446UNPH3dq1iMK9PC45JO01DyeGh8KArbumIFc6vmzKFH7dAhrgQ7nTRCLr+ctbvEqnZNDUnTvHn8324vVjAUynvhMI81b95EYvLWW3wvwiXNct6iUb4ODdGI0m+nF/8YGeG2K1YU93M1ZMyIcl6KUp5NEfJUjRfEWsV+b6BamfZYjDWfVFV6Ot9+m/mSDQ38fYVCXPyoJg9Ij8lIqJu1P52W+YSxGNsl2l5fb75A5HJNFIBxOvlbAKojeMaFq44O/sb1ZHThQn5eKhR53Tr+7p1OGTIoxrKPflTW+qqvl4Tml79kH/l8chx0OIALLwQ+/nFeG1DctjlzShdon+pvuLcX+MY3pCdtZISfn8qiORYsTBcW0bJgwUJFlFqpNBoOS5fy82y2ssHT30/vUzrNSReQsumpFA0BvUBGLFadgSfCdoSnLRKRKn75PPcBePyXX6bh5/WyHXY7DZRYjPt3dRUTvWRSyhjHYnwVCoaijowoHJrN0nPl9UrSecMNNCx9Pl6zuCaR8ybCrJqb2UajGEYkYh5apFc5NCoxliJjegh5+8HB0mFQZp5Nl0saaeVQKdTMImGnDyYrfJDL8ZlOpeTvWpCTYJCEQVUnF246GQl1I6JReq2EN02UYRAF1IUXyHg9RnInCpMLUlRt+/ULV5kMcO+9koyOj3OR5JOflN4qo2c5HJb1AfN59mlrK/A7v8NrEWPVxo0cIxwOEt5EgmNJIMB96us5Hul/v+UW1cx+w5PxYAuSODREki1EhEZGLNEcC+9tWETLggUL04JxcgYqT75Go0XkLeVy3NfvL/b4rF07OQPP66UhITxk0SiNgmyWZCoYpJcnGuX5AG6fzbId9fX8y2QmrmqvXi1DlvQKhnrlvZoakqGDB4tD60IhGcpnFI0Qhh4gQweNYhh1dbIPSoUWlcrz0JMxPfr7SbJee43GXkPDxLBPs/s8mTwaY6jZM88Ad9010UtQSY3RImInH9UKHwQCVP/cvJm/a7td5kcJcrJgQXGxcqA4/1J/34FiNdNQiL+5fF4uZFQiWapKAuLxSG+a08nnetcubtPezhwt43HMPHnpNHNNhcDHZEPsRkbYfl196qLvjXC55MKRIKiBAPC5z/H7Bx6Q4ZlHjrC9QpHQ5+NxCwWZjyVyTI2FiI3nNvsNP/mk9FRWkwOaTMqcVEG4o1GeyxLNsfBehkW0LFiwMG0YJ+dAQOYqmRkgZivSdXU0cNavJ7nQe3yEwV+tspUwBgEaM4EACdILL8i8JWNoozE/ob292AAQRl9TEw2zoSF6soQwiFF5L5Vi/sOaNTKcByitwijq9jQ0MGxStGloqNiDpN/fGFoEFBPSUmRMf00bNpCQ+Xzsq927abB2dU00gKYiv6y/14AUKAGA666j4VutGuOpWrj5ROBUIpvVkG5FoSrn7t1csAiFZC0nM3JizN0ReUaiDh4g1UyXLeMChvi9LV5cnTdJPIsdHVLwRlWpUnrOOdzm1lvNj1NqoUf/264EY4Hv9es5biQSUtBCXyLBiExGLgiJsOjWVr7/j/+QIXmBAD1jiYRUUHW5gAsuoChQKDS5endmtdZ27eJY2NJS3XHE4pcIF4xGOc5cd93Jf54tWJhNWETLggULM45KxrHRaBEheL/6FQ0QEYpjJEOT8aqYbSu8UWZErVx+Qqmwmfr6yvWH9EWYxQr0bbdJT5oI9zETw7j+erZBJOOrauU+ECRThCHOncvrNm6nV2xrbOTf7t00zlpaZk41UH+vw2Ger76e5E4Y1qXCQScr3f1exckgm5WIXTWku7ubiw3GxQ0jORG5OyKcb3iY9e1qa7kAY1Qz3bmT2y1ezGfK5+PxK8E47ujzwux2enuEoI9ZP0xHwtyY3xWL8ToXLGBulqKQCF18Mc9ZiuyZCVZs2lQckqeqUl0Q4HVlMvzN2e0MjZxMvTtjv4XDfG1qqv44Zotf110n6ypasPBehUW0LFiwMKOoxjg2yrKLEDwRBiQUAs1WqifjVTFuW46kTKb2jbieydQf0htaxhX6VasmGoAA2y4ENoSRrQ+1mirZ0Cu2HTlCA62jg9e3ZIkM65sJiHv9zDM0uOvrGVIGyDCnwUG+N4aDViu8cCoin58ZD9TJIJszRewqLW4AJABPPz2RKKRS9Kp6PMVqpsEgn6OuLilII0KARX0uvUqgcewoRZaM4Xv6ftATg5kIn927l9cgPPcLF7I9b78NvPoqf9933gmce+7E/jQuCF12GesP6kPyxsb46vMxL0vkxHV1kahFIpOrd2c879y5kjhP5jhTDT+2YOF0hkW0LFiwMKOo1jgWk64IwXO7pXR6MMiV7GpXqieDckTN7Lty11Ntfpre0DJbod+4kQRKSNO3t8t99Qba/v1czW9vLy2NLM4lwhD1eW4i72XDBh5rfJxG5PAwjdjWVhqTlUhWOW+HWV5NUxPJG8BVdUAaZ/rrNhrikxVeqAYnKgTviSf4bE/XA3WiyeZME7tKAgvPPMP6drmcXHAZH+fzPT5OwqBXMx0bk/lVok5UZyfJ1k9/SqELUVerrW1i31dr7Bt/J9EoCdI991TvhRHPWibDBZO6OinfnsnQ6zQ8zPZmMrzOYJD98vDDwFe+MvG3aDbmiJC8QkGG5LW0UEm1UJDev098gttNxStnPK9+AWgyx5lK+LEFC6czLKJlwYKFGcVkjGNFoVFQXy+l1QGu8ra1yZXq2ZyYKxnela5HGA7lvAB6Y1nUsSkUSC6F8EQoZE7axH5+vzT4urpKG8DlDHOvl8b/8DCPJQoyj42RADmdwPPPS6VHM5S7Tn2ejVBLFF67a6+lypnROCtn+FYrvFANVJXP2ObN1SfwTwVC4bKvj0az2X2aDNmbDbJZDrNB7MoJLAwO8tlOJEg8cjmZB/nWWxPVTLu6WPtO5G/pyfqRIzIcVuQxmf1GKhn7IqxW/zvx+/l+3TqqAla6b+J3cuwYjzU6KutYRaNSnl2oBwqBi/Fx/j88TI+RKJRerj+vvZbHjkS4ODVvHnDFFSSw+mLRLld1RLPU86k/r+WdsmChOlhEy4IFCzOKyRrH+pyicJhGRktL5TpcM4FqQqSquZ5KXgC9sex28ziqSmMxFGLokDBWAgGSsEKheL9MhgZaKMSVcZfL3AAupcgmVvxHRni8kRGSrGyWf8eO0aB8910avXffbe6tKnWd/f0yz0YImTgc0mtnLAKrN87KGb4zYdD19/P5ev11XuuiRVP31FQiSckkjV2jNL+4T5MNy5sO2ZyK924miF01500mpapmfT0/i8eB888nkerooEBFKW/x4sXF4YKjo3zuBgf5KrxDlUiivq02G/dfv37i7ySXk891JdKp/52IvMRcjkQylWLb0mn+Abz/g4N8Nn0+fi7q9lXTn01N0vsvQvq2baPcfakQyqnU0zPC8k5ZsFAZFtGyYMHCjGOyxnFrK3DHHZQgFx6HUoRmMoZjpRC3UqQBKN6v0vWYqXIJUQ9RD0eQyddfZ3hUJkNyMzYGfPjD5tdjtxfnsjU2ct94vNgANqqZGRXZxIr/0aM0Pn0+GpXxOMlAPM73iYSsuyOkmMtdJ8D3sZiskeP18jiJBPf3eCbKxeuNs2ruaTUeiEr3uaeH/6sqvXfd3ZP31BiV8cyMUEEKjNL84j5NJizPqHQ5mWd/qnlW0/UiGkUfVqyQ4gv6Y5jVszLmB5qpmerbKd4LcnjkCH8zo6O8P2Nj5uqZZm1tbKRIjV4F0+fjduPjPL4gheJ4pZ478TsJBvmsCSl3UdevUCDxstn4NzYmvVqpFM/b3c3jV3MfRUmHlhaeS/SBKE9RLSzxGQsWZh4W0bJgwcKsoJRxXC4sZf58GhjVFswsZzhWKrBZijQcOgS89JI0FFeuZJvKGft6L0A0Chw4QAPqa1+jcdXWRrLz/vdz5VqoLCoK2/H661y9NzNm9CQvGqUhKIqqrlrF6xTGv75osl6RLRAgqQuHpfLY3Lk8xrZtUgggFuNKeikiZKY+JiS7w2FZnNbh4P9C1EB41VyuYsl/4z2aitBHpWOI+9zUREI5MkLDORzmfa3WU2NUxhMy1UYjVKjXGaX5FaX6ottm1zWZMMfpGswzUTPN4wF+8xu+r6vj83jzzfJ5MatnVU1+oBn05FBReCx9jlYpEqvvo74+fh6JyPtTV8fnxGbj9uJ4AD2/pcJQ9b8Tu13+rhIJSfZF7lmhwM8Bbut0yjqCLld193E6Xkj97/t0Fp+xYOFUhUW0LFiwcMJQbaheNQUzK3kCKhXYNCr9DQ8zXGnzZhrVHg/w8sskQcuXl85bEobKeecBO3ZwVd1mowE5OEjCEY9TxKKtjX0QiUj5ciH1XEkaWRhNV17Ja4vFgKeeojT0+DjDjMJhqdaoV2RTVZl0X1MjlQ8//GF6rzweSYyyWRLeUmFuwqDt65MG8tNPk8Dl8zQgxar8eefxeJ2drH30+OPFhEjvPahG6KPSfTY7RlOTvM+iSLWikGiuWmWuMmn22bp17EOhjAewP0vdt1tvnXicag3i6RKlmTCYqwkLM/aVOG9dHYt1x2LcJpGgAIzPR891qXpWRg/qZKAnhy5XcfkEM5QqqRAI8Pefz1P8AqD639AQ26+qwCOPlA9DNSN+Ph9/p0NDHA/sdv4lk3wV3rNcjtuvXEmPVDX3capeSLNFihOZD2jBwm8DLKJlwYKFE4LpGI+TNRyrKbBpVPrr7KRU8rPP0lA8dIhtttsZdmYWViiUt0ZGSDwcDhoqmQyNqVCIhtPICI3Nri5pkMbjNK5CIRmOZMwXEdDLTPf1kRi1tTHZPRrldYncDxG2qJddVhRZ6DSf5//19fL6vF4pR+52s34XUPp+3XYb8NBD3Ke2Fjh8mHkljY1SIa61lRLVikLD9/HHi4+lr6FVrdBHufssjiHCxUrJ8K9YQSPW45H3XpBIcc3GhYBkkm2tqZES2tEon61SRqjdPvHZrNYgni5RmikBjXIhmWZGeiAg8wPHxri/yBlMpUgyxPFK1bOaDDIZkjSRs1iNME2pPhJCPO9/PwVhwmESnnnz2H5F4bnWreNvsFIYqpH4ZTI8xqOPsn+iUZ7T7ebnQsLebgcuukgWGK/2Pk7WC2k2HpuNiTNVT8+Chd9WWETLggULJwTTMR4naziWKrBZW0uDXJzbTOmvtrZYATEYJJExCysUYXrBoBSBqKkhIVJVvgpi5fPRQM9meS5RqLhQoHGjl0sW+SIADbRnnqFBV1MjQ9dEOKOicBuA4YG1tdKAE4ZSIDCx0Gl7O0mgotAIttv53YUXAmecUTrvLBbjPonExO/q6kjgRI6dyMsxC5nT19AqJ/ThchUb06Xuc7ljmEliP/posZG5fj0/F7L4eqLm9UoJbUBKaF933eSN0GoM4ukSpZlQayxHVsp5EoWSpiAqisLnUSiMimuebvt27KAEurjnou5UtQs6xjaIkgptbdxWeIx7e2Vx4eZm/l9tGKreKyieXaG8KWpzLV9Oz/muXfx+8WLgAx+QbZ2ssJDwlMdipeuJAaXHY+OYaJEsCxamB4toWbBg4YRgOsbjVJUMxfYNDTRstm8nmQgGgQULipX+BEopIOrDChsauCotxCZE4dFoFDjzTK7m19TI8CWfj8d65x1ZI2jZMvaBzcbz/+xnE/NFjh0DnnsOeO01HqOhQea0xGJSIj6Z5GeKQm+O3c5tb7uNxpaqApdeSq9TPM5Cp2LlWiibRaPcZ82aiUqJ8TjDqJxOGp/XXFN8L0VOmAjNnDOnunpYog2lhD7efZeEyGhMG+/z+vUkbA0NPFc5sRBASoDrjcyhIb6WWggQHi998dpq6ymZPZ8iJ8bMmJ0JIjIdtcZKZKWcJ1H8Vj7/ee6zezePuXgxw29FO6bTvkyGJEssPgwMyLpT+nA7v5/vS4V4mhFwgG0JhSYWW161it6unh6SLn0Y6lTrUSkK8zNjMX5vFA2ZbD/pZeWHhznWtLdP9OqVG48tNUELFmYOFtGyYMFCScxkcdfpGo9TUTLUr0zX1JDUiBo2q1aVFp8wU0AUYYVGL044LEPLslkSsXPPBd73PuCXv6QXy+kE9uwhAaiv52fbtknPyOCgeb7IL3/J73w+Got79sjv83meZ98+fidyPg4coOGWSEgj88kn5Yr5ggVSMELkySxaJPNkAgEpWKFXSgS4at/TQ2PzmmsmhhjpxUbKeQ/MamgJoQ/x/ZVXAt/+trkxbSaYYLezfXY7CaU4h95TKPo1nZYhmB0dMj8P4P0DJi4EzGTdoGpC28xCz1R1cuc1GszV/p4reZ8reRKjUXqGPvOZ0gTCrH3VIhLhOWpqSKYKBX42NMSFkdra4kLDjY0y1LNUH4mSCnqYFenVK3qeey69T8K7XC2M1y2IXbXbl4KZrHwqRc+10as3E2TeggULlWERLQsWLJhiOqpnpTBdY3WyhqMIrYtGJ5d4b6aACJh7cbxe4I03SJ7OP59kKhAgedm6VXoF6uv52bXXAt/7njROhehGKCSNfBG2KHKYGhroGUgkKIF93XXcXlWBBx7gay4nhTf27CFRdLlIlLZv5zYAvWrPP88aOyKfpqmJ56yrIynVK6mtWSO9PYODMlRq5Urze1nq/pS69+KeBgLF3w8NFRvTAJ/Fo0fpQVAUaVgKL6MgTGvWyHaIEMG6OvYDwNpeHg+N0GRSGplAecNzJlb6J5OrKMIuZ+J3OJnfcyXvs95IL1d2oBKBqATx/BhD4OrqeNyBAS5uDA/Ts7thA4nPqlUMZRwbk7+xjRunJlOuD8fbsIG/+7PPZn/6/ZMnWdNFuTFPLyt/9CjHAxE27XBM9OpZRYctWJh9WETLggULEzCb9VRmKiylWsNxqon3ZgaN2Qqw10tDz+eTBU2jURqGeoW+8XEajL/6FQ3Fri6+xuPc/vrrZf6XyBcRohwNDTRmW1qK6wwJD1Q8znOPjfFzt1uqlg0NFauaCVGCI0fY1oEBGmNnncXvjTlKt93G9y+9RC+azcbXzZtpZE628Gm5e69/NvTGdD4vPVJPPy0VBQOBiWFikYgk2PrcMJdLCg4IT1YyScLZ2Cjv8XQNT30fme1frhaZCCnUqx1W+zucqZpx4j5U8naU80aWk1SfqRC4O++kIMvRo3wuzj6bv7MNG4CbbuK2+t9YpXzQau6byLk8dIj3KxIBLr+cizJmmMmIAH2flBrzxFh3+LBUMvV42E6329wTbIUJWrAwu7CIlgULFibgVK+nMhnDcSohMqUMGrMVYFWlR0jUzBEr+i4X++ojH6FXRSj0DQzQMC0UuI3Yvrt7ogdt1Sp6pEZHaTRee22xsaQo9G7t3SuT9f1+es6Ealljo5SAF/s0NAC/+AUFBWw2egWyWX5vvOdHjkiFNJuNZK+ri59FoyRuoh7SVAhCKbhcvLYf/IBEsFDgtbjdxSSwXJiYvpBtMMh22WzFtb30JEv0j7j+yRrK/f3ACy+wXU88wfBRY10wM2+RmSdRqB1W8zss9bwKUQQh3FCuZpyx1lylIsl6b1MoxGsuJbxgbKOxPp0R4vk5fFiG1Waz8vO1axm29+d/DvzXf0kRGkGsAblIUShwAWLOnPKFi/X37eqrJy7aRKNchOjpkUqdbrdccDBex3TroJmVGKj0mxJj3TPP8Nq9Xl6/eA6OHClNCi1YsDA7sIiWBQsWJmCm5KFnC9UUG65EkEpBqPwNDkpjbf165m0J4mbMr1i1SsqVG2tG+Xz0IOnbKhTYEomJxE+fL9LcLPPMxHdGdHQA99wjzy+8PeJ4q1fzPHpVs8suA775TRpgwSBJyrvvsu6VCDXS1xWLx0mwhodlgVWPB/ibv2E/KQrDJteunRxBKAVVZa7Zc8/RqK2tJTEKh2nctrbyeJmMDBPTh2Lqw8SWLSOhPHSI96KrS9b2Kke4J2soC0N4cJDvDxxgHp6xLpiR+Hd0sD9LqR2W+x0KA3r9em5TU0NjesMG9svTT8v7rij8Xp+Tphd30deaE3XeSgl+lPM2lSpSri9kXKk+XTJJ79TgoCxVkE7LGnDiOQqFmAtmXOSIxbjfvn0Mn2ttpZerHKkT9014xfQERhRYdrmkcigALFzI5874XKsqFzIOHOC5Sy00mBGqUs9dtb+p1lZ6vQsF9nEux8WFQqE0KbRgwcLswSJaFixYmIBTPVHazAA1MxyNRUQrGfn9/SRZr71GgyocpoEncpLMVoP7+2mECbnyK68ENm2SK89iRV7kSAljsJIHQEAv5lDK4O/oAD75SXMi2doK3H239D41Nko1RCOuvBLYsmViXTFjnlhzM/D22zRKbTZexxtvcJs775weUe/vJ3F49VUS1NpaeiSEwTg8zPcXXii9KSJMLBTidQqVOa+Xz8T4uDTWvV6SZjNxBgEz78EzzxSHbRohDOH6er6Pxdh+s7pgeuKvqsCDD5ZXOzT7HQqDXBAKh4PPmhBFee654ty8QoEhdiInzUzcZdcukplEgv24dy9JvJ5smQkuCG/T+vUyP07ft/pCxqXq0+lJTSbD+xyNyqK+isJjzJ1rnitmVAbcv5+krlDgc791KxcZSuU1ifsWCExUKRTbdHbKnDCXiwsQZrLub7xBIZtslsR3wYKJpMiMUDU1lfZaTeY35XLRK/fWW7zeYFAW6z5VohIsWPhtgUW0LFiwYIpTOVHazMAyGo7A5L0oGzYwtM/rJWET5MzhMF8NNhrkg4N8L0Qs9B6shgbpwVq1qphklQpRy+dpvArBikrCCaWu00jWVq1iTtb27WyTzUZZ+ubmYgKoqvRwCOl0kSe2ejXJqKLQw6SqNCoHBioThGruQU+PzJkZG6OxLMK17HaZW/b447yW+nqSDREi2dREo1JVSR70njshN17Os6D3Hoj+6+nh/zfcMJHoiuK1oZD0CAohBmNNL/0zEQiwr0UfAxMN6KYmemMASWD0z50gotks783oKPvI4ZiYm9fcLHPSAPNac/E4Canfz7asW0cSL/pLL7ggFCHzeZ7v9ddJLpuaihcEBEkQ9ekKBbZL1KcT/aInj2LholDguZ1Oeq/K5YoJyXyRlyhKF+iLJRt/I/q8JoDkJBAoVinUk5zWVva3w2Eu657JAD/6EfvQZuP17txJkQ69J9KMUN10U3mvVanflNn40d1Nj6EYO0So7KkSlWDBwm8LLKJlwYKFkjiVE6XNauBM1YuiqrK2UmMjDeTBQX5eW0uPidlqsFk4j74Qr74dgsDohQNqaxnatm1b8cp2Swv37emh8aqqNICbm6URWo2amz60TO/pe/ppfm+302j0+egB+O53acyuWkUjevNm9kskQmO6q4skq76e5xefqyrJREvL9OTQRX+KgrCpFP/yeRK6JUvYzkBAXsvGjfxceBV9Phq4GzeSFOlRKNAzJgo8A6U9C+JZEl6b+nr2iZHo6vd3OqVxX1/P/jUq8Yn7oheRGBri/opi7rUqF0YmcgFFeGl9PZ/h2lr2m8jNEyGYdXXm4i5z5/L7rVvZzmxW5j3pn3s96bDbpafqwAH2u88nC0DrvVuiVMCxY+wTgER/6VJJ6gX5qKuTuUWLF/MZFSFxpTyKAl4v+2XPHikO43DIYslGiNDf736X72tqeA59+KlxYWfFitI5ZpEIz9vQQLIlipJfeOFEsmokVED5MUxfsgIoJqfGZ0RRJtYBO5WiEixY+G2BRbQsWLBw2sJIBKfiRRGGysiIrK3U1sYV+0IBOOMMeTyjoVapEK++HS4X2/LTn0pj8uBB5g/V1U0MFbLZgFdekWFZg4NcdW9spHCCWW6L8bqEYdvbC8ybVxwi1tQkJbnTaZ7HZuP7HTtIcEQu0+goP+/s5LFHRnjuvj4phnHhhVy1n44cur4/RahTIMCQTaeT53K7eS01NTT0R0bYTzYbiWg+L+uHKQoN9e3beQ2CDP3jP9JoX7y4dKiWEBXo6SF5EaqMeg+D0TPR28vzAxRfUNXiml568qR/3jo6uK2xyHQ1YWR1ddJ7s2gRiVVHB8NAEwkS01yO/TYyQi9gqdzFnTuBN98kufR6Sabr6ycW8xW/M+FpEnXOxH1JJrlAEA6znSLX6/bb+TyOjrKdiiJJl5F8LFrE30c2Kwtgm5EsI9FYtkyGGiYSPNbSpcXFko0IheRvadkyPndGD2S1Cwd6tcxgUOaILVpk/pwDctyoxhMcDvN3LfI+k0mSO7Nw6VM5KsGChd8WWETLggULpz2Eh0CvlFZNkVejMStqK6XTNLiA8sIJpXLZShk4wpj0eBhGJQy62triWlHJJD0D0SgNtP5+tlFVeY7e3vLy3KpKYYPt22WRZn3RVYDnHB6mMRiJ0KBWVWkEi/576y2Z37NvH48H8LvLL6fh3NUFfOITEw3hqchbX3aZLBSt9xwAsvh0by//Hx5mv73zDu+ZEEwQBC0QAG6+mSTjl79kG+rqSFoffhj4sz8rHaolPCgA+194I/XqdXpy4Pez34S3bGyMz6Peq6N/3gIB3otQSBrhosi0y1VZ/ED/3C1dyu/TaRLU885jnmChQHW+RIJ/wrg35i66XCQG27ZJRclYjKTx0ksn3iNjMeVkUt6XsTHmduVyPNeuXTLXKxDgNn4//+JxElnhBdaTj1SKoW9mOV/CUyvywoS39sgRksXaWins0tbGnDwR3mn2HHq9fC7EPSjlDTdbODA+4y4X8xQfflgWbr7zzolqoaUIVTlypP9d2+302ikKr7VUuPSpHJVgwcJvAyyiZcGChdMaZqEzQHWKcUZj1lhbSWxTjihUKsSrh8slCxyLvKZsloZTOEzSM3euNMpEeF5nJ8lBczPbKOoClVJZjMWKc5NECF4sxuOL4r42Gz9zOmU44vg42+3x0IOWTpOoADyvCIkMBklqFIXHFgSh3H2p5IHTy39ff/3E0KxQqDgcqqOD7c5m2Uaxuj9nDr0ownD9wAeodOd289qcTikOYuZZcLl4XK8XuPhiGs1HjvD8y5aZS7ULItbczO/q69mWVGqiqILHw33SaRLVvj4SE+HZUtXK4gfG566/XypPPvqo9JT19/PZWrzY3BjfsYPXF4nws7PPZr5eXx+v+emni3Ou9MRCb8yvXClDTZ1OfmbM9frQh7i9yLsSpF0U+TYjH8YQ2f5+ko1du0gE83mq/4l8t8OHSRb1Hs9HH5VE0+w5FOGDwEQPJFB6waDUM37uucBXvsI+FTl6RpQjVKXIkf537fOR1CYSUgTlVFOHtWDBgkW0LFiwcBrDLLxq/Xp+V0p9UI9Sxqy+tlI1q8HVKhoKsY1YTCqi+f00skdGpBz8j3/MEDJRR2tkhAa8203jLRqlMVlKZVFA5LmI9q1dy8+efprGdy4n862EwTc2xj9VlSIHQhp8bIxE7cgRSYiCQaqq6Y27ydbRMgvBe+kl6cnSw0yxb9Ei9uvYGA3Ou+8uVsprbKTBOzAgBTZaWvi50bhftgx47LHi0KzaWvb3+Di9PkK9Tu+ZEPl94jno6+N5HntMyrs3NbHPXn6ZbXe7adgfOcLQxESC1yOM9kphZOK+CvnxwUHej6Ehnsfv5znDYSmTrjfGMxmSLBHmNjpKNcnaWuZcATLnSkjG6/MLjYsaoRBw440syv3yy/LZFrlew8Ns8/i49IZ5PKxd1dDA41Wq3bV+vVRTFKUG9uzh9kLiX3hkh4b4WS7He1Ou3l5zM48nVDMrya1XesZFzmI5TNfbZLPxvrW3SzVJKw/LgoVTC6cN0fq7v/s7PPPMM9i2bRtcLhdGReZoGRQKBdx333343ve+h0gkgksuuQTf/va3sWTJktlvsAULFmYdZuFVQ0N8rUZ98ETJ2JuFKMZiNOxsNmm4jY/TOO3r436NjdLwfPddrszv3Elj8qyzmJtU6jq7u+k5E9LmZ5/N4z3+OMna4sU0vufMYXidyyULK8diNFCFMlwuR9IQDNKLNjrKto+M0HuxalVpOW+Xi6/lFCAnW3dLTzAEUe7u5vXMncu8Oj2M4VwtLTKcS6/q5/WyAO727TzHnj3su6VLpUhCudydaBT49a/5eTrN++z1FhvhK1cyf8luJwETeWUuF9tvNNor1VEz9p/fz+djbIz3eXyc91qEouqfcUFEamokKYpGuZ/TOTEXbt06qUBptqjR20tp9VyO1y8EXIJBPgMvvyzFQoaH+X2hQC9UJMLP164tfZ2xGD2AgmAAUmExkeCzrBeXaWmR4aKV6u0JUiSUC8XCQSkydTKKugcCMucwlZJhgx//eHWlIixYsHDicdoQrUwmg49+9KNYsWIFvv/971e1zz/8wz/gX/7lX/DAAw9g0aJF+Nu//Vtce+212LNnD4JilLZgwcJpi1L1tAAafeKzcuE0JyJh3GgIezw0hBWFRmkiwe8dDl7LnDlyv0CA7XrrrWLPyu7dNKhLXafPJ41a8d5oHArVQZE/JOTn/X4avm2Zl10AACcPSURBVLEYiUgsJnNq3nqLx81mSQ7a2tgOfXiV10tDXeSS5PNSXc4M5cLkyuV56dXshoZIssxED1SVpOHee3m9ggAavRXz59NLmM3K82WzlUOzBPELBIBbb+Vnra28n0YjvKuLxnFfH0lIJMJXY0kAsX0sVjkE09h/wSD7X+T0CW+asR/1wg3ieevsBD79adbh0ufCmbXRuKiRz/Oe5/MyZy2XY7+uXMnyCx0d9IC+8op8vlMpHsdYv0oPIe7S28u+SCSkt/XCC4FbbpG5XIsXS4/Z449XX2/PZqN37dgxLkqsXFmaTE31mZ0OFIWLIqIIemMjn3eXq7IaowULFk4OThuidd999wEAHnjggaq2LxQK+Ld/+zf85V/+JW655RYAwA9+8AO0tLTg0UcfxWc+85nZaqoFCxZOEEp5pIDJealmO2HcmMuTSDDc54wz6KkaGKAhL0IDhaCCmehCIECjKhplHpNYmddfp8hbWrpUCnxkszxWubwf/Xfj48Wy9KoKPPAADfNUSuZ1BYNsy09/WlynazIwu4+rVtHzIIQxqsnzAqRQgjByzUK/zFT99u+nYEY8ToNb/NXVVReapTeuAVmcV9/PQs59ZITnER4mEZJnlitWTQimsf/mz6eQSHNzsZCE8AKK/inl6WtqmigNbtZG46LG4KAMi62pkblYV1/NY4vnKxjkb8DnY3tEzpxYVDDr2w0beJ7WVnr+RJhofb2UURf5XPrfs56Id3RIwmckT+JZfvVVPu/79sm8RbPFjFJjTzUFxqeD1laKe1hKghYsnB44bYjWZHHw4EH09/dj9erVxz9zu9248sor8dJLL5UkWul0Gul0+vj7Ma0QR6GQRaGQnd1Gn6IQ1/3bev2nM34b7l1LS7FHym7n58bPCoWT10a7nYbrxo0kUh0dUphBeD7mzqUxSCOY98tmy6JQ4DU0NtIL4nSSBLW38zN9gWFxnfrt3W4a9e3tPJ9oRzTKcLtVq2SfmX3ndPIvn5dejViMhm5HB/f59a9pZNfX8/X557n98uXFRC+ZpKcjm5WGqNPJc+vv49gYVfPefJMekQULeNwXXpAeI+GxeOEFGrf19cx1+s//ZDsbGylxvmkT962tZX+88ALw4Q9LdcXWVllHDOB2wsOiKMz/0odmmT1Lg4Oy3xoasvjwh4Frrsni+edlX+rb0tTEYzc18f45neZ9n8mwjSKPzunkvRT9qIfov54eeouef577rFolBTr07RTfnXMOhRv096NQKL4fQoHymmt4Dfo2AvK5bmvjq8g/czpJgn76U17rBRfwWRfbOhw8rniWfud3zPs3mZRhiKLEQTzOPqyv5/Mong3xLAvYbGyHy8XXUr8lVeVvzuHIwuvlMQ8eBD7zGRbnNv5ejH0kCOITTxT/Fkq1azqw2+X9P5nj2qmA34Y57r2K0/neTabNtkLh9PqZPvDAA/jCF75QMUfrpZdewsqVK9Hb24v29vbjn3/6059GT08PfvGLX5jud++99x73nunx6KOPwufzTavtFixYsGDBggULFixYOH2RSCSwdu1aRKNR1Ohj9E1wUj1apUiNHq+99hqWL18+5XPYhH6shkKhMOEzPf7iL/4CX/ziF4+/HxsbQ1dXF2y21bDZynfmexVk7hsAXAubzXmym2NhErDu3amLfF6uhA8NFXsarrkmi8bGifdNCFU8+yxX5OvrGYbW3i5XzfXHBSZ6+spBeDwiEXq/3v9+eh6M5wdkjlc+z1V8Y3uEB0fvPclmgb/7Ox7D7aa3oa0N+H//T3q2xsaAhx6iJ+zIESnM0Nwsc9fEuYaHub1Q2NuyhW0SEvduN7BkyUSVupoaenL6++lxaW3l//k883NyOfbZkiX0mnzkIww1M+vDeJyhd24325DJZLF27Qb09FyLLVucx69f9Eep+2a8B0NDMjdM79n67GeL74keBw8C//EfvI5AgF4kgPXAFKW4naJQ9Z13Su+IeHaERzESYb+43WyrWZuN918Usa6rY1+2tLDt4+O83/Pn8xyiD5qaWE7BWWF4Ev0ivJwiRLaujsfq7KSnUu95NN4b/TXrRS/4HGdhs23Al750LbJZJ/J5PiOf/GTl347+d1OpvyzMLKw57vTF6XzvbLaxqrc9qUTrc5/7HG6//fay23Sb6ftWgVYtKLq/vx9tullpcHAQLWU0V91uN9yiaIwONpvztHsQZhJUR/vt7oPTFda9OzWhzyNpaaExZgx1NN43ISk+NMR8ErdbynlXK5xgBpG3s24dc1PicRrbb7/NQrOiHpPZsUUOjviuuZnvW1uLrwkA7r+f5Mjh4Oc2G/PTIhH2gRA82LuXpKyrS+aWtbWxptWzz8prr6mh0e33ywK2djuNaRH+d/75NM5F7aFMhn8idC+ZpIGeyzHcbmyM+y9axH5NpYD//V8p0W4mROH3yzyq8XF+vmWLE4cOOdHQwFytXK5YHr25GXjf+4pzbVSVYXbbt/P+j46yjRdfTMKqqrxms7VCVQVefFH2QyTCe9nYyGLC11xT3E59vpHNJu/vyAjJksfDc/f2kih2dxc/a/raYPrnUfTpRz/K423ZInOo8nne7wsukM9uNDqxBpvxupJJXsett7IvNm9mexWFz2JrK0nR448XP59NTaWv2ZiXKX5zS5c6ceyY87jQRKUcKCE5L84hygcEAvK3YOVRzS6sOe70xel67ybT3pNKtBobG9EoqoLOMObNm4fW1lZs2LAB559/PgAqF27atAlf//rXZ+WcFixYsDBV6A2/cgHdpdTOqhVOMEIY2IcPU8kwl6PRWVMjC83edZf5sUV+WFNT5aLNsRgNbuFJcDikN6murljwYN48kq3+fuDSS4HLL5c1tfTX3ttLIuTx8POlSykuIqSvFy+mrP3y5cxdamykamI+z21EMWhRN+2OO2ThXVFs2CjRftttbD8ghSb0tbSEF4n5WsWCC6FQsRT8889PVI/buVPWnopGmX8mxBrKqWeKYy5axH47epTX2dnJftq4sZjo6YU99MIggQDPGQrR+xQISMl3IZCib0Op57GlhfftjTekcEUoxHPv2UPSK/q/1DWZkfv58/ks6HPH9OqCxme/mvINgsz5fMWLA9UQJGMpg7Y2Ptei6LlFsixY+O3GaSOGcfjwYYyMjODw4cNQVRXbtm0DACxYsAABbSY766yz8NWvfhUf+tCHYLPZ8IUvfAF///d/j4ULF2LhwoX4+7//e/h8PqzVV/S0YMGChdMIpdTOMpnJ1/XRG9jCeyNU4MbGpPhFJDLx2H19DPFLJKrznnm99Aq1t3PfZJIejbvuooEaixWfw+vlsW++WarJAcWkRhAhn4/hW4EAPR6RSDF50SvoLV3K42SzEw1vRZGG/NAQiw17vcXX/N3v0lMEkMjdfDOve9UqklIRWul0sk3ARE+K18uQNiF/v28fzxcI8LqEoInXy3am05XVM10u2Q+dnSRLgQANf0EG9ERPTyTE9x4Pn4V0muQsneY9sNkk0TMrmlyKzHR3U8r+pZfYtmyW98Vul6UEyqk4lls4EPfE7NkB5LNfqXyDIHPxOGXth4YqFxrWo1QpA4tkWbBgATiNiNaXv/xl/OAHPzj+XnipXnjhBVx11VUAgD179iAajR7f5v/+3/+LZDKJP/zDPzxesHj9+vVWDS0LFiyc1jAzHvXFe4HK9cMAaWAHgwzpamykgS48an4/yVFdXfGxhbx2Pl+990wY5KL9bjdwww0MDwQmekaEt8NIEsW164kQwPeHD9N7tWYNjXzRFmN/iWvX953+vaKwL+rri685GmUYoKrys+3bSSBuv52eosHBYrLZ0TGxSDBAYrBrlwxnHBsDtm6lumJDA+/F8DDvy/Ll9LR5vVJmvxRZGBpivyUSvDfiuMEgj20MmRPX7XKRhL38MsmVKDjc309iXF8vFRLNQvxKkRlFoZLg22+TpDocvN7zz+c16aXnjZhMQeByNa1EO8wWG/RkTty3jRvp1bJIkgULFmYCpw3ReuCBByrW0DIKKNpsNtx777249957Z69hFixYsHASYDQey3kWSkFvoNrt0gOQydC7sWiRrDulP3ZrK1fxa2ur954B5b0Lk2m/nggdOUKCMTLC9+EwPSjG9F5jf4n/y+WeGa8ZoOdDCNCmUpLc6AtSA/TefOQj0oOlJ3SCqAkUCvysvl7Knsdi9AatWcN9nnqqOMxQtEdPFkQh7PFxntPz/7d3r8FRVnccx/+bJdkkEJZLgA0YE2lrGMZSYiJNaBGFkYuVUpxSKEwmvCjTOuO09jIdqkOFF0y109rpDG1trYP2YqUjoNPCKOmYoCOhRUwsmqJYA4RLJISQC4EEktMXp0/29uw1z+bZJ/l+ZjJxN3s5z559xufHOed/snXQy8zUI26Bn2Xocc+ZI/L22/5pftnZOqxlZ+uw1dsbfS1VpDDj8+mQ19Ojj0tEv360kCUSOzyFvnei332R8I3ERfTnFet7HPoaZnvWJfIaAEYvxwQtAEB0saZJhQq8QHW79QW5cbH/hS+YjwoZxRb+/nfzjVyjCR05Gk77jbbv369HsqZM0WFBJL7QZ7Qn2vS0wPZkZekRtLNn/QUvjMAXOOJnVM/zeoPDRGCw8Xp1BcWTJ/3r1WbM8FdKzMvTz7txQ6/jamvT+3wZ0wx7e0U2b9aPCVwjZBTdMILc+PEiJSU6MAVOvww87rw8/VspXVDiyBH/+qnBQf1ebW36uxCrf82cOqXXZGVm6vYUFMQXRBINT4l+90WCw1xgvyVynIGvMXVq7HVnAMYWghaAtBTrohzmIo0sRBIaJozy2GafeVub/8I3M1Nf3EdaPxTaf5FGjuJpf6Tvgs+n13iJmK+HiiWe6WmB7Vm2TAePpiZ9e+5c/zowIxRcvar/FjiCFBro/vtfPXLk8chQGfFFi0QaG/XIXF+fDiU5ObqIx4cf6tGSiRN1yGtq0qHMCAWTJulAY5RQz831r6u6ciU8JF27pkuvt7XpaYoZGbqta9botrW36+B6/boOgQUF4SNisfrG+Ntbb+lgNTCgR4t6ekQqK+Prn2T+4SCR735gmDPrt0RfI5HRNABjA0ELQNqJ96Ic1ggtLmAmdBSko0OvQVq9OnwamFGm3ZjqtnSpXvuSaEVE47WifReysvRar2QudBOZniai33fz5uC9xET07cDKiyK6kIghdIpad7cOWvPn6/snTNChbe7c8CIcxpqp0OmGBuNC/+BBHZzGjdNVG8+c0WHr1lvDP4+sLH2sly/r8GYE56IiXc7fKOqRmanf++pV3X+hn31o3yxZ4g9/xmibUQnxk0/0cbvderQ03iCSaHhKVGCYEwnut2Reg38YAhCIoAUgrcSazgV7BI6CtLbq+1wuf/EIw8CAyMsvB1fU6+z0F84wLpovX/YHsUj9Guu7YIymRCovH0syoxFut38aXuDeUxMmiKxYodczhZbnDwx0/f3+TZynTNGjWoHrgsyKcGRm+jfbzc3VgSwwfPh8waXpW1t1gPJ6zffc6u/X73Hjhu6XKVP0T3+/Ds+bNumg9corenpopM8+sG8++kiXpjeKZxj7WBnHXVysj6WoSP93Oo1Yu906AEfbViGe12BNFoBQBC0AaSWRamMYOcYoiFGV8Pp1PSpjhAxDaEW97m4dtubN088V8e9/9eKLkTcCFon+XUh2c+ZQPp+uptfR4d8LKR5G0PjoI32MnZ16it93vmPejoUL/ftz5efrqYBXr5pXyAssYd/Xp8PP9ev6PSZPFlm1KjycGKXpCwt12f2bN/X7nDsX/g8VOTk6EBkbIHd26tuBbXC7zfcCM87DSKN0hYWR97EqLta3A6egxtt36RTMACBeGXY3AAACGf/6396uL6bb2/VtFpfbq79fX+RnZOiL+OxsHbhqaiJPawu0eLEOFNeumW8EbPYagd8FYwRs0qTgzZk9nuivEUtrq97s9q9/1b+N0bpYenr0urCuLn0848frdv7jH+Gv/8ILIgcO6NsPPKCn533605HXtxlT0dav1wGoqEgH1dJSHbq8Xn2sRmGSQP39eh1Zfr4ORFOn+gOSwQhzhYW6D82mF8Y6DwP/3tGhQ9nEifo7EvieRpD92tf072nTEu874zPctUv/jrePAMBujGgBSCssLk8fgaMIOTn6IvnkSX0BPzio7+vpCR5tNNYbvfuuDiBut749e7b+MdsIONKIpdut1zG9954uCuH16tGcZDZnjnR88U5TDfws2tr0mqjmZn08kyfr8Dlxon/9ltnrnzunS89v2BB7qqNR0dDjCd8Mt7NTZN8+8xGheNedxVpXFOs8DB15izRKF7qOa+HCxPqOqcQAnIygBSDtsLjcfmZFKFas0NPjLl3SoScvT0/9C7yId7tFvvIVPW0wcN8now9D1yBFK0AxMKAr8Xm9evSlq0vfLilJfHNms6ln8U5TDS3N3turR3Fmz9a/Ozp0Zb68PB26DLFeP5mpsIODuuR7pLVToQFp1iwdbpIR6zwM/Htnpy6YERjKRMJD0ltv6c8w3q0BrJhKzLRDAHYhaAFISywut48xitDSokdpWlr8F/OBVemM9VVmF+AbNw5/Y2LjItuYBpeVpW/39yc26hmpOl5WVuzAFjqicvq0HtGaO1d/NmVlIh9/rAPNjBn6tQ2JVjU0O/7QzXB7e/XvaMHDCECnTulgc+BA+MjXcMrth/7dOJ5164K3BzDKywe2tbNT5P779chePH033M+QCqYA7ETQAgAEuXZN5Px5PSJ18aJ/n6Vr1/xV6WKNEES7QI93xDLaRfaECcGvIaIv7ENfL1Z1vPnz9ePMLvoHBvRncPmyPywMDuqg1damP5e+PpEFC/xl7jMy/NXrhjsN1mwz3Fmz9N/iGRE6fNh85EvEuul4ZkHG6PdI/VdcrH8S2Zg6mc+QaYcA7EbQAgAEycrS4SJ0nyWjIp8Vo43xvIbZRfaSJcEX6BMmRB+1iFUdTyR8JEYkuHT7+fN6RGnWLB125s7VUyM7O/0X/kbJ99AS4cOZBhspZIjEnhoYbcqd8d+pXuMWKyTF+17JfoZUMAVgN4IWACBIf7++OA3cZ2nqVH1/vOXPrRJpHZARqAKr2Jld7Efaw8oo5W5MRQy88A4NEMa0vWvX/GFh2rT4L/wjhUqjcqBI+KbPZscf+F6xpgbGmnI3nOl4hniCjFXrLZMJ98OddggAw0V5dwBAkJwcXdxh2jRdhjw/X9+26wLVCEyvvx5eFjx0HVBoOXNjVOWWW3Swyc/XRSuM6nhmWweEBohZs/RUw/XrdWjw+fwX/skGh9ZWkWeeEdm6Vf8880zksuWR3suYGmhWJj3wuEPLyEf7WyLi3YphuJ9Vsqw6TgBIFiNaAIAgoVO+Cgvtv0CNNHoiEnvUIlZ1vNDjijQSkp9vzWcwMKDLw7/7rj8Yvfuuno64cWN87zHc0SQrRpqcsBUDFUwB2ImgBQAIk24XqKHh59IlXeUvJye+i31jVCW0iEakPaxSGSCuXdPtz8jQ4UpET028dCm+9UMDA/onnjLp0abcWbHWLt2+J2aoYArALgQtAIApswtUu/YkCgw/Fy7okSm3W2T3bn1/Ihf78Vx4pzJA5OTo0bGTJ3VxDqVExo3T98WanhlY+CMzU681s3taXOjnyb5VAKARtAAAcbF7TyKfT1cI/OMfRW7e1CEjsPiF1aMWqRoJcbv1Js69vSJNTfq+uXODN3Y2E1qko71drx8zSsunQ6ix+zsCAOmEoAUAiCld9iTq79cBxdjEWMSZJbt9PpHNm2NXHQxkti7LGNlLh5CVLt8RAEgXBC0AQEzpsifRaCrZ7Xb799+KR7ofe7p8RwAgXVDeHQAQU7ylvFNtLJfsHuljN/b5MiojxpIu3xEASBeMaAEAYkqnUt5OqHSXKiN17MmstUqn7wgApAOCFgAgLukUcMZyye5UH/tw1lql03cEAOxG0AIAxG0sB5zRJFoJ9uGuteI7AgAaQQsAAAdLdN+qWNMC073oBgA4BcUwAABwqNZWkRdeENm1S/9ubY3++MBpgR6Pf1pgYMGLsVxwBACsxIgWAAAOlMxaqninBbLWCgCGj6AFAIADJbOWKpFpgay1AoDhYeogAAAOlMy+VUwLBICRw4gWAAAOlOy+VUwLBICRQdACAMChkg1NTAsEgNQjaAEA4GCEJgBIT6zRAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAYJQYG9ObFAwN2twQAQHl3AABGgdZW/+bFkybpzYt9PrtbBQBjFyNaAAA43MCADllnz4p4PPp3TQ0jWwBgJ0a0AABwuGvX9EjW1Kn+zYuvXNH3s5kxANiDES0AABwuJ0dPF2xv12u02tv17Zwcu1sGAGMXQQsAAIdzu/WarFtuEenr07/vu0/fDwCwB1MHAQAYBXw+kQ0b9HTBnBxCFgDYjaAFAMAo4XazJgsA0gVTBwEAAADAYgQtAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAizkmaO3YsUMWLlwoubm5MmnSpLies2nTJnG5XEE/FRUVqW0oAAAAgDHPMUGrv79f1q5dKw899FBCz1uxYoVcuHBh6OfAgQMpaiEAAAAAaOPsbkC8tm/fLiIizz33XELP83g84vP5UtAiAAAAADDnmBGtZNXV1cn06dPl9ttvl82bN8vFixftbhIAAACAUc4xI1rJWLlypaxdu1aKioqkublZtm7dKkuWLJFjx46Jx+MxfU5fX5/09fUN3e7q6hIREaVuiFI3RqTd6cY47rF6/E5G3zkT/eZc9J0z0W/ORL85l5P7LpE22xq0tm3bNjQlMJKjR49KeXl5Uq+/bt26of++4447pLy8XIqKimT//v3y4IMPmj7nJz/5iWmblDooSuUm1Y7Ro0aUsrsNSA5950z0m3PRd85EvzkT/eZczus7pXrjfqytQevhhx+W9evXR31McXGxZe9XUFAgRUVFcvLkyYiP+dGPfiTf+973hm53dXVJYWGhuFzLxOWaaFlbnEQn9xoRuU9crky7m4ME0HfORL85F33nTPSbM9FvzuXkvnO5uuJ+rK1BKz8/X/Lz80fs/drb26WlpUUKCgoiPsbj8ZhOK3S5Mh33RbCSUnwGTkXfORP95lz0nTPRb85EvzmXU/sukfY6phjGmTNnpLGxUc6cOSMDAwPS2NgojY2N0tPTM/SYOXPmyL59+0REpKenR37wgx9IfX29nDp1Surq6mTVqlWSn58va9asseswAAAAAIwBjimG8eMf/1ief/75odulpaUiIlJbWyv33HOPiIh88MEH0tnZKSIibrdbjh8/Ln/4wx/kypUrUlBQIPfee6/s3r1b8vLyRrz9AAAAAMYOxwSt5557LuYeWipgNV1OTo689tprKW4VAAAAAIRzzNRBAAAAAHAKghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWGyc3Q1Id0opERHp7e2yuSX2UeqGKNUrLleXuFyZdjcHCaDvnIl+cy76zpnoN2ei35zLyX1nZAIjI0TjUvE8agw7e/asFBYW2t0MAAAAAGmipaVFbrnllqiPIWjFMDg4KOfPn5e8vDxxuVx2N8cWXV1dUlhYKC0tLTJx4kS7m4ME0HfORL85F33nTPSbM9FvzuXkvlNKSXd3t8ycOVMyMqKvwmLqYAwZGRkx0+pYMXHiRMedDNDoO2ei35yLvnMm+s2Z6Dfncmrfeb3euB5HMQwAAAAAsBhBCwAAAAAsRtBCTB6PRx5//HHxeDx2NwUJou+ciX5zLvrOmeg3Z6LfnGus9B3FMAAAAADAYoxoAQAAAIDFCFoAAAAAYDGCFgAAAABYjKAFAAAAABYjaMHUjh07ZOHChZKbmyuTJk2K6zmbNm0Sl8sV9FNRUZHahiJIMv2mlJJt27bJzJkzJScnR+655x55//33U9tQhOno6JCqqirxer3i9XqlqqpKrly5EvU5nHMj79e//rXcdtttkp2dLWVlZfLmm29GffyhQ4ekrKxMsrOzZfbs2fL000+PUEsRKpG+q6urCzu3XC6XnDhxYgRbjDfeeENWrVolM2fOFJfLJS+//HLM53DO2S/RfhvN5xtBC6b6+/tl7dq18tBDDyX0vBUrVsiFCxeGfg4cOJCiFsJMMv3205/+VJ566inZuXOnHD16VHw+n9x3333S3d2dwpYi1IYNG6SxsVFeffVVefXVV6WxsVGqqqpiPo9zbuTs3r1bHnnkEXnsscekoaFBFi1aJCtXrpQzZ86YPr65uVnuv/9+WbRokTQ0NMijjz4q3/72t2XPnj0j3HIk2neGDz74IOj8+sxnPjNCLYaIyNWrV+Vzn/uc7Ny5M67Hc86lh0T7zTAqzzcFRLFr1y7l9Xrjemx1dbVavXp1StuD+MTbb4ODg8rn86knnnhi6L7r168rr9ernn766RS2EIGampqUiKgjR44M3VdfX69ERJ04cSLi8zjnRtaCBQvUt771raD75syZo7Zs2WL6+B/+8Idqzpw5Qfd985vfVBUVFSlrI8wl2ne1tbVKRFRHR8cItA7xEBG1b9++qI/hnEs/8fTbaD7fGNGCperq6mT69Oly++23y+bNm+XixYt2NwlRNDc3S2trqyxbtmzoPo/HI4sXL5bDhw/b2LKxpb6+Xrxer3z+858fuq+iokK8Xm/MfuCcGxn9/f1y7NixoHNFRGTZsmUR+6i+vj7s8cuXL5e3335bbty4kbK2IlgyfWcoLS2VgoICWbp0qdTW1qaymbAA55yzjcbzjaAFy6xcuVL+/Oc/y+uvvy4///nP5ejRo7JkyRLp6+uzu2mIoLW1VUREZsyYEXT/jBkzhv6G1GttbZXp06eH3T99+vSo/cA5N3IuXbokAwMDCZ0rra2tpo+/efOmXLp0KWVtRbBk+q6goEB+97vfyZ49e2Tv3r1SUlIiS5culTfeeGMkmowkcc4502g+38bZ3QCMnG3btsn27dujPubo0aNSXl6e1OuvW7du6L/vuOMOKS8vl6KiItm/f788+OCDSb0mUt9vIiIulyvotlIq7D4kLt6+EwnvA5HY/cA5N/ISPVfMHm92P1Ivkb4rKSmRkpKSoduVlZXS0tIiP/vZz+Tuu+9OaTsxPJxzzjOazzeC1hjy8MMPy/r166M+pri42LL3KygokKKiIjl58qRlrzkWpbLffD6fiOh/BSwoKBi6/+LFi2H/KojExdt3//73v+WTTz4J+1tbW1tC/cA5lzr5+fnidrvDRkCinSs+n8/08ePGjZOpU6emrK0IlkzfmamoqJA//elPVjcPFuKcGz1Gy/lG0BpD8vPzJT8/f8Ter729XVpaWoIu4JG4VPbbbbfdJj6fT2pqaqS0tFRE9HqGQ4cOyZNPPpmS9xxL4u27yspK6ezslH/961+yYMECERH55z//KZ2dnbJw4cK4349zLnWysrKkrKxMampqZM2aNUP319TUyOrVq02fU1lZKX/729+C7jt48KCUl5dLZmZmStsLv2T6zkxDQwPnVprjnBs9Rs35ZmclDqSv06dPq4aGBrV9+3Y1YcIE1dDQoBoaGlR3d/fQY0pKStTevXuVUkp1d3er73//++rw4cOqublZ1dbWqsrKSjVr1izV1dVl12GMOYn2m1JKPfHEE8rr9aq9e/eq48ePq69//euqoKCAfhthK1asUPPmzVP19fWqvr5effazn1UPPPBA0GM45+z14osvqszMTPXss8+qpqYm9cgjj6jx48erU6dOKaWU2rJli6qqqhp6/Mcff6xyc3PVd7/7XdXU1KSeffZZlZmZqV566SW7DmHMSrTvfvGLX6h9+/apDz/8UL333ntqy5YtSkTUnj177DqEMam7u3vo/2Miop566inV0NCgTp8+rZTinEtXifbbaD7fCFowVV1drUQk7Ke2tnboMSKidu3apZRSqre3Vy1btkxNmzZNZWZmqltvvVVVV1erM2fO2HMAY1Si/aaULvH++OOPK5/Ppzwej7r77rvV8ePHR77xY1x7e7vauHGjysvLU3l5eWrjxo1hpW455+z3q1/9ShUVFamsrCx15513qkOHDg39rbq6Wi1evDjo8XV1daq0tFRlZWWp4uJi9Zvf/GaEWwxDIn335JNPqk996lMqOztbTZ48WX3xi19U+/fvt6HVY5tR9jv0p7q6WinFOZeuEu230Xy+uZT6/ypBAAAAAIAlKO8OAAAAABYjaAEAAACAxQhaAAAAAGAxghYAAAAAWIygBQAAAAAWI2gBAAAAgMUIWgAAAABgMYIWAAAAAFiMoAUAAAAAFiNoAQAQ4i9/+YtkZ2fLuXPnhu77xje+IfPmzZPOzk4bWwYAcAqXUkrZ3QgAANKJUkrmz58vixYtkp07d8r27dvl97//vRw5ckRmzZpld/MAAA4wzu4GAACQblwul+zYsUO++tWvysyZM+WXv/ylvPnmm0Mha82aNVJXVydLly6Vl156yebWAgDSESNaAABEcOedd8r7778vBw8elMWLFw/dX1tbKz09PfL8888TtAAAplijBQCAiddee01OnDghAwMDMmPGjKC/3XvvvZKXl2dTywAATkDQAgAgxDvvvCNr166V3/72t7J8+XLZunWr3U0CADgMa7QAAAhw6tQp+dKXviRbtmyRqqoqmTt3rtx1111y7NgxKSsrs7t5AACHYEQLAID/u3z5sqxcuVK+/OUvy6OPPioiImVlZbJq1Sp57LHHbG4dAMBJGNECAOD/pkyZIv/5z3/C7n/llVdsaA0AwMmoOggAQIKWL18u77zzjly9elWmTJki+/btk7vuusvuZgEA0ghBCwAAAAAsxhotAAAAALAYQQsAAAAALEbQAgAAAACLEbQAAAAAwGIELQAAAACwGEELAAAAACxG0AIAAAAAixG0AAAAAMBiBC0AAAAAsBhBCwAAAAAsRtACAAAAAIsRtAAAAADAYv8DWHL1FPsioOMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# For the sake of transparency, I did not know how to plot the decision boundary here. I used a bunch of online resources and this is what I got.\n",
    "\n",
    "def plot_classes_with_circle_boundary(X, y, best_theta):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    plt.scatter(X[y == 0][:, 1], X[y == 0][:, 2], s=8, alpha=0.5, color='blue', label='Class 0')\n",
    "    plt.scatter(X[y == 1][:, 1], X[y == 1][:, 2], s=8, alpha=0.5, color='orange', label='Class 1')\n",
    "\n",
    "    theta_0 = best_theta[0]\n",
    "    theta_1 = best_theta[1]\n",
    "    theta_2 = best_theta[2]\n",
    "    theta_3 = best_theta[3]\n",
    "    theta_4 = best_theta[4]\n",
    "\n",
    "    h = -theta_1 / (2 * theta_3)\n",
    "    k = -theta_2 / (2 * theta_4)\n",
    "\n",
    "    radius_squared = (h**2 + k**2 - theta_0 / theta_3)\n",
    "    radius = np.sqrt(radius_squared)\n",
    "\n",
    "    circle = plt.Circle((h, k), radius, color='black', fill=False, linestyle='--', linewidth=1)\n",
    "    plt.gca().add_artist(circle)\n",
    "\n",
    "    x_min, x_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    y_min, y_max = X[:, 2].min() - 0.5, X[:, 2].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    Z = ((xx - h)**2 + (yy - k)**2) - radius**2\n",
    "    Z = np.where(Z <= 0, 1, 0) \n",
    "\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, levels=[-0.5, 0.5, 1.5], colors=['blue', 'orange'])\n",
    "\n",
    "    plt.xlim(x_min, x_max)\n",
    "    plt.ylim(y_min, y_max)\n",
    "    plt.ylabel(r'$x_2$')\n",
    "    plt.xlabel(r'$x_1$')\n",
    "    plt.title('Logistic Regression Decision Boundary with Circular Shape')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "plot_classes_with_circle_boundary(X_test, y_test, best_theta)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
